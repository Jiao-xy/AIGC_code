import random
import jieba
import re
from sentence_transformers import SentenceTransformer, util

# 1. âœ… é€‰æ‹©æ›´é€‚åˆä¸­æ–‡çš„ Sentence Transformer æ¨¡å‹
model = SentenceTransformer("shibing624/text2vec-base-chinese")  # ä¸­æ–‡ç›¸ä¼¼åº¦æ¨¡å‹

# 2. âœ… å®šä¹‰åŸå§‹ä¸­æ–‡æ–‡æœ¬
original_text = """ç”·å­éª‘æ— ç‰ŒåŠ©åŠ›è½¦è¢«æ‹¦æ’ä¼¤äº¤è­¦(å›¾)
æ˜¨å¤©ä¸­åˆ12ç‚¹å¤šï¼Œè®°è€…åœ¨å—äº¬æ–°è¡—å£æ´ªæ­¦è·¯å£ç­‰çº¢ç¯æ—¶ï¼Œç›®ç¹äº†ä¸€åéª‘æ— ç‰ŒåŠ©åŠ›è½¦çš„ç”·å­ä¸ºäº†èº²é¿äº¤è­¦æ‰§æ³•ï¼Œç«Ÿç„¶å°†äº¤è­¦æ’å€’çš„å…¨è¿‡ç¨‹ã€‚è®°è€…éšåä»è­¦æ–¹äº†è§£åˆ°ï¼Œå½“å¤©åœ¨æ–°è¡—å£åœ°åŒºï¼Œæœ‰ä¸¤åäº¤è­¦åœ¨å¯¹æ— ç‰ŒåŠ©åŠ›è½¦è¿›è¡Œæ£€æŸ¥æ—¶è¢«æ’ä¼¤ï¼Œæ‰€å¹¸ä¼¤åŠ¿å¹¶ä¸ä¸¥é‡ã€‚
"""

# 3. âœ… **æŒ‰å­—æ‰“ä¹±ï¼ˆä¿ç•™æ ‡ç‚¹ï¼‰**
def shuffle_by_char(text):
    chars = list(re.sub(r"\s+", "", text))  # å»é™¤å¤šä½™ç©ºæ ¼
    random.shuffle(chars)
    return "".join(chars)

shuffled_text_by_char = shuffle_by_char(original_text)

# 4. âœ… **æŒ‰è¯æ‰“ä¹±ï¼ˆä¿æŒç©ºæ ¼ï¼‰**
def shuffle_by_word(text):
    words = list(jieba.cut(text))  # ç»“å·´åˆ†è¯
    random.shuffle(words)           # æ‰“ä¹±è¯åº
    return " ".join(words)          # é‡æ–°æ‹¼æ¥ï¼ˆç¡®ä¿å•è¯é—´æœ‰ç©ºæ ¼ï¼‰

shuffled_text_by_word = shuffle_by_word(original_text)

# 5. âœ… **è®¡ç®—æ–‡æœ¬åµŒå…¥**
embedding_original = model.encode(original_text, convert_to_tensor=True)
embedding_char_shuffled = model.encode(shuffled_text_by_char, convert_to_tensor=True)
embedding_word_shuffled = model.encode(shuffled_text_by_word, convert_to_tensor=True)

# 6. âœ… **è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦**
similarity_char = util.pytorch_cos_sim(embedding_original, embedding_char_shuffled).item()
similarity_word = util.pytorch_cos_sim(embedding_original, embedding_word_shuffled).item()

# 7. âœ… **è¾“å‡ºç»“æœ**
print(f"ğŸ”¹ åŸå§‹æ–‡æœ¬: {original_text}")

print(f"\nğŸ”¸ æŒ‰å­—æ‰“ä¹±: {shuffled_text_by_char}")
print(f"â¡ æŒ‰å­—æ‰“ä¹±ç›¸ä¼¼åº¦: {similarity_char:.4f}")

print(f"\nğŸ”¸ æŒ‰è¯æ‰“ä¹±: {shuffled_text_by_word}")
print(f"â¡ æŒ‰è¯æ‰“ä¹±ç›¸ä¼¼åº¦: {similarity_word:.4f}")
