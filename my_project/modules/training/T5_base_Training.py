# python -m modules.training.T5_base_Training.py
# modules/training/t5_base_training.py
# ä½¿ç”¨ t5-base æ¨¡å‹åŸ¹è®­æ‰“ä¹±æ–‡æœ¬æ¢å¤ä»»åŠ¡ï¼Œé€éšè¿›åº¦ä¿å­˜æ¨¡å‹

import os
import json
from tqdm import tqdm
from transformers import Trainer, TrainingArguments, T5Tokenizer, T5ForConditionalGeneration
from datasets import Dataset

from modules.utils.jsonl_handler import read_jsonl
from modules.models.manager import ModelManager

# ã€åŸºæœ¬è®¾ç½®ã€‘
model_name = "t5-base"
dataset_path = "data/train_pairs/grouped_shuffle_all.jsonl"
output_dir = "models"
version_name = "t5-base_reorder"

# ã€åŠ è½½ Tokenizer å’Œæ¨¡å‹ï¼ˆä½¿ç”¨ ModelManager é˜²æ­¢é‡å¤åŠ è½½ï¼‰ã€‘
if ModelManager.is_model_loaded(model_name):
    model, tokenizer = ModelManager.get_model(model_name)
else:
    tokenizer = T5Tokenizer.from_pretrained(model_name)
    model = T5ForConditionalGeneration.from_pretrained(model_name)
    ModelManager.register_model(model_name, model, tokenizer)

# ã€è¯»å–æ•°æ®ï¼Œè¿›è¡Œé¢„å¤„ç†ã€‘
data = read_jsonl(dataset_path)
dataset = Dataset.from_list(data)

def preprocess_function(examples):
    inputs = ["reorder: " + s for s in examples["shuffled"]]
    targets = examples["original"]
    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding="max_length")
    labels = tokenizer(targets, max_length=128, truncation=True, padding="max_length")
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

dataset = dataset.map(preprocess_function, batched=True)
dataset = dataset.train_test_split(test_size=0.2, seed=42)
train_dataset = dataset["train"]
eval_dataset = dataset["test"]

print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå…± {len(train_dataset)} æ¡è®­ç»ƒæ•°æ®ï¼Œ{len(eval_dataset)} æ¡éªŒè¯æ•°æ®")

# ã€è®¾ç½®åŸ¹è®­å‚æ•°ã€‘
training_args = TrainingArguments(
    output_dir=os.path.join(output_dir, version_name),
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=4,
    fp16=True,
    num_train_epochs=10,
    save_total_limit=3,
    eval_strategy="epoch",
    save_strategy="epoch",
    logging_steps=500,
    eval_steps=2000,
    report_to="none",
    dataloader_pin_memory=True,
    dataloader_num_workers=1,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
)

# ã€é€’å¢è¿›åº¦ä¿å­˜æ¨¡å‹ + åˆ†æ®µè¯„ä¼°ã€‘
epochs = training_args.num_train_epochs
eval_results = {}
save_ratios = [i / 10 for i in range(1, 11)]  # 10%ä¸ºå•ä½

for epoch in tqdm(range(epochs), desc=f"Training {version_name}"):
    trainer.train()
    for progress in save_ratios:
        if epoch == int(epochs * progress) - 1:
            tag = f"{int(progress * 100)}"
            save_path = os.path.join(output_dir, f"{version_name}_{tag}")
            model.save_pretrained(save_path)
            tokenizer.save_pretrained(save_path)
            print(f"âœ… {tag}% è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜è‡³ {save_path}")
            eval_metrics = trainer.evaluate()
            eval_results[tag] = eval_metrics
            print(f"ğŸ“Š {tag}% è¯„ä¼°ç»“æœ: {eval_metrics}")

# ã€æœ€ç»ˆä¿å­˜å®Œæ¨¡å‹ + è¯„ä¼°ç»“æœã€‘
save_path_final = os.path.join(output_dir, f"{version_name}_100")
model.save_pretrained(save_path_final)
tokenizer.save_pretrained(save_path_final)
eval_metrics = trainer.evaluate()
eval_results["100"] = eval_metrics
print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæ¨¡å‹ä¿å­˜è‡³ {save_path_final}")
print(f"ğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœ: {eval_metrics}")

# ã€ä¿å­˜è¯„ä¼°ç»“æœä¸º JSONã€‘
eval_results_path = os.path.join(output_dir, f"{version_name}_eval_results.json")
with open(eval_results_path, "w") as f:
    json.dump(eval_results, f, indent=4)
print(f"ğŸ“ æ‰€æœ‰é˜¶æ®µè¯„ä¼°ç»“æœå·²ä¿å­˜è‡³ {eval_results_path}")
