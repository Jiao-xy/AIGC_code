import ollama
import re
import spacy
from collections import Counter
from difflib import SequenceMatcher

# åŠ è½½ spaCy è‹±è¯­æ¨¡å‹ï¼ˆç”¨äºè¯­æ³•åˆ†æï¼‰
nlp = spacy.load("en_core_web_sm")

# éœ€è¦é‡ç»„çš„æ–‡æœ¬
input_text = "storages, problems low-density message belief-propagation pre-processing for flash To solve the with a algorithm codes is NAND (LDPC) parity-check the decoding binary of for proposed. data (VNBP-MP) reliability variable-node-based"

# è®¡ç®—åŸå§‹æ–‡æœ¬çš„å•è¯æ•°
def word_count(text):
    return len(text.split())

original_word_count = word_count(input_text)

# æ”¹è¿›åçš„ Promptï¼Œç¡®ä¿ä¸æ”¹å˜é•¿åº¦ï¼Œä¸å¢åŠ æˆ–åˆ é™¤å•è¯
prompt = f"Reorganize the following text while keeping the original sentence length and structure intact. Do not add or remove words excessively. Maintain all technical terms and logical flow exactly as in the original. Only adjust word order for better readability.: {input_text}"

# ä½¿ç”¨ System Prompt ç¦æ­¢ DeepSeek è§£é‡Š
messages = [
    {"role": "system", "content": "You must only return the reorganized text. Do not explain, do not analyze, do not add extra words."},
    {"role": "user", "content": prompt}
]

# ç›®æ ‡ï¼šè‡³å°‘æ”¶é›† 10 ä¸ªç¬¦åˆæ‰€æœ‰è¦æ±‚çš„å¥å­
num_target_sentences = 10
collected_sentences = []
number=0
while len(collected_sentences) < num_target_sentences:
    response = ollama.chat(model='deepseek-r1:7b', messages=messages)
    generated_text = response['message']['content']

    number+=1
    print(f"ç¬¬{number}æ¬¡å¾ªç¯")
    # å»æ‰ <think>...</think> ä¹‹é—´çš„å†…å®¹
    cleaned_text = re.sub(r'<think>.*?</think>', '', generated_text, flags=re.DOTALL).strip()
    
    # ä»…ä¿ç•™å•è¡Œæ–‡æœ¬
    cleaned_text = cleaned_text.replace("\n", " ").strip()
    
    # **1ï¸âƒ£ åœ¨ç”Ÿæˆæ—¶æ£€æµ‹å­—æ•°æ˜¯å¦ç¬¦åˆè¦æ±‚**
    word_diff = word_count(cleaned_text) - original_word_count
    if not (-5 <= word_diff <= 10):  # å…è®¸å•è¯æ•°å˜åŒ–èŒƒå›´ï¼š-5 åˆ° +10
        print("å­—æ•°ä¸ç¬¦åˆ")
        continue
    
    # **2ï¸âƒ£ è¯­æ³•å®Œæ•´æ€§æ£€æµ‹**
    def is_valid_sentence(sentence):
        """ä½¿ç”¨ spaCy æ£€æµ‹å¥å­æ˜¯å¦è¯­æ³•å®Œæ•´"""
        doc = nlp(sentence)
        
        # å¦‚æœå¥å­å¤ªçŸ­æˆ–è€…ä¸æ˜¯å®Œæ•´çš„ä¸»è°“ç»“æ„ï¼Œåˆ™å‰”é™¤
        if len(doc) < 5 or not any(token.dep_ == "ROOT" for token in doc):
            return False
        
        # è®¡ç®—å•è¯é¢‘ç‡ï¼Œé¿å…æ— æ„ä¹‰é‡å¤
        word_freq = Counter(word.text.lower() for word in doc if word.is_alpha)
        if max(word_freq.values()) > len(doc) * 0.5:  # å¦‚æœæŸä¸ªå•è¯å æ¯”è¶…è¿‡ 50%ï¼Œå¯èƒ½æ˜¯æ— æ„ä¹‰çš„å¥å­
            return False

        return True
    
    if not is_valid_sentence(cleaned_text):
        print("è¯­æ³•ä¸å®Œæ•´")
        continue  # è¯­æ³•ä¸å®Œæ•´ï¼Œè·³è¿‡
    
    # **3ï¸âƒ£ å¯è¯»æ€§è¯„ä¼°**
    def readability_score(sentence):
        """æ ¹æ®å¥å­ç»“æ„è¯„åˆ†ï¼ˆæ›´ç®€æ´ã€æ›´æœ‰é€»è¾‘çš„å¥å­å¾—åˆ†æ›´é«˜ï¼‰"""
        doc = nlp(sentence)
        avg_word_length = sum(len(token.text) for token in doc) / len(doc)
        num_commas = sum(1 for token in doc if token.text == ',')
        return 1.0 - (num_commas / len(doc)) - (avg_word_length / 10)  # é€‚å½“å¹³è¡¡æ ‡ç‚¹å’Œå•è¯é•¿åº¦
    
    read_score = readability_score(cleaned_text)
    
    if read_score < 0.5:  # å¦‚æœå¯è¯»æ€§å¤ªå·®ï¼Œè·³è¿‡
        print("å¯è¯»æ€§å¤ªå·®")
        continue

    # **4ï¸âƒ£ é€šè¿‡æ‰€æœ‰ç­›é€‰ï¼ŒåŠ å…¥å€™é€‰é›†**
    collected_sentences.append((cleaned_text, read_score))

# ================= é€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„å‰ 3 ä¸ªå¥å­ =================
def sentence_similarity(s1, s2):
    """è®¡ç®—ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼åº¦"""
    return SequenceMatcher(None, s1, s2).ratio()

# æŒ‰å¯è¯»æ€§ & ç›¸ä¼¼åº¦ç»¼åˆæ’åºï¼Œé€‰æ‹©æœ€å¥½çš„ 3 ä¸ªå¥å­
collected_sentences.sort(key=lambda x: (x[1], sentence_similarity(input_text, x[0])), reverse=True)
best_sentences = [sentence[0] for sentence in collected_sentences[:3]]

# ================= è¾“å‡ºæœ€ç»ˆç»“æœ =================
print("ğŸ”¹ åŸæ–‡ï¼š", input_text)
print("\nâœ… ç”Ÿæˆçš„æœ€ä½³ 3 ä¸ªé‡ç»„ç‰ˆæœ¬ï¼š")
for i, sentence in enumerate(best_sentences, 1):
    print(f"{i}. {sentence}")
