from transformers import T5Tokenizer, T5ForConditionalGeneration

# **1ï¸âƒ£ åŠ è½½æœ¬åœ°è®­ç»ƒå¥½çš„æ¨¡å‹**
model_name = "/home/jxy/models/t5_reorder_test"
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name)

# **2ï¸âƒ£ è®¾å®šæ¨ç†å‡½æ•°**
def reorder_sentence(sentence):
    input_text = "reorder: " + sentence  # è¾“å…¥æ ¼å¼
    input_ids = tokenizer.encode(input_text, return_tensors="pt")
    
    #output_ids = model.generate(input_ids, max_length=128, num_beams=5)  # ğŸš€ è¿›è¡Œæ¨ç†
    output_ids = model.generate(
    input_ids,
    max_length=128,
    do_sample=True,  # âœ… å¯ç”¨é‡‡æ ·ï¼Œè®©è¾“å‡ºæœ‰éšæœºæ€§
    top_k=50,  # âœ… ä»…ä»æ¦‚ç‡æœ€é«˜çš„ 50 ä¸ª token é‡‡æ ·
    top_p=0.95,  # âœ… Nucleus Samplingï¼Œåªä¿ç•™ç´¯è®¡æ¦‚ç‡ 95% çš„ token
    temperature=0.7,  # âœ… æ§åˆ¶é‡‡æ ·çš„éšæœºç¨‹åº¦ï¼ˆè¶Šé«˜è¶Šéšæœºï¼‰
    )

    reordered_sentence = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    
    return reordered_sentence

# **3ï¸âƒ£ æµ‹è¯•æ¨ç†**
shuffled_sentence = "algorithm decoding variable - node - based for LDPC codes"
shuffled_sentence="a the of for algorithm ( is , data with proposed NAND LDPC . VNBP-MP belief-propagation variable-node-based problems ) decoding the parity-check To ) message binary codes pre-processing reliability storages flash for solve low-density ("
#"To solve the problems of the data reliability for NAND flash storages, a variable-node-based belief-propagation with message pre-processing (VNBP-MP) decoding algorithm for binary low-density parity-check (LDPC) codes is proposed."
#"To solve the reliability problems of low-density data storages, a variable-node-based parity-check decoding (LDPC) algorithm is proposed for the NAND (VNBP-MP) message pre-processing with NAND binary codes for belief-propagation."
shuffled_sentence="texts than human-written LLMs, black-box texts. paper, a simple the contain that, effective from on zero-shot more propose perspective detection observation yet typically LLM-generated this based In grammatical the we errors approach of"
#åŸå¥å­ï¼š"In this paper, we propose a simple yet effective black-box zero-shot detection approach based on the observation that, from the perspective of LLMs, human-written texts typically contain more grammatical errors than LLM-generated texts."
#é‡ç»„åï¼š"In this paper, we propose a simple, yet effective LLM-generated detection approach based on the observation of grammatical errors that typically contain zero-shot black-box texts from the perspective of human-written LLMs."
reordered = reorder_sentence(shuffled_sentence)

print("ğŸ”„ ä¹±åºå¥å­:", shuffled_sentence)
print("âœ… é‡ç»„å¥å­:", reordered)
