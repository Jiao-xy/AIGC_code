import json
import random
import nltk
from tqdm import tqdm
from nltk.tokenize import sent_tokenize, word_tokenize

nltk.download("punkt")

# **1ï¸âƒ£ è®¾å®šæ–‡ä»¶è·¯å¾„**
data_files = [
    "/home/jxy/Data/ReoraganizationData/init/ieee-init.jsonl",
    "/home/jxy/Data/ReoraganizationData/init/ieee-chatgpt-generation.jsonl",
]

output_files = {
    "tau_08": "/home/jxy/Data/ReoraganizationData/init/sentence_shuffled_dataset_tau_08.jsonl",
    "tau_05": "/home/jxy/Data/ReoraganizationData/init/sentence_shuffled_dataset_tau_05.jsonl",
    "tau_02": "/home/jxy/Data/ReoraganizationData/init/sentence_shuffled_dataset_tau_02.jsonl",
}

# **2ï¸âƒ£ ç”Ÿæˆä¸åŒ Kendallâ€™s Tau çº§åˆ«çš„æ‰“ä¹±å¥å­**
def shuffle_with_tau(sentence, tau=0.5):
    words = word_tokenize(sentence)
    num_swaps = int(len(words) * (1 - tau))  # è®¡ç®—äº¤æ¢æ¬¡æ•°
    shuffled = words[:]
    
    for _ in range(num_swaps):
        i, j = random.sample(range(len(words)), 2)
        shuffled[i], shuffled[j] = shuffled[j], shuffled[i]

    return " ".join(shuffled)

# **3ï¸âƒ£ ç»Ÿè®¡æ€»è¡Œæ•°ï¼ˆç”¨äºè¿›åº¦æ¡ï¼‰**
total_lines = sum(1 for file in data_files for _ in open(file, "r", encoding="utf-8"))
print(f"ğŸ“„ å‘ç° {total_lines} æ¡æ‘˜è¦æ•°æ®ï¼Œå¼€å§‹å¤„ç†...\n")

# **4ï¸âƒ£ è§£æ JSONL æ–‡ä»¶å¹¶ç”Ÿæˆ 3 ä¸ª JSONL æ•°æ®é›†**
file_handles = {tau: open(path, "w", encoding="utf-8") for tau, path in output_files.items()}

for file in data_files:
    with open(file, "r", encoding="utf-8") as f:
        for line in tqdm(f, total=total_lines, desc="â³ å¤„ç†ä¸­", unit="æ¡æ‘˜è¦"):
            try:
                entry = json.loads(line.strip())  
                abstract_text = entry.get("abstract", "").strip()

                if abstract_text:
                    sentences = sent_tokenize(abstract_text)  

                    for sentence in sentences:
                        shuffled_sentences = {
                            "tau_08": shuffle_with_tau(sentence, tau=0.8),
                            "tau_05": shuffle_with_tau(sentence, tau=0.5),
                            "tau_02": shuffle_with_tau(sentence, tau=0.2),
                        }

                        for tau, shuffled in shuffled_sentences.items():
                            json_entry = {
                                "shuffled_sentence": shuffled,
                                "original_sentence": sentence,
                            }
                            file_handles[tau].write(json.dumps(json_entry, ensure_ascii=False) + "\n")

            except json.JSONDecodeError:
                print(f"âŒ JSON è§£æå¤±è´¥ï¼Œè·³è¿‡è¯¥è¡Œ: {line}")

# **5ï¸âƒ£ å…³é—­ JSONL æ–‡ä»¶**
for f in file_handles.values():
    f.close()

print("\nâœ… 3 ä¸ª JSONL æ•°æ®é›†å·²ä¿å­˜ï¼š")
for tau, path in output_files.items():
    print(f"ğŸ“‚ {tau}: {path}")
