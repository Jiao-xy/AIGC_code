import json
import pandas as pd
import random
import nltk
from tqdm import tqdm  # è¿›åº¦æ¡åº“

nltk.download("punkt")
from nltk.tokenize import sent_tokenize, word_tokenize

# **1ï¸âƒ£ æŒ‡å®šå¤šä¸ª JSONL æ–‡ä»¶**
jsonl_files = [
     "/home/jxy/Data/init/ieee-init.jsonl", 
    "/home/jxy/Data/init/ieee-chatgpt-polish.jsonl", 
    "/home/jxy/Data/init/ieee-chatgpt-fusion.jsonl", 
    "/home/jxy/Data/init/ieee-chatgpt-generation.jsonl",
]

output_file = "sentence_reorder_dataset.csv"

# **ç»Ÿè®¡æ‰€æœ‰ JSONL æ–‡ä»¶çš„æ€»è¡Œæ•°**
total_lines = 0
for file in jsonl_files:
    with open(file, "r", encoding="utf-8") as f:
        total_lines += sum(1 for _ in f)

print(f"ğŸ“„ å‘ç° {total_lines} æ¡æ‘˜è¦æ•°æ®ï¼Œå¼€å§‹å¤„ç†...\n")

# **2ï¸âƒ£ é€æ­¥è§£æ JSONL æ–‡ä»¶å¹¶å†™å…¥ CSV**
data_pairs = []
batch_size = 10000  # æ¯ 10K è¡Œå†™å…¥ä¸€æ¬¡ï¼Œé˜²æ­¢å†…å­˜å ç”¨è¿‡å¤§

with open(output_file, "w", encoding="utf-8") as f_out:
    f_out.write("ä¹±åºå¥å­,æ­£ç¡®å¥å­\n")  # å†™å…¥ CSV å¤´éƒ¨

    for file in jsonl_files:
        with open(file, "r", encoding="utf-8") as f:
            for line in tqdm(f, total=total_lines, desc="â³ å¤„ç†ä¸­", unit="æ¡æ‘˜è¦"):
                try:
                    entry = json.loads(line.strip())  # è§£æ JSON
                    abstract_text = entry.get("abstract", "").strip()

                    if abstract_text:  # ç¡®ä¿æ‘˜è¦å­˜åœ¨
                        sentences = sent_tokenize(abstract_text)  # å¥å­æ‹†åˆ†
                        for sentence in sentences:
                            words = word_tokenize(sentence)  # è¯åˆ†å‰²
                            shuffled_words = words[:]
                            random.shuffle(shuffled_words)  # æ‰“ä¹±é¡ºåº
                            shuffled_sentence = " ".join(shuffled_words)

                            data_pairs.append(f'"{shuffled_sentence}","{sentence}"')

                            # **æ¯ batch_size è¡Œå†™å…¥ä¸€æ¬¡**
                            if len(data_pairs) >= batch_size:
                                f_out.write("\n".join(data_pairs) + "\n")
                                data_pairs = []  # æ¸…ç©ºç¼“å†²åŒº

                except json.JSONDecodeError:
                    print(f"âŒ JSON è§£æå¤±è´¥: {line}")

    # **å†™å…¥æœ€åå‰©ä½™çš„æ•°æ®**
    if data_pairs:
        f_out.write("\n".join(data_pairs) + "\n")

print(f"âœ… è®­ç»ƒæ•°æ®å·²ä¿å­˜è‡³: {output_file}")
