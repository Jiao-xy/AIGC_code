from datasets import Dataset
import json
import re

# ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„æ–‡ä»¶è·¯å¾„
arrow_file = "/home/jxy/.cache/huggingface/datasets/scientific_papers/arxiv/1.1.1/306757013fb6f37089b6a75469e6638a553bd9f009484938d8f75a4c5e84206f/scientific_papers-train-00000-of-00014.arrow"
output_file = "arxiv_cleaned_100.jsonl"
max_samples = 100

def clean_text(text):
    """æ¸…é™¤ arXiv ä¸­çš„æ•°å­¦ç¬¦å·ã€LaTeXã€å¼•ç”¨ç­‰æ ‡è®°"""
    text = re.sub(r"@xmath\d*", "", text)                     # @xmath å ä½ç¬¦
    text = re.sub(r"@xcite", "", text)                        # @xcite å¼•ç”¨
    text = re.sub(r"\[[^\]]*\]", "", text)                    # [table1] è¿™ç±»å¼•ç”¨
    text = re.sub(r"\$[^$]*\$", "", text)                     # $...$ æ•°å­¦å…¬å¼
    text = re.sub(r"\\[a-zA-Z]+\{.*?\}", "", text)            # \mbox{...} ç±»LaTeX
    text = re.sub(r"\s*[_]+\s*", " ", text)  # ç§»é™¤å­¤ç«‹ä¸‹åˆ’çº¿
    text = re.sub(r"\s+", " ", text)                          # å¤šä½™ç©ºæ ¼
    text = re.sub(r"\(\s*\)", "", text)
    return text.strip()

# åŠ è½½ arrow æ•°æ®é›†
print("ğŸ“¥ Loading .arrow file...")
dataset = Dataset.from_file(arrow_file)

# æ¸…æ´—å¹¶ä¿å­˜å‰ N æ¡æ•°æ®ä¸º JSONL
print(f"ğŸš€ Cleaning and saving first {max_samples} samples to {output_file}...")
with open(output_file, "w", encoding="utf-8") as fout:
    for i, example in enumerate(dataset):
        if i >= max_samples:
            break
        cleaned_article = clean_text(example["article"])
        cleaned_abstract = clean_text(example["abstract"])
        if cleaned_article and cleaned_abstract:
            fout.write(json.dumps({
                "article": cleaned_article,
                "summary": cleaned_abstract
            }, ensure_ascii=False) + "\n")

print(f"âœ… æ¸…æ´—å¹¶ä¿å­˜å®Œæˆï¼Œæ–‡ä»¶ä½ç½®ï¼š{output_file}")
