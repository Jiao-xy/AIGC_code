{"article": "additive models provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models . it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models . many examples of such estimators belong to the large class of regularized kernel based methods over a reproducing kernel hilbert space , see e.g. . in the last years many interesting results on learning rates of regularized kernel based models for additive models have been published when the focus is on sparsity and when the classical least squares loss function is used , see e.g. , , , , , and the", "summary": "additive models play an important role in semiparametric statistics . this paper gives learning rates for regularized kernel based methods for additive models . these learning rates compare favourably in particular in high dimensions to recent results on optimal learning rates for purely nonparametric regularized kernel based quantile regression using the gaussian radial basis function kernel , provided the assumption of an additive model is valid . additionally , a concrete example is presented to show that a gaussian function depending only on one variable lies in a reproducing kernel hilbert space generated by an additive gaussian kernel , but does not belong to the reproducing kernel hilbert space generated by the multivariate gaussian kernel of the same variance . * key words and phrases . * additive model , kernel , quantile regression , semiparametric , rate of convergence , support vector machine ."}
{"article": "the leptonic decays of a charged pseudoscalar meson are processes of the type , where , , or . because no strong interactions are present in the leptonic final state , such decays provide a clean way to probe the complex , strong interactions that bind the quark and antiquark within the initial - state meson . in these decays , strong interaction effects can be parametrized by a single quantity , , the pseudoscalar meson decay constant . the leptonic decay rate can be measured by experiment , and the decay constant can be determined by the equation ( ignoring radiative corrections ) where is the fermi coupling constant , is the cabibbo - kobayashi - maskawa ( ckm ) matrix element , is the mass of the meson , and is the mass of the charged lepton . the quantity describes the amplitude for the and -quarks within the to have zero separation , a condition necessary for them to annihilate into the virtual boson that produces the pair . the experimental determination of decay constants is one of the most important tests of calculations involving nonperturbative qcd . such calculations have been performed using various models or using lattice qcd ( lqcd ) . the latter is now generally considered to be the most reliable way to calculate the quantity . knowledge of decay constants is important for describing several key processes , such as mixing , which depends on , a quantity that is also predicted by lqcd calculations . experimental determination of leptonic decay of a meson is , however , very limited as the rate is highly suppressed due to the smallness of the magnitude of the relevant ckm matrix element . the charm mesons , and , are better instruments to study the leptonic decays of heavy mesons since these decays are either less ckm suppressed or favored , i.e. , and are much larger than . thus , the decay constants and determined from charm meson decays can be used to test and validate the necessary lqcd calculations applicable to the -meson sector . among the leptonic decays in the charm - quark sector , decays are more accessible since they are ckm favored . furthermore , the large mass of the lepton removes the helicity suppression that is present in the decays to lighter leptons . the existence of multiple neutrinos in the final state , however , makes measurement of this decay challenging . physics beyond the standard model ( sm ) might also affect leptonic decays of charmed mesons . depending on the non - sm features , the ratio of could be affected , as could the ratio . any of the individual widths might be increased or decreased . there is an indication of a discrepancy between the experimental determinations of and the most recent precision lqcd calculation . this disagreement is particularly puzzling since the cleo - c determination of agrees well lqcd calculation of that quantity . some conjecture that this discrepancy may be explained by a charged higgs boson or a leptoquark . in this article , we report an improved measurement of the absolute branching fraction of the leptonic decay ( charge - conjugate modes are implied ) , , from which we determine the decay constant . we use a data sample of events provided by the cornell electron storage ring ( cesr ) and collected by the cleo - c detector at the center - of - mass ( cm ) energy , near peak production . the data sample consists of an integrated luminosity of containing pairs . we have previously reported measurements of and subsample of these data . a companion article reports measurements of from and , , using essentially the same data sample as the one used in this measurement . the cleo - c detector is a general - purpose solenoidal detector four concentric components utilized in this measurement : a small - radius six - layer stereo wire drift chamber , a 47-layer main drift chamber , a ring - imaging cherenkov ( rich ) detector , and an electromagnetic calorimeter consisting of 7800 csi(tl ) crystals . the two drift chambers operate in a t magnetic field and provide charged particle tracking in a solid angle of % of . the chambers achieve a momentum resolution of % at / . the main drift chamber also provides specific - ionization measurements that discriminate between charged pions and kaons . the rich detector covers approximately % of and provides additional separation of pions and kaons at high momentum . the photon energy resolution of the calorimeter is % at and % at . electron identification is based on a likelihood variable that combines the information from the rich detector , , and the ratio of electromagnetic shower energy to track momentum . we use a geant - based monte carlo ( mc ) simulation program to study efficiency of signal - event selection and background processes . physics events are generated by evtgen , tuned much improved knowledge of charm decays , and final - state radiation ( fsr ) is modeled by the photos program . the modeling of initial - state radiation ( isr ) is based on cross sections for production at lower energies obtained from the cleo - c energy scan near the cm energy where we collect the sample . the presence of two mesons in a event allows us to define a single - tag ( st ) sample in which a is reconstructed in a hadronic decay mode and a further double - tagged ( dt ) subsample in which an additional is required as a signature of decay , the being the daughter of the . the reconstructed in the st sample can be either primary or secondary from ( or ) . the st yield can be expressed as where is the produced number of pairs , is the branching fraction of hadronic modes used in the st sample , and is the st efficiency . the counts the candidates , not events , and the factor of 2 comes from the sum of and tags . our double - tag ( dt ) sample is formed from events only a single charged track , identified as an , in addition to a st . the yield can be expressed as where is the leptonic decay branching fraction , including the subbranching fraction of decay , is the efficiency of finding the st and the leptonic decay in the same event . from the st and dt yields we can obtain an absolute branching fraction of the leptonic decay , without needing to know the integrated luminosity or the produced number of pairs , where is the effective signal efficiency . because of the large solid angle acceptance high segmentation of the cleo - c detector and the low multiplicity of the events which we are concerned , , where is the leptonic decay efficiency . hence , the ratio is insensitive to most systematic effects associated st , and the signal branching fraction obtained using this procedure is nearly independent of the efficiency of the tagging mode . to minimize systematic uncertainties , we tag using three two - body hadronic decay modes only charged particles in the final state . the three st modes and are shorthand labels for events within mass windows ( described below ) of the peak in and the peak in , respectively . no attempt is made to separate these resonance components in the dalitz plot . ] are , , and . using these tag modes also helps to reduce the tag bias which would be caused by the correlation between the tag side and the signal side reconstruction if tag modes high multiplicity and large background were used . the effect of the tag bias can be expressed in terms of the signal efficiency defined by where is the st efficiency when the recoiling system is the signal leptonic decay single in the other side of the tag . as the general st efficiency , when the recoiling system is any possible decays , will be lower than the , sizable tag bias could be introduced if the multiplicity of the tag mode were high , or the tag mode were to include neutral particles in the final state . as shown in . , this effect is negligible in our chosen clean tag modes . the decay is reconstructed by combining oppositely charged tracks that originate from a common vertex and that have an invariant mass within of the nominal mass . we require the resonance decay to satisfy the following mass windows around the nominal masses : ( ) and ( ) . we require the momenta of charged particles to be or greater to suppress the slow pion background from decays ( through ) . we identify a st by using the invariant mass of the tag and recoil mass against the tag . the recoil mass is defined as where is the net four - momentum of the beam , taking the finite beam crossing angle into account ; is the four - momentum of the tag , computed from and the nominal mass of the meson . we require the recoil mass to be within of the mass . this loose window allows both primary and secondary tags to be selected . to estimate the backgrounds in our st and dt yields from the wrong tag combinations ( incorrect combinations that , by chance , lie within the signal region ) , we use the tag invariant mass sidebands . we define the signal region as , and the sideband regions as or , where is the difference between the tag mass and the nominal mass . we fit the st distributions to the sum of double - gaussian signal function plus second - degree chebyshev polynomial background function to get the tag mass sideband scaling factor . the invariant mass distributions of tag candidates for each tag mode are shown in fig . and the st yield and sideband scaling factor are summarized in table . we find summed over the three tag modes . . summary of single - tag ( st ) yields , where is the yield in the st mass signal region , is the yield in the sideband region , is the sideband scaling factor , and is the scaled sideband - subtracted yield . we considered six semileptonic decays , , , , , , and , as the major sources of background in the signal region . the second dominates the nonpeaking background , and the fourth ( ) dominates the peaking background . uncertainty in the signal yield due to nonpeaking background is assessed by varying the semileptonic decay branching fractions by the precision which they are known . imperfect knowledge of gives rise to a systematic uncertainty in our estimate of the amount of peaking background in the signal region , which has an effect on our branching fraction measurement of . we study differences in efficiency , data vs mc events , due to the extra energy requirement , extra track veto , and requirement , by using samples from data and mc events , in which both the and satisfy our tag requirements , i.e. , `` double - tag '' events . we then apply each of the above - mentioned requirements and compare loss in efficiency of data vs mc events . in this way we obtain a correction of for the extra energy requirement and systematic uncertainties on each of the three requirements of ( all equal , by chance ) . the non- background in the signal candidate sample is negligible due to the low probability ( per track ) that hadrons ( or ) are misidentified as . uncertainty in these backgrounds produces a uncertainty in the measurement of . the secondary backgrounds from charge symmetric processes , such as dalitz decay and conversion , are assessed by measuring the wrong - sign signal electron in events . the uncertainty in the measurement from this source is estimated to be . other possible sources of systematic uncertainty include , tag bias , tracking efficiency , identification efficiency , and fsr . combining all contributions in quadrature , the total systematic uncertainty in the branching fraction measurement is estimated to be . in summary , using the sample of tagged decays cleo - c detector we obtain the absolute branching fraction of the leptonic decay through where the first uncertainty is statistical and the second is systematic . this result supersedes our previous measurement of the same branching fraction , which used a subsample of data used in this work . the decay constant can be computed using eq . known values , , , and s. we assume and use the value given in ref . we obtain combining other determination of and decays , we obtain this result is derived from absolute branching fractions only and is the most precise determination of the leptonic decay constant to date . our combined result is larger than the recent lqcd calculation by standard deviations . the difference between data and lqcd for could be due to physics beyond the sm , unlikely statistical fluctuations in the experimental measurements or the lqcd calculation , or systematic uncertainties that are not understood in the lqcd calculation or the experimental measurements . combining other determination of , via , we obtain using this measurement of , we obtain the branching fraction ratio this is consistent , the value predicted by the sm lepton universality , as given in eq . known masses .", "summary": "we have studied the leptonic decay , via the decay channel , using a sample of tagged decays collected near the peak production energy in collisions cleo - c detector . we obtain and determine the decay constant , where the first uncertainties are statistical and the second are systematic ."}
{"article": "studies of laser beams propagating through turbulent atmospheres are important for many applications such as remote sensing , tracking , and long - distance optical communications . howerver , fully coherent laser beams are very sensitive to fluctuations of the atmospheric refractive index . the initially coherent laser beam acquires some properties of gaussian statistics in course of its propagation through the turbulence . as a result , the noise / signal ratio approaches unity for long - distance propagation . ( see , for example , refs.- ) . this unfavourable effect limits the performance of communication channels . to mitigate this negative effect the use of partially ( spatially ) coherent beams was proposed . the coherent laser beam can be transformed into a partially coherent beam by means of a phase diffuser placed near the exit aperture . this diffuser introduces an additional phase ( randomly varying in space and time ) to the wave front of the outgoing radiation . statistical characteristics of the random phase determine the initial transverse coherence length of the beam . it is shown in refs . , that a considerable decrease in the noise / signal ratio can occur under following conditions : ( i ) the ratio of the initial transverse coherence length , , to the beam radius , , should be essentially smaller than unity ; and ( ii ) the characteristic time of phase variations , , should be much smaller than the integration time , , of the detector . however , only limiting cases and have been considered in the literature . ( see , for example , refs . , and ref . , respectively ) . it is evident that the inequality can be easily satisfied by choosing a detector very long integration time . at the same time , this kind of the detector can not distinguish different signals within the interval . this means that the resolution of the receiving system might become too low for the case of large . on the other hand , there is a technical restriction on phase diffusers : up to now their characteristic times , , are not smaller than . besides that , in some specific cases ( see , for example , ref . ) , the spectral broadening of laser radiation due to the phase diffuser may become unacceptably high . the factors mentioned above impose serious restrictions on the physical characteristics of phase diffusers which could be potentially useful for suppressing the intensity fluctuations . an adequate choice of diffusers may be facilitated if we know in detail the effect of finite - time phase variation , introduced by them , on the photon statistics . in this case , it is possible to control the performance of communication systems . in what follows , we will obtain theoretically the dependence of scintillation index on without any restrictions on the value of this ratio this is the main purpose of our paper . further analysis is based on the formalism developed in ref . and modified here to understand the case of finite - time dynamics of the phase diffuser . the detectors of the absorbed type do not sense the instantaneous intensity of electromagnetic waves . they sense the intensity averaged over some finite interval i.e. usually , the averaging time ( the integration time of the detector ) is much smaller than the characteristic time of the turbulence variation , , . therefore , the average value of the intensity can be obtained by further averaging of eq . over many measurements corresponding various realizations of the refractive - index configurations . the scintillation index determining the mean - square fluctuations of the intensity is defined by \\bigg /\\big < \\big > ^2= {\\big<\\bar i \\big>^2}-1,\\ ] ] where the symbol indicates the normal ordering of the creation and annihilation operators which determine the intensity , . ( see more details in refs . , ) . the brackets indicate quantum - mechanical and atmospheric averagings . the intensity depends not only on , but also on the spatial variable . therefore , the detected intensity is the intensity averaged not only over as in eq . , but also over the detector aperture . for simplicity , we will restrict ourselves to calculations of the intensity correlations for coinciding spatial points that correspond to `` small '' detector aperture . this simplification is quite reasonable for a long - distance propagation path of the beam . in the case of quasimonochromatic light , we can choose in the form where and are the creation and annihilation operators of photons momentum . they are given in the heisenberg representation . is the volume of the system . it follows from eqs . , that can be obtained if one knows the average it is a complex problem to obtain this value for arbitrary turbulence strengths and propagation distances . nevertheless , the following qualitative reasoning can help to do this in the case of strong turbulence . we have mentioned that the laser light acquires the properties of gaussian statistics in the course of its propagation through the turbulent atmosphere . as a result , in the limit of infinitely long propagation path , , only diagonal \" terms , i.e. terms ( i ) or ( ii ) , contribute to the right part of eq . . for large but still finite , there exist small ranges of in case ( i ) and , in case ( ii ) contributing into the sum in eq . the presence of the mentioned regions is due to the two possible ways of correlating of four different waves ( see ref . ) which enter the right hand side of eq . . as explained in ref . , the characteristic sizes of regions ( i ) and ( ii ) depend on the atmospheric broadening of beam radii as , thus decreasing increasing . in the case of long - distance propagation , is much smaller than the component of photon wave - vectors perpendicular to the axis . the last quantity grows as . ( see ref . ) . for this reason , the overlapping of regions ( i ) and ( ii ) can be neglected . in this case eq . can be rewritten in the convenient form : where the value , confining summation over , is chosen to be greater than but much smaller than the characteristic transverse wave vector of the photons ; this is consistent above explanations . the two terms in the right - hand side correspond to the two regions of four - wave correlations . the quantity entering the right side of eq . is the operator of photon density in phase space ( the photon distribution function in space ) . it was used in refs . , and for the description of photon propagation in turbulent atmospheres . by analogy , we can define the two - time distribution function then eq . can be rewritten in terms of the distribution functions as let us represent in the form . we assume that , as explained in the text after eq. . in this case the hamiltonian of photons in a turbulent atmosphere can be considered to be independent of time . as a result , both functions defined by eqs . and satisfy the same kinetic equation , i.e. where is the photon velocity , is a random force , caused by the turbulence . this force is equal to , where is the frequency of laser radiation . is the refractive index of the atmosphere . the general solution of the equation for can be written in the form where the functions and obey the equations of motion boundary conditions . the instant is equal to , where is the speed of light . is the time of the exit of photons from the source . this choice of makes it possible to neglect the influence of the turbulence on the initial values of operators ( their dependence on time is as in vacuum ) . the term for can be obtained from eq . by putting . substituting both distribution functions into eq . , we obtain :\\big>,\\ ] ] where and are solutions of eqs . initial conditions and , respectively . the operators on the right side of eq . are related through matching conditions amplitudes of the exiting laser radiation ( see ref . ) by the relation where is the operator of the laser field which is assumed to be a single - mode field and the subscript means perpendicular to the -axis component . the function describes the profile of the laser mode , which is assumed to be gaussian - type function . the quantity is the random phase introduced by the phase diffuser . a similar consideration is applicable to each of four photon operators entering both terms in square brackets of eq . . it can be easily seen that the factor },\\ ] ] describing the effect of phase screen on the beam , enters implicitly the integrand of eq . ( the indices are omitted here for the sake of brevity ) . there are integrations over variables as shown in eq . . furthermore , the brackets , which indicate averaging over different realizations of the atmosperic inhomogeneities , also indicate averaging over different states of the phase diffuser . as long as both types of averaging do not correlate , the factor entering eq . must be averaged over different instants , . to begin , let us consider the simplest case of two phase correlations }\\big > .\\ ] ] it is evident that in the case , as shown schematically in fig . 1 , the factor is sizable if only points and are close to one another . two curves correspond to different instants and . ] therefore , the term given by eq . can be replaced by where is considered to be a gaussian random variable mean - square values given by ^ 2\\rangle = \\langle ^2\\rangle = 2\\lambda c^{-2} ] . as we see , the effect of the phase screen can be described by two parameters , and , which characterize the spatial and temporal coherence of the laser beam . in the limiting case , , the second term in eq . vanishes and the problem is reduced to the case considered in refs . , . in the opposite case , , both terms in eq . are important . this is shown in ref . . in what follows , we will see that these two limiting cases have physical interpretations where where ( slow detector ) and ( fast detector ) , respectively . there is a specific realization of the diffuser in which a random phase distribution moves across the beam . ( this situation can be modeled by a rotating transparent disk large diameter and varying thickness . ) the phase depends here on the only variable , i.e. where is the velocity of the drift . then we have }+e^{-\\lambda c^{-2}}.\\ ] ] comparing eqs . and , we see that the quantity , , stands for the characteristic parameter describing the efficiency of the phase diffuser . the criterion of slow \" detector requires . qualitatively , the two scenarios of phase variations , given by eqs . and , affect in a similar way the intensity fluctuations . in what follows , we consider the first of them as the simplest one . ( this is because the spatial and temporal variables in , given by eq . , are separable . ) vs propagation distance in the case of `` slow '' detector : . the parameter indicates different initial coherence length . in the absence of phase diffuser ( solid line ) . is the conventional parameter describing a strength of the atmospheric turbulence . ] substituting the expressions for operators given by eq . account for the phase factors and averaging over time as shown in eq . , we obtain \\bigg > , \\ ] ] where the notation after sums indicates averaging over different realizations of the atmospheric refractive index . the parameter describes the initial coherence length modified by the phase diffuser . other notations are defined by following relations further calculations follow the scheme described in ref . 2 illustrates the effect of the phase diffuser on scintillations in the limit of a slow \" detector . we can see a considerable decrease in caused by the phase diffuser . at the same time , the effect of the phase screen on becomes weaker for finite values of . moreover , comparing the two upper curves in fig . 3 , we see the opposite effect : slow phase variations result in increased scintillations . there is a simple explanation for this phenomenon : the noise generated by the turbulence is complemented by the noise arising from the random phase screen . the integration time of the detector , , is not sufficiently large for averaging phase variations generated by the diffuser . the function , , has a very simple form in the two limits : ( i) , when ; and ( ii ) , when . then , in case ( i ) and for small values of the initial coherence differs from analogous one in ref . by the value that is much less than unity but , nevertheless , can be comparable or even greater than . in case ( ii ) , the asymptotic value of is close to unity , coinciding results of refs . and . this agrees well known behavior of the scintillation index to approach unity for any source distribution , provided the response time of the recording instrument is short compared source coherence time . ( see , for example , survey ) . a similar tendency can be seen in both figs . 3 and 4 : the curves smallest , used for numerical calculations , are close to the curves without diffuser \" in spite of the small initial coherence length . ] it follows from our analysis that the scintillation index is very sensitive to the diffuser parameters , and , for long propagation paths . on the other hand , the characteristics of the irradience such as beam radius , , and angle - of - arrival spread , , do not depend on the presence of the phase diffuser for large values of . to see this , the following analysis is useful . the beam radius expressed in terms of the distribution function is given by straightforward calculations using eq . ( see ref . ) result in the following explicit form : where and is the inner radius of turbulent eddies , which in our previous calculations was assumed to be equal m . as we see , the third term does not depend on the diffuser parameters and it dominates when . a similar situation holds for the angle - of - arrival spread , . ( this physical quantity is of great importance for the performance of communication systems based on frequency encoded information . ) it is defined by the distribution function as simple calculations , which are very similar to those while obtaining , result in ^ 2=\\frac 2{r 1 ^ 2q 0 ^ 2}+12tz-\\frac { 4z^2}{q 0 ^ 4r^2}(r 1^{-2}+3tq 0 ^ 2z)^2.\\ ] ] for long propagation paths , . reduces to , which like does not depend on the diffuser parameters . as we see , for large distances , the quantities and do not depend on and . this contrasts case of the scintillation index . so pronounced differences can be explained by differences in the physical nature of these characteristics . it follows from eq . that the functional , , is quadratic in the distribution function , . hence , four - wave correlations determine the value of scintillation index . the main effect of a phase diffuser on is to destroy correlations between waves exited at different times . ( see more explanations in ref . this is achieved at sufficiently small parameters and . in contrast , and depend on two wave - correlations , both waves being given at the same instant . therefore , the values of and do not depend on the rate of phase variations ) describing the effect of phase diffuser ] . moreover , these quantities become independent of at long propagation paths because light scattering on atmospheric inhomogeneities prevails in this case . the plots in figs . 3 anf 4 show that the finite - time effect is quite sizable even for very slow \" detectors . our paper makes it possible to estimate the actual utility of phase diffusers in several physical regimes . we have analyzed the effects of a diffuser on scintillations for the case of large - amplitude phase fluctuations . this specific case is very convenient for theoretial analysis because only two parameters are required to describe the effects of the diffuser . phase fluctuations may occur independently in space as well as in time . also , our formalism can be applied for the physical situation in which a spatially random phase distribution drifts across the beam . . ) our results show the importance of both parameters , and , on the ability of a phase diffuser to suppress scintillations . this work was carried out under the auspices of the national nuclear security administration of the u.s . department of energy at los alamos national laboratory under contract no . de - ac52 - 06na25396 . we thank onr for supporting this research .", "summary": "the effect of a random phase diffuser on fluctuations of laser light ( scintillations ) is studied . not only spatial but also temporal phase variations introduced by the phase diffuser are analyzed . the explicit dependence of the scintillation index on finite - time phase variations is obtained for long propagation paths . it is shown that for large amplitudes of phase fluctuations , a finite - time effect decreases the ability of phase diffuser to suppress the scintillations ."}
{"article": "the simulations we discuss here allowed us to obtain spectra of the shg response . we employed comsol multiphysics software ( www.comsol.com ) in order to perform simulations of the linear optical response as described in ref . . a unit cell containing a single sic pillar attached to the sic substrate was constructed , floquet boundary conditions along the -axis and periodic boundary conditions along the -axis , perpendicular to the plane of incidence . a p -polarized plane wave at frequency was launched towards the sic structure at an incident angle of 25 . originating from the p -polarised light source , the electric field inside the sic pillar and substrate was recorded . then , this electric field was translated into the nonlinear polarization , according to eq . ( 1 ) in the main manuscript . there , the following non - zero components of the nonlinear susceptibility were accounted for : , and . as a next step , in the pillar and the substrate was regarded as the source of scattered electric field inside the unit cell . the shg output was then obtained by integrating the power flow through a xy -plane set above the substrate . sweeping the fundamental frequency and taking the dispersion of both linear and nonlinear sic susceptibilities from refs. , we calculated several shg spectra for samples various periodicity of the pillars . we note that in these calculations , the input power density at fundamental frequency was kept constant , and the shg output power was normalized to the area of the xy -plane . the results of the simulations presented in fig . in the main manuscript demonstrate a single pronounced peak corresponding to the excitation of the sphp monopole mode . barnes , w. l. ; dereux , a. ; ebbesen , t. w. surface plasmon subwavelength optics . nature ( london ) * 2003 * , 424 , 824830 maier , s. a. plasmonics : fundamentals and applications ; springer : new york , 2007 schuller , j. a. ; barnard , e. s. ; cai , w. ; jun , y. c. ; white , j. s. ; brongersma , m. l. plasmonics for extreme light concentration and manipulation . mater . * 2010 * , 9 , 193204 boriskina , s. v. ; ghasemi , h. ; chen , g. plasmonic materials for energy : from physics to applications . mater . today * 2013 * , 16 , 375386 brongersma , m. l. ; halas , n. j. ; nordlander , p. plasmon - induced hot carrier science and technology . * 2015 * , 10 , 2534 kauranen , m. ; zayats , a. v. nonlinear plasmonics . photon . * 2012 * , 6 , 737748 hentschel , m. ; utikal , t. ; metzger , b. ; giessen , h. ; lippitz , m. in progress in nonlinear nano - optics ; sabake , s. , lienau , c. , grunwald , r. , eds . ; springer international publishing : switzerland , 2015 ; chapter 9 , pp 153181 butet , j. ; brevet , p .- f . ; martin , o. j. f. optical second harmonic generation in plasmonic nanostructures : from fundamental principles to advanced applications . acs nano * 2015 * , 9 , 1054510562 vahala , k. j. optical microcavities . nature ( london ) * 2003 * , 424 , 839846 barnes , w. l. surface plasmon - polariton length scales : a route to sub - wavelength optics . j. opt . a : pure appl * 2006 * , 8 , s87s93 greffet , j .- j . ; carminati , r. ; joulain , k. ; mulet , j .- p . ; mainguy , s. ; chen , y. coherent emission of light by thermal sources . nature ( london ) * 2002 * , 416 , 6164 hillenbrand , r. ; taubner , t. ; keilmann , f. phonon - enhanced light - matter interaction at the nanometre scale . nature ( london ) * 2002 * , 418 , 159162 , b. ; korobkin , d. ; fietz , c. ; carole , d. ; ferro , g. ; shvets , g. critically coupled surface phonon - polariton excitation in silicon carbide . expr . * 2007 * , 34 , 26672669 caldwell , j. d. ; glembocki , o. j. ; francescato , y. ; sharac , n. ; giannini , v. ; bezares , f. j. ; long , j. p. ; owrutsky , j. c. ; vurgaftman , i. ; tischler , j. g. ; wheeler , v. d. ; bassim , n. d. ; shirey , l. m. ; kasica , r. ; maier , s. a. low - loss , extreme subdiffraction photon confinement via silicon carbide localized surface phonon polariton resonators . nano lett . * 2013 * , 13 , 36903697 chen , y. ; francescato , y. ; caldwell , j. d. ; giannini , v. ; ma , t. w. w. ; glembocki , o. j. ; bezares , f. j. ; taubner , t. ; kasica , r. ; hong , m. ; maier , s. a. spectral tuning of localized surface phonon polariton resonators for low - loss mid - ir applications . acs photonics * 2014 * , 1 , 718724 caldwell , j. d. ; kretinin , a. v. ; chen , y. ; giannini , v. ; fogler , m. m. ; francescato , y. ; ellis , c. t. ; tischler , j. g. ; woods , c. r. ; giles , a. j. ; hong , m. ; watanabe , k. ; taniguchi , t. ; maier , s. a. ; novoselov , k. s. sub - diffractional volume - confined polaritons in the natural hyperbolic material hexagonal boron nitride . commun . * 2014 * , 5 , 5221 dai , s. et al . tunable phonon polaritons in atomically thin van der waals crystals of boron nitride . science * 2014 * , 343 , 11251129 caldwell , j. d. ; vurgaftman , i. ; tischler , j. g. probing hyperbolic polaritons . nat . photon . * 2015 * , 9 , 638640 li , p. ; lewin , m. ; kretinin , a. v. ; caldwell , j. d. ; novoselov , k. s. ; taniguchi , t. ; watanabe , k. ; gaussmann , f. ; taubner , t. hyperbolic phonon - polaritons in boron nitride for near - field optical imaging and focusing . commun . * 2015 * , 6 , 7507 dai , s. ; ma , q. ; andersen , t. ; mcleod , a. s. ; fei , z. ; liu , m. k. ; wagner , m. ; watanabe , k. ; taniguchi , t. ; thiemens , m. ; keilmann , f. ; jarillo - herrero , p. ; fogler , m. m. ; basov , d. n. subdiffractional focusing and guiding of polaritonic rays in a natural hyperbolic material . commun . * 2015 * , 6 , 6963 caldwell , j. d. ; lindsay , l. ; giannini , v. ; vurgaftman , i. ; reinecke , t. l. ; maier , s. a. ; glembocki , o. j. low - loss , infrared and terahertz nanophotonics using surface phonon polaritons . nanophotonics * 2014 * , 4 , 4468 ferguson , b. ; zhang , x .- c . materials for terahertz science and technology . photon . * 2002 * , 1 , 2633 ulbricht , r. ; hendry , e. ; shan , j. ; heinz , t. f. ; bonn , m. carrier dynamics in semiconductors studied time - resolved terahertz spectroscopy . * 2011 * , 83 , 543586 kampfrath , t. ; tanaka , k. ; nelson , k. a. resonant and nonresonant control over matter and light by intense terahertz transients . photon . * 2013 * , 7 , 680690 schllkopf , w. ; gewinner , s. ; junkes , h. ; paarmann , a. ; von helden , g. ; bluem , h. ; todd , a. m. m. the new ir and thz fel facility at the fritz haber institute in berlin . spie * 2015 * , 9512 , 95121l paarmann , a. ; razdolski , i. ; melnikov , a. ; gewinner , s. ; schllkopf , w. ; wolf , m. second harmonic generation spectroscopy in the reststrahl band of sic using an infrared free - electron laser . lett . * 2015 * , 107 , 081101 , a. ; razdolski , i. ; gewinner , s. ; schoellkopf , w. ; wolf , m. effects of crystal anisotropy on optical phonon resonances in the mid - infrared second harmonic response of sic . * 2016 * , arxiv:1607.05207 carpetti , a. ; walsh , g. f. ; minissale , s. ; trevino , j. ; forestiere , c. ; miano , g. ; negro , l. d. multipolar second harmonic generation from planar arrays of au nanoparticles . opt . expr . * 2012 * , 20 , 1579715806 canfield , b. k. ; husu , h. ; laukkanen , j. ; bai , b. ; kuittinen , m. ; turunen , j. ; kauranen , m. local field asymmetry drives second - harmonic generation in noncentrosymmetric nanodimers . nano lett . * 2007 * , 7 , 12511255 raether , h. surface plasmons on smooth and rough surfaces and on gratings ; springer - verlag : berlin , 1988 agarwal , g. s. ; jha , s. s. surface - enhanced second - harmonic generation at a metallic grating . b * 1982 * , 26 , 482 coutaz , j. experimental study of second - harmonic generation from silver gratings of various groove depths . j. opt b * 1987 * , 4 , 105106 quail , j. c. ; simon , h. j. second - harmonic generation from a silver grating surface plasmons . b * 1988 * , 5 , 325329 razdolski , i. ; parchenko , s. ; stupakiewicz , a. ; semin , s. ; stognij , a. ; maziewski , a. ; kirilyuk , a. ; rasing , t. second - harmonic generation from a magnetic buried interface enhanced by an interplay of surface plasma resonances . acs phot . * 2015 * , 2 , 2026 gubbin , c. r. ; martini , f. ; politi , a. ; maier , s. a. ; de liberato , s. strong and coherent coupling between localized and propagating phonon polaritons . * 2016 * , 116 , 246402 shan , j. ; dadap , j. ; stiopkin , i. ; reider , g. ; heinz , t. experimental study of optical second - harmonic scattering from spherical nanoparticles . b * 2006 * , 73 , 023819 kujala , s. ; canfield , b. k. ; kauranen , m. ; svirko , y. ; turunen , j. phonon - enhanced light - matter interaction at the nanometre scale . phys . * 2007 * , 98 , 167403 bachelier , g. ; butet , j. ; russier - antoine , i. ; jonin , c. ; benichou , e. ; brevet , p .- f . origin of optical second - harmonic generation in spherical gold nanoparticles : local surface and nonlocal bulk contributions . b * 2010 * , 82 , 235403 butet , j. ; bachelier , g. ; russier - antoine , i. ; jonin , c. ; benichou , e. ; brevet , p .- f . interference between selected dipoles and octupoles in the optical second - harmonic generation from spherical gold nanoparticles . phys . lett . * 2010 * , 105 , 077401 razdolski , i. ; gheorghe , d. g. ; melander , e. ; hjrvarsson , b. ; patoka , p. ; kimel , a. v. ; kirilyuk , a. ; papaioannou , e. t. ; rasing , t. nonlocal nonlinear magneto - optical response of a magnetoplasmonic crystal . b * 2013 * , 88 , 075436 kruk , s. ; weismann , m. ; bykov , a. y. ; mamonov , e. a. ; kolmychek , i. a. ; murzina , t. ; panoiu , n. c. ; neshev , d. n. ; kivshar , y. s. enhanced magnetic second - harmonic generation from resonant metasurfaces . acs photonics * 2015 * , 2 , 10071012 hille , a. ; moeferdt , m. ; wolff , c. ; matyssek , c. ; rodriguez - oliveros , r. ; prohm , c. ; niegemann , j. ; grafstrom , s. ; eng , l. m. ; ; busch , k. second harmonic generation from metal nano - particle resonators : numerical analysis on the basis of the hydrodynamic drude model . j. phys . c * 2016 * , 120 , 11631169 bluet , j. ; chourou , k. ; anikin , m. ; madar , r. weak phonon modes observation using infrared reflectivity for 4h , 6h and 15r polytypes . eng . * 1999 * , b6162 , 212216 patrick , l. infrared absorption in sic polytypes . phys . rev . * 1967 * , 167 , 809813 feldman , d. w. ; parker , jr . , j. h. ; choyke , w. j. ; patrick , l. phonon dispersion curves by raman scattering in sic , polytypes 3c , 4h , 6h , 15r , and 21r . rev . * 1968 * , 173 , 787793 engelbrecht , f. ; helbig , r. effect of crystal anisotropy on the infrared reflectivity of 6h sic . b * 1993 * , 48 , 1569815707 metzger , b. ; gui , l. ; fuchs , j. ; floess , d. ; hentschel , m. ; giessen , h. strong enhancement of second harmonic emission by plasmonic resonances at the second harmonic wavelength . nano lett . * 2015 * , 15 , 39173922 husu , h. ; canfield , b. k. ; laukkanen , j. ; bai , b. ; kuittinen , m. ; turunen , j. ; kauranen , m. local - field effects in the nonlinear optical response of metamaterials . metamaterials * 2008 * , 2 , 155168 palomba , s. ; novotny , l. nonlinear excitation of surface plasmon polaritons by four - wave mixing . lett . * 2008 * , 101 , 056802 carpetti , a. ; forestiere , c. ; negro , l. d. ; miano , g. full - wave analytical solution of second - harmonic generation in metal nanospheres . plasmonics * 2014 * , 9 , 151166 razdolski , i. ; makarov , d. ; schmidt , o. g. ; kirilyuk , a. ; rasing , t. ; temnov , v. v. nonlinear surface magnetoplasmonics in kretschmann multilayers . acs photonics * 2016 * , 3 , 179183 dai , s. et al . graphene on hexagonal boron nitride as a tunable hyperbolic metamaterial . nano . * 2015 * , 10 , 682687 caldwell , j. d. ; vurgaftman , i. ; tischler , j. g. ; glembocki , o. j. ; owrutsky , j. c. ; reinecke , t. l. atomic - scale photonic hybrids for mid - infrared and terahertz nanophotonics . nano . * 2015 * , 11 , 915", "summary": "we report on strong enhancement of mid - infrared second harmonic generation ( shg ) from sic nanopillars due to the resonant excitation of localized surface phonon - polaritons within the reststrahlen band . the magnitude of the shg peak at the monopole mode experiences a strong dependence on the resonant frequency beyond that described by the field localization degree and the dispersion of linear and nonlinear - optical sic properties . comparing the results for the identical nanostructures made of 4h and 6h sic polytypes , we demonstrate the interplay of localized surface phonon polaritons zone - folded weak phonon modes of the anisotropic crystal . tuning the monopole mode in and out of the region where the zone - folded phonon is excited in 6h - sic , we observe a prominent increase of the already monopole - enhanced shg output when the two modes are coupled . envisioning this interplay as one of the showcase features of mid - infrared nonlinear nanophononics , we discuss its prospects for the effective engineering of nonlinear - optical materials desired properties in the infrared spectral range . light localization in sub - wavelength volumes is a core of modern nanophotonics . conventional methods of achieving strong confinement of the electromagnetic fields extensively utilize unique properties of surface plasmons . a remarkable variety of objects and materials supporting these excitations ensures the key role of plasmonics in a broad range of applications . apart from unparalleled sensitivity of plasmonic structures to the optical properties of the environment , strong light localization facilitates nonlinear - optical effects . owing to the spectral tunability of the localized plasmon resonances and their sizeable nonlinearity , metallic nanostructures of different shapes and sizes have earned their place in nonlinear photonics . despite obvious advantages of plasmon - based nanophotonics , metallic nanoobjects exhibit significant optical losses , which lower the quality factor of the localized surface plasmon modes . fast plasmon damping ( typically on the order of 10 fs ) due to ohmic losses thus inhibits nonlinear - optical conversion . an alternative , promising metal - free approach has been suggested , utilizing polar dielectrics such as sic or bn for high - quality light confinement in the mid - infrared ( ir ) . in these materials , the subdiffractional confinement of electromagnetic radiation relies upon surface phonon polaritons ( sphp ) in the reststrahlen band : the electric polarization is created due to coherent oscillations of the ions instead of the electron or hole densities . due to the significantly longer scattering times associated optical phonons as compared to surface plasmons , the lifetimes of sphps tend to be on the order of picoseconds , much longer than their plasmonic counterparts . in addition , due to energies associated optical phonons , sphps typical frequencies within the mid - ir to the thz domain hold high promise for spectroscopic and nanophotonic applications . in this letter , we undertake a first step towards the largely unexplored domain of mid - ir nonlinear nanophononics . we study the nonlinear - optical response of localized sphps using nanostructures made of different polytypes of sic . using free electron laser ( fel ) radiation in the mid - ir spectral range , we probe second harmonic generation from rectangular arrays of sub - diffractional , cylindrical sic nanopillars . the shg yield in the reststrahlen band of sic demonstrates prominent enhancement at the wavelengths associated excitation of the sphp eigenmodes of the pillars . depending on both the size and the spatial periodicity of the pillars , the shg - probed eigenmode exhibits a spectral shift accompanied strong variations of the shg intensity . analyzing different sic polytypes , we demonstrate the interplay of the localized sphps zone - folded optical phonon modes . we further conclude that strong coupling of the two modes allows for a significant additional modulation of the sphp - enhanced shg output . the schematic of our experimental approach is outlined in fig . ,a . we employed a non - collinear shg configuration discussed elsewhere to perform spectroscopic shg measurements on square arrays of 1 m - tall 4h - sic and 6h - sic pillars main axis of the arrays in the xz plane of incidence . the fundamental radiation incident at 28 and 62 degrees respect to the normal to the sample surface was focused onto the sample peak fluence on the order of 10 mj/ . both 4h and 6h - sic samples were c - cut so that the c -axis of the crystals was parallel to the surface normal . typical shg and linear reflectivity spectra collected using the fel radiation for the two incident polarisations are presented in fig . ,b - e . there , the respective spectra of the bare substrate are shown for comparison . for p -polarised fundamental radiation ( fig . ,d ) , the shg response features two pronounced peaks located at the zone - center frequencies of transverse and longitudinal optical phonons in sic , around 797 and 965 , respectively . the corresponding shg spectrum from the nanopillars demonstrate a much stronger shg signal at around 900 . due to the absence of this peak in the shg spectrum when the fundamental radiation is s -polarised , we attribute this shg feature to the excitation of the monopole sphp mode in the nanopillars . in general , the outgoing shg field is related to the incident electromagnetic fields via the so - called local field factors : where is the nonlinear polarisation and is the nonlinear susceptibility tensor . the excitation of the sphp monopole mode leads to strong localization of the z -projection of the fundamental electric field ( normal to the surface plane ) and thus a resonant enhancement of . the latter results in a pronounced increase of the shg output when the fundamental radiation is p -polarised . however , the sphp dipole modes observed in the range of 920960 rely on the resonant enhancement of the in - plane electric fields described by the local field factors and thus can be excited both p - and s -polarised fundamental radiation . the total shg response is given by a vector sum of the terms on the right hand side of eq . ( 1 ) originating from various tensor components of the nonlinear susceptibility . as the strength of is the largest in this spectral range , the sphp monopole mode , enhancement of , naturally results in a higher shg output than the dipole modes . the results of the systematic studies of the shg response of various arrays of nanopillars are summarized in fig . for the 4h - sic ( a , c ) and 6h - sic ( b , d ) samples . the panels ( a - b ) illustrate the evolution of the shg spectra upon varying pillar diameter . it is seen that upon decreasing , the sphp monopole - driven shg peak exhibits a clear redshift . remarkably , while the sphp monopole mode shifts in the range of about 890 - 910 , the shg enhancement factor associated excitation of the sphp monopole mode varies strongly . the panels ( c - d ) offer a zoom - in into the evolution of the sphp monopole mode - driven shg for a large variety of nanopillar arrays , indicating that the variations of the shg enhancement are observed for both 4h and 6h samples . the dependences of the sphp monopole - driven shg output on the spectral position of the sphp monopole mode for the two sic polytypes are shown in fig . ,a open symbols . = 1200 , 1100 and 1000 nm , respectively . , scaledwidth=47.0% ] the strong dispersion in the sic reststrahlen band suggests that the observed spectral dependence of the shg enhancement could be captured in numerical simulations . we calculated shg response using both linear and nonlinear sic dispersion , the results of the simulation of the linear optical response , and nonlinear polarization from eq . ( 1 ) spatially integrated over the sic volume , following non - zero components of the nonlinear susceptibility : , and . the resultant shg spectra simulated comsol multiphysics software ( www.comsol.com ) are shown in fig . ,b full symbols . it is seen that the steep experimental dependence can not be quantitatively described within the simple model used in the calculations , which yields only a moderate increase of the shg output when the sphp monopole mode frequency is decreased . we note the work of carpetti et al . where the authors thoroughly examined plasmon - induced shg enhancement from arrays of au nanoparticles as a function of the inter - particle distance . in the regime of ( as it is in our case ) , the dependence of the shg output on was explained in terms of the changing filling factor ( and thus the associated number of active nanoemitters ) . for very small inter - particle gaps , a modulation of the shg output has been attributed to the modification of the electromagnetic field localization in the gaps . further , a large mismatch between the spatial period of the nanopillars and the resonant light wavelength rules out the excitation of propagating surface polaritons which are known to enhance the shg output . since all these effects are included in our simulations , we conclude that the origin of the observed shg enhancement is unrelated to the periodicity of the array . an alternative scenario for the observed trend could invoke modifications of the non - local shg contribution enhanced by a regular array structure . the importance of the non - local shg was already demonstrated in a number of subwavelength - separated plasmonic nanoobjects . the amplitude and phase of this non - local shg source depends on the electric field distribution , i.e. on both the pillar size and the periodicity . as such , the interference conditions between the shg sources vary for different samples , thus resulting in a strong modification of the shg output . further , the apparent difference in the shape of the resonant shg output for the 4h and 6h samples ( see fig . ) is related to the anisotropic nature of sic . the hexagonal sic polytypes are known to exhibit zone - folded weak modes in the reststrahlen region originating from particular stacking of the atomic layers along the c -axis of the crystal . these weakly ir - active zone - folded modes can be visualised in the reflectivity measurements at oblique incidence . although zone - folded modes exist in both 4h and 6h polytypes , different stacking of the sic atomic layers is responsible for them having different frequencies , as illustrated in fig . ,c - d . the additional periodicity in the crystal results in folding of the large brillouin zone thus modifying the phonon dispersion and making the excitation of phonons - zero wavevectors possible . it is seen in fig . ,d that the zone - folded mode in the 6h - sic polytype reduced wavevector can be excited in the range of which is close to the typical monopole sphp resonant frequency of the sic nanopillars discussed above . in particular , the interaction of the sphp and zone - folded mode which shifted the apparent spectral positions of the monopole sphp eigenmode in the linear response , is seen responsible for the complex structure of the resonant shg output in our experiments ( fig . ,d ) . the weak ir activity of the zone - folded modes is related to the large negative dielectric permittivity of sic in the reststrahlen band . as such , the out - of - plane component of the electromagnetic field remains small which inhibits the coupling of incident light to the zone - folded phonon mode . however , the excitation of the sphp monopole mode in the nanopillars drives a strong increase of , which facilitates the sphp monopole interaction zone - folded phonon ( fig . ,c ) . figure ,a illustrates the effect of the zone - folded mode on the observed shg output . the open red squares ( 4h ) and blue circles ( 6h ) depict the shg intensity obtained at the sphp monopole ( resonant ) frequencies , and the dashed lines illustrate a clear correlation between the maximum shg output and the spectral position of the sphp monopole peak . similar trends are observed for the 4h and 6h - sic samples as long as the sphp monopole and the zone - folded mode are well - separated . when these two resonances start to overlap , an additional enhancement of the shg output produced at the sphp monopole resonance in 6h - sic samples is observed . moreover , the dependence of the shg signal at the frequency of the zone - folded mode ( green triangles ) exhibits a much faster increase when the two resonances are brought together ( dotted line ) , indicating an efficient interplay between the sphp monopole and the zone - folded mode . we note that the interaction of the localized sphp eigenmodes and the intrinsic excitations of the medium is a unique fingerprint of mid - ir nanophononics . indeed , surface plasmon excitations in metals rely on the free electron gas , which is essentially isotropic . as such , the shg output of plasmonic nanostructures is ( i ) largely determined by the metal of choice , usually au , ( ii ) exhibits only weak spectral dependence and ( iii ) is limited by robust phase relations in the likely case of multiple shg sources . on the contrary , the flexibility of the sphps is provided by the coupling of the surface phonon polariton excitations to the intrinsic bulk phonon modes . the latter can be engineered by designing artificial metamaterials based on hybrid multilayer structures , thus allowing for an effective control of their optical properties . to summarize , we have observed shg output enhancement associated excitation of the sphp eigenmodes in an array of nanopillars grown from sic of different polytypes . the strongest shg output is associated excitation of the monopole sphp mode characterized by strong localization of the normal to surface projection of the electric field . the spectral positions of the shg peaks shift according to the geometric parameters of the nanophononic structures . we found a strong dependence of the magnitude of the shg enhancement on the resonant frequency . this experimentally observed dependence can not be quantitatively described by simply taking into account the sub - diffractional field localization and the dispersion of the linear and nonlinear optical properties of sic . further , we discuss the interplay of the sphps and the intrinsic crystalline anisotropy for an efficient nonlinear - optical conversion . this mechanism is supported by the shg spectral measurements on the 6h - sic nanopillars where excitation of the sphp monopole mode interacting weak zone - folded phonon resulted in an additional enhancement of the shg output . the presence of intrinsic resonances strongly alters the phase relations in their vicinity , providing a natural way for optimizing the shg response in a relatively narrow spectral range . our findings demonstrate high potential of mid - ir nonlinear nanophononics as a novel and promising platform for nonlinear optics and illustrate the rich opportunities it provides for efficient control over nonlinear - optical response . the authors thank g. kichin and a. kirilyuk ( radboud university nijmegen ) for stimulating discussions . s.a.m . acknowledges the office of naval research , the royal society , and the lee - lucas chair in physics . a.j.g . acknowledges financial support from the nrc / nrl postdoctoral fellowship program . funding for j.d.c . was provided by the office of naval research through the naval research laboratory s nanoscience institute ."}
{"article": "significant research efforts being directed to the development of neurocomputers based on the functionalities of the brain , a seismic shift is expected in the domain of computing based on the traditional von - neumann model . the , and the ibm are instances of recent flagship neuromorphic projects that aim to develop brain - inspired computing platforms suitable for recognition ( image , video , speech ) , classification and mining problems . while boolean computation is based on the sequential fetch , decode and execute cycles , such neuromorphic computing architectures are massively parallel and event - driven and are potentially appealing for pattern recognition tasks and cortical brain simulations to that end , researchers have proposed various nanoelectronic devices where the underlying device physics offer a mapping to the neuronal and synaptic operations performed in the brain . the main motivation behind the usage of such non - von neumann post - cmos technologies as neural and synaptic devices stems from the fact that the significant mismatch between the cmos transistors and the underlying neuroscience mechanisms result in significant area and energy overhead for a corresponding hardware implementation . a very popular instance is the simulation of a cat s brain on ibm s blue gene supercomputer where the power consumption was reported to be of the order of a few . while the power required to simulate the human brain will rise significantly as we proceed along the hierarchy in the animal kingdom , actual power consumption in the mammalian brain is just a few tens of watts . in a neuromorphic computing platform , synapses form the pathways between neurons and their strength modulate the magnitude of the signal transmitted between the neurons . the exact mechanisms that underlie the `` learning '' or `` plasticity '' of such synaptic connections are still under debate . meanwhile , researchers have attempted to mimic several plasticity measurements observed in biological synapses in nanoelectronic devices like phase change memories , memristors and spintronic devices , etc . however , majority of the research have focused on non - volatile plasticity changes of the synapse in response to the spiking patterns of the neurons it connects corresponding to long - term plasticity and the volatility of human memory has been largely ignored . as a matter of fact , neuroscience studies performed in have demonstrated that synapses exhibit an inherent learning ability where they undergo volatile plasticity changes and ultimately undergo long - term plasticity conditionally based on the frequency of the incoming action potentials . such volatile or meta - stable synaptic plasticity mechanisms can lead to neuromorphic architectures where the synaptic memory can adapt itself to a changing environment since sections of the memory that have been not receiving frequent stimulus can be now erased and utilized to memorize more frequent information . hence , it is necessary to include such volatile memory transition functionalities in a neuromorphic chip in order to leverage from the computational power that such meta - stable synaptic plasticity mechanisms has to offer . ( a ) demonstrates the biological process involved in such volatile synaptic plasticity changes . during the transmission of each action potential from the pre - neuron to the post - neuron through the synapse , an influx of ionic species like and causes the release of neurotransmitters from the pre- to the post - neuron . this results in temporary strengthening of the synaptic strength . however , in absence of the action potential , the ionic species concentration settles down to its equilibrium value and the synapse strength diminishes . this phenomenon is termed as short - term plasticity ( stp ) . however , if the action potentials occur frequently , the concentration of the ions do not get enough time to settle down to the equilibrium concentration and this buildup of concentration eventually results in long - term strengthening of the synaptic junction . this phenomenon is termed as long - term potentiation ( ltp ) . while stp is a meta - stable state and lasts for a very small time duration , ltp is a stable synaptic state which can last for hours , days or even years . a similar discussion is valid for the case where there is a long - term reduction in synaptic strength frequent stimulus and then the phenomenon is referred to as long - term depression ( ltd ) . such stp and ltp mechanisms have been often correlated to the short - term memory ( stm ) and long - term memory ( ltm ) models proposed by atkinson and shiffrin ( fig . (b ) ) . this psychological model partitions the human memory into an stm and an ltm . on the arrival of an input stimulus , information is first stored in the stm . however , upon frequent rehearsal , information gets transferred to the ltm . while the `` forgetting '' phenomena occurs at a fast rate in the stm , information can be stored for a much longer duration in the ltm . in order to mimic such volatile synaptic plasticity mechanisms , a nanoelectronic device is required that is able to undergo meta - stable resistance transitions depending on the frequency of the input and also transition to a long - term stable resistance state on frequent stimulations . hence a competition between synaptic memory reinforcement or strengthening and memory loss is a crucial requirement for such nanoelectronic synapses . in the next section , we will describe the mapping of the magnetization dynamics of a nanomagnet to such volatile synaptic plasticity mechanisms observed in the brain . let us first describe the device structure and principle of operation of an mtj as shown in fig . (a ) . the device consists of two ferromagnetic layers separated by a tunneling oxide barrier ( tb ) . the magnetization of one of the layers is magnetically `` pinned '' and hence it is termed as the `` pinned '' layer ( pl ) . the magnetization of the other layer , denoted as the `` free layer '' ( fl ) , can be manipulated by an incoming spin current . the mtj structure exhibits two extreme stable conductive states the low conductive `` anti - parallel '' orientation ( ap ) , where pl and fl magnetizations are oppositely directed and the high conductive `` parallel '' orientation ( p ) , where the magnetization of the two layers are in the same direction . let us consider that the initial state of the mtj synapse is in the low conductive ap state . considering the input stimulus ( current ) to flow from terminal t2 to terminal t1 , electrons will flow from terminal t1 to t2 and get spin - polarized by the pl of the mtj . subsequently , these spin - polarized electrons will try to orient the fl of the mtj `` parallel '' to the pl . it is worth noting here that the spin - polarization of incoming electrons in the mtj is analogous to the release of neurotransmitters in a biological synapse . the stp and ltp mechanisms exhibited in the mtj due to the spin - polarization of the incoming electrons can be explained by the energy profile of the fl of the mtj . let the angle between the fl magnetization , , and the pl magnetization , , be denoted by . the fl energy as a function of has been shown in fig . (a ) where the two energy minima points ( and ) are separated by the energy barrier , . during the transition from the ap state to the p state , the fl has to transition from to . upon the receipt of an input stimulus , the fl magnetization proceeds `` uphill '' along the energy profile ( from initial point 1 to point 2 in fig . (a ) ) . however , since point 2 is a meta - stable state , it starts going `` downhill '' to point 1 , once the stimulus is removed . if the input stimulus is not frequent enough , the fl will try to stabilize back to the ap state after each stimulus . however , if the stimulus is frequent , the fl will not get sufficient time to reach point 1 and ultimately will be able to overcome the energy barrier ( point 3 in fig . (a ) ) . it is worth noting here , that on crossing the energy barrier at , it becomes progressively difficult for the mtj to exhibit stp and switch back to the initial ap state . this is in agreement psychological model of human memory where it becomes progressively difficult for the memory to `` forget '' information during transition from stm to ltm . hence , once it has crossed the energy barrier , it starts transitioning from the stp to the ltp state ( point 4 in fig . (a ) ) . the stability of the mtj in the ltp state is dictated by the magnitude of the energy barrier . the lifetime of the ltp state is exponentially related to the energy barrier . for instance , for an energy barrier of used in this work , the ltp lifetime is hours while the lifetime can be extended to around years by engineering a barrier height of . the lifetime can be varied by varying the energy barrier , or equivalently , volume of the mtj . the stp - ltp behavior of the mtj can be also explained from the magnetization dynamics of the fl described by landau - lifshitz - gilbert ( llg ) equation additional term to account for the spin momentum torque according to slonczewski , where , is the unit vector of fl magnetization , is the gyromagnetic ratio for electron , is gilberts damping ratio , is the effective magnetic field including the shape anisotropy field for elliptic disks calculated using , is the number of spins in free layer of volume ( is saturation magnetization and is bohr magneton ) , and is the spin current generated by the input stimulus ( is the spin - polarization efficiency of the pl ) . thermal noise is included by an additional thermal field , , where is a gaussian distribution zero mean and unit standard deviation , is boltzmann constant , is the temperature and is the simulation time step . equation can be reformulated by simple algebraic manipulations as , hence , in the presence of an input stimulus the magnetization of the fl starts changing due to integration of the input . however , in the absence of the input , it starts leaking back due to the first two terms in the rhs of the above equation . it is worth noting here that , like traditional semiconductor memories , magnitude and duration of the input stimulus will definitely have an impact on the stp - ltp transition of the synapse . however , frequency of the input is a critical factor in this scenario . even though the total flux through the device is same , the synapse will conditionally change its state if the frequency of the input is high . we verified that this functionality is exhibited in mtjs by performing llg simulations ( including thermal noise ) . the conductance of the mtj as a function of can be described by , where , is the mtj conductance in the p ( ap ) orientation respectively . as shown in fig . (b ) , the mtj conductance undergoes meta - stable transitions ( stp ) and is not able to undergo ltp when the time interval of the input pulses is large . however , on frequent stimulations time interval as , the device undergoes ltp transition incrementally . (b ) and ( c ) illustrates the competition between memory reinforcement and memory decay in an mtj structure that is crucial to implement stp and ltp in the synapse . we demonstrate simulation results to verify the stp and ltp mechanisms in an mtj synapse depending on the time interval between stimulations . the device simulation parameters were obtained from experimental measurements and have been shown in table i. table i. device simulation parameters + the mtj was subjected to 10 stimulations , each stimulation being a current pulse of magnitude and in duration . as shown in fig . , the probability of ltp transition and average device conductance at the end of each stimulation increases decrease in the time interval between the stimulations . the dependence on stimulation time interval can be further characterized by measurements corresponding to paired - pulse facilitation ( ppf : synaptic plasticity increase when a second stimulus follows a previous similar stimulus ) and post - tetanic potentiation ( ptp : progressive synaptic plasticity increment when a large number of such stimuli are received successively ) . depicts such ppf ( after 2nd stimulus ) and ptp ( after 10th stimulus ) measurements for the mtj synapse variation in the stimulation interval . the measurements closely resemble measurements performed in frog neuromuscular junctions where ppf measurements revealed that there was a small synaptic conductivity increase when the stimulation rate was frequent enough while ptp measurements indicated ltp transition on frequent stimulations fast decay in synaptic conductivity on decrement in the stimulation rate . hence , stimulation rate indeed plays a critical role in the mtj synapse to determine the probability of ltp transition . the psychological model of stm and ltm utilizing such mtj synapses was further explored in a memory array . the array was stimulated by a binary image of the purdue university logo where a set of 5 pulses ( each of magnitude and in duration ) was applied for each on pixel . the snapshots of the conductance values of the memory array after each stimulus have been shown for two different stimulation intervals of and respectively . while the memory array attempts to remember the displayed image right after stimulation , it fails to transition to ltm for the case and the information is eventually lost after stimulation . however , information gets transferred to ltm progressively for . it is worth noting here , that the same amount of flux is transmitted through the mtj in both cases . the simulation not only provides a visual depiction of the temporal evolution of a large array of mtj conductances as a function of stimulus but also provides inspiration for the realization of adaptive neuromorphic systems exploiting the concepts of stm and ltm . readers interested in the practical implementation of such arrays of spintronic devices are referred to ref . the contributions of this work over state - of - the - art approaches may be summarized as follows . this is the first theoretical demonstration of stp and ltp mechanisms in an mtj synapse . we demonstrated the mapping of neurotransmitter release in a biological synapse to the spin polarization of electrons in an mtj and performed extensive simulations to illustrate the impact of stimulus frequency on the ltp probability in such an mtj structure . there have been recent proposals of other emerging devices that can exhibit such stp - ltp mechanisms like synapses and memristors . however , it is worth noting here , that input stimulus magnitudes are usually in the range of volts ( 1.3v in and 80mv in ) and stimulus durations are of the order of a few msecs ( 1ms in and 0. in ) . in contrast , similar mechanisms can be exhibited in mtj synapses at much lower energy consumption ( by stimulus magnitudes of a few hundred and duration of a few ) . we believe that this work will stimulate proof - of - concept experiments to realize such mtj synapses that can potentially pave the way for future ultra - low power intelligent neuromorphic systems capable of adaptive learning . the work was supported in part by , center for spintronic materials , interfaces , and novel architectures ( c - spin ) , a marco and darpa sponsored starnet center , by the semiconductor research corporation , the national science foundation , intel corporation and by the national security science and engineering faculty fellowship . j. schemmel , j. fieres , and k. meier , in neural networks , 2008 . ijcnn 2008.(ieee world congress on computational intelligence ) . ieee international joint conference on .1em plus 0.5em minus 0.4emieee , 2008 , pp . 431438 . b. l. jackson , b. rajendran , g. s. corrado , m. breitwisch , g. w. burr , r. cheek , k. gopalakrishnan , s. raoux , c. t. rettner , a. padilla et al . , `` nanoscale electronic synapses using phase change devices , '' acm journal on emerging technologies in computing systems ( jetc ) , vol . 9 , no . 2 , p. 12 , 2013 . m. n. baibich , j. m. broto , a. fert , f. n. van dau , f. petroff , p. etienne , g. creuzet , a. friederich , and j. chazelas , `` giant magnetoresistance of ( 001 ) fe/(001 ) cr magnetic superlattices , '' physical review letters , 61 , no . 21 , p. 2472 , 1988 . g. binasch , p. grnberg , f. saurenbach , and w. zinn , `` enhanced magnetoresistance in layered magnetic structures antiferromagnetic interlayer exchange , '' physical review b , vol . 39 , no . 7 , p. 4828 , 1989 . w. scholz , t. schrefl , and j. fidler , `` micromagnetic simulation of thermally activated switching in fine particles , '' journal of magnetism and magnetic materials , vol . 233 , no . 3 , pp . 296304 , 2001 . pai , l. liu , y. li , h. tseng , d. ralph , and r. buhrman , `` spin transfer torque devices utilizing the giant spin hall effect of tungsten , '' applied physics letters , vol . 101 , no . 12 , p. 122404 , 2012 . h. noguchi , k. ikegami , k. kushida , k. abe , s. itai , s. takaya , n. shimomura , j. ito , a. kawasumi , h. hara et al . , in solid - state circuits conference-(isscc ) , 2015 ieee international .1em plus 0.5em minus 0.4emieee , 2015 , pp . t. ohno , t. hasegawa , t. tsuruoka , k. terabe , j. k. gimzewski , and m. aono , `` short - term plasticity and long - term potentiation mimicked in single inorganic synapses , '' nature materials , vol . 10 , no . 8 , pp . 591595 , 2011 . r. yang , k. terabe , y. yao , t. tsuruoka , t. hasegawa , j. k. gimzewski , and m. aono , `` synaptic plasticity and memory functions achieved in a wo3- x - based nanoionics device by using the principle of atomic switch operation , '' nanotechnology , vol . 24 , no . 38 , p. 384003", "summary": "synaptic memory is considered to be the main element responsible for learning and cognition in humans . although traditionally non - volatile long - term plasticity changes have been implemented in nanoelectronic synapses for neuromorphic applications , recent studies in neuroscience have revealed that biological synapses undergo meta - stable volatile strengthening followed by a long - term strengthening provided that the frequency of the input stimulus is sufficiently high . such `` memory strengthening '' and `` memory decay '' functionalities can potentially lead to adaptive neuromorphic architectures . in this paper , we demonstrate the close resemblance of the magnetization dynamics of a magnetic tunnel junction ( mtj ) to short - term plasticity and long - term potentiation observed in biological synapses . we illustrate that , in addition to the magnitude and duration of the input stimulus , frequency of the stimulus plays a critical role in determining long - term potentiation of the mtj . such mtj synaptic memory arrays can be utilized to create compact , ultra - fast and low power intelligent neural systems ."}
{"article": "the segmentation process as a whole can be thought of as consisting of two tasks : recognition and delineation . recognition is to determine roughly `` where '' the object is and to distinguish it from other object - like entities . although delineation is the final step for defining the spatial extent of the object region / boundary in the image , an efficient recognition strategy is a key for successful delineation . in this study , a novel , general method is introduced for object recognition to assist in segmentation ( delineation ) tasks . it exploits the pose relationship that can be encoded , via the concept of ball scale ( b - scale ) , between the binary training objects and their associated images . as an alternative to the manual methods based on initial placement of the models by an expert in the literature , model based methods can be employed for recognition . for example , in , the position of an organ model ( such as liver ) is estimated by its histogram . in , generalized hough transform is succesfully extended to incorporate variability of shape for 2d segmentation problem . atlas based methods are also used to define initial position for a shape model . in , affine registration is performed to align the data into an atlas to determine the initial position for a shape model of the knee cartilage . similarly , a popular particle filtering algorithm is used to detect the starting pose of models for both single and multi - object cases . however , due to the large search space and numerous local minimas in most of these studies , conducting a global search on the entire image is not a feasible approach . in this paper , we investigate an approach of automatically recognizing objects in 3d images without performing elaborate searches or optimization . the proposed method consists of the following key ideas and components : * 1 . model building : * after aligning image data from all subjects in the training set into a common coordinate system via 7-parameter affine registration , the live - wire algorithm is used to segment different objects from subjects . segmented objects are used for the automatic extraction of landmarks in a slice - by - slice manner . from the landmark information for all objects , a model assembly is constructed . b - scale encoding : * the b - scale value at every voxel in an image helps to understand `` objectness '' of a given image without doing explicit segmentation . for each voxel , the radius of the largest ball of homogeneous intensity is weighted by the intensity value of that particular voxel in order to incorporate appearance ( texture ) information into the object information ( called intensity weighted b - scale : ) so that a model of the correlations between shape and texture can be built . a simple and proper way of thresholding the b - scale image yields a few largest balls remaining in the image . these are used for the construction of the relationship between the segmented training objects and the corresponding images . the resulting images have a strong relationship actual delineated objects . relationship between and : * a principal component system is built via pca for the segmented objects in each image , and their mean system , denoted , is found over all training images . has an origin and three axes . similarly the mean system , denoted , for intensity weighted b - scale images is found . finally the transformation that maps to is found . given an image to be segmented , the main idea here is to use to facilitate a quick placement of in proper pose as indicated in step 4 below . * hierarchical recognition : * for a given image , is obtained and its system , denoted is computed subsequently . assuming the relationship of to to be the same as of to , and assuming that offers the proper pose of in the training images , we use transformation and to determine the pose of in . this level of recognition is called coarse recognition . further refinement of the recognition can be done using the skin boundary object in the image requirement that a major portion of should lie inside the body region delimited by the skin boundary . moreover , a little search inside the skin boundary can be done for the fine tuning , however , since offered coarse recognition method gives high recognition rates , there is no need to do any elaborate searches . we will focus on the fine tuning of coarse recognition for future study . the finest level of recognition requires the actual delineation algorithm itself , which is a hybrid method in our case and called gc - asm ( synergistic integration of graph - cut and active shape model ) . this delineation algorithm is presented in a companion paper submitted to this symposium . a convenient way of achieving incorporation of prior information automatically in computing systems is to create and use a flexible model to encode information such as the expected size , shape , appearance , and position of objects in an image . among such information , shape and appearance are two complementary but closely related attributes of biological structures in images , and hence they are often used to create statistical models . in particular , shape has been used both in high and low level image analysis tasks extensively , and it has been demonstrated that shape models ( such as active shape models ( asms ) ) can be quite powerful in compensating for misleading information due to noise , poor resolution , clutter , and occlusion in the images . therefore , we use asm to estimate population statistics from a set of examples ( training set ) . in order to guarantee 3d point correspondences required by asm , we build our statistical shape models combining semi - automatic methods : ( 1 ) manually selected anatomically correspondent slices by an expert , and ( 2 ) semi - automatic way of specifying key points on the shapes starting from the same anatomical locations . once step ( 1 ) is accomplished , the remaining problem turns into a problem of establishing point correspondence in 2d shapes , which is easily solved . it is extremely significant to choose correct correspondences so that a good representation of the modelled object results . although landmark correspondence is usually established manually by experts , it is time - consuming , prone to errors , and restricted to only 2d objects . because of these limitations , a semi - automatic landmark tagging method , equal space landmarking , is used to establish correspondence between landmarks of each sample shape in our experiments . although this method is proposed for 2d objects , and equally spacing a fixed number of points for 3d objects is much more difficult , we use equal space landmarking technique in pseudo-3d manner where 3d object is annotated slice by slice . let be a single shape and assume that its finite dimensional representation after the landmarking consisting of landmark points positions , where are cartesian coordinates of the point on the shape . equal space landmark tagging for points for on shape boundaries ( contours ) starts by selecting an initial point on each shape sample in training set and equally space a fixed number of points on each boundary automatically . selecting the starting point has been done manually by annotating the same anatomical point for each shape in the training set . figure shows annotated landmarks for five different objects ( skin , liver , right kidney , left kidney , spleen ) in a ct slice of the abdominal region . note that different number of landmarks are used for different objects considering their size . \\(1 ) the b - scale image of a given image captures object morphometric information without requiring explicit segmentation . b - scales constitute fundamental units of an image in terms of largest homogeneous balls situated at every voxel in the image . the b - scale concept has been previously used in object delineation , filtering and registration . our results suggest that their ability to capture object geography in conjunction shape models may be useful in quick and simple yet accurate object recognition strategies . ( 2 ) the presented method is general and does not depend on exploiting the peculiar characteristics of the application situation . ( 3 ) the specificity of recognition increases dramatically as the number of objects in the model increases . ( 4 ) we emphasize that both modeling and testing procedures are carried out on the ct data sets that are part of the clinical pet / ct data routinely acquired in our hospital . the ct data set are thus of relatively poor ( spatial and contrast ) resolution compared to other ct - alone studies without contrast . we expect better performance if higher resolution ct data are employed in modeling or testing . this paper is published in spie medical imaging conference - 2010 . falcao , a.x . , udupa , j.k . , samarasekera , s. , sharma , s. , hirsch , b.e . , and lotufo , r.a . , 1998 user - steered image segmentation paradigms : live wire and live lane . graph . models image process . 60 ( 4 ) , pp . 233260 . kokkinos , i. , maragos , p. , 2009 . synergy between object recognition and image segmentation using the expectation - maximization algorithm . ieee transactions on pattern analysis and machine intelligience , vol.31 ( 8) , pp.14861501 . brejl , m. , sonka , m. , 2000 . object localization and border detection criteria design in edge - based image segmentation : automated learning from examples . ieee transactions on medical imaging , vol.19 ( 10 ) , pp.973985 . fripp , j. , crozier , s. , warfield , s.k . , ourselin , s. , 2005 . automatic initialisation of 3d deformable models for cartilage segmentation . in proceedings of digital image computing : techniques and applications , pp .", "summary": "this paper investigates , using prior shape models and the concept of ball scale ( b - scale ) , ways of automatically recognizing objects in 3d images without performing elaborate searches or optimization . that is , the goal is to place the model in a single shot close to the right pose ( position , orientation , and scale ) in a given image so that the model boundaries fall in the close vicinity of object boundaries in the image . this is achieved via the following set of key ideas : ( a ) a semi - automatic way of constructing a multi - object shape model assembly . ( b ) a novel strategy of encoding , via b - scale , the pose relationship between objects in the training images and their intensity patterns captured in b - scale images . ( c ) a hierarchical mechanism of positioning the model , in a one - shot way , in a given image from a knowledge of the learnt pose relationship and the b - scale image of the given image to be segmented . the evaluation results on a set of 20 routine clinical abdominal female and male ct data sets indicate the following : ( 1 ) incorporating a large number of objects improves the recognition accuracy dramatically . ( 2 ) the recognition algorithm can be thought as a hierarchical framework such that quick replacement of the model assembly is defined as coarse recognition and delineation itself is known as finest recognition . ( 3 ) scale yields useful information about the relationship between the model assembly and any given image such that the recognition results in a placement of the model close to the actual pose without doing any elaborate searches or optimization . ( 4 ) effective object recognition can make delineation most accurate ."}
{"article": "studies of charm decays are pursued for several different reasons . first of all , there is the possibility of directly observing new physics beyond the standard model ( sm ) , since the effects of cp violation due to sm processes is highly suppressed allowing new physics contributions to be more easily seen than in decays where the sm processes typically have large effects . mixing also is interesting because it could come from either sm or new physics ( np ) processes , and could teach us interesting lessons . another important reason for detailed charm studies is that most s , % , decay into charm , so knowledge about charm decays is particularly useful for decay studies . especially interesting are absolute branching ratios , resonant substructures in multi - body decays , phases on dalitz plots , etc .. other heavier objects such as top quarks decay into quarks and higgs particles may decay large rates to , again making charm studies important . furthermore , charm can teach us a great deal about strong interactions , especially decay constants and final state interactions . charm has been studied at colliders at threshold , first by the mark iii collaboration and more recently by bes and cleo - c , at higher energies , and at fixed target and hadron collider experiments . the detection techniques are rather different at threshold than in other experiments . the resonance decays into ; the world average cross - section is 3.72.09 nb for production and 2.82.09 nb for production . production is studied at , where the cross - section for + is nb . the underlying light quark continuum \" background is about 14 nb . the relatively large cross - sections , relatively large branching ratios and sufficient luminosities , allow experiments to fully reconstruct one as a tag . \" since the charge and flavor of the tag is then uniquely determined , the rest of the event can be examined for characteristics of the other known \" particle . to measure absolute branching ratios , for example at the , the rest of the event is fully reconstructed , as well as the tag . at the meson final states are reconstructed by first evaluating the difference in the energy , , of the decay products beam energy . candidates consistent zero are selected and then the beam - constrained mass is evaluated , where runs over all the final state particles . examples of single and double reconstruction are presented in fig . (a ) that shows the distribution for a or final states . these single tags \" show a large signal and a very small background . (b ) shows a double \" tag sample where both and candidates in the same event are reconstructed . distributions for candidates from either or modes . ( b ) the distribution for candidates for candidates from and modes . the solid curves are a fits to the signals plus the backgrounds , that are indicated by the dashed shapes . the signals are asymmetric due to radiation of the electron beams.,title=\"fig:\",width=302 ] distributions for candidates from either or modes . ( b ) the distribution for candidates for candidates from and modes . the solid curves are a fits to the signals plus the backgrounds , that are indicated by the dashed shapes . the signals are asymmetric due to radiation of the electron beams.,title=\"fig:\",width=294 ] other experiments make use of the both the approximately picosecond lifetimes of charm to identify detached vertices , and the decay , which also serves as a flavor tag in the case of transitions . in charm meson decays , usually a single branching ratio sets the scale for determinations of most other rates , that are measured relative to it . for and these modes are and , respectively . cleo - c , on the other hand uses a different technique where the branching ratios of several modes are determined simultaneously and all absolutely . consider an ensemble of modes , that are both singly reconstructed and also doubly reconstructed , where all combinations of modes may be used . i denote the number of observed single tag charmed particles as , anti - charmed particles as , and double tags as . they are related to the number of events ( either charged or neutral ) through their branching ratios as where and are the reconstruction efficiencies in single and double tag events for each mode . ( in practice the differences in each mode between single and double tag events are small , and . ) solving these equations we find cleo - c has recently updated their absolute branching ratio measurements using a 281 pb data sample , an approximately 5 times larger data sample than used by them for their previous publication . the new preliminary results are shown in table . ( in this table when two errors follow a number , the first error is statistical and the second systematic ; this will be true for all results quoted in this paper unless specifically indicated . ) the absolute branching fractions for charm mesons have been measured unprecedented accuracy . combining the pdg values preliminary cleo - c results for and decays , and using the cleo - c results for , i find cleo - c does not quote a branching ratio for mode because of interferences on the dalitz plot . the or the modes should be used for normalization . since most of the decay modes have been measured as ratios to the mode , i extract an effective branching ratio these rates can be used for many purposes . for example , adding up the number of charm quarks produced in each meson decay at the resonance by summing the , , , charmed baryon and twice the charmonium yields gives a rate of 1.09.04 , where the largest error comes from the yield . there is no definitive evidence for mixing . the best limits yet are % and both at 95% c. l. the limit on of about 8% is just beginning to probe an interesting range . there are two hints that mixing may be soon found . belle finds consistency mixing at 3.9% c. l. in wrong - sign decays and babar finds consistency mixing at 4.5% c. l. in wrong sign decays , thus making further searches more interesting . there have not been any observations of cp or t violation .", "summary": "i discuss new results on absolute branching ratios of charm mesons into specific exclusive final states , cabibbo suppressed decay rates , inclusive decays to mesons , limits on mixing , cp violation and t violation . preliminary results from cleo - c now dominate the world average absolute branching fractions . for the most important normalization modes involving and , the averages are for the cleo - c measures . using this rate , i derive an effective branching ratio , that is appropriate for use in extracting other branching fractions that have often been measured relative to this mode . this number is compared other determinations ."}
{"article": "quantum - mechanical fluctuations during an early epoch of inflation provide a plausible mechanism to generate the energy - density perturbations responsible for observed cosmological structure . while it has been known for quite some time that inflation is consistent open spatial hypersurfaces ( gott 1982 ; guth & weinberg 1983 ) , attention was initially focussed on models in which there are a very large number of -foldings during inflation , resulting in almost exactly flat spatial hypersurfaces for the observable part of the present universe ( guth 1981 ; also see kazanas 1980 ; sato 1981a , b ) . this was , perhaps , inevitable because of strong theoretical prejudice towards flat spatial hypersurfaces and their resulting simplicity . however , to get a very large number of -foldings during inflation it seems necessary that the inflation model have a small dimensionless parameter ( j. r. gott , private communication 1994 ; banks et al . 1995 ) , which would require an explanation . attempts to reconcile these favoured \" flat spatial hypersurfaces observational measures of a low value for the clustered - mass density parameter have concentrated on models in which one postulates the presence of a cosmological constant ( peebles 1984 ) . in the simplest flat- model one assumes a scale - invariant ( harrison 1970 ; peebles & yu 1970 ; zeldovich 1972 ) primordial power spectrum for gaussian adiabatic energy - density perturbations . such a spectrum is generated by quantum - mechanical fluctuations during an early epoch of inflation in a spatially - flat model , provided that the inflaton potential is reasonably flat ( fischler , ratra , & susskind 1985 , and", "summary": "cut - sky orthogonal mode analyses of the -dmr 53 and 90 ghz sky maps are used to determine the normalization of a variety of open cosmogonical models based on the cold dark matter scenario . to constrain the allowed cosmological - parameter range for these open cosmogonies , the predictions of the dmr - normalized models are compared to various observational measures of cosmography and large - scale structure , viz . : the age of the universe ; small - scale dynamical estimates of the clustered - mass density parameter ; constraints on the hubble parameter , the x - ray cluster baryonic - mass fraction , and the matter power spectrum shape parameter ; estimates of the mass perturbation amplitude ; and constraints on the large - scale peculiar velocity field . the open - bubble inflation model ( ratra & peebles 1994 ; bucher , goldhaber , & turok 1995 ; yamamoto , sasaki , & tanaka 1995 ) is consistent current determinations of the 95% confidence level ( c.l . ) range of these observational constraints . more specifically , for a range of , the model is reasonably consistent recent high - redshift estimates of the deuterium abundance which suggest , provided ; recent high - redshift estimates of the deuterium abundance which suggest favour , while the old nucleosynthesis value requires . small shifts in the inferred -dmr normalization amplitudes due to : ( 1 ) the small differences between the galactic- and ecliptic - coordinate sky maps , ( 2 ) the inclusion or exclusion of the quadrupole moment in the analysis , ( 3 ) the faint high - latitude galactic emission treatment , and , ( 4 ) the dependence of the theoretical cosmic microwave background anisotropy angular spectral shape on the value of and , are explicitly quantified . the dmr data alone do not possess sufficient discriminative power to prefer any values for , , or at the 95% c.l . for the models considered . at a lower c.l . , and when the quadrupole moment is included in the analysis , the dmr data are most consistent either or ( depending on the model considered ) . however , when the quadrupole moment is excluded from the analysis , the dmr data are most consistent in all open models considered ( ) , including the open - bubble inflation model . earlier claims ( yamamoto & bunn 1996 ; bunn & white 1996 ) that the dmr data require a 95% c.l . lower bound on are not supported by our ( complete ) analysis of the four - year data : the dmr data alone can not be used to meaningfully constrain . # 10= 0.00em0 - 0 0.03em0 - 0 0.00em.04em0 - 0 0.03em.04em0 - 00 # 1;#2;#3;#4;#5 # 1 # 2 , # 3 , # 4 , # 5 # 1;#2;#3 # 1 # 2 , # 3 # 1;#2;#3 # 1 # 2 , # 3 # 1 mit - ctp-2548 , kuns 1399 0.5 cm august 1996"}
{"article": "formation and bose - einstein condensation ( bec ) of molecules have recently been achieved based on ultracold atoms magnetically - tuned feshbach resonances . in these experiments , feshbach coupling is induced by tuning a foreign molecular state near the scattering continuum , which allows for an efficient transfer of colliding atoms into molecules . this method works for virtually all alkali atoms , and can create ultracold molecules from various sources including bose condensates , degenerate fermi gases , or normal thermal gases . feshbach molecules have special and unique properties . they typically populate only one weakly - bound quantum state , and the bound state can strongly couple to the scattering continuum via feshbach resonance . we may ask the following question : should feshbach molecules rather be considered as molecules in a specific rovibrational state or as pairs of scattering atoms near the continuum ? this distinction is particularly crucial in the studies of the bec to bcs ( bardeen - cooper - schrieffer state ) crossover in degenerate fermi gases , which call for a clarification of the quantum nature of the feshbach molecules . molecular states near feshbach resonances have been recently investigated based on sophisticated and complete two - body or many - body theory and multi - channel scattering calculations . all works suggest that the feshbach molecule is generally a coherent mixture of the foreign molecule in the closed channel and long - range atom pair in the open scattering channel . near resonances large resonance widths , the molecules can be well approximated as pairs in the open channel . for narrow resonances , as suggested by numerical calculation , the closed channel dominates and a short - range molecule picture is appropriate . in this paper , we use a simple two - channel model to describe two interacting atoms near a feshbach resonance ( . ii ) . to account for the finite interaction range of real atoms , we introduce a spherical box potential , which allows us to analytically calculate the molecular bound state in different regimes and their threshold behavior ( . iii and . iv ) . finally , we apply our model to feshbach molecules in recent fermi gas experiments and to characterize the associated feshbach resonances ( . we model the interaction of two identical , ultracold atoms mass based on an open channel that supports the scattering continuum and a closed channel that supports the foreign bound state . the wave function of the atoms is generally expressed as , where and are the amplitudes in the open and closed channels , respectively , and is the inter - atomic separation . we assume the interaction is described by a spherical box potential interaction range of , see fig . ( 1 ) . for , the potential energy of the open channel is 0 and the closed channel . for , the open ( closed ) channel has an attractive potential of , and a coupling term between the channels . the wave function satisfies the schrdinger equation : . a bound state energy relative to the scattering continuum is supported by the closed channel.,width=211 ] the solution of the above equation for zero scattering energy can be expressed as : where the scattering length and are constants , are the eigen wave numbers \" for associated eigen states . based on the boundary conditions and , we get the latter equation shows how in general , each channel contributes to the scattering length . in cold atom systems , feshbach resonances are , in most cases , induced by hyperfine interactions or spin - spin interactions . both interactions are many orders of magnitude weaker than the relevant short range exchange potential . it is an excellent approximation to assume and . hence , we have , and . in this limit , the closed channel contribution is significant only when the foreign state is close to the continuum , in which case the last term in eq . ( 7 ) diverges . given the energy of the closed channel state as and , the boundary condition allows us to expand the last term in eq . ( 7 ) as . here characterizes the feshbach coupling strength . to the same order of expansion , the middle term in eq . ( 7 ) is a constant across the resonance and can be identified as , where is the background scattering length . equation ( 7 ) reduces to experimentally , the relative energy between the continuum and the bare state can be adjusted linearly by a magnetic field -induced zeeman shift , where and is the magnetic moment of the open(closed ) channel . replacing by , we can rewrite eq . ( 8) in terms of the magnetic field as where the resonance width and the resonance position are given by several interesting features are shown here . first of all , we find the resonance width is proportional to both the feshbach coupling and the background scattering properties . the latter dependence is due to the fact that the scattering amplitude at short range is proportional to the scattering length . a larger short range scattering amplitude leads to a stronger coupling to the closed channel . secondly and importantly , the resonance position is offset by exactly relative to the crossing of the bare state and the continuum , , see eq . ( 11 ) . for a positive scattering length , this shift is negative . this feature leads to the renormalization \" of the feshbach resonance location discussed in ref . . to understand the origin of the resonance shift , we should return to eq . the divergence of the scattering length occurs when the open channel contribution ( middle term ) is exactly canceled by the closed channel one ( last term ) . for systems large background scattering lengths and strong feshbach couplings , this cancelation can occur even when the bare state is far away from the continuum . a large resonance shift then results . now we turn to the binding energy of the molecules . assuming a bound eigen state exists near the continuum at , where is the binding energy , we can determine by following essentially the same calculation as eq . ( 1)-(7 ) . the equivalence of eq . ( 7 ) gives where . assuming and the bound states in both channels are close to the continuum , namely , and , we can expand the two terms on the right side of eq . ( 12 ) to leading order as and , respectively . equation ( 12 ) then reduces to this result shows the evolution of the eigen state near the resonance . similar result is obtained in ref . based on a contact potential . we can immediately see that in the absence of the feshbach coupling , the solutions of eq . ( 13 ) are and ( for ) , which exactly correspond to the bare bound states in the closed channel and the open channel ( for ) , respectively . in the presence of the feshbach coupling , eq . ( 13 ) suggests an avoided level crossing \"- like energy structure , see fig . ( 2 ) , which also illustrates the resonance position shifts . the level crossing , however , is not hyperbolic as it is in a two - level system . in particular , at small binding energies , the bound state energy approaches the continuum quadratically , see fig . ( 2 ) inset . far below the continuum , the bound state approaches the bare state in the closed channel . , solid lines ) . we assume ( a ) and and ( b ) and , where can be any relevant length scale . arrows mark the offset resonance positions . insets show the threshold behavior of the bound state.,width=268 ] to better quantify the role of the open and closed channel , we can write the wave function of the eigen state as and , approximations , satisfies and the mixing angle is defined below . we show in eq . ( 15 ) that the eigen state generally occupies both the closed channel and open channel . we can introduce a mixing amplitude as the amplitude in the closed channel the mixing fraction can be evaluated by a direct integration of the closed channel wave function . alternatively , noticing that the mixing also leads to a dependence of the eigen state on the bare state , we can also derive from the dependence of on , or from the magnetic moment of the feshbach molecule . all methods lead to the same result despite the seemingly complex equations shown in previous sections , the feshbach molecules are simple and universal near the scattering continuum . expanding eq . ( 13 ) small and using eq . ( 9)-(11 ) , we find the binding energy of the feshbach molecules has a simple dependence on the scattering length and increases quadratically in magnetic field near the resonance , namely , where . equation ( 20 ) shows identical dependence on scattering length and interaction range as of single channel molecules in the threshold regime . furthermore , taking the limit in eq . ( 14 ) and ( 19 ) , we find the molecular wave function here is purely in the open channel . its spatial extent is determined by quantum uncertainty , , and can be much larger than the interaction range . in this limit , the feshbach molecules are identical to long - range atom pairs in a single open channel . by expanding eq . ( 19 ) at small and using eq . ( 13 ) , we find the closed channel fraction can be expressed as where . from eq . ( 22 ) , we see that provides the leading order estimation of the closed channel admixture . when or ( this condition applies when ) , the feshbach molecule is purely in the open channel . as expected , the threshold regime is wider for resonances larger and . we can further determine the open channel - dominated \" regime by setting in eq . ( 19 ) . for resonances small , this condition corresponds to , which , in terms of magnetic field , maps to only a small fraction of near the resonance . for resonances large , the open channel dominates when , which covers the full resonance width when , and covers the entire upper branch of the bound state when . based on the range of the single channel regime , we suggest the broad(narrow ) resonances be defined as those . within the width of the feshbach resonance , the molecules associated broad ( narrow ) resonance are better described as long range pairs in the open channel ( short range molecules in the closed channel ) . we note that this definition is purely based on two - body physics . .parameters of the li and k feshbach resonances . interaction range is derived from ref . , see text . feshbach coupling is derived from eq . is bohr radius and is bohr magneton . ( dotted lines ) and mixing fractions ( solid lines ) of the molecules near the li and k feshbach resonances . the curves are calculated from eq . ( 13 ) , eq . ( 19 ) and the parameters in table 1 . binding energies from multi - channel calculation ( dashed lines ) , from jila group measurement ( open square ) and the mixing fractions measurement from rice group ( open circles ) are shown for comparison . the shaded areas indicate the typical bec - bcs crossover regimes , .,width=268 ] finally , we apply our model to the li and k feshbach molecules created in recent bec - bcs experiments . these molecules are stable near the resonance and both the molecular binding energies and the scattering lengths have been well measured and studied . to model the interaction of atoms , we adopt , , and from recent measurements and numerical calculations . to account for the finite range of the atomic interaction , which at low temperatures is determined by the van der waals potential of , we choose the interaction range in our model to be the mean scattering length defined in ref . this choice ensures the same behavior of the scattering length in the threshold regime . all parameters are given in table i. in fig . ( 3 ) , we show the calculated binding energy and the mixing fraction of the feshbach molecules for the two li resonances and one k resonance . the results agree very well multi - channel calculation and the measurements on molecular binding energy , magnetic moment and mixing fraction . both the li resonance at 834 g and the k resonance are broad and , respectively . the open channel - dominated regimes of 210 mhz for the 834 g li resonance is also larger than the fermi energy of 20 khz in the experiments.(here the fermi wave number is . ) for the k resonance , the full upper branch of the molecular state is open channel dominated mixing fractions less than . therefore , we conclude the open channel description of these feshbach molecules in the crossover regime to be a good approximation . for the narrower li resonance at g , we obtain and 31 hz 20 khz . this indicates an extremely narrow open channel regime of less than 50 g near the resonance , where the gas parameter is still over . crossover experiments based on these feshbach molecules can not be described by open channel atom pairs and may lead to qualitatively different physics . we attribute the large difference between the two li resonances to their different couplings and very different background scattering length , see table i. in the above discussions , we note that fermi energy is an external parameter which depends on the density of the sample . whether the molecules in the crossover regime can be described by single channel strongly depends on the density . the parameter , however , provides a better and independent measure to classify feshbach resonances . we find that the two feshbach resonances in li are the two extremes of broad and narrow resonances and . in summary , the two - channel model provides a simple picture to understand the molecular state near the feshbach resonances . the analytic results of the molecular binding energy and mixing fraction on li and k agree and other sophisticated calculations very well . based on the threshold behavior of the bound state , we suggest a dimensionless parameter to assess the broadness \" of the feshbach resonance . we thank p.s . julienne and n. nygaard for stimulating discussions and r. grimm s lithium and cesium groups in innsbruck for the support during our visit . the author is partially supported by the lise - meitner program of the austrian science fund ( fwf ) . s. jochim , m. bartenstein , a. altmeyer , g. hendl , s. riedl , c. chin , j. hecker denschlag and r. grimm , science * 302 * , 2101 ( 2003 ) ; m. greiner , c.a . regal , d.s . jin , nature * 426 * , 537 ( 2003 ) ; m. zwierlein , c.a . stan , c.h . schunck , s.m.f . raupach , s. gupta , z. hadzibabic , and w. ketterle , phys . 91 * , 250401 ( 2003 ) . j. herbig , t. kraemer , m. mark , t. weber , c. chin , h .- c . ngerl , and r. grimm , science * 301 * , 1510 ( 2003 ) ; s. drr , t. volz , a. marte , and g. rempe phys . rev . * 92 * , 020406 ( 2004 ) ; k. xu , t. mukaiyama , j.r . abo - shaeer , j.k . chin , d. miller , and w. ketterle , phys . rev . lett . * 91 * , 210402 ( 2003 ) . b. marcelis , e.g.m . van kempen , b.j . verhaar , and s.j.j.m.f . kokkelmans , phys . a * 70 * , 012701 ( 2004 ) ; s.j.j.m.f . kokkelmans , j.n . milstein , m.l . chiofalo , r. walser , and m.j . holland , phys . a * 65 * , 053617 ( 2002 ) .", "summary": "we present a two - channel model to describe the quantum state of two atoms finite - range interaction near a feshbach resonance . this model provides a simple picture to analytically derive the wave function and the binding energy of the molecular bound state . the results agree excellently and multichannel calculations . for small binding energies , the system enters a threshold regime in which the feshbach molecules are identical to long range atom pairs in single channel . according to their threshold behavior , we find feshbach resonances can be classified into two types ."}
{"article": "the study of supernovae ( sne ) has greatly advanced in the last few years . intensive and highly automated monitoring of nearby galaxies ( e.g. , li et al . 1996 ; treffers et al . 1997 ; filippenko et al . 2001 ; dimai 2001 ; qiu & hu 2001 ) , wide - field , moderately deep surveys ( e.g. , reiss et al . 1998 ; gal - yam & maoz 1999 , 2002 ; hardin et al . 2000 ; schaefer 2000 ) , and cosmology - oriented , deep , high - redshift sn search projects ( perlmutter et al . 1997 ; schmidt et al . 1998 ) now combine to yield hundreds of new sn discoveries each year . ambitious programs that are currently planned or underway filippenko , a. v. , & chornock , r. 2001 , iau circ . 7754 filippenko , a. v. , li , w. d. , treffers , r. r. , & modjaz , m. 2001 , in small - telescope astronomy on global scales , ed . w. p. chen , c. lemme , & b. paczyski ( san francisco : asp , conf . 246 ) , 121 filippenko , a. v. , matheson , t. , & ho , l. c. 1993 , apj , 415 , l103 filippenko , a. v. , et al . 1992a , apj , 384 , l15 filippenko , a. v. , et al . 1992b , aj , 104 , 1543 filippenko , a. v. , et al . 1995b , apj , 450 , l11 fukugita , m. , ichikawa , t. , gunn , j. e. , doi , m. , shimasaku , k. , & schneider , d. p. 1996 , , 111 , 1748 galama , t. j. , et al . 1998 , nature , 395 , 670 gal - yam , a. , & maoz , d. 1999 , in `` cosmic explosions , '' ed . s. s. holt & w. w. zhang ( new york : aip ) , p. 107 gal - yam , a. , & maoz , d. 2000 , iau circ . 7405 gal - yam , a. , & maoz , d. 2002 , in preparation gal - yam , a. , maoz , d. , & sharon , k. 2002 , mnras , in press , astro - ph/0109089 gal - yam , a. , & shemmer , o. 2001 , iau circ . 7602 ; see http://wise-obs.tau.ac.il/avishay/local.html germany , l. m. , reiss , d. j. , sadler , e. m. , schmidt , b. p. , & stubbs , c. w. 2000 , , 533 , 320 goobar , a. , & perlmutter , s. 1995 , apj , 450 , 14 hamuy , m. , & pinto , p. a. 2002 , apjl , 566 , l63 hamuy , m. , et al . 2001 , apj , 558 , 615 hamuy , m. , et al . 2002 , aj , in press , astro - ph/0203491 hardin , d. , et al . 2000 , iau circ . 7406 hflich , p. , straniero , o. , limongi , m. , dominguez , i. , & chieffi , a. 2001 , in rev . mexicana astron . 10 , the seventh texas - mexico conference on astrophysics : flows , blows , and glows , ed . w. lee & s. torres - peimbert ( mexico , df : inst . astron . , unam ) , 157 iwamoto , k. , et al . 2000 , apj , 534 , 660 jannuzi , b. , et al . 2001 ; see http://www.noao.edu/noao/noaodeep johnson , h. l. 1965 ; see moro & munari 2000 for details jorgensen , h. e. , lipunov , v. m. , panchenko , i. e. , postnov , k. a. , & prokhorov , m. e. 1997 , , 486 , 110 kirshner , r. p. , & kwan , j. 1974 , apj , 193 , 27 krisciunas , k. , margon , b. , & szkody , p. 1998 , pasp , 110 , 1342 leibundgut , b. 1988 , ph.d . thesis , university of basel leonard , d. c. , filippenko , a. v. , barth , a. j. , & matheson , t. 2000 , apj , 536 , 239 leonard , d. c. , et al . 2002a , pasp , 114 , 35 leonard , d. c. , et al . 2002b , aj , submitted li , w. , filippenko , a. v. , treffers , r. r. , riess , a. g. , hu , j. , & qiu , y. 2001a , , 546 , 734 li , w. , et al . 1996 , iau circ . 6379 li , w. , et al . 2001b , pasp , 113 , 1178 loewenstein , m. 2000 , apj , 532 , 17 madau , p. , della valle , m. , & panagia , n. 1998 , mnras , 297 , l17 matheson , t. , filippenko , a. v. , li , w. , leonard , d. c. , & shields , j. c. 2001 , aj , 121 , 1648 matteucci , f. , & greggio , l. 1986 , , 154 , 279 miknaitis , g. , & krisciunas , k. 2001 , iau circ . 7778 miknaitis , g. , miceli , a. , stubbs , c. , covarrubias , r. , & lawton , b. 2001a , iau circ . 7731 miknaitis , g. , rest , a. , stubbs , c. , stoughton , c. , & sdss collaboration . 2001b , baas , 199.84.04 miller , d. l. , & branch , d. 1990 , aj , 100 , 530 minkowski , r. 1941 , pasp , 53 , 224 moro , d. , & munari , u. 2000 , a&as , 147 , 361 pain , r. , et al . 1996 , , 473 , 356 parodi , b. r. , saha , a. , sandage , a. , & tammann , g. a. 2000 , apj , 540 , 634 patat , f. , et al . 2001 , apj , 555 , 900 perlmutter , s. , et al . 1997 , apj , 483 , 565 perlmutter , s. , et al . 1999 , apj , 517 , 565 perlmutter , s. , & snap collaboration . 2000 , baas , 197.61.01 phillips , m. m. , lira , p. , suntzeff , n. b. , schommer , r. a. , hamuy , m. , & maza , j. 1999 , , 118 , 1766 qiu , y. , & hu , j. y. 2001 , iau circ . 7753 qiu , y. , li , w. , qiao , q. , & hu , j. 1999 , aj , 117 , 736 reiss , d. , germany , l. m. , schmidt , b. p. , & stubbs , c. w. 1998 , aj , 115 , 26 rest , a. , miceli , a. , & covarrubias , r. 2001 , iau circ . 7740 rhoads , j. e. 2001 , apj , 557 , 943 richards , g. t. , et al . 2001 , , 122 , 1151 richmond , m. w. et al . 1995 , , 109 , 2121 . riess , a. g. , et al . 1998 , aj , 116 , 1009 riess , a. g. , et al . 1999 , aj , 117 , 707 riess , a. g. , et al . 2001 , apj , 560 , 49 ruiz - lapuente , p. , & canal , r. 1998 , apj , 497 , l57 sadat , r. , blanchard , a. , guiderdoni , b. , & silk , j. 1998 , a&a , 331 , l69 schaefer , b. e. 2000 , iau circ . 7387 schlegel , d. j. , finkbeiner , d. p. , & davis , m. 1998 , apj , 500 , 525 schlegel , e. m. 1990 , mnras , 244 , 269 schmidt , b. p. , kirshner , r. p. , & eastman , r. g. 1992 , apj , 395 , 366 schmidt , b. p. , et al . 1994 , , 432 , 42 schmidt , b. p. , et al . 1998 , apj , 507 , 46 stoughton , c. , et al . 2002 , , 123 , 485 sullivan , m. , ellis , r. , nugent , p. , smail , i. , & madau , p. 2000 , , 319 , 549 treffers , r. r. , peng , c. y. , filippenko , a. v. , & richmond , m. w. 1997 , iau circ . 6627 tripp , r. 1998 , , 331 , 815 turatto , m. , et al . 2000 , apj , 534 , 57 vanden berk , d. e. , et al . 2001 , baas , 199.84.05 van dyk , s. d. , peng , c. y. , king , j. y. , filippenko , a. v. , treffers , r. r. , li , w. , & richmond , m. w. 2000 , pasp , 112 , 1532 weymann , r. j. , storrie - lombardi , l. j. , sawicki , m. , & brunner , r. 1999 , eds . , photometric redshifts and high - redshift galaxies ( san francisco : asp ) york , d. g. , et al . 2000 , aj , 120 , 1579 yungelson , l. , & livio , m. 2000 , apj , 528 , 108 clccc ia & 1994d & 22 & 0.0015 & 1,9 + & 1987l & 2 & 0.0074 & 1 + & 1995d & 4 & 0.0066 & 9 + & 1999dk & 5 & 0.0150 & 9 + & 1999ee & 12 & 0.0114 & 10 + ib & 1984l & 12 & 0.0051 & 1,9 + & 1991ar & 1 & 0.0152 & 2 + & 1998dt & 2 & 0.0150 & 2 + & 1999di & 1 & 0.0164 & 2 + & 1999dn & 3 & 0.0093 & 2 + ic & 1994i & 14 & 0.0015 & 1,3 + & 1990u & 8 & 0.0079 & 2 + & 1990b & 4 & 0.0075 & 2 + ii - p & 1999em & 27 & 0.0024 & 4 + & 1992h & 13 & 0.0060 & 1,9 + & 2001x & 12 & 0.0049 & 6,9 + iin & & 13 & 0.0030 & 5,7 + & 1994y & 1 & 0.0080 & 1 + & 1994ak & 1 & 0.0085 & 1 + iib & 1993j & 12 & 0 & 1 + & 1996cb & 3 & 0.0024 & 8 + total & & 172 & & + clccc 1991t - like & 1991 t & 12 & 0.0058 & 1,5 + & 1998es & 7 & 0.0106 & 5 + 1991bg - like & 1991bg & 5 & 0.0035 & 2,5 + & 1998bp & 2 & 0.0104 & 5 + & 1998de & 3 & 0.0166 & 5 + & 1999da & 4 & 0.0127 & 5 + 2000cx - like & 2000cx & 23 & 0.0079 & 3,4 + total & & 56 & & +", "summary": "large numbers of supernovae ( sne ) have been discovered in recent years , and many more will be found in the near future . once discovered , further study of a sn and its possible use as an astronomical tool ( e.g. , as a distance estimator ) require knowledge of the sn type . current classification methods rely almost solely on the analysis of sn spectra to determine their type . however , spectroscopy may not be possible or practical when sne are faint , numerous , or discovered in archival studies . we present a classification method for sne based on the comparison of their observed colors synthetic ones , calculated from a large database of multi - epoch optical spectra of nearby events . we discuss the capabilities and limitations of this method . for example , type ia sne at redshifts can be distinguished from most other sn types during the first few weeks of their evolution , based on vs. colors . type ii - p sne have distinct ( very red ) colors at late ( d ) stages . broadband photometry through standard johnson - cousins filters can be useful to classify sne out to . the use of sloan digital sky survey ( sdss ) filters allows the extension of our classification method to even higher redshifts , and the use of infrared bands , to . we demonstrate the application of this method to a recently discovered sn from the sdss . finally , we outline the observational data required to further improve the sensitivity of the method , and discuss prospects for its use on future sn samples . community access to the tools developed is provided by a dedicated website ."}
{"article": "the time varying stern - gerlach , sg , interaction of a relativistic fermion e.m . wave has been proposed to separate beams of particles opposite spin states corresponding to different energies . we will show how spin polarized particle will exchange energy electromagnetic field of an rf resonator . let us denote the coordinates of a particle in the laboratory , and the coordinates in the particle rest frame , prf . in the latter the sg force that represents the action of an inhomogeneous magnetic field on a particle endowed magnetic moment is f sg = (^ * b ) = x ( ^ * b ) + y ( ^ * b ) + z ( ^ * b ) = ge2 m s . here is the elementary charge for protons and positrons , , and for antiprotons and electrons , , making and either parallel or antiparallel to each other , respectively . is the rest mass of the particle , the gyromagnetic ratio and the anomaly defined as a = g-22 = \\ { ll 1.793 ( g=5.586 ) & p,|p + + 1.160 10 ^ -3 & e^ .. notice that in eq. we have defined the magnetic moment as in the rest frame , rather than as . in the rest frame the quantum vector , or spin , has modulus and its component parallel to the magnetic field lines can only take the following values s m=(-s , -s+1, .... ,s-1 , s ) , where is the reduced planck s constant . combining eqs. and we obtain for the magnetic moment in the prf = ||=g|e|4 m = \\ { l 1.41 10 ^ -26 jt^-1 + + 9.28 10 ^ -24 jt^-1 .. for a particle traveling along the axis , the lorentz transformations of the differential operators and of the force yield \\ { lll x = x & y = y & z = ( z + c t ) + + f = 1f & f = f & ( f z = f z ) .. the force is boosted to the laboratory system as f sg = 1 x ( ^ * b ) + 1 y ( ^ * b ) + z ( ^ * b ) . because of the lorentz transformation of the fields and \\ { l e = ( e + cb ) - ^2 + 1(e ) + + b = ( b - ce ) - ^2 + 1(b ) .. the energy in the rest frame becomes ( ^ * b ) = ^* x ( b x + ce y ) + ^* y ( b y - ce x ) + ^* zb z . combining eqs. and , by virtue of eq. , after some algebra we can finally obtain the sg force components in the laboratory frame : \\ { l f x = ^* x(b xx + c e yx ) + ^* y(b yx - c e xx ) + 1^* zb zx + + f y = ^* x(b xy + c e yy ) + ^* y(b yy - c e xy ) + 1^* zb zy + + f z = ^* xc zx + ^* yc zy + ^* zc zz , . \\ { l c zx = ^2 + + c zy = ^2 + + c zz = ( b zz + c b zt ) .. these results can also be obtained from the quantum relativistic theory of the spin- charged particle . let us introduce the dirac hamiltonian h = e+ c(p - ea ) + 0 mc^2 having made use of the dirac s matrices = , 0 = , = 0 = , where is a vector whose components are the pauli s matrices x = , y = , z = , is the identity matrix , the null matrix and having chosen the -axis parallel to the main magnetic field . a standard derivation leads to the non relativistic expression of the hamiltonian exhibiting the sg interaction `` normal '' magnetic moment = e+ ( p - ea)^2 - ( b ) which coincides pauli equation and is valid in the prf . to complete the derivation we must add the contribution from the anomalous magnetic moment to the sg energy term in the previous equation , factor , yielding - b = - ^ * b ^ * = g . in order to obtain the -component of the sg force in the laboratory frame along the direction of motion of the particle , we must boost the whole pauli term of eq. by using the unitary operator in the hilbert space , which expresses the lorentz transformation u^-1 u = g( 0b ) that can be written in terms of the equivalent transformation in the spinor space s = = + = , u = = = , u = (= ) . from eqs. and , due to the algebraic structure of the and matrices , we obtain in the laboratory frame the three components of the sg force \\ { lll s^-1 ( 0 x ) s & = & 0 x + s^-1 ( 0 y ) s & = & 0 y + s^-1 ( 0 z ) s & = & ( 0 z ) + i 0 5 . , 5 = x y z 0 = i . from eqs. we can deduce the expectation values of the sg force in the laboratory system defined spin -along the -axis in our case- via the expectation values of the pauli matrices and of the pauli interaction term of the proper force f z = 0 y^2^*. in our case only the second of eqs. gives a non vanishing result , while both the first and third produce a null contribution to the force , because of the orthogonality of the two spin states and the properties of the matrices . let us consider the standing waves built up inside a rectangular radio - frequency resonator , tuned to a generic te mode . resonator dimensions are : width , height and length , as shown in fig. . on the cavity axis , which coincides beam axis , the electric and magnetic fields are \\\\ \\\\ b x & = & - { b 0\\over k c^2 } \\left({m\\pi\\over a}\\right ) \\left({p\\pi\\over d}\\right ) \\sin\\left({m\\pi x\\over a}\\right ) \\cos\\left({n\\pi y\\over b}\\right ) \\cos\\left({p\\pi z\\over d}\\right ) \\cos\\,\\omega t \\\\ \\\\ b y & = & - { b 0\\over k c^2 } \\left({n\\pi\\over b}\\right ) \\left({p\\pi\\over d}\\right ) \\cos\\left({m\\pi x\\over a}\\right ) \\sin\\left({n\\pi y\\over b}\\right ) \\cos\\left({p\\pi z\\over d}\\right ) \\cos\\,\\omega t \\\\ \\\\ b z & = & b 0 \\cos\\left({m\\pi x\\over a}\\right ) \\cos\\left({n\\pi y\\over b}\\right ) \\sin\\left({p\\pi z\\over d}\\right ) \\cos\\,\\omega t \\ ] ] where is the rf peak magnetic field , , and are integer mode indeces , and k c = . the angular frequency of the e.m . wave from the rf generator is = = 2c = c. in contrast open waveguide , in a bounded cavity we can define a phase velocity and a cavity wavelength , as typical of any e.m . in a refractive media , according to the relations = = dp . and = ph . it is also = c = = notice that can take any value , even larger than one , since it is freely dependent on the cavity geometrical parameters . moreover , combining eqs. and we obtain d = p = p which describes the connection between the cavity length and the wavelengths , as shown in fig. . for simplicity , let s choose the transverse electric mode , so eqs. and reduce respectively to = = c = c = or , setting the mode index , = = c = c = , which are the quantities pertaining to the preferred mode whose non zero field components on the cavity axis are \\ { l b y(z , t ) = - b 0 t + + e x(z , t ) = -b 0 t .. it is important to emphasize that in all the field components met so far there is a clear separation between spatial and temporal contributions , as typical of standing waves . besides , the boundary conditions of the electric and magnetic fields of the e.m . dictate the shape of the spatial component which , in turn , oscillates in time frequency . then , at the cavity entrance and exit the field components become on axis \\ { l b y(0,t ) = -b 0 t + + e x(0,t ) = 0 .. and \\ { l b y(d , t ) = -b 0 t = b 0 t + + e x(d , t ) = -t = 0 .. where is a generic time . the null values of at the cavity ends confirm a typical pattern of the transverse electric mode . from eq. , after some algebra , we obtain tha a charged fermion which crosses a radio - frequency resonator , tuned on the te mode , acquires ( or loses ) an energy amount when interacts field component in the `` body '' of the cavity shown in fig . ( u ) = 0^df z dz = 0^d^*c zydz = ^2 ^ 2 b 0^ * ( 1 + ) still assuming that the spin is not precessing . however , since the cavity can not be completely enclosed but must have apertures at both ends to allow the particle bean to pass through and consequently will have fringe fields , in order to calculate the full sg interaction it is necessary to deal interaction these fields . this is discussed right below . in order to fulfill the boundary conditions and , a cavity tuned in its mode must be exactly filled by either an even or an odd number of cavity dependent half wave - lengths , eq. , as illustrated in figs . and . consider now a bunch of particles crossing the cavity in synchronism rf field . this requires that the bunch centre of mass that enters the cavity at the instant and would leave the cavity at , at magnetic field values , respectively b y(0,0 ) = -b 0 b y(d , ) = b 0 the field values at both ends fade rapidly to zero over a small distance just outside the cavity ( see figures . ) we may consider these fringe fields as small - valued functions in the -plane , since the time necessary for a particle to proceed through this distances can be very small in comparison , depending of course by the size of the beam channel , or \\ { llllll & = & -b 0g(z ) & & g(-)=0 , & g(0)=1 + + & = & b 0h(z ) & & h(d)=1 , & h(d+)=0 .. under these conditions , a relativistic fermion spin directed along the -axis and traversing the cavity will experience a sg force parallel to the -axis ( direction of motion ) , see eq. f z = ^ * c zy where is given by the second of the set of eqs. . for the moment we assume that the spin will conserve its orientation during traversal the electric field and its derivatives in this equation are almost constantly zero , because of the boundary conditions on the walls of the cavity and at the extreme points and . furthermore , the function is almost zero along the fringe segments because of its proportionality to , equal to the mentioned before . consequently we have c zy ^2 , and for the entire fringe field \\ { lll & = & -b 0^*^2 + + & = & b 0^*^2 .. making use of eqs . and , the energy increments {\\m in} ] related to the fringe fields are easily evaluated since the integrals and only depend upon the extreme points and do not depend on the curve that connects them . in fact becomes an exact differential . then we obtain for the energy exchange at both edges ( u ) = ( u ) = - b 0^*^2 . the total energy exchange at the edges is therefore ( u ) = ( u ) + ( u ) = - 2b 0^*^2 . by adding the fringe contributions to the cavity body crossing contribution seen before , obtain ( u ) = ( u ) + ( u) x = -^2 b 0^ * f ( , ) ( , ) = . for ultra relativistic particles eq . reduces to ( u ) -^2 b 0^ * ( 1- ) . this last result deserves a few comments . in fact , if we set = 2 d = = the total energy contribution vanishes , implying a full cancellation of the effect . on the other hand if we set = the total energy contribution becomes ( u ) -2 ^ 2 b 0^ * as deduced from eq. . in table i we gather values calculated from eq. for non - relativistic and ultra - relativistic particles for , either or at two proton energies . each is accompanied by the corresponding ratio cavity - length over cavity - height . * table i : * furthermore , if we consider two contiguous cavities , there will be a gradient between the positive at the end of the first cavity and a negative at the beginning of the second cavity , as shown in fig . . in this case we may consider the magnetic field at the interface as linearly dependent on , that is reiterating what done before , obtain rcl & = & -2b 0 + + f z & = & -2b 0^*^2 + + ( u ) = ( u ) & = & -^f z dz = -2b 0^ * ^2 = -2b 0^*^2 which means that , for cavities , we shall have as final result for ultra relativistic particles ( u ) = n(u ) - ( n-1)(u ) - ( u ) = \\ { ll 0 & ph = 2 + + b 0^*^2 & ph = 3 .. conversely , if is even , particles their spin pointing always in the same direction can not exchange energy standing wave of a te resonator . a spin rotator can align the particle magnetic moments either parallel or anti - parallel to the directions of the magnetic field gradients , thus allowing the desired energy interaction . this situation would be similar to what happens in a multi - stage tandem van de graaff , where the ions are repetitively accelerated by the same electrostatic field , becoming alternatively negative , via an addition of electrons , or positive , via electron stripping . unfortunately , the field integral ( tm , for ) for attaining a spin rotation is so large that this solution is unpractical . instead , the example of equal to an odd number seems much more suitable since does not require cumbersome magnets , but only longer cavities ( compare eqs . and ) . in fact , the magnetic moments are ( de)accelerated by the field tails at the cavity ends , while do nt change their energy when crossing the cavities . this situation resembles the wideroe linac where the charged particles are accelerated by the electric fields between two contiguous drift tubes , but do nt change their energy while crossing the tubes themselves . on the basis of the previous estimates , we feel ready to propose the time varying sg interaction as a method for attaining a spin state separation of an unpolarized beam of , say ( anti)protons , since the energy of particles opposite spin orientations will differ and beams in the two states can be separated . in a first stage of the study of a sensible practical design , we intend to proceed numerical simulations . as a first step , we intend to verify the correctness of eqs. and setting once and then , in a cavity where the field line pattern can be realistically controlled . beyond the verification of the present theory , there is also the aim of studying the effects generated by the spin precession inside the cavity , that we did not yet address in this note . next , we shall consider a spin splitter scheme based on the lattice of an existing or planned ( anti)proton ring endowed array of splitting cavities . the principal aim of the latter implementations is to check the mixing effect of the longitudinal phase - plane filamentation , i.e. the actual foe which could frustrate the entire spin splitting process . first , we want to thank waldo mackay , who has participated on so many discussions on the whole idea but who was regrettably prevented by numerous commitments from participate to the editing of the present note . we thank renzo parodi for his help for us to better understand the subtleties of the standing waves building up . thanks are also due to chris tschalaer for fruitful discussions on the role of the fringe fields . m. conte , m. ferro , g. gemme , w.w . mackay , r. parodi , m. pusterla : the stern - gerlach interaction between a traveling particle and a time varying magnetic field , infn / tc-00/03 , 22 marzo 2000 . ( http : xxx.lanl.gov / listphysics/0003 , preprint 0003069 ) p. cameron , m. conte , a. luccio , w.w . mackay , m. palazzi and m. pusterla : the relativistic stern - gerlach interaction and quantum mechanics implications , proceedings of the spin2002 symposium , 9 - 14 september 2002 , brookhaven , eds . makdisi , a.u . luccio and w.w . mackay , aip conference proceedings 675 ( 2003 ) p. 786 . j.d.jackson , classical elecrodynamics , john wiley & sons inc . , new york 1975 r.p . feynman , quantum electrodynamics benjamin inc . , new york 1961 . s. ramo , j.r . whinnery and t. van duzer , fields and waves in communication electronics , john wiley and & sons , new york , 1965 . m.conte,a.u.luccio,w.w.mackay and m.pusterla stern gerlach force on a precessing magnetic moment proc . pac07 , albuquerque , nm ( 2007 ) , p.3729 m. conte , w.w . mackay and r. parodi : an overview of the longitudinal stern - gerlach effect , bnl-52541 , uc-414 , november 17 1997 . m. palazzi : ph.d thesis , genoa university , june 6 2003 .", "summary": "the general expression of the stern - gerlach force is deduced for a relativistic charged spin- particle which travels inside a time varying magnetic field . this result was obtained either by means of two lorentz boosts or starting from dirac s equation . then , the utilization of this interaction for attaining the spin states separation is reconsidered in a new example using a new radio - frequency arrangement ."}
{"article": "excitons in semiconductors have been the subject of many experimental and theoretical investigations of bose condensation . low - energy exciton - exciton interactions are characterized by the exciton - exciton scattering length , , which determines the thermodynamics of a low density gas and is crucial for modeling the thermalization time of a dilute exciton gas . despite its importance , the exciton - exciton scattering length is an elusive quantity , being difficult to measure experimentally or to estimate theoretically . as is well - known in atomic physics , scattering lengths can be extremely sensitive to the details of the interactions between particles . in particular , the existence of a weakly bound or nearly bound state causes the scatter length to become quite large . therefore , a priori one should suspect that exciton - exciton scattering may be a very material dependent property of semiconductors . reliable theoretical predictions of exciton - exciton scatting lengths require both a very accurate hamiltonian for the semiconductor , and an accurate solution to the ( four - particle ) scattering problem . in this paper we provide an essentially exact solution to exciton - exciton scattering for a commonly used single - band effective mass hamiltonian . this solution allows us to study three important questions : ( 1 ) how sensitive is the scattering length to the mass ratio , ( 2 ) how does the scattering length depend on spin states ( singlet or triplet ) of the scattering excitons , and ( 3 ) to what degree can inter - exciton exchange of electrons or holes cause excitons to scatter into different spin states ? this calculations also serve as a benchmark for the single band limit of more complicated scattering hamiltonians . one experimental method for measuring the exciton scattering cross section is to look at line width broadening of the recombination spectra in a gas of excitons . collisions between excitons increase the line width , causing the line width to depend on the exciton - exciton scattering rate , , where is the density and is a typical exciton velocity . extracting cross sections from a line width requires that ( 1 ) the density and velocity distribution are known , and ( 2 ) elastic scattering is the fastest process . as discussed below , is a good material for comparison to the model studied in this work . et al. have performed such experiments on and have found a line width broadening that suggests an upper bound of on the scattering length . although our simulations do not exactly model , we will compare our results to this value . theoretical approaches to this problem start effective mass approximation , in which the system under consideration consists of two electrons , labeled and , and two holes , labeled and . the hamiltonian is where . the hamiltonian has symmetry under exchange of electrons and exchange of holes , so eigenstates may be denoted by two exchange quantum numbers . the s - wave states are symmetric under exchange of excitons ; a condition which is satisfied by states and , where the signs refer to ( anti)symmetry under exchange of electrons and holes , respectively . although this hamiltonian is a well - accepted model for exciton - exciton scattering , we should point out a few of its deficiencies . for small excitons , such as those in , that have radii not much larger than the lattice spacing , non - parabolic terms in the kinetic energy and other corrections to the potential energy may be necessary . for many semiconductors , such as si and ge , the valence band is a mixture of three bands and can not be described by a single parabolic band . in the case of , the valence band is the parabolic spin - orbit split off band , and there are fewer complications . interband exchange ( virtual electron - hole recombination ) is an important effect that has been neglected , and could be modeled by an additional spin - dependent potential term . this hamiltonian also describes a family of scattering processes for other particles , including hydrogen - hydrogen , positronium - positronium , and muonium - muonium scattering . the equal mass case is at an extreme ( positronium scattering ) , where the born - oppenheimer approximation is the least applicable . there have been several theoretical estimates of exciton - exciton scattering for bulk systems and quantum wells as well as calculations on biexciton - biexciton scattering, only the bulk , elastic scattering calculations are directly comparable to the results of this paper , but the techniques presented here could be generalized to the other scattering problems . also , the results presented here provide a benchmark for evaluating the approximations used in other theoretical treatments , and could lend insight into the reliability of the approximations in more complicated situations . one standard theoretical approach is diagrammatic perturbation theory , as presented in the work of keldysh and kolsov and haug and hanamura. they estimate the exciton - exciton scattering matrix as arising from a single term , , where represents a state of two noninteracting excitons momentum and and is the inter - exciton coulomb interaction . this method gives an estimate of ( independent of the mass ratio ) , where is the exciton radius , but it is an uncontrolled approximation which may have limited validity in the low energy limit . one serious drawback of the method is that it does not include effects of the biexciton in the scattering . as we show later , biexciton vibrational states cause strong dependence of the scattering length on the mass ratio , which is not captured by the low order perturbation theory . a second common approach was developed by elkomoss and munchy, and uses an effective exciton - exciton potential defined by , where is the wavefunction for two free excitons a distance apart . the effective potential arises from the hartree term and is used in a two - particle central - field calculation . while an exciton - exciton scattering pseudo - potential would be a very useful tool , this approximate form has some serious drawbacks . among its deficiencies are a lack of correlation , no van der waals attraction , a failure to reproduce biexciton states , and a vanishing interaction potential for . the cross sections calculated by this method are small and lack qualitative agreement results of the present work . some insight into exciton - exciton scattering can be gained by considering the bound states , biexcitons . since the number of bound states , , enters in the phase shift at zero energy , , it is necessary that a good computation method for low energy scattering be able accurately calculate biexciton binding energies. for the mass ratios considered ( and far beyond , including deuterium ) the biexcitons can not bind in the states , so biexcitons in rotational states always have wavefunctions . detailed theoretical descriptions of biexcitons can be found in ref . the equal mass case was shown to have a bound biexciton by hyllerass and ore using a variational argument, and a better variational estimate of the binding energy was given by brinkman , rice and bell, who found , where is the exciton binding energy . however , because of the importance of correlation energy , the latter variational treatment was missing half of the biexciton binding energy , as shown by diffusion monte carlo ( dmc ) calculations, which find . dmc is a quantum monte carlo ( qmc ) method that uses a random walk to project out the ground state wavefunction from a variational wavefunction , in order to stochastically sample the exact ground state energy . the success of dmc for calculating biexciton energies has been a motivation for its use in the present scattering calculations . the -matrix approach to scattering is to examine the standing waves of the system . as shown by carlson , pandharipande , and wiringa and alhassid and koonin, by fixing nodes in the standing waves the scattering problem may be cast as a stationary state problem suitable for qmc methods . for an elastic scattering process , we label the distance between the products by , and the reduced mass of the products by . in exciton - exciton scattering there is a subtlety in the definition of r due to inter - exciton exchange , which we will address below in our discussion of the exciton - exciton scattering wavefunctions . nonetheless , for large separation , the relative motion of the products is free - particle like , so the many - body wavefunction depends on as , \\ ] ] where is the relative angular momentum , is the scattering momentum , and is the phase shift . if we constrain the wavefunction to have a node at a large exciton separation , we find a discrete energy spectrum , which may be computed by ground state or excited state methods , such as dmc . each choice of gives a spectrum of states , energies that determine values of , where . the scattering matrix elements are determined by the phase shifts , - 1.\\ ] ] carlson has also proposed fixing the logarithmic derivative of the wavefunction at the boundary instead of setting wavefunction to zero , were is the normal to the boundary surface , at a fixed radius , and parameterizes the boundary condition . this formulation has the advantage of separating the choice of simulation size ( subject to lying in the asymptotic region ) , from the sampling of energy , which is handled by varying , and is particularly well suited for finding the scattering length . the application to vmc calculations is straight - forward , but preserving the boundary condition in dmc calculations requires a method of images . the results presented here do not use the logarithmic - derivative boundary condition . the use of excited states is necessary when there is a bound state and , more generally , when the scattering state being studied has its first node before the asymptotic region is reached . we use a qmc method to calculate excited states developed by ceperley and bernu, to adapt vmc and dmc methods for a hilbert space of several low energy wavefunctions . a set of trial wavefunctions is chosen , . the generalized eigenvalue equation to be solved is, d {k\\beta}(t)=0 , \\ ] ] where is the eigenvector eigenvalue and the matrices and are the overlap and hamiltonian matrices in our trial basis , given by the parameter is the projection time . the eigenvalues are energy eigenvalues within the hilbert space spanned by the projected trial functions , and approach the exact energy eigenvalues in the limit of large . the matrices and are sampled random walks , using a guiding function which must be positive everywhere . the guiding function must have significant overlap basis functions , and should be optimized to decrease the variance of the sampled matrices . at each step in the random walk , the coordinates of the particles are updated using where is a normally distributed random variate zero mean and unit variance and is the time step . in the limit of small , eq . describes a process for sampling . the matrix element of is estimated by integrating the local energy of the guiding function , , along the random walk , }.\\ ] ] the estimators for matrices and are where and are the local energies of the trial basis states . , at large exciton - exciton separation . the asymptotic form of the -wave scattering states are symmetric or antisymmetric combinations of these configurations . this symmetric / antisymmetric form is used for the trial wavefunctions and , using and from eq . . ] we now discuss the form for the exciton scattering functions and . as mentioned before , inter - exciton exchange of particles complicates the definition of exciton - exciton separation . there are two configurations for well - separated excitons , as shown in fig . . configuration i has the electrons and hole paired as , ; and configuration ii as , . we choose wavefunctions and to represent these states , where , and parameters in the function are variational . these wavefunctions represent two excitons in a relative s - wave state . since these are not eigenstates of the exchange operator for electrons or holes , , we take linear combinations of the two for our trial wavefunctions , and . for large separation of excitons , the exponential factors prohibit both configurations from simultaneously contributing to the wavefunction . thus , a node can be approximated in the scattering wavefunction by simply requiring that be zero for all . the error introduced by this approximation is of order , and is another limit on the use of small values for . since we only do calculations for low energy scattering , large , the lack of a well - defined exciton - exciton separation distance for short distances does not matter . of the dmc states relative to the vmc states as a function of dmc projection time , for basis states . the eigenvalue equation is given by eqs . , where the hamiltonian and overlap matrices have been sampled using eqs . and . ] this method for calculating scattering properties is very sensitive to the energy spectra . to get accurate energies , we do not try to construct and optimize elaborate variational wavefunctions , but rather use dmc to project the energy from trial wavefunctions of the form given in eq . . the coefficients , , , and are chosen to obey the cusp conditions on the wavefunction for small particle separations . the s - wave envelope functions are taken as solutions to an empirical exciton - exciton scattering potentials , where and have been self - consistently fit to approximate the energy spectrum of the four particle scattering states . we take the guiding function to have the same form as the wavefunctions ^{1/2}$ ] . the parameters are chosen to bias sampling towards the collision : for states and for states to check for convergence of the energies in dmc , we plot the energy difference , , as a function of projection time in fig . . we see convergence after a projection time of 3 . , for ( a ) symmetric states , and ( b ) antisymmetric states , . the lowest energy curve in ( a ) is the biexciton binding energy . these functions determine the phase shifts and , by the relationship in eq . . ] we thus find two energy spectra for each value of , as shown in figs . (a ) and (b ) . the spectra for the symmetric states , show a clearly bound biexciton state , as seen in fig . (a ) . the antisymmetric states , as shown in fig . (b ) , have no bound state . the binding energy of the biexciton is , in agreement other ground state calculations , and is insensitive to the position of the node because it is localized . in contrast , the delocalized scattering states are quite sensitive to , and their dependence on is a measure of the elastic scattering matrix elements . for the two -wave scattering states , for , calculate using eq . and the data from fig . . ] .coefficients for polynomomial fit to the low energy part of the phase shift functions for the case . the collision of two excitons well defined initial and final spin states can be determined by decomposing the scattering events into the two channels , and . using the change of basis matrix ( table ) , we find , where the coefficients and for all non - zero s - wave scattering processes are given in table . the s - wave scattering cross sections are given by , where there is a factor of two enhancement due to the identical particle statistics . the spin - dependent cross sections take the form , , \\ ] ] where , , and depend on the initial and final spin states and are tabulated in table . the scattering lengths are given by , where the derivatives of the phase shifts are determined from the linear coefficients in table . ) , for exciton - exciton scattering , for the processes : ( a ) singlet - singlet singlet - singlet , ( b ) triplet - triplet triplet - triplet for total spin ( dashed line ) and ( solid line ) , ( c ) triplet - singlet triplet - singlet , and ( d ) triplet - triplet singlet - singlet and singlet - singlet triplet - triplet , both . ] the calculated spin - dependent scattering lengths for the case are presented in the last column of table . these are the low - energy limit the cross - sections shown in fig . . in fig . we have plotted the s - wave scattering cross sections versus scattering momentum for the case and all non - zero spin configurations . fig . (a ) shows scattering of two singlet - excitons . scattering of two triplet - excitons is shown in fig . (b ) , where the solid line represents the spin aligned state , and the dashed line represents the state . the state scatters particularly strong because it has a large contribution from the channel , which is enhanced by the weakly bound biexciton . triplet - excitons in a relative state are spatially antisymmetric and thus have no s - wave scattering . we show s - wave scattering of triplet - excitons from singlet - excitons in fig . (c ) . this state has two distinguishable excitons , and can scatter by both s - wave and p - wave processes . as can be seen in table , the only contribution to the cross section is from the weaker channel . the coefficient for s - wave scattering is particularly small because only half the scattering process is symmetric ( s - wave ) , and there is an additional factor of one - half which cancels the identical particle factor . there is also an triplet- to singlet - exciton conversion cross section given in fig . (d ) . although this is an inelastic process in experimental situations , it conserves energy according to our model hamiltonian because we do not have an explicit interband spin coupling . the conversion of two triplet - excitons to two singlet - excitons can be understood as an inter - exciton exchange of a pair of electrons ( or holes ) . since the spins of the individual excitons do not correspond to symmetries of the hamiltonian , they need not remain constant during scattering . this conversion process is a physical consequence of the two inequivalent scattering channels and . this effect has been reported in experimental and theoretical work on exciton scattering in quantum wells . and as a function of the electron - hole mass ratio . the divergence in near is due to the appearance of second bound biexciton state . solid lines are a guide to the eye . ] the dependence of the cross sections on mass may be numerically studied by our methods . in fig . we show our calculated and as a function of mass ratio , . we find that the scattering length is remarkably insensitive to the mass ratio for ( corresponding to a wide range of semiconductors ) , but then diverges near . this feature is lost in previously published theoretical treatments of exciton - exciton scattering . the divergence in near is due to the acquisition of a biexciton vibrational state . for the biexciton has no bound excited states , while a molecule has 15 bound vibrational states . our calculations have shown the first of these appears near , dramatic effects on the scattering length . the curve is relatively featureless because there are are no bound antisymmetric states in this range . we interpret the upward drift of for larger mass ratios as a systematic error due to difficulties in projecting states in excitonic systems very different electron and hole masses . the heavy particle determines the projection time while the light particle determines the diffusion time step . the difficulty in handling large mass ratios make the method ( as presented here ) complementary to calculations that use the born - oppenheimer approximation . it is important to realize that similar relationships must exist between the scattering length and other material parameters , such as the luttinger - kohn parameters describing realistic hole states , external strain , and spin - orbit coupling , to name a few . theoretical studies of such effects will need similar high - accuracy scattering calculations , but applied to more accurate hamiltonians , and are an area for future research . to summarize , we have shown that there are several significant elastic scattering processes for excitons , and have given numerically exact values for a widely used theoretical model . we find strong triplet - triplet and singlet - singlet scattering , weaker triplet - singlet scattering and triplet - triplet to singlet - singlet conversion processes . scattering is relatively insensitive to the mass ratio for , but becomes very sensitive and actually diverges near . dmc has been found be a good tool for this four - particle excited state calculation , since the detection of weakly bound states requires very accurate evaluation of the correlation energy . this computational approach should be extended in many ways . the extension to higher angular momentum states would give important corrections at higher scattering energies . application to biexciton - biexciton scattering are possible , but would be a bit more difficult because the scattering wavefunction would then have to describe eight interacting particles . most importantly , the method should be adapted to better hamiltonians so that the sensitivity of the scattering length to material properties for a wide range of materials can be studied . this approach should be quite useful for quantum well problems , which have similarities to the bulk problem study here , but have many more experimental parameters that can affect exciton - exciton interaction . we would like to thank k. ohara and j. carlson for useful discussions .", "summary": "we calculate cross sections for low energy elastic exciton - exciton scattering within the effective mass approximation . unlike previous theoretical approaches , we give a complete , non - perturbative treatment of the four - particle scattering problem . diffusion monte carlo is used to calculate the essentially exact energies of scattering states , from which phase shifts are determined . for the case of equal - mass electrons and holes , which is equivalent to positronium - positronium scattering , we find for scattering of singlet - excitons and for triplet - excitons , where is the excitonic radius . the spin dependence of the cross sections arises from the spatial exchange symmetry of the scattering wavefunctions . a significant triplet - triplet to singlet - singlet scattering process is found , which is similar to reported effects in recent experiments and theory for excitons in quantum wells . we also show that the scattering length can change sign and diverge for some values of the mass ratio / , an effect not seen in previous perturbative treatments ."}
{"article": "for fixed integers and , we consider the admissible sequences of lattice paths in a colored square given in . each admissible sequence of paths can be associated partition of . in section , we show that the number of self - conjugate admissible sequences of paths associated is equal to the number of standard young tableaux of shape , and thus can be calculated using the hook length formula . we extend this result to include the non - self - conjugate admissible sequences of paths and show that the number of all such admissible sequences of paths is equal to the sum of squares of the number of standard young tableaux of partitions of height less than or equal to . using the rsk correspondence in , it is shown in ( , corollary 7.23.12 ) that the sum of squares of the number of standard young tableaux of partitions of height less than or equal to is equal to the number of -avoiding permutations of . in section , we apply our results to the representation theory of the affine kac - moody algebra . let , and denote the simple roots , simple coroots , and fundamental weights respectively . note that . for , set and . as shown in , are maximal dominant weights of the irreducible -module . we show that the multiplicity of the weight in is the number of -avoiding permutations of , which proves conjecture 4.13 in . for fixed integers and , consider the square containing unit boxes in the fourth quadrant so that the top left corner of the square is at the origin . we assign color to a box if its upper left corner has coordinates . this gives the following colored square : a lattice path on is a path joining the lower left corner to the upper right corner moving unit lengths up or right . for two lattice paths on we say that if the boxes above are also above . now , we draw lattice paths , on such that . for integers , where , , we define to be the number of -colored boxes between and . we define to be the number of -colored boxes below and to be the number of -colored boxes above . denote by the set of all admissible sequences of paths . notice that there are 0-colored boxes in and hence for any admissible sequence of paths , . in addition , it follows from definition (2 ) that for any admissible sequence of paths . thus , we can and do associate an admissible sequence of paths on partition of . in this case , we say that this admissible sequence of paths is of type and often draw as a young diagram . figure (a ) is an element of , where and are shown in figures (b ) , (c ) , and (d ) , respectively . notice that this admissible sequence of paths is of type .", "summary": "for and , we consider certain admissible sequences of lattice paths in a colored square . we show that the number of such admissible sequences of lattice paths is given by the sum of squares of the number of standard young tableaux of partitions of height , which is also the number of -avoiding permutations of . finally , we apply this result to the representation theory of the affine lie algebra and show that this quantity gives the multiplicity of certain maximal dominant weights in the irreducible module ."}
{"article": "it is well known that the classical magnetoresistance ( mr ) in metals or semiconductors closed free electron fermi surface increases quadratically increasing magnetic field for and saturates when . here is the zero - magnetic - field mobility . hence , the extraordinarily high and linear mr ( lmr ) , which breaks this familiar rule , has been gaining much attention as soon as its discovery . in the past decade , this unexpected lmr has been reported in silver chalcogenide, indium antimonide, silicon, mnas - gaas composite material, and graphene. kapitza s linear law indicates that the metal shows a magnetoresistance linear in perpendicular magnetic field when it has an open fermi surface and a mean free path longer than the electronic larmor radius . recently , another two models , irrespective of the open fermi surface , have been constructed to provide possible mechanisms for the lmr phenomenon . abrikosov suggested a quantum - limit origin of lmr for the homogenous system gapless linear energy spectrum. his model requires that landau levels are well formed and the carrier concentration is small that all electrons occupy only the lowest landau band . alternatively , parish and littlewood developed a classical model without involving linear spectrum. ignoring the concrete microscopic mechanism , they attributed this unusual mr to the mobility fluctuations in a strongly inhomogenous system . topological insulators ( tis ) are novel materials full energy gap in bulk , while there are gapless surface states . due to its unique band structure only one helical dirac cone and linear energy dispersion, the surface states of the ti bise become an excellent platform for the study of quantum - limit lmr . the recent experiment in this flat surface system , however , reported that a large positive mr , which becomes very linear above a characteristic field of t , was observed even in an opposite situation where the carrier sheet density is high that electrons occupy more than one landau levels. moreover , they found that raising temperature to room temperature almost has no influence on the observed lmr . it is striking that this observation is in conflict abrikosov s model and also classical parish - littlewood model . so far a reliable theoretical scheme capable of explaining this novel experiment has still been lacking . in this paper , we generalize the balance - equation approach to a system modeling the surface states of a three - dimensional ti to investigate the two - dimensional magnetotransport in it . we find that a positive , nonsaturating and dominantly linear magnetoresistance can appear within quite wide magnetic - field range in the ti surface state having a positive and finite effective g - factor . this linear magnetoresistance shows up in the system of high carrier concentration and low mobility when electrons are in extended states and spread over many smeared landau levels , and persists up to room temperature , providing a possible mechanism for the recently observed linear magnetoresistance in topological insulator bise nanoribbons. we consider the surface state of a bise-type large bulk gap ti in the - plane under the influence of a uniform magnetic field applied along the direction. following the experimental observation, we assume that the fermi energy locates in the gap of the bulk band and above the dirac point , i.e. the surface carriers are electrons . further , the separations of the fermi energy from the bottom of bulk band and dirac point are much larger than the highest temperature considered in this work . hence , the contribution from the bulk band to the magnetotransport is negligible . these electrons , scattered by randomly distributed impurities and by phonons , are driven by a uniform in - plane electric field in the topological surface . the hamiltonian of this many - electron and phonon system consists of an electron part , a phonon part , and electron - impurity and electron - phonon interactions and : here , the electron hamiltonian is taken in the form , \\ ] ] in which , , and , stand , respectively , for the canonical momentum , coordinate , momentum and spin operators of the th electron having charge , is the vector potential of the perpendicular magnetic field in the landau gauge , is the fermi velocity , is the effective g - factor of the surface electron , and is the bohr magneton the free electron mass . the sum index in eq. goes over all electrons of total number in the surface state of unit area . in the frame work of balance equation approach, the two - dimensional center - of - mass ( c.m . ) momentum and coordinate and , and the relative - electron momenta and coordinates and are introduced to write the hamiltonian into the sum of a single - particle c.m . part and a many - particle relative - electron part : , .\\ ] ] in this , is the canonical momentum of the center - of - mass and is the canonical momentum for the th relative electron . here we have also introduced c.m . spin operators and . the commutation relations between the c.m . spin operators and and the spin operators , and of the th electron are of order of : = n^{-1}2\\,{\\rm i}\\,\\varepsilon {\\beta 1\\beta 2\\beta 3}\\sigma j^{\\beta 3} ] , i.e. the relative - electron momenta and coordinates can be treated as canonical conjugate variables , the relative - motion part is just the hamiltonian of electrons in the surface state of ti in the magnetic field without the presence of the electric field . in terms of the c.m . coordinate and the relative electron density operator , the electron impurity and electron phonon interactions can be written as here and are respectively the impurity potential ( an impurity at randomly distributed position ) and electron phonon coupling matrix element in the plane - wave representation , and and being the creation and annihilation operators for a phonon of wavevector in branch having frequency . velocity ( operator ) is the time variation of its coordinate : = v {\\rm f}(\\sigma {\\rm c}^y\\ , -\\sigma {\\rm c}^x\\ , ) ] . here is the single - particle lifetime and is the cyclotron frequency of linear - energy - dispersion system being the zero - temperature fermi level . using a semi - empirical parameter to relate transport scattering time , and expressing zero - field mobility at finite temperature, we can write the landau - level broadening as ^{1/2}.\\ ] ] in the present study we consider the case of -doping , i.e. the fermi level is high enough above the energy zero of the dirac cone in the range of `` + ' ' -branch levels and the states of `` ''-branch levels are completely filled , that they are irrelevant to electron transport . special attention has to be paid to the level , since , depending on the direction of exchange potential the effective g - factor of a ti surface state , , can be positive , zero or negative. the sign and magnitude of the effective g - factor determines how many states of the zero level should be included in or excluded from the available states for electron occupation in the case of -doping at a magnetic field . ( i ) if , the level center is exactly at and the system is electron - hole symmetric . the total number of negative energy states ( including the states of the lower half of the level and states of the \"-branch levels ) and that of positive energy states ( including the states of the upper half of the level and states of the \"-branch levels ) do not change when changing magnetic field . therefore , the lower - half negative energy states of this level are always filled and the upper - half positive - energy states of it are available for the occupation of particles which are counted as electrons participating in transport in the case of -doping . ( ii ) for a finite positive , the level moves downward to negative energy and its distance to the nearest \"-branch level is closer than to the nearest + \" -branch level at finite magnetic field strength . this is equivalent to the opening of an increasingly enlarged ( increasing ) energy gap between the + \" -branch states and the states of the zero - level and the \"-branch levels . the opening of a sufficient energy gap implies that increasing magnetic field the states in the + \" -branch levels would no longer shrink into the zero - level , and thus the level should be completely excluded from the conduction band , i.e. only particles occupying the + \" -branch states are counted as electrons participating in transport in the case of -doping , when the magnetic field gets larger than a certain value ( depending on the magnitude of ) . ( iii ) for a finite negative , the level moves upward to positive energy and an increasingly enlarged energy gap will be opened between the states of the zero - level and the + \" -branch and the states of \"-branch levels , and particles occupying the level and + \" -branch states are electrons participating in transport when the magnetic field gets larger than a certain value . as a result , the experimentally accessible sheet density of electrons participating in transport is related to the fermi energy by the following equation valid at finite for the magnetic field larger than a certain value : in which + 1\\}^{-1} ] , even for the lowest landau level , i.e. the whole landau - level spectrum is smeared . increasing the zero - field mobility the magnitude of resistivity decreases , and when the broadened landau - level width becomes smaller than the neighboring level interval , , a weak sdh oscillation begin to occur around the linearly - dependent average value of at higher portion of the magnetic field range , as seen in fig.(c ) , ( d ) and ( e ) for and . on the other hand , in the case of large mobility , e.g. , where the broadened landau - level widths are much smaller than the neighboring level interval even for level index as large as , the magnetoresistivity shows pronounced sdh oscillation and the linear - dependent behavior disappears , before the appearance of quantum hall effect, as shown in fig.(f ) . abrikosov s model for the lmr requires the applied magnetic field large enough to reach the quantum limit at which all the carriers are within the lowest landau level, while it is obvious that more than one landau levels are occupied in the experimental samples in the field range in which the linear and non - saturating magnetoresistivity was observed. for the given electron surface density , the number of occupied landau levels , or the filling factor , at different magnetic fields is shown in fig.(f ) , as well as in the fig.(d ) and ( e ) , where the integer - number positions of , i.e. filling up to entire landau levels , coincide minima of the density - of - states or the dips of sdh oscillation . this is in contrast case , where the integer number of , which implies a filling up to the center position of the th landau levels , locates at a peak of sdh oscillation , as shown in fig.b . the observed sdh oscillations in the bise nanoribbon exhibiting nonsaturating surface lmr in the experiment favor the former case : a finite positive effective . is plotted as a function of the surface electron density at magnetic field : ( a ) at different values of zero - field mobility , and ( b ) at different values of zero - field conductivity .,scaledwidth=40.0% ] at various lattice temperatures . here the zero - magnetic - field mobility at zero temperature is .,scaledwidth=35.0% ] next , we examine the density - dependence of the linear magnetoresistivity . to compare abrikosov s quantum magnetoresistance which suggests a behavior, we show the calculated for above lmr versus the carrier sheet density in fig. at fixed magnetic field t . the mobility is taken respectively to be and m/vs to make the resistivity in the lmr regime . a clearly linear dependence of on the surface density is seen in all cases , indicating that this non - saturating linear resistivity is almost inversely proportional to the carrier density . in the figure we also show versus under the condition of different given conductivity and . in this case the half - width is independent of surface density . the linear dependence still holds , indicating that this linear behavior is not sensitive to the modest -dependence of landau level broadening as long as the system is in the overlapped landau level regime . from the above discussion , it is obvious that lmr shows up in the system having overlapped landau levels and the separation of landau levels makes the mr departure from the linear increase . at high temperature , the thermal energy would smear the level separation and phonon scatterings further broaden landau levels . hence , it is believed that this lmr will be robust against raising temperature . this is indeed the case as seen in fig. , where we plot the calculated magnetoresistivity for the above system zero - temperature linear mobility m/vs versus the magnetic field at different lattice temperatures . we can see that raising temperature to room temperature has little effect on the linearity of mr . due to the decreased mobility at higher temperature from phonon scattering , the weak sdh oscillation on the linear background tends to vanish . these features are in good agreement experimental report. in summary , we have studied the two - dimensional magnetotransport in the flat surface of a three - dimensional ti , which arises from the surface states wavevector - linear energy dispersion and a finite , positive zeeman splitting within the bulk energy gap . when the level broadening is comparable to or larger than the landau - level separation and the conduction electrons spread over many landau levels , a positive , dominantly linear and non - saturating magnetoresistance appears within a quite wide range of magnetic field and persists up to room temperature . this remarkable lmr provides a possible mechanism for the recently observed linear magnetoresistance in topological insulator bise nanoribbons. in contrast to quantum hall effect which appears in the case of well formed landau levels and to abrikosov s quantum magnetotransport, which is limited to the extreme quantum limit that all electrons coalesce into the lowest landau level , the discussed lmr is a phenomena of pure classical two - dimensional magnetotransport in a system having linear - energy - dispersion , appearing in the regime of overlapped landau levels , irrespective of its showing up in relatively high magnetic field range . furthermore , the present scheme deals spatially uniform case without invoking the mobility fluctuation in a strongly inhomogeneous system , which is required in the classical parish and littlewood model to produce a lmr. the appearance of this significant positive - increasing linear magnetoresistance depends on the existence of a positive and sizable effective g - factor . if the zeeman energy splitting is quite small the resistivity would exhibit little change changing magnetic field . in the case of a negative and sizable effective g - factor the magnetoresistivity would decrease linearly increasing magnetic field . therefore , the behavior of the longitudinal resistivity versus magnetic field may provide a useful way for judging the direction and the size of the effective zeeman energy splitting in ti surface states .", "summary": "a positive , non - saturating and dominantly linear magnetoresistance is demonstrated to occur in the surface state of a topological insulator having a wavevector - linear energy dispersion together finite positive zeeman energy splitting . this linear magnetoresistance shows up within quite wide magnetic - field range in a spatially homogenous system of high carrier density and low mobility in which the conduction electrons are in extended states and spread over many smeared landau levels , and is robust against increasing temperature , in agreement recent experimental findings in bise nanoribbons ."}
{"article": "a magnitude limited complete census of variable stars in nearby dwarf galaxies allows important contributions to the star formation history of these systems . measurements of some variable stars can supply improved distance determinations for the host galaxies , others will provide important constraints for the population analysis . different classes of variables can further improve the understanding of the star formation history of these system , functioning as tracers of star formation during different epochs . we expect the data set of our long term monitoring program to be especially well suited to study the contents of red long - period variables and to re - investigate the paucity of cepheids days as reported by sandage & carlson ( 1985 ) . we selected a sample of six local group dwarf irregular galaxies which are visible 0.8 m telescope of our institute at mt . the names and additional data from the literature compilation by mateo ( 1998 ) are shown in table 1 . .names , variable star counts , absolute -band brightness in mag , and current distance estimation in kpc for the dwarf galaxies observed in our project . the data are taken from the literature compilation by mateo ( 1995 ) . for leo a the data are from the work of dolphin et . al ( 2002 ) and from this work . this work the observations so far were carried out in and -band , sparsely sampling a three year period starting test observations in 1999 . this part of the data set should be sensitive for long period variable stars periods up to days . additional observations in , and -band were obtained during 3 observing campaigns at the 1.23 m telescope on calar alto densely sampling three two week long periods . these observations should provide a ground for a search for variable stars shorter periods ranging from days up to days . the acquired data were bias subtracted , flat - fielded and cosmic ray rejected . then , the images from one night were astrometrically aligned to a common reference frame and combined individual weights proportional to their . for each epoch , consisting of all the stacked images of a single night , a difference image against a common deep reference frame was created using an implementation ( gssl & riffeser , 2002 , 2003 ) of the alard algorithm ( alard & lupton , 1998 ) . finally , these difference images were convolved stellar psf . to extract lightcurves from the reduced data , first all pixels deviating significantly from the reference image in a minimum number of epochs were flagged , utilizing the complete per - pixel error propagation of our data reduction pipeline . then , using these coordinates as input , values and associated errors are read from the difference images and the lightcurve data are assembled . to search for periodic signals in the extracted difference fluxes , a lomb ( 1976 ) algorithm using the interpretation from scargle ( 1982 ) is applied . the photometric calibration was conducted using the hst data published by schulte - ladbeck et al . for the galaxies leo a , and ugca 92 , we have a very good monitoring and a large fraction of the data passed already the pipeline . the leo a data set serves as test case : a total of 26 variable star candidates were detected . among them , we identified 16 secure long period variables ( typical average values , and period ) , and we have 8 further candidates for lpvs . in addition we were able to identify two good candidates for cephei stars best fitting periods of 6.4 and 1.69 days . the later candidate was previously described by dolphin et al . ( 2002 ) as c2-v58 period of 1.4 days . the dolphin et al . period solution fails in deriving a reliable lightcurve , yet , applying our period value to their data set yields reasonable results . the phase convolved lightcurves for the two cephei variables are shown in figure 1 . the color magnitude diagram shown in the left panel of figure 2 is based upon the hst data published by tolstoy et al . ( 1996 ) and schulte - ladbeck et al . flagged by bigger symbols are those variables from our sample that lie inside the hst field of view , two cephei variables in the instability strip ( crosses ) and the candidates for long term variability ( triangles ) in the regime of the red giants . tolstoy et al . ( 1996 ) based on ground - based data found a distance modulus for leo a of 24.2 and a resulting distance of 690 kpc ( see also schulte - ladbeck et al . ) . this result got further support by the search for short periodic variables wiyn telescope within 3 consecutive days in dec . 2000 ( dolphin et al . our data complement this dataset for longer periods . the right hand panel of figure 2 shows the period - luminosity ( pl ) relation of the smc shifted to the distance determined by tolstoy et al . the short period variables measured by dolphin coincide shown pl relation . the overplotted values for the two cepheids from our survey ( crosses ) support this relation also in the regime of longer periods . we presented preliminary results for our survey for variable stars in a sample of irregular local group dwarf galaxies . for the leo a dwarf galaxy , the best analysed case so far , we already identified a total of 26 candidates for variability , 16 of these as long period variables and 2 cephei stars . we compared the later period - luminosity relation and the short period variables discussed by dolphin et al . we found , that our cepheids fully support their findings and the resulting distance estimate for leo a. this result is further in good agreement trgb distance ( tolstoy et al . , schulte - ladbeck et al . ) . the location of the lpvs in the color - magnitude diagram indicate that most of them are early asymptotic giant branch stars . while a complete census of these intermediate age stars is missing for most of the local group members , a proper statistic of their appearance can guide the reconstruction of the star formation history at the age of several gyr by - passing the age metalicity degeneracy inherent to color magnitude diagram studies . we like to thank drs . i. drozdovsky , c. maraston , r.e . schulte - ladbeck , and e. tolstoy for helpful discussion . we acknowledge the support of the calar alto and wendelstein staff . j. fliri and a. riffeser carried out some of our observations . the project is supported by the deutsche forschungsgemeinschaft grant ho 1812/3 - 1 and ho 1812/3 - 2 . alard , c. & lupton , r. h. , , 503 , 325 dolphin , a. e. et al . 2002 , , 123 , 3154 gssl c. a. & riffeser a. 2002 , , 381 , 1095 gssl , c. a. & riffeser , a. 2003 , asp conf . 295 , 229 lomb n. r. 1976 , , 39 , 447 mateo m. l. 1998 , , 36 , 435 sandage , a. & carlson , g. 1985 , , 90 , 1464 scargle j. d. 1982 , , 263 , 835 schulte - ladbeck r. et al . 2002 , , 124 , 896 tolstoy e. et al . 1996 , , 116 , 1244", "summary": "dwarf galaxies in the local group provide a unique astrophysical laboratory . despite their proximity some of these systems still lack a reliable distance determination as well as studies of their stellar content and star formation history . we present first results of our survey of variable stars in a sample of six local group dwarf irregular galaxies . taking the leo a dwarf galaxy as an example we describe observational strategies and data reduction . we discuss the lightcurves of two newly found cephei stars and place them into the context of a previously derived p - l relation . finally we discuss the lpv content of leo a."}
{"article": "invariants are a popular concept in object recognition and image retrieval . they aim to provide descriptions that remain constant under certain geometric or radiometric transformations of the scene , thereby reducing the search space . they can be classified into global invariants , typically based either on a set of key points or on moments , and local invariants , typically based on derivatives of the image function which is assumed to be continuous and differentiable . the geometric transformations of interest often include translation , rotation , and scaling , summarily referred to as similarity transformations . in a previous paper , building on work done by schmid and mohr , we have proposed differential invariants for those similarity transformations , plus linear brightness change . here , we are looking at a non - linear brightness change known as gamma correction . gamma correction is a non - linear quantization of the brightness measurements performed by many cameras during the image formation process . the idea is to achieve better perceptual results by maintaining an approximately constant ratio between adjacent brightness levels , placing the quantization levels apart by the just noticeable difference . incidentally , this non - linear quantization also precompensates for the non - linear mapping from voltage to brightness in electronic display devices . gamma correction can be expressed by the equation where is the input intensity , is the output intensity , and is a normalization factor which is determined by the value of . for output devices , the ntsc standard specifies . for input devices like cameras , the parameter value is just inversed , resulting in a typical value of . the camera we used , the sony 3 ccd color camera dxc 950 , exhibited . for the kodak megaplus xrc camera ] shows the intensity mapping of 8-bit data for different values of . it turns out that an invariant under gamma correction can be designed from first and second order derivatives . additional invariance under scaling requires third order derivatives . derivatives are by nature translationally invariant . rotational invariance in 2-d is achieved by using rotationally symmetric operators . the key idea for the design of the proposed invariants is to form suitable ratios of the derivatives of the image function such that the parameters describing the transformation of interest will cancel out . this idea has been used in to achieve invariance under linear brightness changes , and it can be adjusted to the context of gamma correction by at least conceptually considering the logarithm of the image function . for simplicity , we begin 1-d image functions . let be the image function , i.e. the original signal , assumed to be continuous and differentiable , and the corresponding gamma corrected function . note that is a special case of where . taking the logarithm yields derivatives , and . we can now define the invariant under gamma correction to be {0mm}{13 mm } & = \\\\ & = \\ ] ] the factor has been eliminated by taking derivatives , and has canceled out . furthermore , turns out to be completely specified in terms of the original image function and its derivatives , i.e. the logarithm actually does nt have to be computed . the notation indicates that the invariant depends on the underlying image function and location the invariance holds under gamma correction , not under spatial changes of the image function . a shortcoming of is that it is undefined where the denominator is zero . therefore , we modify to be continuous everywhere : {0mm}{8 mm } { \\normalsize } & & { \\normalsize if } \\\\ & & { \\normalsize else } \\\\ \\ ] ] where , for notational convenience , we have dropped the variable . the modification entails . note that the modification is just a heuristic to deal poles . if all derivatives are zero because the image function is constant , then differentials are certainly not the best way to represent the function . if scaling is a transformation that has to be considered , then another parameter describing the change of size has to be introduced . that is , scaling is modeled here as variable substitution : the scaled version of is . so we are looking at the function where the derivatives respect to are , , and . now the invariant is obtained by defining a suitable ratio of the derivatives such that both and cancel out : {0mm}{10 mm } & = \\ ] ] analogously to eq . , we can define a modified invariant {0mm}{8 mm } { \\normalsize } & & { \\normalsize if cond2 } \\\\ & & { \\normalsize else } \\\\ \\ ] ] where condition cond1 is , and condition cond2 is . again , this modification entails . it is a straightforward albeit cumbersome exercise to verify the invariants from eqs . and analytical , differentiable function . as an arbitrary example , we choose the first three derivatives are , , and . then , according to eq . , . if we now replace gamma corrected version , say , the first derivative becomes , the second derivative is , and the third is . if we plug these derivatives into eq . , we obtain an expression for which is identical to the one for above . the algebraically inclined reader is encouraged to verify the invariant for the same function . shows the example function and its gamma corrected counterpart , together their derivatives and the two modified invariants . as expected , the graphs of the invariants are the same on the right as on the left . note that the invariants define a many - to - one mapping . that is , the mapping is not information preserving , and it is not possible to reconstruct the original image from its invariant representation . if or are to be computed on images , then eqs . to have to be generalized to two dimensions . this is to be done in a rotationally invariant way in order to achieve invariance under similarity transformations . the standard way is to use rotationally symmetric operators . for the first derivative , we have the well known gradient magnitude , defined as where is the 2-d image function , and , are partial derivatives along the x - axis and the y - axis . for the second order derivative , we can use the linear laplacian horn also presents an alternative second order derivative operator , the quadratic variation since the qv is not a linear operator and more expensive to compute , we use the laplacian for our implementation . for the third order derivative , we can define , in close analogy quadratic variation , a cubic variation as the invariants from eqs . to remain valid in 2-d if we replace , , and . this can be verified by going through the same argument as for the functions . recall that the critical observation in eq . was that cancels out , which is the case when all derivatives return a factor . but such is also the case rotationally symmetric operators mentioned above . for example , if we apply the gradient magnitude operator to , i.e. to the logarithm of a gamma corrected image function , we obtain returning a factor , and analogously for , qv , and cv . a similar argument holds for eq . where we have to show , in addition , that the first derivative returns a factor , the second derivative returns a factor , and the third derivative returns a factor , which is the case for our 2-d operators . while the derivatives of continuous , differentiable functions are uniquely defined , there are many ways to implement derivatives for sampled functions . we follow schmid and mohr , ter haar romeny , and many other researchers in employing the derivatives of the gaussian function as filters to compute the derivatives of a sampled image function via convolution . this way , derivation is combined smoothing . the 2-d zero mean gaussian is defined as the partial derivatives up to third order are , , , , , , , , . they are shown in fig . . we used the parameter setting and kernel size these kernels , eq . , for example , is implemented as at each pixel , where denotes convolution . we evaluate the invariant from eq . in two different ways . first , we measure how much the invariant computed on an image without gamma correction is different from the invariant computed on the same image but gamma correction . theoretical , this difference should be zero , but in practice , it is not . second , we compare template matching accuracy on intensity images , again without and gamma correction , to the accuracy achievable if instead the invariant representation is used . we also examine whether the results can be improved by prefiltering . a straightforward error measure is the absolute error , where `` 0gc '' refers to the image without gamma correction , and gc stands for either `` sgc '' if the gamma correction is done synthetically via eq . , or for `` cgc '' if the gamma correction is done via the camera hardware . like the invariant itself , the absolute error is computed at each pixel location of the image , except for the image boundaries where the derivatives and therefore the invariants can not be computed reliably . shows an example image . the sgc image has been computed from the 0gc image , . note that the gamma correction is done after the quantization of the 0gc image , since we do nt have access to the 0gc image before quantization . shows the invariant representations of the image data from fig . and the corresponding absolute errors . since , we have . the dark points in fig . , ( c ) and ( e ) , indicate areas of large errors . we observe two error sources : * the invariant can not be computed robustly in homogeneous regions . this is hardly surprising , given that it is based on differentials which are by definition only sensitive to spatial changes of the signal . * there are outliers even in the sgc invariant representation , at points of very high contrast edges . they are a byproduct of the inherent smoothing when the derivatives are computed differentials of the gaussian . note that the latter put a ceiling on the maximum gradient magnitude that is computable on 8-bit images . in addition to computing the absolute error , we can also compute the relative error , in percent , as then we can define the set of reliable points , relative to some error threshold , as and , the percentage of reliable points , as where is the number of valid , i.e. non - boundary , pixels in the image . shows , in the first row , the reliable points for three different values of the threshold . the second row shows the sets of reliable points for the same thresholds if we gently prefilter the 0gc and cgc images . the corresponding data for the ten test images from fig . is summarized in table . derivatives are known to be sensitive to noise . noise can be reduced by smoothing the original data before the invariants are computed . on the other hand , derivatives should be computed as locally as possible . these conflicting goals to be considered , we experiment gentle prefiltering , using a gaussian filter of size =1.0 . the size of the gaussian to compute the invariant is set to =1.0 . note that and can not be combined into just one gaussian because of the non - linearity of the invariant . respect to the set of reliable points , we observe that after prefiltering , roughly half the points , on average , have a relative error of less than 20% . gentle prefiltering consistently reduces both absolute and relative errors , but strong prefiltering does not . template matching is a frequently employed technique in computer vision . here , we will examine how gamma correction affects the spatial accuracy of template matching , and whether that accuracy can be improved by using the invariant . an overview of the testbed scenario is given in fig . . a small template of size , representing the search pattern , is taken from a 0gc intensity image , i.e. without gamma correction . this query template is then correlated corresponding cgc intensity image , i.e. the same scene but gamma correction switched on . if the correlation maximum occurs at exactly the location where the 0gc query template has been cut out , we call this a correct maximum correlation position , or cmcp . the correlation function employed here is based on a normalized mean squared difference : where is an image , is a template positioned at , is the mean of the subimage of at of the same size as , is the mean of the template , and . the template location problem then is to perform this correlation for the whole image and to determine whether the position of the correlation maximum occurs precisely at . demonstrates the template location problem , on the left for an intensity image , and on the right for its invariant representation . the black box marks the position of the original template at ( 40,15 ) , and the white box marks the position of the matched template , which is incorrectly located at ( 50,64 ) in the intensity image . on the right , the matched template ( white ) has overwritten the original template ( black ) at the same , correctly identified position . visualizes the correlation function over the whole image . the white areas are regions of high correlation . the example from figs . and deals only one arbitrarily selected template . in order to systematically analyze the template location problem , we repeat the correlation process for all possible template locations . then we can define the correlation accuracy ca as the percentage of correctly located templates , where is the size of the template , is the set of correct maximum correlation positions , and , again , is the number of valid pixels . we compute the correlation accuracy both for unfiltered images and for gently prefiltered images , . shows the binary correlation accuracy matrices for our example image . the cmcp set is shown in white , its complement and the boundaries in black . we observe a higher correlation accuracy for the invariant representation , which is improved by the prefiltering . we have computed the correlation accuracy for all the images given in fig . . the results are shown in table and visualized in fig . . we observe the following : * the correlation accuracy ca is higher on the invariant representation than on the intensity images . * the correlation accuracy is higher on the invariant representation gentle prefiltering , , than without prefiltering . we also observed a decrease in correlation accuracy if we increase the prefiltering well beyond . by contrast , prefiltering seems to be always detrimental to the intensity images ca . * the correlation accuracy shows a wide variation , roughly in the range 30%% for the unfiltered intensity images and 50%% for prefiltered invariant representations . similarly , the gain in correlation accuracy ranges from close to zero up to 45% . for our test images , it turns out that the invariant representation is always superior , but that does nt necessarily have to be the case . * the medians and means of the cas over all test images confirm the gain in correlation accuracy for the invariant representation . * the larger the template size , the higher the correlation accuracy , independent of the representation . a larger template size means more structure , and more discriminatory power . we have proposed novel invariants that combine invariance under gamma correction invariance under geometric transformations . in a general sense , the invariants can be seen as trading off derivatives for a power law parameter , which makes them interesting for applications beyond image processing . the error analysis of our implementation on real images has shown that , for sampled data , the invariants can not be computed robustly everywhere . nevertheless , the template matching application scenario has demonstrated that a performance gain is achievable by using the proposed invariant . bob woodham suggested to the author to look into invariance under gamma correction . his meticulous comments on this work were much appreciated . jochen lang helped acquisition of image data through the acme facility . d. forsyth , j. mundy , a. zisserman , c. coelho , c. rothwell , `` invariant descriptors for 3-d object recognition and pose '' , ieee transactions on pattern analysis and machine intelligence , vol.13 , no.10 , pp.971 - 991 , oct.1991 . d. pai , j. lang , j. lloyd , r. woodham , `` acme , a telerobotic active measurement facility '' , sixth international symposium on experimental robotics , sydney , 1999 . see also : http://www.cs.ubc.ca/nest/lci/acme/", "summary": "this paper presents invariants under gamma correction and similarity transformations . the invariants are local features based on differentials which are implemented using derivatives of the gaussian . the use of the proposed invariant representation is shown to yield improved correlation results in a template matching scenario ."}
{"article": "in quantum information processing , information is stored and processed quantum system . a quantum system is always in contact surrounding environment , which leads to decoherence in the quantum system . decoherence must be suppressed for quantum information stored in qubits to be intact . there are several proposals to fight against decoherence . quantum error correction , abriviated as qec hereafter , is one of the most promising candidate to suppress environmental noise , which leads to decoherence . by adding extra ancillary qubits , in analogy classical error correction , it is possible to encode a data qubit to an -qubit codeword in such a way that an error which acted in the error quantum channel is identified by measuring another set of ancillary qubits added for error syndrome readout . then the correct codeword is recovered from a codeword suffering from a possible error by applying a recovery operation , whose explicit form is determined by the error syndrome readout . in contrast conventional scheme outlined in the previous paragraph , there is a scheme in which neither syndrome readouts nor syndrome readout ancilla qubits are required . in particular , in , a general efficient scheme was proposed . a data qubit is encoded encoding ancilla qubits by the same encoding circuit as the conventional one , after which a noisy channel is applied on the codeword . subsequently , the inverse of the encoding circuit is applied on a codeword , which possibly suffers from an error . the resulting state is a tensor product of the data qubit state possible error and the ancilla qubit state . it is possible to correct erroneous data qubit state by applying correction gates ancilla qubits as control qubits and the data qubit as a target qubit . this paper presents two examples of error correcting codes falling in the second category . the noisy quantum channel is assumed to be fully correlated , which means all the qubits constituting the codeword are subject to the same error operators . in most physical realizations of a quantum computer , the system size is typically on the order of a few micrometers or less , while the environmental noise , such as electromagnetic wave , has a wavelength on the order of a few millimeters or centimeters . then it is natural to assume all the qubits in the register suffer from the same error operator . to demonstrate the advantage of the second category , we restrict ourselves within the noise operators in the following , where is the number of constituent qubits in the codeword . we show that there exists an -qubit encoding which accommodates an -qubit data state if is odd and an -qubit date state if is even . although the channel is somewhat artificial as an error channel , we may apply our error correction scheme in the following situation . suppose alice wants to send qubits to bob . their qubit bases differ by unitary operations or . even when they do not know which basis the other party employs , the can correctly send qubits by adding one extra qubits ( when is odd ) or two extra qubits ( when is even ) . we state the theorems and prove them in the next section . the last section is devoted to summary and discussions . in the following , denotes the th component of the pauli matrices and we take the basis vectors so that is diagonalized . we introduce operators and acting on the -qubit space , where as mentioned before . let be complex matrices , and let . denote by the ( joint ) rank- numerical range of , which is the collection of such that for some rank- orthogonal projection . a quantum channel of the form has a -dimensional quantum error correcting code ( qecc ) if and only if . to prove this statement , we need to recall the knill - laflamme correctability condition , which asserts that given a quantum channel error operators , is a qecc of if and only if , where is the projection operator range space . it should be clear that if and only if there is a qecc dimension . now it follows from and the relations when is even and when is odd that the channel has a -dimensional qecc if and only if by noting that irrespective of rank , we find if and only if . suppose is odd . then . our proof is constructive . for , denote . let then , where is the number of -combinations from elements . since we have let be the orthogonal projection onto . then the above observation shows that and . therefore , , which shows that and hence is shown to be a -dimensional qecc . now let us turn to the even case . we first state a lemma which is necessary to prove the theorem . let be a normal matrix . then the rank- numerical range of is the intersection of the convex hulls of any eigenvalues of . the proof of the lemma is found in . suppose is even . then but . proof let . by theorem , . consider observe that the projection onto satisfies and and hence , which proves . since is a commuting family , and can be diagonalized simultaneously . we may assume that since , we have let us show that . we first note the identity for hermitian . let us replace by and by to obtain . since and commute , is normal and lemma is applicable . from eqs . and , we find has eigenvalues and each eigenvalue is -fold degenerate . by taking and in lemma , we find the rank- numerical range of is the intersection of the convex hulls of any eigenvalues . since each eigenvalue has multiplicity , each convex hull involves at least three eigenvalues . by inspecting four eigenvalues plotted in the complex plane , we easily find the intersection of all the convex hulls is a single point , which proves . similarly , we prove . from these equalities we obtain suppose . let be a rank- projection such that . let \\ ] ] where each has size . from and , we have four independent equations let be the singular value decomposition of , where is a nonnegative diagonal matrix and . then the above equations are solved as by collecting these results , we find the projection operator is decomposed as \\\\\\,.\\ ] ] since rank and , it follows from that . let then both and are non - singular . on the other hand , the assumption implies and hence , which is a contradiction . therefore , . in the following , we give an explicit construction of qecc for in eq . . the technique is based on theorem and the results in . let be the matrix columns in the set define the matrix $ ] . in our qec , an -qubit state is encoded ancilla qubit as . then a noisy quantum channel is applied on the encoded state and subsequently the recovery operation is applied so that the decoded state automatically appears in the output syndrome measurements . our qec is concisely summarized as where . choosing an encoding amounts to assigning each of column vectors in a basis vector of the whole hilbert space without repetition . therefore there are large degrees of freedom in the choice of encoding . in the following examples , we have chosen encoding whose quantum circuit can be implemented least number of cnot gates . since our decoding circuit is the inverse of the encoding circuit , it is also implemented least number of cnot gates . when , the unitary operation can be chosen as when , can be chosen as figure shows quantum circuits of the matrix for and . -qubit state single ancilla qubit initially in the state . ( a ) is for while ( b ) is for . the quantum channel in the box represents a quantum operation fully correlated noise given in eq . the output ancilla state is for error operators and ( and ) for and for and ( and ) for .,width=529 ] it follows from eq . that the recovery circuit is the inverse of the encoding circuit . it seems , at first sight , that the implementations given in fig . 1 contradict . since the controlled not gate in the end of the recovery circuit is missing in the encoding circuit . note , however , that the top qubit is set to initially and the controlled not gate is safely omitted without affecting encoding . we construct a decoherence - free encoding when is even as follows . the codeword in this case is immune to the noise operators , which is an analogue of noiseless subspace / subsystem introduced in . let then evidently a vector is separately invariant under the action of and . there are orthogonal vectors of such form , e.g. we have four vectors , for . thus we find a decoherence - free encoding for qubits by projecting onto this invariant subspace spanned by these basis . it should be noted that the projection operator to the subspace spanned by the four vectors in eq . satisfies rank and , which shows . it is easy to generalize this result to cases arbitrary . figure ( a ) and ( b ) depict quantum circuits for ( a ) and ( b ) , respectively . -qubit state ancilla qubit initially in the state . ( a ) is for while ( b ) is for . the quantum channel in the box represents a quantum operation fully correlated noise given in eq . the output ancilla state is always , irrespective of error operators acted in the channel.,width=529 ] we have shown that there is a quantum error correction which suppresses fully correlated errors of the form , in which qubits are required to encode ( i ) data qubit states when is odd and ( ii ) data qubit states when is even . we have proved these statements by using operator theoretical technique . neither syndrome measurements nor ancilla qubits for syndrome measurement are required in our scheme , which makes physical implementation of our scheme highly practical . examples and are analyzed in detail and explicit quantum circuits implementing our qec least number of cnot gate were obtained . since the error operators are closed under matrix multiplication , errors can be corrected even when they act on the codeword many times . a somewhat similar qec has been reported in . they analyzed a partially correlated noise , where the error operators acts on a fixed number of the codeword qubits simultaneously . they have shown that the quantum packing bound was violated by taking advantage of degeneracy of the codes . justification of such a noise physically , however , seems to be rather difficult . they have also shown that correlated noise acting on an arbitrary number of qubits can encode data qubits . in contrast , we have analyzed a fully correlated noise , which shows the highest degeneracy , and have shown that data qubits can be encoded -qubit codeword when is odd . clearly , our qec suppressing fully correlated errors is optimal as it is clear that one can not encode qubits as data qubits for odd and we have shown that one can not encode qubits for even . ckl was supported by a usa nsf grant , a hk rgc grant , the 2011 fulbright fellowship , and the 2011 shanxi 100 talent program . he is an honorary professor of university of hong kong , taiyuan university of technology , and shanghai university . mn and ht were supported by `` open research center '' project for private universities : matching fund subsidy from mext ( ministry of education , culture , sports , science and technology ) . ytp was supported by a usa nsf grant . nss was supported by a hk rgc grant .", "summary": "we investigate an efficient quantum error correction of a fully correlated noise . suppose the noise is characterized by a quantum channel whose error operators take fully correlated forms given by , and , where is the number of qubits encoding the codeword . it is proved that ( i ) qubits codeword encodes data qubits when is odd and ( ii ) qubits codeword implements an error - free encoding , which encode data qubits when is even . quantum circuits implementing these schemes are constructed . quantum error correction , higher rank numerical range , recovery operator , mixed unitary channel"}
{"article": "the origin - destination ( od ) matrix is important in transportation analysis . the matrix contains information on the number of travellers that commute or the amount of freight shipped between different zones of a region . the od matrix is difficult and often costly to obtain by direct measurements / interviews or surveys , but by using incomplete traffic counts and other available information one may obtain a reasonable estimate . a particular application of the od matrix estimation is in the area of public transport . in order to improve their service , the responsible managers are looking for on - going evaluation of the passenger flow and the reasons that would influence this flow . this is typically the case for the city rail , sydney bus and sydney ferry organisations , which handle the public transport in the region around the city of sydney , australia . cityrail and co are handling a large number of stations ( wharfs , bus stops ) for trains ( buses and ferries ) across the state . they carry thousands of passengers every day , and periodically optimise the time - table schedule to best meet the changing demand . + + an ideal optimization of the schedule would consider the resources in trains , drivers , stations and passengers . while the primary informations ( trains , drivers , stations ) are known to cityrail and co , the number of passenger on each train between each station can not be deduced easily given their current passenger flow data collection processes . + + various approaches to estimating the od matrix using traffic counts have been developed and tested using traffic counts , or road traffic flows , . most of the papers in the literature solve this problem by postulating a general model for the trip distribution , for example a gravity type model , which aims at introducing a prior knowledge on the traffic flows and assigning a cost to each journey . then the inference is produced to estimate the parameters of this model . all these papers are not passengers oriented . + most of the work relating to od matrix estimation are based on passengers observations assuming the knowledge of where the people get in and out of the public transport . lo et al developed a framework centred on the passenger choice , which they called the random link choice , and model this to obtain a maximum likelihood estimator . nandi et al applied a strategy centred on a fixed cost per person per kilometre assumption on the air - route network of india and provide some comparisons real data . + when the information is not available ( for example we have no data on when passengers get off the bus ) , kostakos offers to use a wireless detection of the passengers trips , and lundgren and peterson s model is based on a target od - matrix previously defined . however , none of the cited work considered using survey data . indeed , if no complete information is available about the passengers destinations , the simplest solution is to use an appropriate survey to estimate destination information . furthermore , what characteristics of the survey are required for the estimation to be accurate ? bierliaire and toint introduces a structure - based estimation of the origin - destination matrix based on parking surveys . in their article , they used the parking surveys to infer an a priori estimate of the od matrix , and they used this prior in coordination partial observations of the network flows to derive a generalized least square estimator of the od matrix . despite its novelty , this article assume that the behaviour of car - user and public transport users are the same , at least regarding their respective od matrix . given that the public transport network topology is often different from the road network topology , one may doubt the accuracy of this assumption . moreover , they just use the partial structure extracted from the surveys . + the purpose of this paper is then to develop an estimation procedure for the origin - destination matrix based on the ticket records available for the transport network and/or on previous surveys . unlike the article from bierliaire , we use survey data collection from public transport users , and estimate the approximate whole matrix structure through the estimation of its eigenvectors . we propose a robust version of the estimator to avoid biases induced by the survey . we also construct a regression estimation procedure that accounts for the influence of exogenous variable such as the weather conditions or the time of the year . + we first briefly present the passenger model , and then move on to outlining the observations model . in section , we explain how the measurements are obtained , and what measurements error should be expected . in section , we explain the assumptions we make on the measurements , and how this affects our estimation procedure . we present in section the maximum likelihood ( ml ) estimation procedure , by providing a system of equation to be solved , for deriving estimators . we improve on this ml estimation to make it robust to survey biases in section . finally , we present a simulation example and an application to a real world case in section . we finally comment on the results and outline some future research opportunities . let be the matrix of passengers number between the stations in the rail network over time period so that is the number of passengers who depart from station and arrive at station at time period . given that there is an obvious time dependency here , denoted by the period in which the commuting occur ( for example a day ) . the purpose of this work is to provide an estimation of given the observations specified in section . the observations provided about the passengers are very different , and only considering them all allow a direct estimation of . we list in the subsections , and the different kind of observations . a casual commuter is defined as a single or return journey that is not repeated regularly ( e.g. daily ) . typically , people going to a once - in - a - year event will buy their ticket for that trajectory and will probably return on the same day . accordingly for single and day return tickets , we have complete information under the assumption that they take the next train after purchasing their ticket and that they take the shortest route . let be that matrix of measurements . each journey between major stations , the passenger has to validate his ticket through the machines at the entrance of the station , and do it again at the exit . between minor stations we assume they take the next train to arrive at the station they purchased their ticket at and assume they take the trio planners recommended route for that time . two scenarios are considered . in the first one , ( called ) , every station in the network have these machines . in the second case ( called ) only major stations have these machines . in any case , let call the vector corresponding to the departures at the stations , and the vector of arrivals . fortunately we can have regular passengers specific departure and destination , and this matrix will be denoted , where the rows stand for the departure stations and the columns for the arrival stations . this matrix is observed , and assumed distributed according to a poisson probability function mean . + the main part of the information , however , remains unknown . indeed most of the passengers will probably have a zone ticket for a period of time , from 1 week to 1 year . the nature of these tickets make the station of departure and arrival unknown , and is the main challenge of this paper . let call the matrix of zone passengers numbers . + to make a proper statistical inference , we need two assumptions ; * the traveller will act independently of the validity duration of his ticket ; * the regular traveller commits to a return journey on each working day . the observations linked to this model are two - folds . for major stations , we have the total number of passengers that crossed the boom gates , in and out . for stations without boom gates , the observations have to estimated using a survey . we also have access to the total number of people valid zone ticket at time ( e.g. the day of the analysis ) , denoted , in the end , the total number of regular passenger at the time period will be denoted , and we have , these very different observations , we need a good fitting model based on reasonable assumptions . sections , , and presents these assumptions for each parameter in our model . recall that is a matrix of count , the main assumption on that matrix is that the number of passenger is the sum of the casual passengers plus the regular passengers plus a matrix stating the unusual big events such as major sporting events , or large concerts ( called ) , the casual commuter journey could be assumed to be poisson distributed i.e. is supposed to be drawn poisson distribution which parameter belong to the matrix . ] where is the matrix of means for the counts . + however , the variance of the counts are not expected to be equal to their mean and so the poisson counts assumption may be unrealistic . therefore , we decided to use a negative binomial regression model for , which can be over - dispersed in order to better describe the distribution of the counts . we specify that is distributed according to a gamma distribution , . for a purpose of simplicity , let be distributed as negative binomial parameters and ( we will denote ) . according to the definition of the measurements , the following relationships hold : where and are the vectors of the total number of departures and arrivals at each station during time period . for the same reasons as described for the casual matrix , we will use a negative binomial distribution to model the uncertainty around the regular traveller s information . however , unlike the casual commuter , we do not suspect an over - dispersion but an under - dispersion , so that , and . let and be the expectation of and . when the model is well defined , the estimation procedure is computationally straight forward , e.g. , between major stations where we have complete information of arrivals and departures . meaning that the maximum likelihood estimation method accuracy , practically depends on the efficient solving of the optimization problem . in this section , the stationary model parameters are estimated from the data . since the process is unlikely to be stationary , we present a second option ( section ) , a multivariate spatio - temporal model that we expect to fit the data better . the estimation procedure will be carried out in well - defined steps . if we ignore the time dependence , the successive observations can be considered independent , identical random counts from negative binomial or poisson distribution . this means that simple maximum likelihood estimation should work well , especially for large sample sizes . we observe for several realizations . given no space - time dependencies we assume that is independently distributed as . the likelihood is then , \\ ] ] where stands for one element of the matrix . we thus can estimate the parameters through , despite the absence of closed form solution to this problem , the optimization algorithms can quickly lead to a global maximum . unfortunately we do nt have complete information for those weekly , monthly , quarterly or anuual tickets ( long - term tickets ) . we have information of the times they enter and departs at major stations but we do nt have complete information for the long term tickets either to or from minor stations . our assumption here is that only a proportion of the people will travel on day , where . is an additional parameter that reflects the passengers habit . it does exist because when performing the estimation , one may find a bigger estimation of travellers than what is observed . some of the difference is due to the randomness of , but it might also be explained by the fact that travellers prepaid long term tickets will not necessary travel each of the working day of the week . + however , we may provide the same estimation for the parameters as we did in the previous section , that is , where stands for the same likelihood function as above . + this leads us to the final estimation , the contribution this paper makes to the literature . the aim is to estimate the matrix available departure and arrival data . the first step is to estimate the general shape of the matrix . the problem is to achieve this in a simple way given that is to be estimated parameters , and only equations . the following paragraph presents an elegant solution to this problem . + recall as the expectation of . it is assumed symmetric , we can diagonalize it , so that , where is a projection matrix of eigenvectors of and is a diagonal matrix , terms equal to the respective eigenvalues . therefore , if the structure of is known ( i.e. the eigenvectors are known ) and constant , then we have reduced the problem to solving a system of unknown parameters equations . and the previous estimations , we have the following system , where and are obtained by simple subtraction . the probability density function of the observations can then be written , \\quad p \\big ( y {di}^t \\vert r z , p {rz } \\big ) & \\sim & ( \\sum j r^{ij} z , p {rz})\\ ] ] where and . according to this equation , we then have likelihood equations ( ] , \\ ] ] most of the optimization algorithms that deal constraint require an initialization which belong to the constrained space . one could be tempted to address as a starting point the mean value of the observations , according to the one - dimensional result . however , it is very unlikely that this initial point will satisfy the constraints . therefore , the best choice so far seems to be the diagonal elements of the matrix , given that they naturally fill * constraint 1 * and * constraint 2*. + + the complete optimization program therefore becomes , initial value . this optimization program can be replaced by an explicit expression of the estimator , subject to some constraints stated in . the main constraint is the poisson distribution assumption , so that we have , + * proposition 1 : * assume that , then ^{-1 } \\ ] ] where is the matrix of estimated eigenvalues of . + if now we consider a gaussian likelihood instead of poisson , the following maximum likelihood estimator is found , + * proposition 2 : * assume that , then where is the matrix of estimated eigenvalues of . + the proofs of propositions 1 and 2 are presented in . we can also derive the follwing theorem , that ensures us of the quality of the estimation , + * theorem 1 * + assume that {\\ a.s.\\ } p ] stands for the scale of the survey , ] . then , and we have , where stands for the probability density function of . + the first integral decreases towards as grows to infinity according to eq . . the argument for the second integral is the following . according to the assumption of strong convergence of , converge towards the dirac function as goes to infinity . being strictly positive , this ends the proof . . ] * calculation in case of poisson regression ( and log link function ) * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + the beginning of the reasoning is similar to the previous one . then , if we assume that exogenous variables have impacts on the number of passengers , we can write , where are symmetric matrices reflecting the intercept for baseline commuter flows and the variable influences for changes in commuter flows from known daily influences . moreover , we assume that the same diagonalization ( meaning same eigenvectors ) can be applied , which lead us to , therefore , will be distributed according to a poisson distribution following parameter , where the parameters to be estimated are , which means we have to estimate parameters . + the probability of one observation can then be written , which gives the following log - likelihood , therefore , to obtain the final system of equation , we need to calculate the derivatives of the log - likelihood respect to each parameter .", "summary": "the estimation of the number of passengers identical journey is a common problem for public transport authorities . this problem is also known as the origin - destination estimation ( od ) problem and it has been widely studied for the past thirty years . however , the theory is missing when the observations are not limited to the passenger counts but also includes station surveys . + our aim is to provide a solid framework for the estimation of an od matrix when only a portion of the journey counts are observable . + our method consists of a statistical estimation technique for od matrix when we have the sum - of - row counts and survey - based observations . our technique differs from the previous studies in that it does not need a prior od matrix which can be hard to obtain . instead , we model the passengers behaviour through the survey data , and use the diagonalization of the partial od matrix to reduce the space parameter and derive a consistent global od matrix estimator . we demonstrate the robustness of our estimator and apply it to several examples showcasing the proposed models and approach . we highlight how other sources of data can be incorporated in the model such as explanatory variables , e.g. rainfall , indicator variables for major events , etc , and inference made in a principled , non - heuristic way . constraint maximum likelihood estimation , eigenvectors , counts estimation"}
{"article": "high q cavities such as whispering gallery mode ( wgm ) cavities have recently demonstrated quality factors as high as and have shown the potential to reach even higher q values . however , there are difficulties in measurement of the linewidth and q of such high q cavities . while in theory , the q factor could be as high as and is limited only by rayleigh scattering , in practice , it is limited by other losses in the cavity . they include absorption and scattering losses due to impurities in the cavity material , and light - induced losses due to nonlinear processes . due to the extremely small mode volume and high q - factor of the cavity , the cavity build - up intensity is extremely high , even in the case of an input small power ( as small as several mw ) . such a high resonator intensity leads to very efficient nonlinear processes inside wgm cavities , such as raman scattering , second harmonic generation , and four - wave mixing . whereas this is beneficial in many applications , it causes additional losses in the cavity and thus makes the q factor measurement unreliable ( at least , making it power - dependent ) . squeezed states of vacuum or light have been used in many applications such as improvement in interferometric and absorption measurements , for quantum teleportation and quantum cryptography , and for quantum imaging . however , to the best of our knowledge , no experiment for measurements of cavity parameters by use of squeezing has yet been reported . in this paper we propose and demonstrate an alternative method of measuring q factors by use of a squeezed vacuum field which is equivalent to a field correlated quantum sidebands . this technique is advantageous over traditional optical methods in that it utilizes the injection of squeezed vacuum into a test cavity not to excite any nonlinear processes in the cavity . when the input field is detuned from the cavity resonance frequency , it transmits only the upper or lower quantum sidebands within the cavity linewidth while reflecting the counterparts ( associated upper or lower sidebands ) and all the other sidebands . the linewidth of the cavity can then be measured by observing the destruction of the correlation between the upper and lower quantum sidebands respect to the carrier frequency . we show that the linewidth and q factor of a test cavity using the method agrees those measured by traditional optical methods . this paper is organized as follows : in . , we describe the theoretical framework for the measurement method . in . , we explain the validity of the use of squeezed vacuum as a probe for non - invasive measurements and compare the technique to using a classical state . in . , we demonstrate the method using a test cavity known cavity parameters and compare the parameter values obtained by the new method and the traditional optical methods . the conclusions of the paper are summarized in . . consider a squeezed vacuum field carrier and sideband frequencies , and respectively . as shown in fig . , when the upper sideband of the squeezed vacuum field is injected into an optical cavity resonance frequency and mirror reflectivities , and , the reflected field and its adjoint are given in terms of and its adjoint by where is the frequency - dependent cavity reflection coefficient and is the vacuum noise coupling coefficient associated transmission and intra - cavity losses . when the cavity is not perfectly mode - matched , the reflected field contains the cavity - coupled reflection and the promptly reflected field that does not couple to the cavity due to mode mismatch such that where and are spatially orthogonal and }}{1-e^{-i\\left } } , \\\\ r m & = & .\\ ] ] here , is the detuning from the cavity resonance given by and we have assumed that the resonance frequency of is far from that of such that the reflection coefficient can be treated as a frequency - independent constant at frequencies around the resonance frequency of . the vacuum noise coupling coefficients are then given by the cavity mirror reflectivity and transmission of each mirror satisfies where l is the loss of each mirror . the intra - cavity losses can be absorbed into . , r , and r , respectively . is the upper sideband of an injected field at frequency , is the cavity - filtered reflection at the frequency , is the transmission at the frequency , and is the vacuum field that couples in due to losses in the cavity at the frequency . is the cavity resonance frequency . the carrier field at frequency transmits through the cavity when . ] since the carrier is detuned from the cavity resonance frequency , the reflection acquires extra frequency - dependent phase shifts at the detuned carrier frequency and the sideband frequencies , respectively given by where and are the round - trip length and free spectral range of the cavity , and is the speed of light in vacuum . for simplicity , we transform into the rotating frame of the carrier frequency in the frequency domain , such that eqs . and become where and satisfy the commutation relations = 2\\pi\\delta(\\omega-\\omega^{'}),\\ ] ] and all others vanish ( similarly for , , , , , and ) . in the two - photon representation , the amplitude and phase quadratures of are defined by ,\\ ] ] respectively ( similarly for , , , and ) . a little algebra yields the amplitude and phase quadrature fields of the reflected light in compact matrix form , where we use the two - photon matrix representation for the operator ( similarly for , , , and ) , is a matrix representing propagation through the cavity , and comprises an overall phase shift , rotation by angle , and attenuation by factor . here we have defined , \\\\ a {\\pm } & \\equiv & {2}\\left.\\ ] ] in the case of no carrier detuning , , and and a vanish , giving neither quadrature angle rotation nor asymmetrical amplitude attenuation . in the case of cavity detunings , nonzero gives quadrature angle rotation . from eq . , when we perform homodyne detection of the reflected field local oscillator ( lo ) field , the measured amplitude and phase quadrature variances of the field , defined by and ( similarly for , , , and ) , are found in terms of the mode - matched input amplitude and phase quadrature variances and to be \\left({cc } 1\\\\1 \\right ) \\nonumber\\\\ & & + \\eta m ( 1-r m^2 ) \\left({cc } 1 \\\\ 1 \\right ) + \\eta l \\left({cc } 1 \\\\ 1 \\right),\\ ] ] where and are the composite efficiencies of detection associated cavity - coupled and cavity - mismatched modes respectively , is the coupling of detection losses , and . the detection efficiency is a product of the quantum efficiency of the photodiodes and the mode - overlap efficiency lo mode . eq . can be rewritten in terms of the quadrature variances of the incident field since the cavity - coupled reflection and the mode - mismatch reflection originate from the same incident field , such that and therefore , \\left({cc } v 1^{a } \\\\ v 2^{a } \\right ) \\nonumber\\\\ & & + \\left \\left({cc } 1\\\\1 \\right).\\ ] ] note that if the input field is in a vacuum or coherent state such that , then , as expected , and no cavity information is contained in the output state . if the carrier frequency is detuned downward from the cavity resonance frequency , the cavity transmits only the upper sidebands within the cavity linewidth and replaces them by vacuum at those frequencies while reflecting the associated lower sidebands and all the other sidebands . hence , the cavity - coupled reflected field is composed of the uncorrelated sidebands within the linewidth and the reflected correlated sidebands outside of it . the consequence is the destruction of the correlation within the linewidth between the upper and lower quantum sidebands . this is analogous to the destruction of the correlation between electro - optically modulated coherent sidebands in pairs , in which the beat between the carrier and the upper or lower sideband can be measured only when either sideband is absorbed into the cavity , reflecting the carrier and other sideband . the beat could not be observed if all the fields were reflected . similar measurements could be done transmission of the squeezed vacuum field through the cavity . however , the signal - to - noise ratio would not be as good as in the reflection method because the background of the transmission signal is shot noise . it is convenient to define the test cavity linewidth , the quality factor , and the finesse , as \\nonumber\\\\ & \\simeq & }{\\pi(r 1 r 2 r 3)^{1/4}}\\,\\omega {\\rm fsr},\\ ] ] and respectively . the approximations made in eqs . and are valid for high q cavities . , , , and will be treated as free fitting parameters . we also assume the input mirror is lossless such that . since we are interested in having as little light ( at the carrier frequency ) as possible in the test cavity , it is instructive to calculate the average photon number in the field we use . the average photon number in squeezed light squeeze factor and squeeze angle is given by where is the coherent amplitude of the light . as the number of coherent photons becomes zero , resulting in squeezed vacuum , eq . becomes this is the average photon number in squeezed vacuum generated by squeezing . note that if the field is unsqueezed , . for a squeeze factor of 1.5 corresponding to the squeezed or anti - squeezed level of db which is the current experimental limit , . therefore , it is fair to say that the optical influence of ideal squeezed vacuum on cavities is negligible . and are shown as solid and dashed curves , respectively , for different input states . ( a ) and ( b ) show the ( impure ) input state db and db , in the absence of the cavity . ( c ) and ( d ) show the cavity - coupled response to the squeezed and anti - squeezed vacuum injection , respectively . ( e ) and ( f ) show the cavity - coupled response to injection of a classically noisy state db , db . comparing ( e ) and ( c ) , we note that squeezing improves the signal contrast , but the classical noise and the anti - squeezed quadrature behave almost identically . ] similarly , it is instructive to compare this technique to using a classical state . for simplicity , assuming that the quadrature variance in both quadratures is frequency - independent , we consider the case in which the lower sideband is fully transmitted through an impedance - matched cavity and the upper sideband is fully reflected at the input mirror such that and at , respectively , which gives from eq . thus , the amplitude and phase quadrature variances of the reflected field are found to be in the absence of coherent light , the signal contrast can be defined as the quadrature variance at detuning frequency compared to the cavity - uncoupled quadrature variance at off - resonance frequencies , in which case and , and the signal contrasts at the two orthogonal quadratures are respectively given by in the limiting case of and , we obtain we see that has about the same limiting level as in the classical case , while grows if gets smaller . classically , ( the shot noise limit ) , but using squeezed vacuum we can obtain , or improved signal contrast for a measurement in the squeezed quadrature . this is illustrated in fig . , where we compare the signal contrast for measurement of the cavity linewidth using a classical field signal contrast for squeezed field injection . the cavity - coupled responses of the classical and anti - squeezed quadrature variances behave almost identically in the case of the impedance - matched cavity , whereas squeezing improves the signal contrast of the measurement . it is important to note that even in the absence of technical noise , quadrature variance measurements are intrinsically contaminated by quantum noise itself . the standard deviation of the quadrature variances is given by thus , the noise of the measurement is proportional to the measured value itself , and many averages can be performed to achieve smaller uncertainty levels . this is different from the classical case where the parameters of a cavity are measured by measuring the transmission of a probe optical field incident on the cavity as a function of cavity detuning . in this case , the measurements are fundamentally limited by shot noise : the number of measured photons ( n ) has uncertainty proportional to . therefore , the signal - to - noise ratio grows as the number of the transmitted photons increases . mhz and mhz respectively . the squeezed vacuum generator is composed of an optical parametric oscillator ( opo ) and a second harmonic generator ( shg ) that pumps the opo . the cavity length is locked to the laser frequency by the pdh - locking servo and pzt ( pzt2 ) . the homodyne angle is locked by the noise - locking servo and pzt ( pzt1 ) . ] the experiment is schematically shown in fig . . the nd : yag laser ( lightwave model 126 ) gives an output of cw 700 mw at 1064 nm , which is injected into the squeezed vacuum generator ( squeezer ) . the squeezer is composed of a second harmonic generator ( shg ) and an optical parametric oscillator ( opo ) , both using 5 mgo : linbo nonlinear crystals placed within optical cavities ( hemilith for the shg and monolith for the opo ) in the type i phase - matching configuration . the shg pumped by the nd : yag laser generates 250 mw at 532 nm , which then pumps the opo below threshold vacuum seed . the resultant field generated by the opo is a squeezed vacuum field squeezing bandwidth of 66.2 mhz defined by the opo cavity linewidth . a sub - carrier field , frequency - shifted by an acousto - optic modulator ( aom ) to a frequency that is coincident cavity tem mode , is injected into the other end of the opo cavity . the cavity is thus locked to the tem mode , offset by 220 mhz from the carrier frequency , using the pound - drever - hall ( pdh ) locking technique . the frequency - shift is necessary to ensure that no cavity transmitted light at the fundamental frequency is injected into the opo cavity since it acts as a seed and degrades broadband squeezing due to the imperfect isolation of the faraday isolator . this is especially important for high q cavities linewidths as narrow as khz because low - frequency squeezing is difficult to achieve . the squeezed vacuum is injected into a triangular test cavity fsr of 713 mhz and fwhm of khz , both measured by traditional methods using light . the frequency shift , of the subcarrier is mhz so that the carrier frequency is detuned from the tem mode by mhz . as a result of this frequency shift , only the upper sidebands are within the cavity linewidth , destroying the correlation between the upper and lower sidebands and , therefore , destroying the squeezing or anti - squeezing . this cavity - coupled squeezed vacuum reflection is measured by balanced homodyne detection , where the field to be measured interferes local oscillator ( lo ) field and is detected by two ( nearly ) identical photodetectors . the difference of the two photodetector signals is sent to an hp4195a spectrum analyzer ( sa ) to measure the noise variance of the squeezed or anti - squeezed quadrature . the results are shown in fig . . the experimental data are exponentially averaged 100 times . the resolution bandwidth of the spectrum analyzer is 100 khz . since the squeezed vacuum does not carry any coherent amplitude , the noise - locking technique is employed to lock the homodyne angle to either the squeezed or anti - squeezed quadrature at 2 mhz . khz . ] before fitting the experimental data points , the homodyne efficiencies and , and the quantum efficiency of the photo - detectors need to be taken into account . the sum of the homodyne efficiencies and the quantum efficiency were independently measured to be and respectively . the sum of the efficiencies in eq . is given by . we ignore since the cavity mode - matching efficiency is and hence , which yields . moreover , we have assumed that the input mirror m is lossless . this assumption is valid since it is a single - pass loss and does not influence the linewidth of the cavity . we then fit eq . to the measured data points free parameters , , and ; both the data and the fits are shown in fig . . the resulting fitting values are , and mhz . therefore , the fwhm linewidth of the cavity is found to be khz , which agrees classically measured linewidth of the cavity within the uncertainty ( khz ) . we note that can be determined from the fit , but here we have used the optically measured value to estimate the linewidth . this is valid because any loss in the cavity does not change the fsr . we have proposed and experimentally demonstrated a method for non - invasive measurements of optical cavity parameters by use of squeezed vacuum . the technique has the advantage over traditional optical methods that the injection of a squeezed vacuum field as a probe for cavity parameters does not excite any nonlinear processes in cavities , and is , therefore , useful for ultrahigh q cavities such as whispering gallery mode ( wgm ) cavities . we have shown that when a squeezed vacuum field is injected into a detuned cavity , the linewidth and factor of a test cavity can be determined by measuring the destruction of upper and lower quantum sidebands respect to the carrier frequency . the linewidth of a test cavity is measured to be khz , which agrees classically measured linewidth of the cavity within the uncertainty ( khz ) . we have also show that the use of squeezed fields leads to better signal contrast , as expected . we would like to thank our colleagues at the ligo laboratory , especially thomas corbitt and christopher wipf , and stan whitcomb for his valuable comments on the manuscript .", "summary": "we propose and experimentally demonstrate a method for non - invasive measurements of cavity parameters by injection of squeezed vacuum into an optical cavity . the principle behind this technique is the destruction of the correlation between upper and lower quantum sidebands respect to the carrier frequency when the squeezed field is incident on the cavity . this method is especially useful for ultrahigh cavities , such as whispering gallery mode ( wgm ) cavities , in which absorption and scattering by light - induced nonlinear processes inhibit precise measurements of the cavity parameters . we show that the linewidth of a test cavity is measured to be khz , which agrees classically measured linewidth of the cavity within the uncertainty ( khz ) ."}
{"article": "to enhance chemical reactivity of cu surfaces nitrogen oxides ( no ) is an important issue for development of new catalytic materials effective in the no reduction process . the dissociative adsorption of no , for example , was found to be less expected on cu , compared highly reactive rh , ir , ru , co , and ni surfaces , although dissociative adsorption was reported at finite temperatures in experiments . in order to provide active surfaces for no dissociation , cu thin films and low index surfaces were considered on one hand . in several electronic structure calculations based on the density functional theory ( dft ) , on the other hand , dissociative adsorption of no was found to be possible but energetically un - favored compared molecular adsorption . we note that the simulations were often performed respect to reactions on stable bulk surfaces . although the theoretical data suggested less reactivity of cu bulk surfaces for no reduction , there could be remarkable reactivity on some surface - like atomic structures of cu . when we considered wider classes of nano - scale structures other than defined surfaces of bulk cu crystals , one could find another clue . in this line of approach , indeed , many theoretical investigations computer simulations had been done intending to explore efficiency of e.g. step - like structures of various metals . to explore possible no dissociation , we consider ultra thin cu structures . in this study , we focus on a cu atomic layer , that is the triangular lattice of cu . we adopted structural optimization simulations based on electronic structure calculations to find a stable cu triangular lattice ( cu - tl ) . on this thin structure , we adsorbed an no molecule and performed an optimization simulation . after finding molecular adsorbed structures , we searched possible dissociative adsorption on the cu structures . to find a possible reaction path and to conclude a reduction process , we performed simulations for reaction path estimation . in the discussion of this paper , by comparing the obtained adsorption energies each other , we will discuss a possible no reduction mechanism by using cu nano - structures . we adopted the electronic structure calculation based on the density functional theory to estimate the electronic state , and to obtain inter - atomic forces . in this simulation , the kohn - sham wavefunctions were expanded in the plane - waves and the electron charge density was given both on a real space mesh and on the fourier mesh . an approximation for the exchange - correlation energy functional by perdew , burke , and ernzerhof in the scheme of the generalized gradient approximation was adopted . the ultra - soft pseudo - potential was utilized to describe the valence electron state . all of our simulations were done using the simulation package , the quantum espresso . the calculation conditions are summarized as follows . the energy cut - off for the wave function expansion was 30 , while the cut - off for the charge density was 240 . the brillouin zone integration was done using a mesh of 8 for the largest super cell adopted . these values were refined , if the computation facility allowed much accurate calculations . the convergence criterion for the force constant was that the simulation ended , when the absolute value of the total force vector became less than 1 . to explore possible high reactivity of cu nano - structures , we considered atomic - layer structures . an important structure for our discussion is the cu triangular lattice ( cu - tl ) . in this section , we show data for structural and electronic properties of cu - tl . we obtained an optimized lattice structure using a cu atomic layer in a primitive super cell . major calculation conditions were the same as those given in section . the -point mesh was 24 in this simulation . the cell was given in a hexagonal structure . the vacuum layer had thickness of 15 . in this simulation , the value of the lattice constant was optimized . the bond length was found to be 2.43 . ) this value is rather small compared to the bond length 2.55 of the bulk fcc cu . the reason for shrink in the bond length is mainly to reduce the total band energy . the total energy of tl was energetically higher than the bulk cu by 1.2 ev per a cu atom . of the triangular lattice of cu . the value of in rydberg is given as a function of the lattice constant . , height=302 ] starting from some initial conditions , we found appearance of cu - tl in optimized structures . as another evidence to show the local stability of cu - tl , we considered an atomic two - layer structure ( atls ) . this structure was obtained by cutting the bulk fcc cu crystal and was placed in a simulation super - cell . the layer structure was perpendicular to the ( 100 ) direction of bulk cu and thus was contained in an orthorhombic unit cell . energy difference between atls and cu - tl was 3.11 ev per a cu atom . an optimization calculation of the structure concluded local stability . but , atls was not kept against global reconstruction which was happened when an no molecule was adsorbed on it . furthermore , we found a strongly reacted structure starting from an no molecule adsorbed on atls . it means that using atls as an initial structure , naively speaking , we realized simulated annealing in our simulation . compared this un - stable structure , cu - tl was found to be stable . once the molecule was adsorbed on atls , reconstruction of atls happened and formation of cu - tl was observed in our simulations . conversely , we can say that cu - tl is stable against distortion making corrugation toward atls . even when one observed local stability of an atomic structure in simulation , however , a final evidence of the structure would be requested to be given using real experiments . realization of an atomically thin layer , i.e. cu - tl , will need development of a fabrication method . recently , formation of an atomic layer of pb on the si(111 ) surface was reported . in this superconducting pb system , positions of pb atoms are affected by the atomic structure of the substrate and inter - atomic distance between pb atoms is not determined independently from the substrate . the most remarkable example of natural realization of the atomic layer is graphene . this unique flexible structure of carbon is possible to be supported in air according to the strong c - c sp bonding . peeling a graphene sheet and pasting it on a silicon - di - oxide surface , graphene is obtained efficiently from graphite . in case of cu , we may expect formation of an atomic layer on a suitable inert substrate . we might be able to keep the atomic layer as a film pasted on a support nano - meter - scale hole . then , mechanical properties of the atomic layer would be paid attention like a graphene sheet . but for our consideration of no adsorption , a local structure of cu is important . so , we assume an atomic - scale local structure in a part of nano - scale cu . the density of states ( dos ) of cu - tl is shown in fig . . the major peaks are characterized similarly to the bulk copper . looking dos from the low energy region , we see that the band starts from -6.38 ev and spreads over above the fermi energy . sharp peaks of 3d levels are seen from -4.04 ev but the 3d bands end below the fermi level . thus , parfectly filled 3d band configuration is kept and the structure behaves as an metal . these characteristic features are seen in the electronic band structure of cu - tl , too . ) along the -m line , or the k- line , we see hybridization of the band and a 3d band . comparison cu ( 111 ) surface allows us to evaluate similarity and difference between cu - tl and the bulk cu surface . the density of states in the band leveled almost around 0.2 owing to two - dimensional nature . dos in the 3d bands peaked well above 10 for cu - tl in the unit of states / ev per a unit cell , while the value is from 4 to 6 , except for a singularity at the top of the 3d bands , for the cu ( 111 ) surface . the shorter bond length of cu atoms , the height in dos should be lower in a fixed lattice structure . thus , the higher dos peak for cu - tl than for the bulk cu suggests that two - dimensional nature of cu - tl affects dos . since dos at the fermi level is almost the same for both cu - tl and the cu ( 111 ) surface , the chemical reactivity of no is expected to be similar , if the structure is kept undeformed . however , we should note that the top of cu 3d bands is much closer to the fermi energy for cu - tl than the cu ( 111 ) surface . this tendency suggests higher reactivity of cu - tl against no . when the stable adsorption site is the on - top site , similarity in characteristic energy like the adsorption energy would be expected . however , if a bridge site or a hollow site became stable for no on cu - tl , we could have difference even in the chemical reactivity from that on the cu ( 111 ) surface . this is because much easy deformation of the cu network structure is expected for cu - tl and the bond formation between no and cu - tl will create distortion . in the next section , we discuss occurrence of strong reactions between no and cu - tl . we consider adsorption of no on cu - tl and an atomic step like structure ( ass ) created on an cu atomic layer . the second structure was found in optimization simulations of no adsorption on atls . observing results of no - adsorbed structures starting from atls , we identified a stable substrate structure in a super cell as cu - tl in our simulations . therefore , we regarded cu - tl and ass as typical atomic - scale layer structures of cu . several characteristic adsorption sites for no were found on these structures . molecular adsorbed structures were obtained by structural optimization . starting from an initial structure no molecule a little separated from a substrate , cu - tl , ass or atls , each adsorbed structure was determined . by a series of simulations , we found the next general rules for molecular adsorption . on cu - tl , adsorption on a hollow site is energetically most favorable . on ass , a bridge site on the cu array is energetically most favorable among sites including an on - top site , a hollow site in the back surface , and a bridge site in the back surface . thus , we treat these locally stable structures only in the following discussion . while , structures corresponding to dissociative adsorption were given by locating n and o atoms a little separated on the substrate and by optimizing the whole structure . we have found two locally stable dissociative adsorbed structures on cu - tl and on ass . the structures are depicted in fig . . as typical structures , we consider these structures only . we define the adsorption energy by the next formula . here , is the molecular adsorption energy , while is the dissociative adsorption energy . the values of and are the total energy of a cu slab that of another slab n atom and an o atom adsorbed on the cu slab , is the total energy of a cu slab without no , and is the total energy of the no molecule contained in a super cell same size as the other calculations . molecular dissociation energy is defined as , adsorbed structures found in our simulations are itemized in the next list . the adsorption energy is also shown in each parenthesis for convenience . molecular adsorption on cu - tl : : in adsorption of a no molecule on a surface of cu - tl , a hollow site ( -0.83 ev ) is selected . see the center figure of fig . ( a ) . molecular adsorption on ass : : in adsorption of a no molecule on an atomic step - like structure , a bridge site ( -1.32 ev ) is selected . see the center figure of fig . ( b ) . dissociative adsorption : : dissociative adsorption of no is found on tl ( -1.92 ev ) and on ass ( -1.69 ev ) . see the right figures of fig . ( a ) and ( b ) . now , dissociative adsorption structures are discussed . we have two typical dissociative adsorption structures on cu - tl and on ass . in the first structure , the nitrogen atom locates at a center of five surrounding cu atoms . ( see the right figures of fig . ( a ) . ) this structure may be regarded as a nitrogen interstitial impurity in a cu lattice . arrangement of cu is largely distorted from pure tl , so that the n atom is embedded in cu layer . the oxygen atom locates at a hollow site and it is embedded in cu layer . the local structure of these impurity sites are ncu and ocu . here , the ocu structure is planer . a reason for appearance of the high coordination numbers for n and o is that cu valence is not largely modified and that 3d configuration is almost kept . electrons are in extended states so that the local n and o are efficiently screened by neighboring five and four copper atoms . on ss , we have another dissociative adsorbed structure for no . the nitrogen atom is again embedded in the cu structure . ( see the right figure of fig . ( b ) . ) in this structure , the oxygen atom is at a bridge site and keeps two - fold coordination , while the nitrogen atom has four - fold coordination . now we compare the obtained values of adsorption energy those in the literature . the molecular adsorption energy is higher for ass than those on cu - tl . except for a case of a bond - center site on the back surface of ass , molecular adsorption favors the bridge site of the step - like structure . this general tendency is natural in comparison to the other examples known in the literature . the most notable feature of our results is the finding of the large dissociative adsorption energy . we conclude that the dissociative adsorption may happen , when the nitrogen atom can go to an interstitial site of a cu structure . the large value of ( -1.92 ev on tl and -1.69 ev on ass ) is actually possible , since these structures possess high coordination of cu around the nitrogen atom . on the clean cu ( 111 ) surface , no favors the molecular adsorption ( adsorption energy of -1.22 ev estimated in ref . ) against the dissociation of no , where the dissociative adsorption energy is estimated to be -0.79 ev in ref . . the qualitative difference between data for known bulk surfaces and our result should be attributed on movement of cu atoms in the reconstruction process . in our simulation , positions of cu atoms are rather easily modified because the atomic structure of cu is just a single layer . even in the optimization simulation , we can reach the nitrogen insertion in the cu structures . from the present result , we conjecture the following picture . if a cu structure allows large configurational distortion owing to the chemical reaction , the nitrogen atom can move into the cu structure and form the local ncu configuration . ( or 5 . ) owing to the energy reduction coming from the large formation energy of the local ncu structure , we can expect even the dissociative adsorption of no on cu . in the real cu nano - structures , there can happen large distortion of cu configuration owing to finite temperatures and possible local strain . therefore , our simulation , which is prepared using the atomic layer of cu , might have derived a hidden possible path of the no dissociative adsorption on cu structures . to estimate a reaction path on the no reduction on cu - tl , we estimated the local structure and the energy of a transition state using the nudged - elastic - band method . the initial configuration was the molecular adsorbed structure on cu - tl and the final configuration was the dissociative adsorbed structure obtained in . the dissociation reaction was determined by obtaining the transition state energy for the no reduction process . the activation energy for dissociation of no on the atomic layer is estimated using the next definition . an upper bound of the transition potential barrier is estimated to be 1.4 ev . in the initial state , the no molecule adsorbed on cu - tl nitrogen atom binding to the cu surface . in the transition state , the oxygen atom had local bond connections surrounding cu atoms to reduce the total energy . to form this distorted structure in the transition state , the whole cu atomic configuration were optimized , creating drastic change in cu - tl . utilizing the dft - gga simulations , we have shown that no dissociative adsorption may happen on an atomic cu layer , which is the triangular lattice of cu atoms ( cu - tl ) . the reactivity of cu - tl against molecular adsorption of no was found to be similar to the cu(111 ) surface . some stable sites for no were found to give molecular adsorption . however , our optimization simulation revealed that there was a co - adsorbed structure of n and o atoms , which was energetically stabler by 1.08ev than the molecular adsorbed cu - tl structure . a reaction path estimation showed existence of a path energy barrier of 1.4ev . thus , we may conclude molecular dissociation of no on the cu atomic layer . the large dissociation energy appears owing to formation of local n - cu or o - cu bondings and creation of local n - cu and o - cu structures . we further considered an atomic step - like structure ( ass ) of cu , which was an atomic - scale wrinkle in the cu - tl structure . the absolute value of the molecular adsorption energy on the step was larger than the values found for cu - bulk surfaces or cu - tl . our simulation revealed that there existed a dissociative adsorbed structure in which a nitrogen impurity site embedded in a cu structure was created . the estimated dissociation energy of no became -0.37 ev on ass . flexibility against modification of this cu atomic structure in the nano - meter scale is decisive both to stabilize dissociative adsorption of no and to reduce the energy barrier on the no - reduction path . catalytic activity of cu to reduce no should appear on the atomically flexible cu networks . therefore , in order to realize cu - based no reduction catalysts , it is important to create atomic structures of cu , i.e. atomic layers , atomic scale clusters , and atomic scale networks , which allow conformational change .", "summary": "to investigate chemical reactivity of cu atomic - scale structures , we performed simulations based on the generalized gradient approximation in the density functional theory . an atomic layer of cu forming a triangular lattice ( tl ) was found to give a stable structure . the nitrogen monoxide molecule ( no ) was adsorbed on some atomic sites of tl or on an atomic step structure ( ass ) of cu . the molecular adsorption energy on tl was -0.83 ev . our data suggested that dissociative adsorption of no dissociation energy of -1.08 ev was possible energy barrier of order 1.4 ev . in this optimized structure , the nitrogen and oxygen atoms were embedded in the cu layer . on the step , no adsorbed at a bridge site and the formation energy of cu-(no)-cu local bond connections was estimated to be around -1.32 ev . molecular dissociation of no dissociation energy of -0.37 ev was also possible around ass ."}
{"article": "there are reasons to believe that cosmic rays ( crs ) around the ankle at are dominated by extragalactic protons . scattering processes in the cosmic microwave background ( cmb ) limit the propagation of ultra high energy ( uhe ) charged particles in our universe . a continuation of a power - like cr spectrum above the greisen - zatsepin - kuzmin ( gzk ) cutoff at about is only consistent proton dominance if the sources lie within the proton attenuation length of about 50 mpc . very few astrophysical accelerators can generate crs energies above the gzk cutoff ( see e.g. for a review ) and so far none of the candidate sources have been confirmed in our local environment . it has been speculated that decaying superheavy particles , possibly some new form of dark matter or remnants of topological defects , could be a source of uhe crs , but also these proposals are not fully consistent cr spectrum at lower energies . the observation of gzk excesses has led to speculations about a different origin of uhe crs . berezinsky and zatsepin proposed that cosmogenic neutrinos produced in the decay of the gzk photopions could explain these events assuming a strong neutrino nucleon interaction . we have followed this idea in ref . and investigated the statistical goodness of scenarios strongly interacting neutrinos from optically thin sources using cr data from agasa and hires ( see fig . ) and limits from horizontal events at agasa and contained events at rice . -branes , and string excitations ( see ref . ) . ] the flux of uhe extragalactic protons from distant sources is redshifted and also subject to pair production and photopion - production in the cmb which can be taken into account by means of propagation functions . the resonantly produced photopions provide a guaranteed source of cosmogenic uhe neutrinos observed at earth . in astrophysical accelerators inelastic scattering of the beam protons off the ambient photon gas in the source will also produce photopions which provide an additional source of uhe neutrinos . the corresponding spectrum will in general depend on the details of the source such as the densities of the target photons and the ambient gas . we have used the flux of crs from optically thin sources using the luminosities given in ref . in the goodness - of - fit test . for a reasonable and consistent contribution of extragalactic neutrinos in vertical crs one has to assume a strong and rapid enhancement of the neutrino nucleon interaction . the realization of such a behavior has been proposed in scenarios beyond the ( perturbative ) sm ( see ref . ) . for convenience , we have approximated the strong neutrino nucleon cross section in our analysis by a -behavior shown in fig . , parameterized by the energy scale and width of the transition , and the amplification compared to the standard model predictions . our analysis showed that uhe crs measured at agasa and hires can be interpreted to the 90% cl as a composition of extragalactic protons and strongly interacting neutrinos from optically thin sources in agreement experimental results from horizontal events at agasa and contained events at rice ( see fig . ) . the pierre auger observatory combines the experimental techniques of agasa and hires as a hybrid detector . better energy resolution , much higher statistics and also stronger bounds on horizontal showers it will certainly help to clarify our picture of uhe crs in the future . the author would like to thank the organizers of the erice school on nuclear physics 2005 `` neutrinos in cosmology , in astro , particle and nuclear physic '' for the inspiring workshop and vihkos ( `` virtuelles institut fr hochenergiestrahlungen aus dem kosmos '' ) for support . m. ahlers , a. ringwald , and h. tu , astropart . ( to appear ) , preprint astro - ph/0506698 . v. berezinsky , a. z. gazizov and s. i. grigorieva , preprint hep - ph/0204357 ; v. berezinsky , a. z. gazizov and s. i. grigorieva , . m. ahlers et al . , . k. greisen , ; g. t. zatsepin and v. a. kuzmin , . d. f. torres and l. a. anchordoqui , . d. v. semikoz and g. sigl , . v. s. beresinsky and g. t. zatsepin , . m. takeda et al . , . d. j. bird et al . , ; r. u. abbasi et al . , ; r. u. abbasi et al . , . s. yoshida , .", "summary": "the origin and chemical composition of ultra high energy cosmic rays is still an open question in astroparticle physics . the observed large - scale isotropy and also direct composition measurements can be interpreted as an extragalactic proton dominance above the ankle at about . photopion production of extragalactic protons in the cosmic microwave background predicts a cutoff at about in conflict excesses reported by some experiments . in this report we will outline a recent statistical analysis of cosmic ray data using strongly interacting neutrinos as primaries for these excesses ."}
{"article": "a multistable system is one that possesses a large number of coexisting attractors for a fixed set of parameters . there is ample evidence for such phenomena in the natural sciences , examples coming from neurosciences and neural dynamics - , optics , chemistry , condensed matter and geophysics . multistability also seems to be an essential complexity - generating mechanism in a large class of agent - based models . in view of this , it is important to identify the dynamical mechanisms leading to multistability and , in particular , to construct simple models where this phenomenon might be under control . the first mathematical result in this direction was obtained by newhouse who proved that , near a homoclinic tangency , a class of diffeomorphisms in a two - dimensional manifold has infinitely many attracting periodic orbits ( sinks ) , a result that was later extended to higher dimensions . it has also been proved that , in addition to infinitely many sinks , infinitely many strange attractors exist near the homoclinic tangencies . the stability of the phenomena under small random perturbations has been studied . a second dynamical mechanism leading to multistability is the addition of small dissipative perturbations to conservative systems . conservative systems have a large number of coexisting invariant sets , namely periodic orbits , invariant tori and cantori . by adding a small amount of dissipation to a conservative system one finds that some of the invariant sets become attractors . not all invariant sets of the conservative system will survive when the dissipation is added . however , for sufficiently small dissipation , many attractors ( mainly periodic orbits ) have been observed in typical systems . the problem of migration between attractors and their stability in multiple - attractor systems has also been studied by other authors . most of results are based on numerical evidence . however , using the techniques of deformation stability some rigorous mathematical results may be obtained . finally , it has been found recently that , for parameter values near the feigenbaum period - doubling accumulation point , quadratic maps coupled by convex coupling may have a large number of stable periodic orbits . this is one of the phenomena we study in detail in this paper . the emphasis on quadratic maps near the feigenbaum accumulation point has a motivation close to the idea of control of chaos . the typical situation in control of chaos , is that of a strange attractor infinite number of embedded periodic orbits , all of them unstable . these orbits are then stabilized by several methods . if , instead of a large number of unstable periodic orbits , one has , for example , a large number of sinks , the controlling situation would seem more promising and robust , because the control need not be so accurate . it would suffice to keep the system inside the desired basin of attraction . at the period - doubling accumulation point the feigenbaum attractor , because of the properties of the flip bifurcations , coexists infinite set of unstable periodic orbits . by coupling , as we will show , an arbitrarily large number of orbits may become stable . the existence of a large number of stable periodic orbits for just two coupled quadratic maps , provides a simple model where multistability is well under control , in the sense that not only the nature of the phenomenon is completely understood as one may also compute the range of parameters that provides any desired number of stable orbits . this should be contrasted , for example , concrete models for the newhouse phenomenon . rather than merely focusing on multistability , we also study the phenomenology of two coupled quadratic maps , in particular the bifurcations of periodic orbits and the regime of synchronization .. the stabilization of orbits in the coupled system is similar to that obtained in higher dimensional coupled map lattices exception that , due to the restricted dimension of the phase space , the types of bifurcations are different in our system . the results concerning the multistability phenomenon at also considerably extend , and also correct , some imprecise statements in . coupled map lattices ( cml ) are discrete dynamical systems generated by the composition of a local nonlinearity and a coupling . the phase space of the cml considered in this letter is the square ^{2} ] into itself . therefore , the convex combination in ensures that ^{2})\\subset ^{2} ] , and one can prove that synchronization occurs . when is sufficiently small , this happens even though . starting from synchronization and modifying the parameters , non - synchronized ( periodic ) orbits appear from bifurcations of synchronized ( periodic ) ones . to understand this phenomenon , as well as the bifurcations of subsequent orbits , we now study analytically the periodic orbits of period 1 and 2 . let be the synchronized fixed point denoted in -variables . it exists for any values of the parameters and has no other fixed point in ^{2} ] . computing the corresponding jacobian , one obtains the equation for the multipliers \\lambda + \\left ( 1 - 2\\varepsilon \\right ) ^{2}(s^{2}-d^{2})^{2}=0\\ ] ] where direct calculations show that , if , the multipliers , say and , have zero imaginary part iff . under this condition , we have if and iff . ( the inequality indeed holds if and , see figure 1 . ) consequently , by increasing , the symmetric orbit suffers an inverse pitchfork bifurcation at . this bifurcation is generic for a symmetric orbit in a system symmetry and the conditions of the bifurcation theorem hold when the curve is crossed upward . this bifurcation creates two non - symmetric period-2 orbits ( one orbit and its symmetric ) . we have checked that these orbits exist for any and . for , their components are combinations of a fixed point of and the components of a period-2 orbit . when the imaginary part of and is not zero , we have . ( once again , if and , the inequality is satisfied , see figure 1 . ) the symmetric orbit is thus stable in the interval . if and the curve is crossed upward , this orbit suffers a hopf bifurcation creating a locally stable invariant circle . a numerical calculation shows that the latter is destroyed when is sufficiently large or when is sufficiently small . obviously , if , it does not exist and the bifurcation at which is a period - doubling bifurcation of creates a period-4 orbit . note that invariant circles in two - dimensional cml resulting from the destabilization of a symmetric orbit and their normal form had already been reported in . in that work , the system is also defined by , but the local map is and may be larger than . figure 2 shows an example of the phenomenology described above . numerically , it is more convenient to follow the orbits from to increasing values of the coupling . in this picture , as well as in the following ones the map parameter is ( the accumulation point of the period - doubling cascade ) . in figure 2 , from ( the circle ) to ( the point labelled 1 ) , the symmetric orbit is unstable . the figure also shows the invariant circle for . between the points 1 and 2 , the symmetric orbit is stable . at point 2 , the pitchfork occurs , the symmetric orbit becomes unstable and the non - symmetric orbits are created . finally , the point 3 corresponds to the collapse on the synchronized fixed point . the previous phenomenology is not restricted to small periods but extend to any power of 2 . in particular , the synchronized period- orbit may destabilize to create a symmetric ( non - synchronized ) orbit of twice the period . given , let be the components of the period- orbit of . the points are the components of the synchronized period- orbit of . by the chain rule and since each jacobian at is diagonal , the corresponding multiplier along the anti - diagonal direction is the condition that this multiplier equals determines , if , a co - dimension 1 period - doubling bifurcation . applying the reasoning of the previous section to each component , we conclude that this bifurcation creates an orbit property and for all , which is called a phase - opposition period- orbit . since , this bifurcation occurs only if the bifurcation along the diagonal direction has occurred ( the local period - doubling bifurcation of ) . in other words , the phase opposition period- orbit exists only if the synchronized period- orbit does . moreover it follows from figure 3 that , at least for , the phase opposition period- orbit exists only if the phase opposition period- orbit does . this is confirmed analytically for the period orbit whose existence condition is the instability of the synchronized period orbit in the anti - diagonal direction . one obtains and if and and if ( see figure 1 ) . furthermore , a numerical calculation at , reported in figure 3 , shows that the succession of bifurcations of a phase opposition orbit does not depend on the period . on this picture , we have plotted the values of for the hopf bifurcation , the pitchfork bifurcation and the period - doubling bifurcation creating the orbit , versus the power of the period . for each period , the phenomenology is identical to that described in the previous section , adequate change of scale in . in addition , the picture shows that several phase opposition orbits may be stable for fixed . this stabilization is an effect of the coupling that will be discussed below . finally , since the phase opposition orbits are the first orbits to appear when the parameters are varied from synchronization and since the first such orbit that is created is of period 2 , it follows that a necessary and sufficient condition for synchronization is , the condition for the existence of the latter . we now analyze the existence and the stability of other period- orbits for . our interest for this value of is that the scaling properties of are reflected on scaling laws for the periods and values of at which the bifurcations occur ( see figure 3 and 8) . we only consider the orbits which for have the same period on projection to both axis and . these orbits are followed numerically when increases and are referred using the phase shift of their components at . for , the map has a period- orbit for each , whose components for up to 5 are shown in figure 5 . in this picture , the numbers reflect the order in which the components are visited and the tree structure represents the origin of each component in the bifurcation cascade . an important notion is the dyadic distance between the components of an orbit . is the number of steps one has to go back in the bifurcation tree to meet a common component . the dyadic distance is used to characterize the families of periodic orbits that we are considering . for instance , the coordinates of each component of a synchronized orbit are at distance 0 , those of a phase - opposition orbit are at distance 1 . accordingly , when we speak of distance orbit we refer to the dyadic distance of the coordinates of its components . for any , there are different orbits distance which have coordinates out of phase by steps , . the distance of a period- orbit is at most . for , the only symmetric orbits are those at distance 0 and 1 . this property is preserved for as shows figure 6 for . the succession of bifurcations of orbits distance should then differ from those distance 1 . the differences are seen in figure 6 which shows the evolution of the eigenvalues . for , the orbit is unstable . when increases , it suffers two collisions orbits of twice the period when the eigenvalues cross and then becomes stable . ( when decreasing , these collisions would be period - doubling bifurcations . ) if increases further , the orbit collides unstable one of the same period in a saddle - node bifurcation when the larger eigenvalue reaches 1 . for larger values of , the orbit does not exist . the unstable orbit which it collides is the one that at has period in one projection and in the other . for higher dyadic distances , the overall variation of the eigenvalues is similar to the case . figure 7 shows a typical example of these phenomena for the case . between and the point labelled 1 in the figure , the orbit is unstable . the point 1 corresponds to the smaller eigenvalue crossing -1 ( see figure 6 ) . therefore , between the point 1 and 2 , the orbit is stable . it disappear at the point 2 when it collides unstable orbit of the same period . we have seen that the coupling stabilizes the orbits distance larger than 0 at . there are indeed two mechanisms responsible for this stabilization .. the determinant of the jacobian of a period- orbit is the term coming from the coupling decreases when increases . however , there is yet a second stabilizing mechanism . denote by the remaining factor in the determinant without coupling , is simply the square of the multiplier of for the periodic orbit . from the properties of the feigenbaum - cvitanovic functional equation it follows that this factor converges to a fixed value around when increases . the coupling however , changes the position of the orbit components in such a way that this factor also decreases . it is the combined action of this decrease contraction of the coupling that brings the eigenvalues into the interior of the unit circle and stabilizes the orbits . for small there is a simple geometrical interpretation for the variation of . the reason why in the one dimensional map the product remains constant , when grows , is because each time the period doubles , the doubling in the number of factors greater than one is compensated by the fact that the component of the orbit closest to zero approaches zero a little more . for the unstable orbits along the period - doubling chain , the orbit components closest to zero alternate on each side of the origin . the contracting effect of the convex coupling tends to bring the orbits back in the period - doubling hierarchy . therefore , because the component closest to zero has to move across the origin for the orbit to approach the one half the period , this implies that the product of the coordinates is going to decrease . the greater the dyadic distance between the orbit projections on the axis , the greater will be the perturbation that the original ( one - dimensional ) orbits suffer . therefore one expects the contracting effect in to increase dyadic distance . this effect is quite apparent on figure 8 which shows the stabilizing and destabilizing lines for orbits distance from 1 to 4 . the shift downwards of the stable regions for successively larger dyadic distances implies that the smaller is , the larger the number of distinct stable orbits that are obtained . an accurate numerical estimate of the number of distinct orbits is obtained by computing the derivative at for each and dyadic distance . actually this derivative provides an accurate estimate of itself , because this one varies almost linearly for most of the stable range of the orbits . on figure 9 , the scaling properties , when grows , of this derivative are shown . from these results one computes notice that in figure 9 there is more than one data point for each pair which correspond to non - equivalent orbits same dyadic distance . * the value of the smallest parameter that stabilizes an orbit of dyadic distance equal to the power * the value of the largest parameter for which a orbit is stable from this , one obtains the result that at least distinct stable orbits are obtained if is only a lower bound on the number of distinct stable periodic orbits , because here we have studied only orbits same period under projection in the two axis . in conclusion : for sufficiently small an arbitrarily large number of distinct stable periodic orbits is obtained . however , for any fixed , it is an arbitrarily large number that is obtained , not an infinite number . most orbits either synchronize ( and are then unstable ) or disappear as grows . as a result , a reasoning based on the implicit function theorem , as used in is misleading . given a sequence of orbits of different periods , even if they remain as orbits for a small perturbation , that does not mean that their ( smallest ) periods remain distinct .", "summary": "the phenomenology of a system of two coupled quadratic maps is studied both analytically and numerically . conditions for synchronization are given and the bifurcations of periodic orbits from this regime are identified . in addition , we show that an arbitrarily large number of distinct stable periodic orbits may be obtained when the maps parameter is at the feigenbaum period - doubling accumulation point . an estimate is given for the coupling strength needed to obtain any given number of stable orbits ."}
{"article": "in solid - core photonic crystal fibers ( pcf ) the air - silica microstructured cladding ( see fig . ) gives rise to a variety of novel phenomena including large - mode area ( lma ) endlessly - single mode operation . though pcfs typically have optical properties very different from that of standard fibers they of course share some of the overall properties such as the susceptibility of the attenuation to macro - bending . macrobending - induced attenuation in pcfs has been addressed both experimentally as well as theoretically / numerically in a number of papers . however , predicting bending - loss is no simple task and typically involves a full numerical solution of maxwell s equations as well as use of a phenomenological free parameter , e.g. an effective core radius . in this paper we revisit the problem and show how macro - bending loss measurements on high - quality pcfs can be predicted high accuracy using easy - to - evaluate empirical relations . predictions of macro - bending induced attenuation in photonic crystal fibers have been made using various approaches including antenna - theory for bent standard fibers , coupling - length criteria , and phenomenological models within the tilted - index representation . here , we also apply the antenna - theory of sakai and kimura , but contrary to refs . we make a full transformation of standard - fiber parameters such as , , and to fiber parameters appropriate to high - index contrast pcfs triangular arrangement of air holes . in the large - mode area limit we get ( see appendix ) for the power - decay , , along the fiber . for a conversion to a db - scale should be multiplied by . in eq . , is the bending radius , is the effective area , is the index of silica , and is the recently introduced effective v - parameter of a pcf . the strength of our formulation is that it contains no free parameters ( such as an arbitrary core radius ) and furthermore empirical expressions , depending only on and , have been given recently for both and . from the function we may derive the parametric dependence of the critical bending radius . the function increases dramatically when the argument is less than unity and thus we may define a critical bending radius from where . typically the pcf is operated close to cut - off where so that the argument may be written as this dependence was first reported and experimentally confirmed by birks et al . and recently a pre - factor of order unity was also found experimentally in ref . we have fabricated three lma fibers by the stack - and - pull method and characterized them using the conventional cut - back technique . all three fibers have a triangular air - hole array and a solid core formed by a single missing air - hole in the center of the structure , see fig . . for the lma-20 macro - bending loss has been measured for bending radii of r=8 cm and r=16 cm and the results are shown in fig . the predictions of eq . are also included . it is emphasized that the predictions are based on the empirical relations for and provided in refs . and respectively and therefore do not require any numerical calculations . similar results are shown in figs . and for the lma-25 and lma-35 fibers , respectively . the pcf , in theory , exhibits both a short and long - wavelength bend - edge . however , the results presented here only indicate a short - wavelength bend - edge . the reason for this is that the long - wavelength bend - edge occurs for . for typical lma - pcfs it is therefor located in the non - transparent wavelength regime of silica . in conclusion we have demonstrated that macro - bending loss measurements on high - quality pcfs can be predicted good accuracy using easy - to - evaluate empirical relations only and as input parameters . since macro - bending attenuation for many purposes and applications is the limiting factor we believe that the present results will be useful in practical designs of optical systems employing photonic crystal fibers . the starting point is the bending - loss formula for a gaussian mode in a standard - fiber where is the effective area , is the core radius , is the bending radius , and the standard - fiber parameters are given by substituting these parameters into eq . we get in the relevant limit where . here , and in eqs . and have been introduced . for large - mode area fibers we make a further simplification for the isolated propagation constant ; using that we arrive at eq . . m. d. nielsen acknowledges financial support by the danish academy of technical sciences .", "summary": "we report on an easy - to - evaluate expression for the prediction of the bend - loss for a large mode area photonic crystal fiber ( pcf ) triangular air - hole lattice . the expression is based on a recently proposed formulation of the v - parameter for a pcf and contains no free parameters . the validity of the expression is verified experimentally for varying fiber parameters as well as bend radius . the typical deviation between the position of the measured and the predicted bend loss edge is within measurement uncertainty . 10 url # 1`#1`urlprefix#2 j. c. knight , `` photonic crystal fibres , '' nature * 424 * , 847851 ( 2003 ) . t. a. birks , j. c. knight , and p. s. j. russell , `` endlessly single mode photonic crystal fibre , '' opt . lett . * 22 * , 961963 ( 1997 ) . t. srensen , j. broeng , a. bjarklev , e. knudsen , and s. e. b. libori , `` macro - bending loss properties of photonic crystal fibre , '' electron . lett . * 37 * , 287289 ( 2001 ) . t. srensen , j. broeng , a. bjarklev , t. p. hansen , e. knudsen , s. e. b. libori , h. r. simonsen , and j. r. jensen , `` spectral macro - bending loss considerations for photonic crystal fibres , '' iee proc .- opt . * 149 * , 206 ( 2002 ) . n. a. mortensen and j. r. folkenberg , `` low - loss criterion and effective area considerations for photonic crystal fibers , '' j. opt . a : pure appl . opt . * 5 * , 163167 ( 2003 ) . j. c. baggett , t. m. monro , k. furusawa , v. finazzi , and d. j. richardson , `` understanding bending losses in holey optical fibers , '' opt . commun . * 227 * , 317335 ( 2003 ) . j. sakai and t. kimura , `` bending loss of propagation modes in arbitrary - index profile optical fibers , '' appl . opt . * 17 * , 14991506 ( 1978 ) . j. sakai , `` simplified bending loss formula for single - mode optical fibers , '' appl . opt . * 18 * , 951952 ( 1979 ) . a. w. snyder and j. d. love , optical waveguide theory ( chapman & hall , new york , 1983 ) . n. a. mortensen , `` effective area of photonic crystal fibers , '' opt . express * 10 * , 341348 ( 2002 ) . http://www.opticsexpress.org/abstract.cfm?uri=opex-10-7-341 . n. a. mortensen , j. r. folkenberg , m. d. nielsen , and k. p. hansen , `` modal cut - off and the parameter in photonic crystal fibers , '' opt . lett . * 28 * , 18791881 ( 2003 ) . m. d. nielsen , n. a. mortensen , j. r. folkenberg , and a. bjarklev , `` mode - field radius of photonic crystal fibers expressed by the parameter , '' opt . lett . * 28 * , 23092311 ( 2003 ) . m. d. nielsen and n. a. mortensen , `` photonic crystal fiber design based on the parameter , '' opt . express * 11 * , 27622768 ( 2003 ) . http://www.opticsexpress.org / abstract.cfm?uri = opex-11 - 21 - 2762% ."}
{"article": "multiscale dynamics is present in many phenomena , e.g. , turbulence , finance , geosciences , etc , to quote a few . it has been found in many multiscale dynamics systems that the self - similarity is broken , in which the concept of multiscaling or multifractal is relevant . this is characterized conventionally by using the structure - functions ( sfs ) , i.e. , , in which is an increment separation scale . note that for the self - similarity process , e.g. , fractional brownian motion ( fbm ) , the measured is linear . while for the multifractal process , e.g. , turbulent velocity , it is usually convex . other methods are available to extract the scaling exponent . for example , wavelet based methodologies , ( e.g. , wavelet leaders , wavelet transform modulus maxima ) , hilbert - based method , or the scaling analysis of probability density function of velocity increments , to name a few . each method has its owner advantages and shortcomings . for example , the classical sfs is found to mix information of the large- ( resp . known as infrared effect ) and small - scale ( resp . known as ultraviolet effect ) structures . the corresponding scaling exponent is thus biased when a large energetic structure is present . previously the influence of the large - scale structure has been considered extensively by several authors . for example , praskvosky et al . , found strong correlations between the large scales and the velocity sfs at all length scales . sreenivasan & stolovitzky observed that the inertial range of the sfs conditioned on the large scale velocity show a strong dependence . huang et al . , showed analytically that the influence of the large - scale structure could be as large as two decades down to the small scales . blum et al . , studied experimentally the nonuniversal large - scale structure by considering both conditional eulerian and lagrangian sfs . they found that both sfs depend on the strength of large - scale structures at all scales . in their study , the large - scale structure velocity is defined as two - point average , i.e. , /2 ] , a linear trend is removed within a window size . ideally , scales larger than , i.e. , are removed or constrained from the original data . this implies that the da procedure is a high - pass filter in the physical domain . the kinetic energy of is related directly fourier power spectrum , i.e. , in which and is the fourier power spectrum of . this illustrates again that the da procedure acts a high - pass filter , in which the lower fourier modes ( resp . ) are expected to be removed or constrained . for a scaling process , i.e. , , it leads a power - law behavior , i.e. , the physical meaning of is quite clear . it represents a cumulative energy over the fourier wavenumber band ] ) . we emphasize here again that the da acts as a high - pass filter in physical domain and the intermittency nature of is still retained . the above mentioned detrending analysis can remove / constrain the large - scale influence , known as infrared effect . this could be utilized to redefine the sf to remove / constrain the large - scale structure effect as following . after the da procedure , , the velocity increment can be defined within a window size as , i.e. , in which represents for the th segment . we will show in the next subsection why we define an increment half width of the window size . a th - order dsf is then defined as , i.e. , for a scaling process , we expect a power - law behavior , i.e. , in which the scaling exponent is comparable one provided by the original sfs . to access negative orders of ( resp . the right part of the singularity spectrum , see definition below ) , the dsfs can be redefined as , i.e. , in which is local average for the th segment . a power - law behavior is expected , i.e. , . it is found experimentally that when , eqs . and provide the same scaling exponents . in the following we do not discriminate these two definitions for dsfs . for different methods : structure - function ( dashed line ) , first - order detrending analysis ( thin solid line ) , and the detrended structure - function ( thick solid line ) . the detrended scale is demonstrated by a vertical solid line . ideally , scales larger than , i.e. , ( resp . ) are expected to be removed after the detrending process . ] to understand better the filter property of the detrending procedure and dsfs , we introduce here a weight function , i.e. , in which is the fourier power spectrum of , and is a second - order moment , which could be one of or , or , respectively . the weight function characterizes the contribution of the fourier component to the corresponding second - order moment . note that an integral constant is neglected in the eq . . for the second - order sfs , one has the following weight function , i.e. , for a scaling process , one usually has a fast decaying fourier spectrum , i.e. . hence , the contribution from small - scale ( resp . high wavenumber fourier mode ) is decreasing . the sfs might be more influenced by the large - scale part for large values of . for the detrended data , the corresponding weight function is ideally to be as the following , i.e. , the dsfs ( resp . the combination of the da and sf ) have a weight function , i.e. , comparing original sfs , the dsfs defined here can remove / constrain the large - scale effect . figure shows the corresponding for the sf , detrending analysis , and dsf , respectively . the detrended scale is illustrated by a vertical line , i.e. , . we note here that definition of eq . , provides a better compatible interpretation fourier power spectrum since we have . this is the main reason why we define the velocity increment half size of the window width . we provide some comments on eq . . the above argument is exactly valid for linear and stationary processes . in reality , the data are always nonlinear and nonstationary for some reasons , see more discussion in ref . . therefore , eq . holds approximately for real data . another comment has to be emphasized here for the detrending procedure . several approaches might be applied to remove the trend . however , the trend might be linear or nonlinear . therefore , different detrending approaches might provide different performances . in the present study , we only consider the st - order polynomial detrending procedure , which is efficient for many types of data . for fractional brownian motion on the range . the inset shows the singularity spectrum on the range . the errorbar is the standard deviation estimated from 100 realizations . ideally , one should have and . both methods provide the same and and statistical error . ] for the lognormal process intermittent parameter . the errorbar is the standard deviation from the 100 realizations . the theoretical singularity curve is illustrated by a solid line . both estimators provide the same singularity spectra and statistical error . ] we first consider here the fractional brownian motion as a typical mono - scaling process . fbm is a gaussian self - similar process normal distribution increment , which is characterized by , namely hurst number . a wood - chan algorithm is used to synthesize the fbm hurst number . we perform 100 realizations length points each . power - law behavior is observed on a large - range of scales for . the corresponding singularity spectrum is , i.e. , ideally , one should have a single point of singularity spectrum and . however , in practice , the measured singularity spectrum is always lying in a narrow band . figure shows the measured singularity spectrum for sfs and dsfs for , in which the inset shows the singularity spectra estimated on the range . visually , both estimators provide the same and the same statistical error , which is defined as the standard deviation from different realizations . we now consider a multifractal random walk lognormal statistics . a multiplicative discrete cascade process lognormal statistics is performed to simulate a multifractal measure . the larger scale corresponds to a unique cell of size , where is the largest scale considered and is a dimensional scale ratio . in practice for a discrete model , this ratio is often taken as . the next scale involved corresponds to cells , each of size . this is iterated and at step cells are retrieved . finally , at each point the multifractal measure is as the product of cascade random variables , i.e. , where is the random variable corresponding to position and level in the cascade . following the multifractal random walk idea , a nonstationary multifractal time series can be synthesized as , i.e. , where is brownian motion . taking a lognormal statistic for , the scaling exponent for the sfs , i.e. , , is written as , where is the intermittency parameter characterizing the lognormal multifractal cascade . synthetic multifractal time series are generated following eq . . an intermittent parameter is chosen for levels each , corresponding to a data length points each . a total of 100 realizations are performed . the statistical error is then measured as the standard deviation from these realizations . figure shows the corresponding measured singularity spectra , in which the theoretical value is illustrated by a solid line . graphically , the theoretical singularity spectra are recovered by both estimators . statistical error are again found to be the same for both estimators . we would like to provide some comments on the performance of these two estimators . for the synthesized processes , they have the same performance since there is no intrinsic structure in these synthesized data . but for the real data , as we mentioned above , they possess nonstationary and nonlinear structures . therefore , as shown in below , they might have different performance . and from experimental homogeneous and nearly isotropic turbulent flow . they are respectively 3rd - order sfs and without absolute value , and 3rd - order dsfs and without absolute value . the horizontal solid line indicates the kolmogorovs four - fifth law . an observed plateau for indicates an inertial range on the range , corresponding to a wavenumber range . roughly speaking , a plateau for indicates an inertial range on the range . the height of the inertial range are respectively , , and , in which the statistical error is the standard deviation obtained from the inertial range . note that the inertial range are for the sfs and for the dsfs . the corresponding scaling exponents are , , and . the statistical error is the 95% fitting confidence on the inertial range . ] . the errorbar is the standard deviation from 120 realizations . the inset shows the corresponding scaling exponents . for comparison , the lognormal model intermittent parameter is illustrated by a solid line . ] we consider here a velocity database obtained from a high reynolds number wind tunnel experiment in the johns - hopkins university reynolds number . an probe array four x - type hot wire anemometry is used to record the velocity sampling wavenumber of khz at streamwise direction , in which is the size of the active grid . these probes are placed in the middle height and along the center line of the wind tunnel to record the turbulent velocity simultaneously for a duration of 30 second . the measurement is then repeated for 30 times . finally , we have data points ( number of measurements number of probes duration time sampling wavenumber ) . therefore , there are 120 realizations ( number of measurements number of probes ) . the fourier power spectrum of the longitudinal velocity reveals a nearly two decades inertial range on the wavenumber range scaling exponent , see ref . this corresponds to time scales . here is the kolmogorov scale . note that we convert our results into spatial space by applying the taylors frozen hypothesis . more detail about this database can be found in ref. . to determine the inertial range in real space , we plot the measured compensated 3rd - order moments in fig. for the sfs ( and without absolute value ) , dsfs ( and without absolute value ) , respectively . a horizontal solid line indicates the kolmogorovs four - fifth law . a plateau is observed for on the range , which agrees very well inertial range predicted by , i.e. , on the range . the corresponding height and scaling exponent are absolute value ( resp . without absolute value ) and ( resp . ) , respectively . the statistical error is the standard deviation obtained from the range . note that the kolmogorovs four - fifth law indicates a linear relation . it is interesting to note that , despite of the sign , we have on nearly two - decade scales . for comparison , the 3rd - order sfs are also shown . roughly speaking , a plateau is observed on the range . this inertial range is shorter than the one predicted by the fourier analysis or dsfs , which is now understood as the large - scale influence . the corresponding height and scaling exponent are without absolute value ( resp . absolute value ) and ( resp . ) . therefore , the dsfs provide a better indicator of the inertial range since it removes / constrains the large - scale influence . we therefore estimate the scaling exponents for the on the range for directly without resorting to the extended self - similarity technique . for the sfs , we calculate the scaling exponents on the range for directly . figure shows the measured singularity spectra for , in which the errorbar is a standard deviation from 120 realizations . the inset shows the corresponding scaling exponents . for comparison , the lognormal model intermittent parameter is shown as a solid line . visually , the dsfs curve fully recovers the lognormal curve not only on the left part ( resp . ) but also on the right part ( resp . ) . due to the large - scale contamination , the sfs underestimates the scaling exponents when . this leads an overestimation of the left part of singularity spectrum ( see in fig. ) . however , if one resorts the ess algorithm when measuring the sf scaling exponent , the corresponding singularity spectrum is then horizontal shifted to the theoretical curve . this has been interpreted as that the ess technique suppresses the finite reynolds number effect . we show here that if one removes / constrains the effect of large - scale motions , one can retrieve the scaling exponent ( resp . singularity spectrum ) without resorting the ess technique . or in other words , the finite reynolds number effect manifests at large - scale motions , which is usually anisotropic too . in this paper , we introduce a detrended structure - function analysis to remove / constrain the influence of large - scale motions , known as the infrared effect . in the first step of our proposal , the st - order polynomial trend is removed within a window size . by doing so , the scales larger than , i.e. , , are expected to be removed / constrained . in the second step , a velocity increment is defined half of the window size . the dsf proposal is validated by the synthesized fractional brownian motion for the mono - fractal process and a lognormal random walk for the multifractal process . the numerical test shows that both sfs and dsfs estimators provide a comparable performance for synthesized processes without intrinsic structures . when applying to the turbulent velocity obtained from a high reynolds number wind tunnel experiment , the 3rd - order dsfs show a clearly inertial range on the range linear relation . the inertial range provided by dsfs is consistent one predicted by the fourier power spectrum . note that , despite of the sign , the kolmogorovs four - fifth law is retrieved for the 3rd - order dsfs . the corresponding 3rd - order sfs are biased by the large - scale structures , known as the infrared effect . it shows a shorter inertial range and underestimate the 3rd - order scaling exponent . the scaling exponents are then estimated directly without resorting to the ess technique . the corresponding singularity spectrum provided by the dsfs fully recovers the lognormal model intermittent parameter on the range . however , the classical sfs overestimate the left part singularity spectrum ( resp . underestimate the corresponding scaling exponents ) on the range . this has been interpreted as finite reynolds number effect and can be corrected by using the ess technique . here , to our knowledge , we show for the first time that if one removes / constrains the influence of the large - scale structures , one can recover the lognormal model without resorting to the ess technique . the method we proposed here is general and applicable to other complex dynamical systems , in which the multiscale statistics are relevant . it should be also applied systematically to more turbulent velocity databases different reynolds numbers to see whether the finite reynolds number effect manifests on large - scale motions as well as we show for high reynolds number turbulent flows . this work is sponsored by the national natural science foundation of china under grant ( nos . 11072139 , 11032007,11161160554 , 11272196 , 11202122 and 11332006 ) , pu jiang project of shanghai ( no . 12pj1403500 ) , innovative program of shanghai municipal education commission ( no . 11zz87 ) and the shanghai program for innovative research team in universities . y.h . thanks prof . schmitt for useful comments and suggestions . we thank prof . meneveau for sharing his experimental velocity database , which is available for download at c. meneveau s web page : http://www.me.jhu.edu/meneveau/datasets.html . we thank the two anonymous referees for their useful comments and suggestions . f. schmitt , y. huang , z. lu , y. liu , and n. fernandez , analysis of velocity fluctuations and their intermittency properties in the surf zone using empirical mode decomposition , j. mar . 77 ( 2009 ) , pp . 473481 . j. muzy , e. bacry , and a. arneodo , multifractal formalism for fractal signals : the structure - function approach versus the wavelet - transform modulus - maxima method , e 47 ( 1993 ) , pp . 875884 . y. huang , f.g . schmitt , j.p . hermand , y. gagne , z. lu , and y. liu , arbitrary - order hilbert spectral analysis for time series possessing scaling statistics : comparison study detrended fluctuation analysis and wavelet leaders , phys . e 84 ( 2011 ) , p. 016208 . y. huang , f. schmitt , q. zhou , x. qiu , x. shang , z. lu , and y. liu , scaling of maximum probability density functions of velocity and temperature increments in turbulent systems , phys . fluids 23 ( 2011 ) , p. 125101 . praskovsky , e.b . gledzer , m.y . karyakin , and y. zhou , the sweeping decorrelation hypothesis and energy - inertial scale interaction in high reynolds number flows , j. fluid mech . 248 ( 1993 ) , p. 493 . blum , g.p . bewley , e. bodenschatz , m. gibert , a. gylfason , l. mydlarski , g.a . voth , h. xu , and p. yeung , signatures of non - universal large scales in conditional structure functions from various turbulent flows , new j. phys . 13 ( 2011 ) , p. 113020 . n. huang , z. shen , s. long , m. wu , h. shih , q. zheng , n. yen , c. tung , and h. liu , the empirical mode decomposition and the hilbert spectrum for nonlinear and non - stationary time series analysis london , ser . a 454 ( 1998 ) , pp . 903995 .", "summary": "the classical structure - function ( sf ) method in fully developed turbulence or for scaling processes in general is influenced by large - scale energetic structures , known as infrared effect . therefore , the extracted scaling exponents might be biased due to this effect . in this paper , a detrended structure - function ( dsf ) method is proposed to extract scaling exponents by constraining the influence of large - scale structures . this is accomplished by removing a st - order polynomial fitting within a window size before calculating the velocity increment . by doing so , the scales larger than , i.e. , , are expected to be removed or constrained . the detrending process is equivalent to be a high - pass filter in physical domain . meanwhile the intermittency nature is retained . we first validate the dsf method by using a synthesized fractional brownian motion for mono - fractal processes and a lognormal process for multifractal random walk processes . the numerical results show comparable scaling exponents and singularity spectra for the original sfs and dsfs . when applying the dsf to a turbulent velocity obtained from a high reynolds number wind tunnel experiment , the 3rd - order dsf demonstrates a clear inertial range on the range , corresponding to a wavenumber range . this inertial range is consistent one predicted by the fourier power spectrum . the directly measured scaling exponents ( resp . singularity spectrum ) agree very well lognormal model intermittent parameter . due to large - scale effects , the results provided by the sfs are biased . the method proposed here is general and can be applied to different dynamics systems in which the concepts of multiscale and multifractal are relevant . fully developed turbulence ; intermittency ; detrended structure - function"}
{"article": "a fair number of astronomers and astronomy students have a physical challenge . it is our responsibility to learn the basics of accessibility to be able to help our library patrons to gain access to things that they need for their studies and work . astronomy is often seen as a very visual science . after all , its origins lie in looking at the skies . hence , it is a common belief that you need to use your sight to be able to study astronomy . this is strictly not true . in reality , we have been using assistive technologies telescopes , sensors , computers for a long time now to gain access to data that the human eye does not see unaided . visual information is coming to us as large streams of bytes . the modern astronomer is hardly bound by physical limitations . one can produce solid research sitting comfortably in front of one s personal computer . there are many examples of physically challenged individuals who have made successful careers in science . those who have seen the movie contact based on carl sagan s novel are familiar blind astronomer who is listening to radio signals instead of watching them on the screen . his character is based on a real scientist , dr . d. kent cullers . there are other success stories in fact , too many to enumerate here . but , you ask , is nt the sheer amount of information a major hindrance to those who can not browse it easily ? yes , it is to some degree . electronic textual materials provide both a possibility and a challenge for those vision . in theory , it is possible for almost anyone to access online information , but in practice , this requires know - how and proper tools . plenty of assistive technologies exist to overcome hindrances . the daisy standard for digital talking books has been an important tool for making electronic texts easy to browse . not all hindrances are in the visual domain . imagine an elderly astronomer who has the full use of his or her intelligence , but whose hands are shaking , and who might have some difficulty pointing a mouse when navigating a webpage and filling out search forms . it is a challenging task for librarians and information specialists to make our services and search forms accessible to people diversity of abilities so that they can do the research necessary for building careers as active contributors in their chosen fields of research . but what does accessibility look like ? there is a pervasive myth that it looks boring . this is strictly not true . accessible design should be functional enough , not just pretty . proper html code and other techniques , we can make the text compliant technological aids . if the html coding is poor , a document may be impossible to open such aids or it could be impossible to navigate the text . the author of this paper was involved university - wide accessibility project that was undertaken by the university of helsinki in 20052006 , follow up in 20082009 . it was recognized that accessibility must cover not only our physical surroundings , but also the online environment as well . in spring 2009 , we noticed that the new national online system for applying for university education was not accessible to blind students . the system was provided by the finnish ministry of education , and we challenged them to fix it . to our big surprise , they did , working in collaboration the finnish federation of the visually impaired . figure 1 shows a page from the application system . it looks exactly the same both before and after accessibility changes were made . differences can be seen on the coding level , but otherwise one can not tell the old version from the new one by visual inspection alone . the change has resulted in a major functional improvement . the old version could not even be opened assistive technology , and blind students could not use it . now they can . accessibility needs some muscle to drive it . it is not just about good people doing good deeds it is also about ensuring that everyone has access to things that matter to them . we need guidelines and standards , preferably legislation to back them up . in the united states , section 508 of the rehabilitation act regulates purchases made federal funding . it is about `` access to and use of information and data that is comparable to that provided to others . '' a market for accessible products helps big publishers to take accessibility into account . when a publisher has a large enough number of customers who need to buy accessible products , they will be motivated to sell accessible products . we also need strong standards . the world wide consortium has updated its web content accessibility guidelines ( wcag ) version 2 dates back to 2008 . this new version of wcag is meant to be a practical tool , evidenced by its three levels of accessibility : * a : minimum * aa : medium * aaa : as accessible as possible you will find a good wcag2 checklist online . the ideal thing to do would be to make your website as accessible as possible , but in practice you need to read the guidelines and identify the accessibility level best suited to serving your users . let s look at a concrete example by applying an a - level guideline to an existing search form . the guideline states : `` form inputs have associated text labels or , if labels can not be used , a descriptive title attribute . '' let s look at a part of an ads search form original coding . this piece of code is from the section which requires an object for selection . 0.2 in ` < input name = obj req value = yes type = checkbox > require object for selection ` 0.2 in let s add some more coding ( in boldface ) . rather than just a checkbox , we now have a text label . 0.2 in ` < input id = obj req name = obj req value = yes type = checkbox > < label for = obj req > require object for selection</label > ` 0.2 in figure 2 shows what has changed . the text label in question has been highlighted . it is no longer necessary to hit the small checkbox it is enough if you just click the associated text . this makes the box much easier to check . you can do clever things html . there are however many other formats to consider : pdf , flash , and office products , to name just a few . no matter what the material at hand , it needs structure above all else . otherwise , a blind person who tries to read a text has to read everything from beginning to end and is not able to navigate to a chapter or a footnote . even pdf which used to be an accessibility nightmare can now boast of a structure to make it more accessible it s called tagged pdf . as a general guideline , no matter what kind of document you are writing , you will need to stick to structure . do you use subtitles that are bold and in a different font ? please , use proper titles instead and use styles to control the fonts and such . let s take a peek at an html page that has structure . there are tools to make the structure visible . the box in figure 3 has been done wave toolbar . this example is taken from planetary and space science . a good amount of structure has been revealed . the html structure of earth , moon and planets , shows next to nothing . its only structure is a", "summary": "making online resources more accessible to physically challenged library users is a topic deserving informed attention from astronomy librarians . recommendations like wcag 2.0 standards and section 508 , in the united states , have proven valuable , and some vendors are already making their products compliant them . but what about the wide variety of databases and other resources produced by astronomy information professionals themselves ? few , if any , of these are currently compliant accessibility standards . here we discuss some solutions to these accessibility challenges ."}
{"article": "the transformation , upon charge doping , of an antiferromagnetic ( af ) mott insulator into a superconducting ( sc ) metal and the role of af correlations in the appearance of superconductivity have challenged researchers since the discovery of high- superconductivity in cuprates . is the af order an indispensable component or a competitor for the high- phenomenon ? in a prototype high- cuprate lasrcuo , the long - range af order is destroyed by doped holes way before the superconductivity sets in , which has led to a general belief that the spin frustration is a prerequisite for metallic conduction and superconductivity . the destructive impact of static spin order on superconductivity was further supported by the observation of sc suppression at a peculiar 1/8 doping in labacuo . on the other hand , spin excitations are often suggested to provide glue for sc pairing , implying the ultimate importance of af correlations , be they static or dynamic . besides , the incompatibility of static af order and sc may be not necessarily a general feature of cuprates . in bacuo ( is a rare - earth element ) , for instance , the long - range af order survives up to much higher doping levels than in lasrcuo , though the possibility of its coexistence superconductivity still remains to be clarified . in strongly anisotropic high- cuprates , the -axis charge transport appears to be remarkably sensitive to the spin ordering in cuo planes . in bacuo crystals , for example , the -axis resistivity exhibits a steep increase at the nel temperature . even relatively weak modifications of the spin structure such as spin - flop or metamagnetic transitions result in surprisingly large changes by up to an order of magnitude in the -axis resistivity of both hole - doped lasrcuo and electron - doped prlacecuo and ndcecuo crystals . this sensitivity of the interplane charge transport in cuprates to the spin order can be , and actually is , employed for tracing the evolution of the spin state doping , temperature , or magnetic fields . while electrical resistivity measurements have proved to be a very convenient tool for mapping the magnetic phase diagrams in cuprates , their usage has an obvious limitation ; namely , they fail as the superconductivity sets in . because of this limitation , previous resistivity studies of bacuo crystals could not clarify whether the long - range af order vanishes by the onset of superconductivity , or extends further , intervening the sc region . it sounds tempting to employ strong magnetic fields to suppress the superconductivity and to use the -axis resistivity technique of detecting the spin order in otherwise inaccessible regions of the phase diagram . in the present paper , we use this approach to study the very region of the af - sc transformation in lubacuo and ybacuo single crystals . bacuo single crystals nonmagnetic rare - earth elements lu and y were grown by the flux method and their oxygen stoichiometry was tuned to the required level by high - temperature annealing subsequent quenching . in order to ensure that no oxygen - enriched layer was formed at the crystal surface during the quenching process , one of the crystals was dissolved in acid in several steps ; resistivity measurements detected no considerable change in the sc transition upon the crystal s surface destruction . the -axis resistivity was measured using the ac four - probe technique . to provide a homogeneous current flow along the -axis , two current contacts were painted to almost completely cover the opposing -faces of the crystal , while two voltage contacts were placed in small windows reserved in the current ones . the magnetoresistance ( mr ) was measured by sweeping temperature at fixed magnetic fields up to 16.5 t applied along the axis of the crystals . a representative curve obtained for a lubacuo single crystal doping level slightly lower than required for the onset of superconductivity is shown in fig . 1 . in general , the -axis resistivity in bacuo crystals of non - sc composition exhibits two peculiar features upon cooling below room temperature , both of which can be seen in fig . 1 . the first one is a pronounced crossover at ( k for the particular composition in fig . 1 ) , indicating a change decreasing temperature of the dominating conductivity mechanism from some kind of thermally activated hopping to a coherent transport . it is worth noting that a similar coherent - incoherent crossover was observed in other layered oxides as well . the second feature is a sharp growth of the resistivity associated long - range af ordering . if the crystals were less homogeneous , the low - temperature resistivity upturn would be easy to confuse usual disorder - induced charge localization . however , this sharp resistivity anomaly characteristic negative peak in the derivative ( inset in fig . 1 ) is definitely related to the spin ordering at the nel temperature : it has been traced from the parent compositions bacuo well - known to avoid any doubt in its origin . , of a lubacuo single crystal . the sharp growth of the resistivity upon cooling below k is caused by the af ordering . inset : anomaly in the normalized derivative associated nel transition.,width=287 ] in carefully prepared crystals , the af transitions remain sharp for all compositions , including crystals very low k , that is times lower than original k in parent bacuo . it is important to emphasize that the transitions at k remain virtually as sharp as in undoped parent crystals even though spin freezing into a spin - glass state is usually expected for such low temperatures and high hole concentrations . moreover , the impact of the af ordering on does not weaken decreasing nel temperature ; as can be seen in fig . 1 , the resistivity of the crystal increases by more than 50% upon cooling below , while in crystals the corresponding growth does not exceed 15 - 20% . what do these observations tell about the impact of doped holes on copper spins ? apparently , the sharp af transitions are hard to reconcile strongly frustrated spin states and disordered spin textures in cuo planes that are usually expected to emerge in cuprates doping . besides , a strong frustration - induced reduction of the staggered magnetization required to account for the decrease in would necessarily diminish the impact of the interplane spin ordering on , which again disagrees observations . on the other hand , if the role of mobile doped holes is not to introduce a uniform spin frustration , but simply to break the long - range af order into two - dimensional domains in cuo planes , the observed behavior is easier to understand . in this case , it is the af domains in cuo planes that become the elementary magnetic units and the long - range af state should develop through ordering of their phases , which can occur rather abruptly . correspondingly , the evolution doping should be governed by the decreasing af domain size , rather than . in turn , the ordering of af domains whose local staggered magnetization does nor change appreciably hole doping leaves room for large changes in the -axis resistivity even at low . the and values determined from the -axis resistivity of bacuo crystals have been used to establish the doping - temperature phase diagram in fig . 2 . a peculiarity of bacuo crystals is that their doping level is determined both by the oxygen content and by the degree of its ordering . for characterizing the doping level , we use therefore the in - plane conductivity instead of the oxygen content ; the former is a good measure of the hole density given that the hole mobility stays almost constant in the doping region under discussion . bacuo ( = lu , tm , y ) crystals near the af - sc transformation . the af and sc transition temperatures , and , are presented as a function of the in - plane conductivity which is a good measure of the hole density in the shown doping region . the nel temperature was determined either at the position of the jump ( middle point ) in the derivative ( open circles ) , or at the position of the negative peak in ( solid circles).,width=326 ] as can be seen in fig . 2 , the long - range af order in bacuo appears to be much more stable than in lasrcuo where it vanishes well in advance before the onset of superconductivity . in bacuo , the af phase boundary flattens upon approaching the sc compositions and hits the sc region , crossing the line at k . the observed overlap of the sc and af regions is very close to the area where sr studies of ybacuo ceramics revealed the coexistence of superconductivity spontaneous static magnetism . given that the -axis resistivity studied here is sensitive to the interlayer spin ordering , the static magnetism detected by sr should in fact be related to the three - dimensional af order . the superconductivity in bacuo thus develops directly from the af - ordered state without any intervening paramagnetic or spin - glass region . cuo single crystal for two oxygen concentrations near the af - sc transformation . for the superconducting composition , the data were taken at several magnetic fields from zero up to 16.5 t applied along the axis . the sharp upturn in the resistivity associated nel transition shows up as the superconductivity is suppressed magnetic field.,width=326 ] according to the established phase diagram ( fig . 2 ) , an increase of the hole density in cuo planes by % per cu ( from % to % , assuming the onset of superconductivity at % doping ) turns an af bacuo crystal without any sign of superconductivity into a bulk superconductor . what happens af order upon entering the sc region , does it vanish abruptly ? zero - field curves measured on the same lubacuo crystal for two hole doping levels ( that differ by .5 - 0.6% per cu ) indeed demonstrate a switch from an af state sharply growing below to a sc state ( fig . however , when the superconductivity is suppressed magnetic field , the steep increase in associated af ordering is recovered back ( fig . 3 ) . moreover , the recovered nel temperature is merely several kelvin lower than for the non - sc composition ( upper curve in fig . 3 ) and the resistivity increase is not reduced appreciably either . as long as the sc in lubacuo and ybacuo crystals is weak enough to be killed by the 16.5-t field , the unveiled curves keep demonstrating the anomalous growth below 15 - 20k associated nel transition . this behavior indicates that , at least when superconductivity is suppressed magnetic fields , the af order extends to considerably higher doping levels than the sc onset . consequently , at zero magnetic field the af and sc orders either coexist each other in a certain range of doping , or the af order is frustrated in the sc state but revives as the superconductivity is destroyed magnetic field . a switching between the af and sc orders was indeed suggested based on early sr studies , yet no further proofs were collected . the close location and even overlapping of the af and sc orders on the phase diagram raise another question of whether the af and sc orders reside in nanoscopically separated phases in cuo planes or coexist on the unit - cell scale , which calls for local microscopic tools to be clarified . j. m. tranquada , a. h. moudden , a. i. goldman , p. zolliker , d. e. cox , g. shirane , s. k. sinha , d. vaknin , d. c. johnston , m. s. alvarez , a. j. jacobson , j. t. lewandowski , and j. m. newsam , phys . rev . b * 38 * , 2477 ( 1988 ) .", "summary": "the remarkable sensitivity of the -axis resistivity and magnetoresistance in cuprates to the spin ordering is used to clarify the doping - induced transformation from an antiferromagnetic ( af ) insulator to a superconducting ( sc ) metal in bacuo ( lu , y ) single crystals . the established phase diagram demonstrates that the af and sc regions apparently overlap : the superconductivity in bacuo , in contrast to lasrcuo , sets in before the long - range af order is completely destroyed by hole doping . magnetoresistance measurements of superconducting crystals k give a clear view of the magnetic - field induced superconductivity suppression and recovery of the long - range af state . what still remains to be understood is whether the af order actually persists in the sc state or just revives when the superconductivity is suppressed , and , in the former case , whether the antiferromagnetism and superconductivity reside in nanoscopically separated phases or coexist on an atomic scale . keywords : phase diagram , antiferromagnetism , magnetoresistance , c - axis conductivity ."}
{"article": "cp violation , initially observed only in the system , is one feature of the standard model ( sm ) that still defies clear theoretical understanding . the ckm picture , which describes all the observed cp violation in terms of a single phase in the quark - mixing matrix , has been vindicated by the recent measurements of mixing at belle and babar . cp violation is in fact one of the necessary ingredients for generating the observed excess of baryons over antibaryons in the universe . the amount of cp violation present in the quark sector is , however , too small to generate a baryon asymmetry of the observed level of . new sources of cp violation beyond the sm are therefore a necessity . supersymmetry ( susy ) is arguably the most attractive extension of the sm , as it solves , for instance , the problem of the instability of the electroweak symmetry - breaking scale against radiative corrections . already the minimal supersymmetric standard model ( mssm ) provides possible new sources of cp violation through additional cp - violating phases , which can not be rotated away by simple field redefinitions . a large number of these phases , particularly those involving sparticles of the first and to a large extent of the second generation , are severely constrained by measurements of the electric dipole moments ( edms ) of the electron , muon , neutron as well as hg and tl . however , these constraints are model - dependent . it has been demonstrated that cancellations among different diagrams allow certain combinations of these phases to be large in a general mssm . furthermore , if the sfermions of the first two generations are sufficiently heavy , above the range , the edm constraints on the phase of the higgsino mass parameter , in general constrained to , get weaker ; the sfermions of the third generation can still be light . non - vanishing phases of and/or the trilinear scalar couplings can induce explicit cp violation in the higgs sector via loop corrections . though these phases generate edms independently of the first two generations of sfermions , the edms are suppressed by the mass scale of the two heavy higgses . for a thorough discussion of the edms see and", "summary": "the longitudinal polarization of fermions ( tops and taus ) produced in sfermion decays to neutralinos or charginos can be a useful tool for the determination of susy parameters . we discuss this fermion polarization in the context of the mssm complex parameters . we show that the dependence on cp - violating phases can be large and that the fermion polarization may hence be used as a sensitive probe of cp phases in the mssm . cern - ph - th/2004 - 086 + hephy - pub 790/04 + iisc - chep/7/04 + fi2004 - 15 + hep - ph/0405167 * fermion polarization in sfermion decays as + a probe of cp phases in the mssm * + thomas gajdosik , rohini m. godbole , sabine kraml + institute of physics , vilnius lt-2600 , lithuania + centre for high energy physics , indian institute of science , bangalore 560012 , india + inst . f. hochenergiephysik , sterr . akademie d. wissenschaften , 1050 vienna , austria + department of physics , cern , theory division , 1211 geneva 23 , switzerland +"}
{"article": "the variability of ex lup was discovered by miss e. janssen in 1944 while examining spectral plates at the harvard observatory ( mclaughlin 1946 ) . herbig ( 1950 ) first pointed out the similarity of ex lupi s spectral characteristics and t tauri stars strong emission lines of h , caii , feii , and hei . in one of the spectrograms he obtained in 1949/1950 the h and caii lines clearly show an inverse p cygni profile . herbig ( 1977a ) assigned the spectral type of m0:ev using the 5850 - 6700 range . photographic and visual light - curves covering a century of observations revealed the irregular photometric behaviour of the star ( mclaughlin 1946 , bateson et al . outbursts of up to 5 magnitudes may occur , but the star normally shows only small amplitude irregular variations . the most prominent events last about one year . the typical recurrence time scale of outbursts is of the order of a decade . + up to now there are only a few other stars known comparable outburst characteristics ( herbig 1989 ) . this small group of very active t tauri stars has been called exors or sometimes sub - fuors . both names point to an affinity to the so called fu orionis stars ( fuors ) . fuors are another group of young low mass stars even stronger outbursts lasting for decades . unlike exors , during an outburst fuor spectra turn from t tauri characteristics to that of much earlier f or g supergiants lacking strong line emission ( herbig 1977b ) . fuors have high mass accretion rates ( ,hartmann 1991 ) and strong winds ( e.g. calvet et al . 1993 ) and they may be the source that drive herbig - haro flows ( reipurth 1989 ) . + exors are little studied , but potentially of great interest because they may represent an intermediate level of activity between ordinary active t tauri stars and full blown fu orionis eruptions . in order to cast further light on this interpretation , we have followed some exors spectroscopically and photometrically during 1993 and 1994 . the star ex lup has been at a low level of activity during the . in the early this situation changed and the star became active ( jones et al . 1993 , hughes et al . amateur observations ( variable star section of the royal astronomical society of new zealand , unpublished ) indicated a strong brightening in february / march 1994 . patten ( 1994 ) reports some follow - up photometric and low resolution spectroscopic observations of the same outburst . + in this paper we present part of our optical observations of ex lup taken at eso , la silla . we concentrate on data obtained during the outburst in march 1994 and include some spectroscopic observations carried out in august 1994 when the star only exhibited post - outburst low level activity . a complete presentation of our data will appear in a future paper . differential ccd photometry has been carried out at the 0.9m - dutch and the 1.54m - danish telescopes . this photometry was later calibrated respect to standard stars including extinction and colour corrections . all reductions have been made apphot package in iraf . typical errors ( 1 ) in the differential photometry are b=0.005 , v=0.004 , r=0.004 whereas the absolute magnitude scale itself is accurate to about 0.01 in all three colours . + the resulting lightcurves in b , v , and r are presented in fig . 1 . the maximum occurred between february 25 and march 4 ( herbig , priv . the fading tail of the eruption can be described as an exponential decline small fluctuations superimposed . variability of more than 0.1mag is present on timescales of less than one hour ( e.g. march 6.3 , see also patten 1994 ) . figure 2 displays the colour change in b - v during the decline . the star clearly becomes redder when fading . for comparison we have included some points close to minimum light taken from the literature . the outburst amplitude was about v=2.0mag and b=2.6mag . spectroscopic observations in the blue spectral range were carried out during the first few nights in march 1994 on the eso-1.52 m telescope using the boller & chivens spectrograph at 1.2 resolution . after the decline of ex lup we obtained post - outburst spectra in the same wavelength region at resolutions of 1.5 and 12 at the 3.5m - ntt emmi in august 1994 . all spectra have been reduced ctioslit package in iraf . observations of spectrophotometric standards and nightly extinction curves allowed for a flux calibration . + in fig.3 we present two spectra of ex lup : one close to the outburst maximum and the other at low activity almost half a year after the eruption . some of the emission lines of h , caii , feii , hei , and heii are indicated . under the assumption that the total light can be decomposed into an underlying t tauri star photosphere , a continuum source , and superimposed emission lines , we now discuss the different spectral components and their variability . a powerful method to determine the continuum excess emission is to determine the veiling by comparison spectra of stars of the same spectral type and luminosity class but lacking any disk signature ( hartigan et al . 1989 , 1991 ) . the accuracy of the veiling determination decreases rapidly when the emission component exceeds the photospheric luminosity . in the case of ex lup during its eruption we therefore did not intend to derive the veiling and the true excess emission spectrum by comparison spectral type standards , but we could examine the spectral variability caused by the outburst . + no photospheric absorption features are seen during the outburst ( upper spectrum in fig.3 ) but they appear in the post - outburst spectrum . thus the major source of variability presumably is a featureless continuum . therefore , a difference spectrum between outburst and post - outburst spectra should be a good measure of the continuum emission spectrum . in fig . 4 we plot two difference spectra at low resolution . the first shows the difference between an outburst ( march 3 ) and a post - outburst ( august 16 ) spectrum , while the second shows the difference between two post - outburst ( august 18 and 16 ) spectra which displays normal low - level variability . the continuum emission spectrum displaying the normal low - level activity is bluer than the continuum emission present during outburst . the most intriguing features in the spectra of ex lup are strong emission lines . the balmer series can be seen up to h15 especially during times of minimum activity . equivalent widths and fluxes of individual lines are given in table 1 . essentially all strong emission lines have increasing fluxes as the star brightens . however due to the steep rise of the continuum the equivalent widths decrease , which is also evident in the data from patten ( 1994 ) at h , h , and h during the maximum . obviously the caii lines have a larger flux amplification during the outburst than the balmer lines . there is some indication that line fluxes of metals do not increase while the star goes into outburst ( cai , feii , srii ) . + lrrrr & & & & + identification & w & w & flux & flux + & & & & + & & & & + & & & & + h11 3771 & -1.0 & -4.2 & 16 & 6 + h10 3798 & -1.5 & -7.0 & 25 & 9 + h 9 3835 & -1.2 & -12.1 & 20 & 16 + h 8 3889 & -2.7 & -13.0 & 44 & 18 + sii 3906 & -0.2 & -0.8 & 3 & 1 + caii 3934 & -7.7 & -12.0 & 123 & 15 + .comparison of selected emission lines at different levels of activity . equivalent widths and line fluxes during the outburst measured on march 3 and in the post - outburst spectrum on august 16 & -0.4 & -1.7 & 8 & 3 + heii 4686 & -0.3 & -0.9 & 6 & 2 + h 4861 & -9.4 & -16.8 & 196 & 30 + feii 4924 & & -1.5 & & 2 + the presence of inverse p cygni profiles in the strongest emission lines during outburst , as first noted by herbig ( 1950 ) , is here corroborated . at balmer lines higher than h9 the equivalent width of the redshifted absorption dip is even larger than the width of the emission component . comparing the sequence of spectra between march 3 and 6 we can see a substantial fading of the absorption . the mean velocity displacement of the absorption measured in these spectra is km / s . this absorption component is still visible in our spectrum taken on august 18 ( fig.5a ) . we also plot the difference between the two spectra from august 18 and august 16 to enhance the visibility of the absorption dip and to remove possible contamination due to photospheric lines . the displacement of the absorption dip measured in the post - outburst difference spectrum corresponds to a velocity of km / s . photospheric features of the underlying t tauri star can be seen only in the post - outburst spectra . figure 6 shows the region around cai 4227 , which is the strongest stellar absorption line , in two post - outburst spectra . the difference of these two spectra no longer exhibits the absorption line , and the change of total flux by about 40% is therefore due to continuum emission rather than photospheric variability . + the photospheric lines of the t tauri star are veiled , even at minimum brightness . the superimposed emission line spectrum additionally fills in many absorption lines . the measurement of the veiling is therefore rather difficult . we find a good fit to the observed strength of absorption lines by introducing a flat continuum emission equal to the photospheric continuum of the underlying star ( veiling r=1 , comparison 202560 , spectral type m0v ) at 4200 when the brightness of ex lup is v=13.0 . the outburst of ex lup can be understood in terms of a mass accretion event causing increased continuum emission in a hot region close to the surface of the star where the infalling matter finally releases its kinetic energy . the total light of the photosphere and the hot region becomes dominated by the latter and therefore it is much bluer during the outburst . furthermore all photospheric lines are heavily veiled ( assuming that r=1 at minimum light then the veiling during outburst would be r ) . the different slope of the continuum emission in the outburst compared to the post - outburst ( see fig.4 ) indicates that the hot region is cooler during outburst ( assuming no change in extinction due to circumstellar matter ) . this interpretation then implies a dramatic expansion of the hot region in order to account for the observed rise in luminosity during the outburst . + the inverse p cygni profiles of many emission lines prove the infall motion of accreted material . the velocity derived from the redward displacement of the absorption component of these lines are of the order of 300 km / s and therefore much higher than those assumed in the classical boundary layer model for t tauri stars ( lynden - bell & pringle , 1974 ) . however , these high infall velocities may result from magnetospherically mediated disk accretion ( camenzind 1990 , knigl 1991 , hartmann et al . high resolution studies of classical t tauri stars have revealed a large fraction of stars exhibiting inverse p cygni structures ( e.g. appenzeller 1977 , edwards et al . , 1994 ) . the usual low level variability might be caused by geometrical effects during the rotation of the star . the more dramatic outbursts could be attributed to episodic changes in the magnetosphere , resulting in more extended infall flows of circumstellar material onto the star . + acknowledgements : we thank g.herbig for alerting us to the outburst of ex lup in early march 1994 . also we are grateful to the following observers for kindly providing part of their observing time : t.abbott , j.f.claeskens , d.de winter , c.flynn , h.jerjen , a.manchado , f.patat , n.robichon , p.stein . tl & wb were supported by student fellowships of the european southern observatory . wb acknowledges support by the deutsche forschungsgemeinschaft ( dfg ) under grant yo 5/16 - 1 . appenzeller i. , 1977 , a&a * 61 * , 21 bastian u. , & mundt r. , 1979 , a&as * 36 * , 57 bateson f.m . , mcintosh r. , & brunt d. , 1990 , publ . of var.star section of the roy.astron.soc . of new zealand no.16 , 49 calvet n. , hartmann l. , & kenyon s.j . , 1993 , apj * 402 * , 623 camenzind m. , 1990 , rev . astron . * 3 * , 234 edwards s. , hartigan p. , ghandour l. , & andrulis c. , 1994 , aj * 108 * , 1056 hartigan p. , hartmann l. , kenyon s. , & hewett r. , 1989 , apjs * 70 * , 899 hartigan p. , kenyon s.j . , hartmann l. et al . , 1991 , apj * 382 * , 617 hartmann l. , 1991 , in the physics of star formation and early stellar evolution , ed . c.j . lada & n.d . kylafis , kluwer academic publishers , p.623 hartmann l. , hewett r. , & calvet n. , 1994 , apj * 426 * , 669 herbig g.h . , 1950 , pasp * 62 * , 211 herbig g.h . , 1977a , apj * 214 * , 747 herbig g.h . , 1977b , apj * 217 * , 693 herbig g.h . , 1989 , in low mass star formation and pre - main sequence objects , b. reipurth , eso conference and workshop proceedings no.33 , p.233 herbig g.h . , gilmore a.c . , & suntzeff n. , 1992 , ibvs no.3808 hughes j. , hartigan p. , krautter j. , kelemen j. , 1994 , aj * 108 * , 1071 jones a.f . , albrecht w.b . , gilmore a.c . , & kilmartin p.m. , 1993 , iauc no.5791 knigl a. , 1991 , apj * 370 * , l39 lynden - bell d. , & pringle j.e . , 1974 , mnras * 168 * , 603 mclaughlin d.b . , 1946 , aj * 52 * , 109 patten b.m . , 1994 , no.4049 reipurth b. , 1989 , nature * 340 * , 42", "summary": "we have observed an outburst of the t tauri star ex lup in march 1994 . we present both photometric ( bvr ) and spectroscopic ( low and medium resolution ) observations carried out during the decline after outburst . the star appears much bluer during outburst due to an increased emission of a hot continuum . this is accompanied by a strong increase of the veiling of photospheric lines . we observe inverse p cygni profiles of many emission lines over a large brightness range of ex lup . we briefly discuss these features towards the model of magnetospherically supported accretion of disk material . 2.5 cm # 1to -1.5pt#1"}
{"article": "the liquid - gas ( lg ) phase transition in nuclear matter remains illusive and a hot research topic despite of the great efforts devoted to understanding its nature and experimental manifestations by the nuclear physics community over many years . for a recent review , see , e.g. , refs. . most of the previous studies have focused on the lg phase transition in symmetric nuclear matter . while in an asymmetric nuclear matter , the lg phase transition is expected to display some distinctly new features because of the isospin degree of freedom and the associated interactions and additional conservation laws . this expectation together need to understand better properties of asymmetric nuclear matter relevant for both nuclear physics and astrophysics have stimulated a lot of new work recentlyliko97,ma99,wang00,su00,lee01,li01,natowitz02,li02,chomaz03,sil04,lizx04,chomaz06,li07 . moreover , the study on the lg phase transition in asymmetric nuclear matter has received recently a strong boost from the impressive progress in developing more advanced radioactive beams that can be used to create transiently in terrestrial laboratories large volumes of highly asymmetric nuclear matter . though significant progress has been made recently in studying properties of isospin asymmetric nuclear matter and the lg phase transition in it , there are still many challenging questions to be answered . among the main difficulties are our poor understanding about the isovector nuclear interaction and the density dependence of the nuclear symmetry energy . fortunately , recent analyses of the isospin diffusion data in heavy - ion reactions have allowed us to put a stringent constraint on the symmetry energy of neutron - rich matter at sub - normal densities betty04,chen05,lichen05 . it is therefore interesting to investigate how the constrained symmetry energy may allow us to better understand the lg phase transition in asymmetric nuclear matter . moreover , both the isovector ( i.e. , the nuclear symmetry potential ) and isoscalar parts of the single nucleon potential should be momentum dependent . however , effects of the momentum - dependent interactions on the lg phase transition in asymmetric nuclear matter were not thoroughly investigated previously . we report here our recent progress in investigating effects of the isospin and momentum dependent interactions on the lg phase transition in hot neutron - rich nuclear matter within a self - consistent thermal model using three different interactions . the first one is the isospin and momentum dependent mdi interaction constrained by the isospin diffusion data in heavy - ion collisions . the second one is a momentum - independent interaction ( mid ) which leads to a fully momentum independent single nucleon potential , and the third one is an isoscalar momentum - dependent interaction ( emdyi ) in which the isoscalar part of the single nucleon potential is momentum dependent but the isovector part of the single nucleon potential is momentum independent . we note that the mdi interaction is realistic , while the other two are only used as", "summary": "the liquid - gas phase transition in hot neutron - rich nuclear matter is investigated within a self - consistent thermal model using different interactions without isospin and/or momentum dependence . the boundary of the phase - coexistence region is shown to be sensitive to the density dependence of the nuclear symmetry energy as well as the isospin and momentum dependence of the nuclear interaction ."}
{"article": "the study of the phase transition of frustrated spin systems on two - dimensional ( 2d ) lattices is a central problem in modern condensed mater physics . a competition of exchange interaction can lead to frustration , where spatial arrangement of magnetic ions in a crystal for which a simultaneous antiparallel ordering of all interacting spin is impossible . in particular , one of the frustrated 2d models most discussed is the quantum spin- heisenberg antiferromagnet on a square lattice competing nearest - neighbor ( nn ) and next - nearest - neighbor ( nnn ) antiferromagnetic exchange interactions ( known as model ) . the criticality of this heisenberg model on a square lattice are relatively well known at . there are two magnetically long - range ordered phases at small and at large values of separated by an intermediate quantum paramagnetic phase without magnetic long - range order in the region between and , where the properties of these disordered phase are still under intensive debate . for , the system possesses antiferromagnetic ( af ) long - range order wave vector , staggered magnetization smaller than the saturated value ( quantum fluctuations ) , which vanished continuously when . for we have two degenerate collinear states which are the helical states pitch vectors and . these two collinear states are characterized by a parallel spin orientation of nearest neighbors in vertical ( or horizontal ) direction and an antiparallel spin orientation of nearest neighbors in horizontal ( or vertical ) direction , and therefore exhibit nel order within the initial sublattice a and b. at , the magnetization jumps from a nonzero to a zero value . the phase transition from nel to the quantum paramagnetic state is second order , whereas the transition from the collinear to the quantum paramagnetic state is first order . et al . have shown that the intermediate quantum paramagnetic is a ( singlet ) plaquette crystal , and the ground and first excited states are separated by a finite gap . the interest to study the two - dimensional heisenberg antiferromagnet have been greatly stimulated by its experimental realization in vanadium phosphates compounds , such as livosio , livogeo , and vomoo , which might be described by this frustrated model in the case of . these isostructural compounds are characterized by a layered structure containing v ions . the structure of v layer suggest that the superexchange is similar . in these compounds a second order phase transition to a long - range ordered magnetic phase has been observed . nmr spin - lattice relaxation measurements below shows that the order is collinear . due to the two - fold degeneracy of the ground - state for it is not possible to say a priori which will be the magnetic wave vector ( i.e. , and ) below . on the other hand , such a scenario can change by considering spin - lattice coupling which will lift the degeneracy of the ground - state and will lower its energy . then , any structural distortion should inevitably reduce this competing interactions and thus reduces the frustration . in the case of this frustrated magnetic materials , the competing interactions are inequivalent but their topology and magnitudes can be tuned so that the strong quantum fluctuations destroy the long - range ordering . experimentally the ground state phase diagram of frustrated compounds , described by the model , can be explored continuously from high to the low regime by applying high pressures ( p ) , which modify the bonding lengths and angles . recent results from x - ray diffraction measurements on the livosio compound has shown that the ratio decreases by about when the pressure increases from to gpa . a generalization of the heisenberg antiferromagnetic model on a square lattice was introduced by nersesyan and tsvelik and studied by other groups , the so - called model . in the model is considered inequivalence nn couplings and in the two orthogonal spatial lattice dimensions the nnn bonds across the diagonals to have the same strength . study of extensive band structure calculations for the vanadium phosphates abvo(po) ( ab = pb , srzn , bazn , and bacd ) have indicated four inequivalent exchange couplings : and between nn and and between nnn . for example , in srznvo(po) was estimated and causing a distortion of the spin lattice . this spatial anisotropy tends to narrow the critical region and destroys it completely at a certain value of the interchain parameter . on the other hand , by using the continuum limit of the spin- model starykh and balents have shown that this transition splits into two , presence of an intermediate quantum paramagnetic ( columnar dimer ) phase for . bishop , et al , by using coupled cluster treatment found the surprising and novel result that there exists a quantum triple point ( * qtp * ) coordinates at , below which there is a second - order phase transition between the * af * and * caf * phases while above this * qtp * are these two ordered phases separated by the intermediate magnetically disordered phase ( vbs or rvb ) . the order parameters of both the * af * and * caf * phases vanish continuously both below and above the * qtp * , which is typical of second - order phase transition . there is some evidence that the transition between the * caf * and intermediate phases is of first - order . using exact diagonalization small lattice of size , the intermediate * qp * phase for all interval of $ ] has been obtained for the pure spin- model on a square lattice . these results are in accordance results obtained by starykh and balentes , that predicted not the * qtp * in the ground - state phase diagram recently observed by bishop , et al. . the ground state ( gs ) properties of the two - dimensional frustrated heisenberg antiferromagnet have been investigated by various methods . the exact diagonalization starts from singlet states on pairs of sites , which cover the whole 2d lattice . however , the manifold of these states which can be constructed is nonorthogonal and overcomplete . this numerical methods are limited to small clusters due to storage problems . the computation on the largest cluster has been performed by schulz and co - workes years ago . in spite of the great improvements achieved during this time , it is not possible so far to repeat this calculation for the next interesting cluster . this is only possible other technique , as the quantum monte carlo simulation . due to the progress in computer hardware and the increased efficiency in programing , very recently the gs of the quantum spin-1/2 model have been calculated by the lanczos algoritm for a square lattice sites . the theoretical treatment of the frustrated quantum models is far from being trivial . many of the standard many - body methods , such as quantum monte carlo techniques , may fail or become computationally infeasible to implement if frustration is present due to the minus - sign problem . hence , there is considerable interest in any method that can deal frustrated spin systems . this considerable qualitative difference in the ground state phase diagram in the plane of the quantum spin- model further motivates us to study this issue by alternative methods . using a variational approximation , in which plaquettes of four spins are treated exactly , oliveira has studied the ground state phase diagram of the pure heisenberg antiferromagnet on a square lattice , where the quantitative results are in good accordance more sophisticated method ( exact diagonalization ) . in this work , we generalize this variational method to treat the anisotropic square lattice ( model ) . the rest of this paper is organized as follows : in . ii , the model is presented and a brief discussion of results . in . iii , the method is applied for the case of one plaquette four spins interacting other plaquette type mean field approximation . main results will be presented in . iv , as well as some discussions . finally , in . v we will give a brief summary . the critical behavior of the quantum spin- heisenberg model has been studied for many years , but very little has been done in the anisotropic square lattice case , which is described by following hamiltonian : where is the spin- pauli spin operators , the index labels the ( row ) and ( column ) components of the lattice sites . the first sum runs over all nn and the second sum runs over all nnn pairs . we denote the hamiltonian ( 1 ) by model , strength along the row direction , along the column direction , along the diagonals , and we assume all couplings to be positive . the classical model ( 1 ) has only two ordered ground - states : * af * ( or nel ) for and columnar stripe ( * caf * ) for separated by a first - order line at . quantum fluctuations play a significant role in the magnetic phase diagram of the system at zero temperature . we will investigate the role of quantum fluctuations on the stability of the nel and collinear phases . in the case ( quantum limit ) , the line splits into two phase transitions , where the ordered states ( * af * and * caf * ) are separated by an intermediate quantum paramagnetic ( * qp * ) phase , both on a square lattice . exact diagonalization has estimated a critical line at , for the transition between the * caf * and * qp * states , and at between the * af * and * qp * states . the phase diagram in the plane obtained is in accordance starykh and balents . however , the existence of * qtp * ( quantum triple point ) that was predicted by bishop , et al . , is not present in their obtained phase diagram . moreover , they found only presence of second - order phase transitions in the phase diagram . this contradictory qualitative results ( existence or not of * qtp * ) is the primary motivation behind this present work . on the other hand , a critical endpoint ( * ce * ) is a point in the phase diagram where a critical line meets and is truncated by a first - order line . this * ce * appear in the phase diagram of many physical systems such as binary fluid mixtures , superfluids , binary alloys , liquid crystals , certain ferromagnets , etc , and have been known for over a century . despite the * ce * long history , new singularities at the * ce * were predicted . fisher and upton argued that a new singularity in the curvature of the first - order phase transition line should arise at a * ce*. this prediction was confirmed by fisher and barbosas phenomenological studies for an exactly solvable spherical model . in conclusion of the analysis of the multicritical behavior observed in the ground - state phase diagram in the plane for the model , we have the presence of a quantum critical endpoint ( * qce * ) and not * qtp * as mentioned other works therefore , the objective of this work is to obtain the * qce * using the variational method , that was developed previously by oliveira in the pure limit case . we first express the fluctuations around the classical ground state ( * af * and * caf * phases ) , where consider a trial vector state for the ground state as a product of plaquette state . we denote the plaquettes by label , that is composed of four spins , where it do not overlap ( mean field ) on the square lattice as illustrated in figure 1 . each plaquette state is given by and spin operators that are considered in eq . ( 2 ) . ] where \\{ , } is the vector basis , \\{ } are real variational parameters obeying the normalization condition . this choice of vector states , the mean value of the spin operator in each site of the plaquette is given by , where the components in the and directions are null . using the trial vector state defined in the eq . ( 2 ) , we obtain the magnetizations at each site that are given by and where we have used the same set of parameters ( canonical transformation ) of ref. , i.e. , , and , which obeys the normalization condition . the ground state energy per spin and unit of , , is given by and , %\\ ] ] where is the mean value of a given observable calculated in the vector state of the plaquette as illustrated in fig . the variational energy can be evaluated using the properties of the spin- pauli operator components , i.e. , , and , that is expressed for + \\nonumber\\\\ & 2\\left ( 1-\\lambda\\right ) \\left ( y^{2}v^{2}-z^{2}\\omega^{2}\\right ) + 2x\\left ( y\\lambda+z\\right ) + \\alpha\\left . %\\ ] ] to obtain the minimum energy boundary condition given by normalization , we use the lagrange multiplier method which correspond the minimization of the functional the stationary solutions are obtained by solving the set of nonlinear equations {c}% -\\left ( \\lambda+1\\right ) x-4\\left ( \\lambda+1\\right ) xu^{2}+2\\left ( y\\lambda+z\\right ) + 12\\alpha xu^{2}=2\\eta x\\\\ \\left ( 1-\\lambda\\right ) \\left ( y+4yv^{2}\\right ) + 2x\\lambda-2\\alpha\\left ( y - z\\right ) -12\\alpha yv^{2}=2\\eta y\\\\ -\\left ( 1-\\lambda\\right ) z-4\\left ( 1-\\lambda\\right ) z\\omega^{2}% + 2x+2\\alpha\\left ( y - z\\right ) -12\\alpha z\\omega^{2}=2\\eta z\\\\ -\\left ( \\lambda+1\\right ) u=2\\eta u\\\\ \\left ( 1-\\lambda\\right ) v-2\\alpha v=2\\eta v\\\\ -\\left ( 1-\\lambda\\right ) \\omega-2\\alpha\\omega=2\\eta\\omega \\right . , %\\ ] ] where is the lagrange multiplier . the variational parameters , and are determined simultaneously solving the system of equations ( 12 ) combined normalization condition for each phase . in the quantum paramagnetic ( * qp * ) phase we have . we note that in the isotropic limit , our results reduce the same expression obtained by oliveira . in this disordered phase , the ground state vector is an eigenvector of , where is the total spin of the th plaquette of four spins , zero eigenvalue ( singlet state ) . in the * af * ordered phase we have the boundary condition , and in the * caf * phase . the order parameters and are numerically obtained as a function of frustration parameter for a given value of spatial anisotropy . we observe that the order parameter goes smoothly to zero when the frustration parameter increases from zero to characterizing a second - order phase transition . a simple fitting of the form in the vicinity of the second - order transition gives the same classical value for the critical exponent . on the other hand , for and the staggered magnetization increases monotonically frustration parameter in the * caf * phase , discontinuity of at , which is a first - order phase transition . for , the * qp * intermediate phase between the two ordered states ( * af * and * caf * ) disappears , and a direct transition between the magnetically ordered * af * and * caf * located at the crossing point correspondent to the classical value . the ground state phase diagram in the plane is displayed in fig . the solid line indicate the critical points and the dashed lines represent first - order frontiers . we observe three different phases , namely : * af * ( antiferromagnetic ) , * caf * ( collinear antiferromagnetic ) and * qp * ( quantum paramagnetic ) . the * af * and * qp * phases are separated by a second - order transition line , while the * qp * and * caf * phases are separated by a first - order transition line . the presence of the interchain parameter has the general effect of suppressing the * qp * phase . the * qp * region decreases gradually decrease of the parameter , and it disappears completely at the quantum critical endpoint * * qce** where the boundaries between these phases emerge . below this * qce * , i.e. , for , there is a direct first - order phase transition between the * af * and * caf * phases , transition point ( classical value ) . in order to illustrate the nature of the phase transition , we also show , in inset fig . 2 , the behavior of the staggered magnetization ( order parameter ) as a function of the frustration parameter for and . from curves such as those shown in fig . 2 we see that for there exists an intermediate region between the critical point at which for the * af * phase , characterizing a second - order transition , and the point at which the order parameter presents a discontinuity for the * caf * phase , characterizing a first - order transition . for , the order parameter of the * af * phase decreases monotonically increase of the frustration parameter from , for , to zero for . in the * caf * phase decreases from for to for , characterizing a direct first - order transition between the magnetically ordered * af * and * caf * phases located at the crossing point . we note that the definition of the order parameter difer of factor when compared calculations which use other methods ( i.e. , ) . therefore , in the limit of the not frustrated square lattice antiferromagnetic , solving the equations ( 12 ) and applying the corrections factor we found which is consistent numerical results obtained by various methods such as series expansion , quantum monte carlo simulation , and others , and can also be compared experimental results for the knif , kmnf , and rbmnf compounds . plane for the quantum spin- model on a square lattice , where and . the dashed and solid lines corresponds the first- and second - order transitions lines , respectively . the black point represents the quantum critical endpoint ( * qce * ) . the notations indicated by * af * , * caf * and * qp * corresponds the antiferromagnetic , collinear antiferromagnetic and quantum paramagnetic phases , respectively . the dotted line correspond the classical solution . ] in summary , we have studied the effects of quantum fluctuations due to spatial and frustration parameter in the quantum spin- heisenberg model . using a variational method we calculated the sublattice magnetization for the * af * and * caf * phases . for values of the frustration contributes significantly to the existence of a disordered intermediate state ( * qp * ) between the two * af * and * caf * ordered phases , while for , we have a direct first - order transition between the * af * and * caf * phases . we have observed , by analyzing the order parameters of the * af * and * caf * phases , that the phase transitions are of second and first - order between the * af - qp * and * caf - qp * , respectively . the obtained phase diagram can be compared recent results which used effective - field theory and coupled - cluster method , showing the same qualitative results predicting a paramagnetic region for small interlayer parameter ( i.e. , ) , and for this * qp * phase disappears by presenting a direct first - order transition between the * af * and * caf * phases . on the other hand , recent calculations of second order spin wave theory have indicated that the intermediate * qp * phase exists for all in accordance results of exact diagonalization . we speculate that by using a more sophisticated method , for example , quantum monte carlo simulations and density matrix renormalization group ( dmrg ) method , this disordered region should disappear for certain values of . r. f. bishop , p. h. y. li , r. darradi , j. schulenburg , and j. richter , phys . b * 78 * , 054412 ( 2008 ) ; r. f. bishop , p. h. y. li , r. darradi , j. schulenburg , j. richter , and c. e. campbell , j. phys . : condens . matter * 20 * , 415213 ( 2008 ) . see also , r. darradi , j. richter , j. schulenburg , r. f. bishop , and p. h. y. li , j. phys . : conference series * 145 * , 012049 ( 2009 ) . p. carretta , r. melzi , n. papinutto , and p. millet , phys . * 88 * , 047601 ( 2002 ) ; p. carretta , n. papinutto , c. b. azzoni , m. c. mozzati , e. pavarini , s. gonthier , and o. millet , phys . b . * 66 * , 094420 ( 2002 ) .", "summary": "the phase transition of the quantum spin- frustrated heisenberg antiferroferromagnet on an anisotropic square lattice is studied by using a variational treatment . the model is described by the heisenberg hamiltonian antiferromagnetic interactions : nearest - neighbor ( nn ) different coupling strengths and along x and y directions competing next - nearest - neighbor coupling ( nnn ) . the ground state phase diagram in the space , where and , is obtained . depending on the values of and , we obtain three different states : antiferromagnetic ( * af * ) , collinear antiferromagnetic ( * caf * ) and quantum paramagnetic ( * qp * ) . for an intermediate region we observe a * qp * state between the ordered * af * and * caf * phases , which disappears for above some critical value . the boundaries between these ordered phases merge at the quantum critical endpoint ( * qce * ) . below this * qce * there is again a direct first - order transition between the * af * and * caf * phases , behavior approximately described by the classical line . * pacs numbers * : 75.10.jm , 05.30.-d , 75.40.-s , 75.40.cx"}
{"article": "in adaptive control and recursive parameter estimation one often needs to adjust recursively an estimate of a vector , which comprises constant but unknown parameters , using measurements of a quantity here is a vector of known data , often called the regressor , and is a measurement error signal . the goal of tuning is to keep both the estimation error and the parameter error as small as possible . there are several popular methods for dealing problem above , for instance least - squares . maybe the most straightforward involve minimizing the prediction error via gradient - type algorithms of the form : where is a constant , symmetric , positive - definite gain matrix . let us define and analyze differential equations and , which under the assumption that is identically zero read : the nonnegative function has time derivative hence inspection of the equation above reveals that is limited in time , thus , and also that the error ( norms are taken on the interval where all signals are defined ) . these are the main properties an algorithm needs in order to be considered a suitable candidate for the role of a tuner in an adaptive control system . often or something similar is also a desirable property . to obtain the latter , normalized algorithms can be used ; however , the relative merits of normalized versus unnormalized tuners are still somewhat controversial . another alternative is to use a time - varying , as is done in least - squares tuning . in we present a tuner that sets the second derivative of , and in the effects of a white noise on the performance of the two algorithms are compared . then we show some simulations and make concluding remarks . classical tuners are such that the velocity of adaptation ( the first derivative of the parameters ) is set proportional to the regressor and to the prediction error . we propose to set the acceleration of the parameters : notice that the the formula above is implementable ( using integrators ) if measurement error is absent , because the unknown appears only in scalar product . choose another function of lyapunovian inspiration : taking derivatives along the trajectories of gives integrating we obtain which leads immediately to the desired properties : the slow variation property follows without the need for normalization , and now we obtain instead of as before . we might regard as a modified error , which can be used in the stability analysis of a detectable or `` tunable '' adaptive system via an output - injection argument ; see . a generalization of is and constant , symmetric , positive - definite matrices such that and . the properties of tuner , which can be obtained using the positive - definite function in the same manner as before , are we now consider the effects on the expected value and covariance of of the presence of a measurement error . the assumptions are that is a white noise zero average and covariance and that are given , deterministic data . for comparison purposes , first consider what happens when the conventional tuner is applied to in the presence of measurement error : the solution to the equation above can be written in terms of s state transition matrix as follows hence because by assumption . here the notation , denoting the expectation respect to the random variable , is used to emphasize that the stochastic properties of are not under consideration . the conclusion is that will converge to zero in average as fast as does . the well - known persistency of excitation conditions on are sufficient for the latter to happen . to study the second moment of the parameter error , write the covariance of can be written as the sum of four terms . the first is deterministic . the second term because has zero mean , and the third term is likewise zero . the fourth term where fubini s theorem and the fact were used . performing the integration and adding the first and fourth terms results in this equation can be given the following interpretation : for small , when is close to the identity , the covariance of remains close to , the outer product of the error in the initial guess of the parameters itself . as , which will happen if is persistently exciting , tends to . this points to a compromise between higher convergence speeds and lower steady - state parameter error , which require respectively larger and smaller values of the gain . algorithms that try for the best of both worlds parameter convergence in the mean - square sense often utilize time - varying , decreasing gains ; an example is the least - squares algorithm . we shall now attempt a similar analysis for the acceleration tuner applied to , which results in the differential equation let where , , each is a function of unless otherwise noted , and the dot signifies derivative respect to the first argument . if , following the same reasoning used for the velocity tuner , one concludes that and that however the properties of the acceleration and velocity tuners are not yet directly comparable because the right - hand side of does not lend itself to immediate integration . to obtain comparable results , we employ the ungainly but easily verifiable formula , ' '' '' valid for arbitrary scalars and , and make the ] simplifying assumption : + + + + + + + + + + + + + + + + + + + + + + + + for , and 3 , , where are scalars and is the identity matrix . premultiplying by ] , integrating from 0 to , and using the simplifying assumption gives formula . ' '' '' taking in , results positive - semidefinite , therefore the combination of and shows that can be increased without affecting s steady - state covariance . on the other hand , to decrease the covariance we need to increase , which roughly speaking means increasing damping in . since and can be increased without affecting the stability properties shown in , a better transient steady - state performance compromise might be achievable acceleration tuner than velocity tuner , at least in the case when , , and are `` scalars . '' notice that by construction . ] approximate analysis : + + + + + + + + + + + + + + + + + + + + + + the derivation of inequality does not involve any approximations , and therefore provides an upper bound on , valid independently of . a less conservative estimate of the integral in can be obtained by replacing by its average value in the definition of in . this approximation seems reasonable because appears inside an integral , but calls for more extensive simulation studies . to obtain a useful inequality , we require ; namely , using the schur complement or , using the simplifying assumption and substituting by its approximation suppose further that . looking for the least conservative estimate , we pick , the least value of that keeps . thus 1 \\left}{4m 1 ^ 2 m 2m 3r(1+\\mu 2 ) -r}.$ ] taking we repeat the previous , exact result . for large positive values of the first term of the right - hand side of tends to , which indicates that the steady - state covariance of the parameter error decreases when the signal increases in magnitude , and that it can be made smaller via appropriate choices of the gains and . the situation for the accelerating tuner is hence much more favorable than for the conventional one . the simulations in this section compare the behavior of the accelerating tuner those of the gradient tuner and of a normalized gradient one . all simulations were done in open - loop , regressor a two - dimensional signal , and without measurement noise . figure shows the values of and respectively when is a two - dimensional step signal . in figure the regressor is a sinusoid , in figure an exponentially increasing sinusoid , and in figure a pseudorandom signal generated using matlab . no effort was made to optimize the choice of gain matrices ( , , and were all chosen equal to the identity ) , and the effect of measurement noise was not considered . the performance of the accelerating tuner is comparable , and sometimes superior , to that of the other tuners . = 2.5 in = 2.5 in = 2.5 in = 2.5 in = 2.5 in = 2.5 in = 2.5 in = 2.5 in other ideas related to the present one are replacing the integrator in positive - real transfer function , and using high - order tuning . high - order tuning generates as outputs as well as its derivatives up to a given order ( in this sense we might consider the present algorithm a second - order tuner ) , but unlike the accelerating tuner requires derivatives of up to that same order . we expect that accelerating tuners will find application in adaptive control of nonlinear systems and maybe in dealing topological incompatibility known as the `` loss of stabilizability problem '' in the adaptive control literature . the stochastic analysis in indicates that the performance and convergence properties of the accelerating tuner , together moderate computational complexity , may indeed make it a desirable tool for adaptive filtering applications . it seems that a better transient steady - state performance compromise is achievable accelerating tuner than velocity tuner . to verify this conjecture , a study of convergence properties of the accelerating tuner and their relation persistence of excitation conditions is in order , as well as more extensive simulations in the presence of measurement noise .", "summary": "we propose a tuner , suitable for adaptive control and ( in its discrete - time version ) adaptive filtering applications , that sets the second derivative of the parameter estimates rather than the first derivative as is done in the overwhelming majority of the literature . comparative stability and performance analyses are presented . * key words : * adaptive control ; parameter estimation ; adaptive filtering ; covariance analysis ."}
{"article": "the construction of background field formalism for n=2 super - yang - mills theory ( sym ) in projective hyperspace is an open problem . such a formalism is desirable for any ( non-)supersymmetric theory as it simplifies ( loop ) calculations and even intermediate steps respect gauge covariance . a major obstacle in solving this problem for the n=2 case seems to be the lack of knowledge relating the gauge connections to the tropical hyperfield , which describes the sym multiplet for all practical purposes . we note that the closely related n=2 harmonic superspace does nt encounter this issue as the hyperfield , describing the sym multiplet is itself a connection , . in fact , background field formalism in harmonic superspace has quite a straightforward construction . although the construction has some subtleties , it has been refined in a series of papers along relevant calculations . in this paper , we solve the problem of constructing the background field formalism in projective superspace without the need for knowing the connections explicitly in terms of . this is possible by choosing the background fields to be in a ` real ' representation and the quantum fields to be in the ` analytic ' representation . this is reminiscent of the quantum - chiral but background - real representation used in n=1 superspace . what this does is make the effective action independent of and dependent on background fields ( like ) ` dimension ' greater than ( since the lowest one is a spinor ) . non - existence of -dimension background fields ( like ) is a crucial requirement for the non - renormalization theorems to hold as discussed in . this directly leads to a proof of finiteness beyond 1-loop . ( a different approach for proof of finiteness has been discussed in . ) the coupling of quantum fields to background fields comes through the former s projective constraint alone , which simplifies the vertex structure a lot . the calculations are also simplified at 1-hoop as most -integrals turn out to be trivial since the background fields have trivial -dependence . this means that the -integration effectively vanishes from the effective action and as expected from the supergraph rules , only one -integration survives at the end of the calculations . we also work in fermi - feynman gauge so there are no ir issues to worry about while evaluating the super - feynman graphs . another important aspect is the ghost structure of the theory in this background gauge . apart from the expected faddeev - popov ( fermionic ) and nielsen - kallosh ( bosonic ) ghosts , we require two more extra ghosts , namely real bosonic and complex fermionic . this is in contrast to n=1 sym but very similar to the harmonic treatment of n=2 theory . heuristically , we can even see that such a field content would give a vanishing -function for n=4 . moreover , we will see that the loop contributions of and extra ghosts have spurious divergences arising due to multiple s . these are very similar to the ` coinciding harmonic ' singularities in the case , which manifest themselves at 1-loop level via the subtleties regarding regularization of similar looking determinants . however , in case , we do not encounter such striking similarities . only the divergences turn out to be similar , leading to a cancellation between the vector hyperfield s contribution and that of the extra ghosts . the finite pieces in the effective action are contributed by these extra ghosts only . this section is mostly built on the ordinary projective superspace construction of sym detailed in . we review it briefly below for the sake of continuity . we also use the 6d notation to simplify some useful identities involving background covariant derivatives and moreover , the results carry over to n=1 6d sym in a trivial manner this notation . the projective hyperspace comprises of usual spacetime coordinates , four fermionic ones and a complex coordinate on cp . the full n=2 superspace requires four more fermionic coordinates in addition to these projective ones . the super - covariant derivatives corresponding to these extra s define a projective hyperfield via the constraint . the algebra of the covariant derivatives will be given below but we note here that in the ` real ' representation ( called ` reflective ' in and the one we use extensively in this paper ) the s are -dependent . their anti - commutation relation at different s is all that we need here : the scalar hypermultiplet is described by an ` arctic ' hyperfield that contains only non - negative powers of and the vector hypermultiplet by a ` tropical ' , which contains all powers of . to construct the relevant actions , the integration over this internal coordinate is defined to be the usual contour integration , contour being a circle around the origin ( for our purposes in this paper ) . so , the projective measure simply reads : ( usual factor of being suppressed ) . now , we are ready to delve into the details of the background field formalism . the gauge covariant derivatives , , describing n=2 sym satisfy the following ( anti- ) commutation relations ( written in 6d notation ) : =- {}w a^{}\\,,\\\\ \\{ {a},w b^{}\\}={{\\cal d}} {ab} {}^{}-}}{2}c {ab}f {}^{}\\,,\\\\ =f ^{}\\,,\\\\ = {}\\,,\\quad =0\\ , , \\ ] ] where the su(2 ) index , and are the field strengths , and are the triplet of auxiliary scalars . the 4d scalar chiral field strength , is related to the spinor field strength via appropriate spinor derivatives . we solve the commutation relation for by writing , where is an unconstrained complex hyperfield . we can do a background splitting of ( similar to n=1 superspace ) such that being the background covariant derivative . we can now choose ` real ' representation for the background derivatives independently such that . this simplifies the -dependence of the connections : since these connections have simple -dependence , the -integrals in the effective action can be trivially done . moreover , the quantum part of the full covariant derivatives then can be chosen to be in ` analytic ' representation , , and . the projective ( analytic ) constraint on hyperfields ` lifts ' to so we can now define a background projective hyperfield as such that . then , the scalar hypermultiplet s action reads : the vector hyperfield s action looks the same as in the ordinary case ; the difference being that the appearing below is only the quantum piece and is background projective : we know from that this action should give an expression for and hence the ` analytic ' representation for quantum hyperfields is a consistent choice . the background dependence of comes through the projective constraint and the background covariant derivatives only . the following identities will be useful in showing that and deriving other results in the following sections : ^4\\,,\\\\ {1}^4 {2}^4=\\left {2}^4\\,,\\ ] ] where is the gauge - covariant dalembertian and . as the quantum connections do not appear explicitly in the calculations , we will drop the usage of curly fonts to denote the background fields ( as has been done above ) and also the subscript ` ' on from now on . the quantization procedure in the background gauge proceeds similar to the ordinary case . the ordinary derivatives are now background - covariant derivatives so gets replaced by ( or ) everywhere . moreover , we need extra ghosts for the theory to be consistent in this formalism as we elaborate further in the following subsections . the scalar hypermultiplet is background projective but the structure of its action is still the same as in the ordinary case . that means the kinetic operator appearing in the equations of motion is , , still holds . so the derivation of the propagator performed in goes through after employing these changes : and : the gauge - fixing for the vector hypermultiplet leading to faddeev - popov ( fp ) ghosts is still similar to the ordinary case and we just quote the results suitable modifications : v 2\\,;\\\\ { { \\cal s}} {fp}&=-{}\\int dx\\,d^4\\theta\\,dy\\,\\left.\\ ] ] the propagators for the fp ghosts are similar to the scalar hypermultiplet and will be written down later . we will always work in fermi - feynman gauge but let us derive the propagator for arbitrary as this technique will be useful later . we first combine the terms quadratic in from the above equation and the vector hypermultiplet action to get {1}^4 v 2\\nonumber\\\\ = & -}}{2g^2}\\int dx\\,d^4\\,dy 1\\,dy 2\\,v 1{y {12}^2}\\lefty {12}^2\\left({2}{}+\\cdots\\right ) v 2\\nonumber\\\\ = & -}}{2g^2}\\int dx\\,d^4\\,dy 1\\,dy 2\\,v 1\\left\\left({2}{}+\\cdots\\right ) v 2\\,.\\ ] ] then , we add a generic real source to the quadratic gauge - fixed vector action : {2y {12}^2}v 2-dx\\,d^8\\,dy 2\\,j 2v 2\\right\\}\\nonumber\\\\ = & -}}{g^2}\\left\\{\\int dx\\,d^4\\,dy {1,2}\\,v 1\\left^4}{2y {12}^2}v 2-dx\\,d^4\\,dy 2\\,{{\\cal j}} 2v 2\\right\\}.\\ ] ] here , is now defined to be ( background ) projective . now , equation of motion for reads ^4}{y {12}^2}={{\\cal j}} 2\\,,\\ ] ] which we can solve to write in terms of . this amounts to inverting the kinetic operator for as we will see . assuming the following ansatz for : and demanding it satisfy , we are led to because \\left=(y {02})\\,.\\ ] ] plugging and in the action , we get which leads to the required propagator , first derived ( for the ordinary case ) in this expression simplifies for to as does the quadratic part of the vector action in background field gauge , the gauge fixing function leads to additional ghosts apart from the fp ghosts , which contribute to the 1-loop calculations . to see that , consider the effective action defined by the following functional : where is found by the normalization condition . it gives so simplifies to we can rewrite the last factor as where are unconstrained hyperfields . proceeding similar to the harmonic case , we redefine and introduce nielsen - kallosh ( nk ) ghost to account for the resulting jacobian . this means the 1-loop contribution for n=2 sym coupled to matter simplifies to : for n=4 , the scalar hypermultiplet is in adjoint representation and its contribution will cancel the joint fp and nk ghosts contributions . the remaining two terms have spurious divergences due to multiple s but their joint contribution has to be finite , which will turn out to be the case as we develop this section further . to incorporate the effect of fields directly in the path integral , we choose to introduce a real scalar and a complex fermion as follows : where so the background field requires 3 fermionic ghosts and 2 bosonic ghosts and the full quantum action for n=2 sym coupled to matter reads : +s {fp}(v , b , c)+s {nk}(v , e)+s {xr}(v , x , r)+s {}(v,).\\ ] ] the fp and nk ghosts are background projective hyperfields . the actions for these ghosts look the same as those in the case of non - background gauge . the action for fp ghosts is given in equation and that for nk ghost is similar to the scalar hypermultiplet s action . that means their propagators are straightforward generalizations and read now , we focus on the new ingredient of the background field formalism : the extra ghosts . in the same vein as the vector hypermultiplet , we can simplify the actions of these ghosts . let us just concentrate on the scalar ghost action as the fermionic ghost can be treated similarly : x 2\\\\ = & \\,-}}{4}dx d^4dy {1,2}\\,x 1\\leftx 2\\\\ = & \\,-}}{4}dx d^4dy {1,2}\\,x 1\\leftx 2\\,.\\ ] ] the propagator can then be derived in a similar way as the vector propagator arbitrary . lets add a source term to the action for x ghost : x 2+{}dx\\,d^8\\,dy 2\\,j 2x 2\\nonumber\\\\ = & -}}{4}dx\\,d^4\\,dy {1,2}\\,x 1{\\left(})}{y {12}^2}{\\right)}{}x 2+{}dx\\,d^4\\,dy 2\\,{{\\cal j}} 2x 2\\,.\\ ] ] the equation of motion for now reads adopting an ansatz for ( similar to what was done for before ) , {{2}{}^2}2{{\\cal j}} 0\\,,\\ ] ] we find that and satisfy . collecting all the results , the action reduces to which leads to the required propagator the propagator for the fermionic ghost has a similar expression . given this new construction of the background field formalism for sym , we can now employ it to calculate contributions to the effective action coming from different hypermultiplets . the general rules for constructing diagrams in the background field formalism are similar to the ordinary case discussed in . however , as expected in this formalism , the quantum propagators form the internal lines of the loops and the external lines correspond to the background fields . the and operators in the propagators need to be expanded around ( the connection - independent part of ) , which will generate the vertices vector connection and background fields . for the extra ghosts , we can further simplify the nave rules by noticing that the vertices have -factor and the propagator will generate such a factor in the numerator due to the presence of . thus , we can remove them from the very start and work revised propagator and vertex for the purpose of calculating diagrams . let us now collect all the relevant feynman rules below . {\\left(}{}- 0{\\right)}\\ ] ] ] scalar + + + + + + the one - loop contribution from the scalar hypermultiplet to the effective action can not be written in a fully gauge covariant form projective measure . thus , the diagrammatic calculation required to get this contribution ( which includes the uv - divergent piece too ) is not accessible via the formalism constructed here . we note that such an issue appears in the n=1 background formalism too when the scalar multiplets in complex representation are considered . the calculations can not be performed covariantly and explicit gauge fields appear in addition to the connections . ] vector + + + + + + the contribution to one - loop n - point diagrams from vector hypermultiplet running in the loop would be given by the following : where the numerical subscript on denotes the external momenta dependence . as usual , to kill the extra -function , at least four should be available from the vertices and so . the first non - vanishing contribution is from the 4-point diagram : too many s lead to spurious singularity , similar to ` coinciding harmonic ' singularities in . these will cancel when we take into account the ghosts . ] extra ghosts + + + + + + + + + + + + their combined contribution to one - loop n - point diagrams reads : \\nonumber\\\\ & { \\left(}w^(1) {,}+ ... {\\right)} ... \\, {n}^4^8( {n1 } ) )}{y {nb}}{k n^2}w^(n ) {,}+ ... {\\right)}\\nonumber\\\\ \\sim&-d^4kd^4 ndy {1a, ... ,1b} {1b}^4^8( {n1})-1+y {1a}(y {1a,2b}){\\right)}}{y {1a}}{k 1 ^ 2}\\nonumber\\\\ & { \\left(}w^(1 ) {,}+ ... {\\right)} ... \\,-1+y {na}(y {nb,1b}){\\right)}}{y {1b}}{k n^2}{\\left(}w^(n ) {,}+ ... {\\right)}.\\ ] ] again , the first non - vanishing contribution is from that has the same singularity structure as the vector in leading to a cancellation , in addition to the following finite part : the last line follows because only -independent pieces of s can survive the -integrals . till here , we have treated s as fields depending on individual external momenta and eq . is the complete 4-point effective action . assuming them to be momentum independent , we can further simplify this expression in case of the u(1 ) gauge group and perform the integral over loop - momentum to get where we used the reduction to 4d for . using this and the fact that is related to , we get the same non - holomorphic 4-point contribution ( full superspace measure ) to n=4 sym action rather directly when compared to the calculation done in ( for similar calculations in see , for example , ) . ] 2-loops + + + + + + + we can also see that there are no uv divergences at two - loops . the proof is similar to that given in the ordinary case , i.e. , absence of sufficient s . only 3 diagrams shown in fig . are supposed to contribute at 2-loops . all of them will vanish due to the -algebra unless we get at least from the expansion of the propagators . this , as we have seen before , brings in 4 more s making these 2-loop diagrams convergent . furthermore , we note that the arguments of apply in our case since there is no background connection , there can not be any divergences at 2 or more loops from just power counting . this situation is different than where such ` 0-dimensional ' connections are present and arguments similar to the one given above involving number of s have to be used and at higher loops they can be quite involved . we have formulated the background field formalism for n=2 , 4d projective superspace . the crucial ingredient was to recognize that different representations for background and quantum pieces of the hypermultiplets are required . choosing real representation for the background fields allowed non - renormalization theorems to be applicable here as the lowest - dimensional fields available were spinors . the usual choice of analytic representation for the quantum fields allowed us to make a simple extension of the existing ` ordinary ' super - feynman rules to the background covariant rules . moreover , there are extra ghosts required ( apart from fp and nk ghosts ) to evaluate the full sym effective action . these extra ghosts also appear in the harmonic case but in projective case , they cancel the spurious ` harmonic ' divergences coming from vector hypermultiplet in a straightforward manner and the resultant finite pieces are as expected for n=4 . the uv divergent parts come only from the usual ( fp and nk ) ghosts and scalar hypermultiplet . however , their contribution can not be directly calculated in the formalism developed here for reasons mentioned in section . we also gave a diagrammatic 2-loops argument for finiteness of n=2 sym coupled matter . this is easily supplanted by the power counting argument of in general , which directly leads to a proof for finiteness beyond 1-loop . for n=1 background formalism , there exist improved rules as showcased in and our hope is that such techniques could be applied to what we have developed in this paper . that would lead to a further simplification of the higher - loop calculations while also allowing explicit inclusion of the scalar hypermultiplet s 1-loop contribution . this research work is supported in part by nsf grant no . phy-0969739 . u. lindstrm and m. roek , commun . math . phys . http://inspirehep.net/search?ln=en&ln=en&p=find+j+\"commun.math.phys.,115,21\"&of=hb&action search=search&sf=&so=d&rm=&rg=25&sc=0 ; commun . http://inspirehep.net/search?ln=en&ln=en&p=find+j+\"commun.math.phys.,128,191\"&of=hb&action search=search&sf=&so=d&rm=&rg=25&sc=0 . w. siegel , 2010 , http://arxiv.org/abs/1005.2317 ; + d. jain and w. siegel , phys . * d83 * ( 2011 ) 105024 ] ; + d. jain and w. siegel , phys . rev . * d86 * ( 2012 ) 065036 ] . d. jain and w. siegel , phys . * d86 * ( 2012 ) 125017 ] . s. m. kuzenko , int . * a14 * ( 1999 ) 1737 ] . d. jain and w. siegel , phys . * d80 * ( 2009 ) 045024 ] . a. galperin , e. ivanov , s. kalitzin , v. ogievetsky and e. sokatchev , class . http://inspirehep.net/search?ln=en&ln=en&p=find+j+\"class.quant.grav.,1,469\"&of=hb&action search=search&sf=&so=d&rm=&rg=25&sc=0 ; + e. ivanov , a. galperin , v. ogievetsky and e. sokatchev , class . http://inspirehep.net/search?ln=en&ln=en&p=find+j+\"class.quant.grav.,2,601\"&of=hb&action search=search&sf=&so=d&rm=&rg=25&sc=0 ; class . http://inspirehep.net/search?ln=en&ln=en&p=find+j+\"class.quant.grav.,2,617\"&of=hb&action search=search&sf=&so=d&rm=&rg=25&sc=0 ; + a.s . galperin , e.a . ivanov , v.i . ogievetsky , and e.s . sokatchev , harmonic superspace ( cambridge univ . press , 2001 ) . i. l. buchbinder , e. i. buchbinder , s. m. kuzenko and b. a. ovrut , phys . lett . * b417 * ( 1998 ) 61 ] ; + i. l. buchbinder and s. m. kuzenko , mod . phys . * a13 * ( 1998 ) 1623 ] . i. l. buchbinder , e. i. buchbinder , e. a. ivanov , s. m. kuzenko and b. a. ovrut , phys . lett . * b412 * ( 1997 ) 309 ] ; + i. l. buchbinder , s. m. kuzenko and b. a. ovrut , phys . lett . * b433 * ( 1998 ) 335 ] . e. i. buchbinder , i. l. buchbinder and s. m. kuzenko , phys . * b446 * ( 1999 ) 216 ] ; + s. m. kuzenko and i. n. mcarthur , phys . * b506 * ( 2001 ) 140 ] ; + s. m. kuzenko and i. n. mcarthur , phys . lett . * b513 * ( 2001 ) 213 ] . i. l. buchbinder , e. a. ivanov and a. y. petrov , nucl . phys . * b653 * ( 2003 ) 64 ] . i. l. buchbinder and a. yu . petrov , phys . * b482 * ( 2000 ) 429 ] . m. t. grisaru , w. siegel and m. roek , nucl . * b159 * ( 1979 ) 429 . m. t. grisaru and w. siegel , nucl . phys . * b201 * ( 1982 ) 292 . p. s. howe , k. s. stelle , p. c. west , phys . lett . * b124 * ( 1983 ) 55 . f. gonzalez - rey , 1997 , http://arxiv.org/abs/hep-th/9712128 . f. gonzalez - rey and m. roek , phys . * b434 * ( 1998 ) 303 ] . m. t. grisaru and d. zanon , phys . lett . * b142 * ( 1984 ) 359 ; + m. t. grisaru and d. zanon , nucl . phys . * b252 * ( 1985 ) 578 . t. r. morris , phys . * b164 * ( 1985 ) 315 .", "summary": "we introduce a new background field method for n=2 superspace . ( we treat projective hyperspace , but similar remarks apply for the harmonic case . ) in analogy to n=1 , background gauge fields are in the real representation , so the lowest - dimension potentials are spinor and the usual non - renormalization theorems are manifest . another consequence is that the r - coordinates disappear from the effective action ."}
{"article": "the experimental data used in this paper were collected by the forward looking radar of the us army research laboratory . that radar was built for detection and possible identification of shallow explosive - like targets . since targets are three dimensional objects , one needs to measure a three dimensional information about each target . however , the radar measures only one time dependent curve for each target , see figure 5 . therefore , one can hope to reconstruct only a very limited information about each target . so , we reconstruct only an estimate of the dielectric constant of each target . for each target , our estimate likely provides a sort of an average of values of its spatially distributed dielectric constant . but even this information can be potentially very useful for engineers . indeed , currently the radar community is relying only on the energy information of radar images , see , e.g. . estimates of dielectric constants of targets , if taken alone , can not improve the current false alarm rate . however , these estimates can be potentially used as an additional piece of information . being combined currently used energy information , this piece of the information might result in the future in new classification algorithms , which might improve the current false alarm rate . an inverse medium scattering problem ( imsp ) is often also called a coefficient inverse problem ( cip ) . imsps / cips are both ill - posed and highly nonlinear . therefore , an important question to address in a numerical treatment of such a problem is : how to reach a sufficiently small neighborhood of the exact coefficient without any advanced knowledge of this neighborhood ? the size of this neighborhood should depend only on the level of noise in the data and on approximation errors . we call a numerical method , which has a rigorous guarantee of achieving this goal , globally convergent method ( gcm ) . in this paper we develop analytically a new globally convergent method for a 1-d inverse medium scattering problem ( imsp ) generated by multiple frequencies . in addition to the analytical study , we test this method numerically using both computationally simulated and the above mentioned experimental data . first , we derive a nonlinear integro - differential equation in which the unknown coefficient is not present . element of this paper is the method of the solution of this equation . this method is based on the construction of a weighted least squares cost functional . the key point of this functional is the presence of the carleman weight function ( cwf ) in it . this is the function , which is involved in the carleman estimate for the underlying differential operator . we prove that , given a closed ball of an arbitrary radius center at in an appropriate hilbert space , one can choose the parameter of the cwf in such a way that this functional becomes strictly convex on that ball . the existence of the unique minimizer on that closed ball as well as convergence of minimizers to the exact solution when the level of noise in the data tends to zero are proven . in addition , it is proven that the gradient projection method reaches a sufficiently small neighborhood of the exact coefficient if its starting point is an arbitrary point of that ball . the size of that neighborhood is proportional to the level of noise in the data . therefore , since restrictions on are not imposed in our method , then this is a globally convergent numerical method . we note that in the conventional case of a non convex cost functional a gradient - like method converges to the exact solution only if its starting point is located in a sufficiently small neighborhood of this solution : this is due to the phenomenon of multiple local minima and ravines of such functionals . unlike previously developed globally convergent numerical methods of the first type for cips ( see this section below ) , the convergence analysis for the technique of the current paper does not impose a smallness condition on the interval of the variations of the wave numbers . the majority of currently known numerical methods of solutions of nonlinear ill - posed problems use the nonlinear optimization . in other words , a least squares cost functional is minimized in each problem , see , e.g. chavent , engl , gonch1,gonch2 . however , the major problem these functionals is that they are usually non convex . figure 1 of the paper scales presents a numerical example of multiple local minima and ravines of non - convex least squares cost functionals for some cips . hence , convergence of the optimization process of such a functional to the exact solution can be guaranteed only if a good approximation for that solution is known in advance . however , such an approximation is rarely available in applications . this prompts the development of globally convergent numerical methods for cips , see , e.g. . the first author coauthors has proposed two types of gcm for cips single measurement data . the gcm of the first type is reasonable to call the tail functions method `` . this development has started from the work and has been continued since then , see , e.g. and", "summary": "a new numerical method is proposed for a 1-d inverse medium scattering problem multi - frequency data . this method is based on the construction of a weighted cost functional . the weight is a carleman weight function ( cwf ) . in other words , this is the function , which is present in the carleman estimate for the undelying differential operator . the presence of the cwf makes this functional strictly convex on any a priori chosen ball center at in an appropriate hilbert space . convergence of the gradient minimization method to the exact solution starting from any point of that ball is proven . computational results for both computationally simulated and experimental data show a good accuracy of this method . * key words * : global convergence , coefficient inverse problem , multi - frequency data , carleman weight function * 2010 mathematics subject classification : * 35r30 ."}
{"article": "although the sunspot number varies periodically time average period of 11 year , the individual cycle period ( length ) and also the strength ( amplitude ) vary in a random way . it is observed that the stronger cycles have shorter periods and vice versa . this leads to an important feature of solar cycle known as waldmeier effect . it says that there is an anti - correlation between the rise time and the peak sunspot number . we call this as we1 . now instead of rise time if we consider the rise rate then we get very tight positive correlation between the rise rate and the peak sunspot number . we call this as we2 . another important aspect of solar activity are the grand minima . these are the periods of strongly reduced activity . a best example of these is the during during 16451715 . it was not an artifact of few observations , but a real phenomenon ( hoyt & schatten 1996 ) . from the study of the cosmogenic isotope c data in tree rings , usoskin et al . ( 2007 ) reported that there are grand minimum during last years . we want to model these irregularities of solar cycle using flux transport dynamo model ( choudhuri et al . 1995 ; dikpati & charbonneau 1999 ; chatterjee et al . 2004 ) . in this model , the turbulent diffusivity is an important ingredient which is not properly constrained . therefore several groups use different value of diffusivity and this leads to two kinds of flux transport dynamo model high diffusivity model and low diffusivity model . in the earlier model , the value of diffusivity usually used is s ( see also jiang et al . 2007 and yeates et al . 2008 for details ) , whereas in the latter model , it is s . we mention that the mixing length theory gives the value of diffusivity as s . another important flux transport agent in this model is the meridional circulation . only since we have some observational data of meridional circulation near the surface and therefore we do not know whether the varied largely solar cycle in past or not . however if the flux transport dynamo is the correct dynamo for the solar cycle , then one can consider the solar cycle period variation as the variation for the because the cycle period is strongly determined by the strength of the meridional circulation in this model . now the periods of the solar cycle indeed had much variation in past , then we can easily say that the had significant variation solar cycle . therefore the main sources of randomness in the flux transport dynamo model are the stochastic fluctuations in process of generating poloidal field and the stochastic fluctuations in the meridional circulation . in this paper we explore the effects of fluctuations of the latter . we model last cycles by fitting the periods variable meridional circulation in a high diffusivity model based on chatterjee et al . ( 2004 ) model . the solid line in fig . (a ) shows the variation of the amplitude of used to model the periods of the cycles . note that we did not try to match the periods of each cycles accurately which is bit difficult . we change between two cycles and not during a cycle . in addition , we do not change if the period difference between two successive cycles is less than of the average period . ( in m s ) time ( in yr ) . the solid line is the variation of used to match the theoretical periods observed periods . ( b ) variation of theoretical sunspot number ( dashed line ) and observed sunspot number ( solid line ) time . ( c ) scatter diagram showing peak theoretical sunspot number and peak observed sunspot number . the linear correlation coefficients and the corresponding significance levels are given on the plot.,scaledwidth=100.0% ] in fig . (b ) , we show the theoretical sunspot series ( eruptions ) by dashed line along observed sunspot series by solid line . the theoretical sunspot series has been multiplied by a factor to match the observed value . it is very interesting to see that most of the amplitudes of the theoretical sunspot cycle have been matched observed sunspot cycle . therefore , we have found a significant correlation between these two ( see fig . (c ) ) . this study suggests that a major part of the fluctuations of the amplitude of the solar cycle may come from the fluctuations of the meridional circulation . this is a very important result of this analysis . now we explain the physics of this result based on yeates et al . toroidal field in the flux transport model , is generated by the stretching of the poloidal field in the tachocline . the production of this toroidal field is more if the poloidal field remains in the tachocline for longer time and vice versa . however , the poloidal field diffuses during its transport through the convection zone . as a result , if the diffusivity is very high , then much of the poloidal field diffuses away and very less amount of it reaches the tachocline to induct toroidal field . therefore , when we decrease in high diffusivity model to match the period of a longer cycle , the poloidal field gets more time to diffuse during its transport through the convection zone . this ultimately leads to a lesser generation of toroidal field and hence the cycle becomes weaker . on the other hand , when we increase the value of to match the period of a shorter cycle , the poloidal field does not get much time to diffuse in the convection zone . hence it produces stronger toroidal field and the cycle becomes stronger . consequently , we get weaker amplitudes for longer periods and vice versa . however , this is not the case in low diffusivity model because in this model the diffusive decay of the fields are not much important . as a result , the slower meridional circulation means that the poloidal field remains in the tachocline for longer time and therefore it produces more toroidal field , giving rise to a strong cycle . therefore , we do not get a correct correlation between the amplitudes of theoretical sunspot number and that of observed sunspot number when repeat the same analysis in low diffusivity model based on dikpati & charbonneau ( 1999 ) model . we study the using flux transport dynamo model . we have seen that the stochastic fluctuations in the process and the stochastic fluctuations in the are the two main sources of irregularities in this model . therefore , to study we first introduce suitable stochastic fluctuations in the poloidal field source term of process . we see that this study can not reproduce we1 ( fig . (a ) ) . however it reproduces we2 ( fig . (b ) ) . finally we introduce stochastic fluctuations in both the poloidal field source term and the meridional circulation . we see that both we1 and we2 are remarkably reproduced in this case ( see fig . ) . we repeat the same study in low diffusivity model based on dikpati & charbonneau ( 1999 ) model . however in this case we are failed to reproduce we1 , only we2 is reproduced . the details of this work can be found in karak & choudhuri ( 2011 ) . we have realized that the is important in modeling many aspects of solar cycle . therefore we check whether a large decrease of the leads to a maunder - like grand minimum . to answer this question , we decrease to a very low value in both the hemispheres . we have done this in the decaying phase of the last sunspot cycle before maunder minimum . we keep at low value for around 1 yr and then we again increase it to the usual value but at different rates in two hemispheres . in northern hemisphere , is increased at slightly lower rate than southern hemisphere . ( in m s ) in northern and southern hemispheres time . ( b ) the butterfly diagram . ( c ) the dashed and dotted lines show the sunspot numbers in southern and northern hemispheres , whereas the solid line is the total sunspot number . ( d ) variation of energy density of toroidal field at latitude 15 at the bottom of the convection zone.,scaledwidth=100.0% ] in fig . , we show the theoretical results covering the maunder minimum episode . fig . (a ) , shows the maximum amplitude of meridional circulation varied over this period in two hemispheres . in fig . (b ) , we show the butterfly diagram of sunspot numbers , whereas in fig . (c ) , we show the variation of total sunspot number along individual sunspot numbers in two hemispheres ( see the caption ) . in order to facilitate comparison observational data , we have taken the beginning of the year to be 1635 . note that our theoretical results reproduce the sudden initiation and the gradual recovery , the north - south asymmetry of sunspot number observed in the last phase of maunder minimum and the cyclic oscillation of solar cycle found in cosmogenic isotope data . we also mention that if we reduce the poloidal field to a very low value at the beginning of the maunder minimum then also we can reproduce maunder - like grand minimum ( choudhuri & karak 2009 ) . however in both the cases , either we need to reduce the or the poloidal field at the beginning of the maunder minimum . however if we reduce the poloidal field little bit , then one can reproduce maunder - like grand minimum at a moderate value of meridional circulation . the details of this study can be found in karak ( 2010 ) . we have shown that suitable stochastic fluctuations in the meridional circulation , we are able to reproduce many important irregular features of solar cycle including waldmeier effect and maunder like grand minimum . however we are failed to reproduce these results in low diffusivity model . therefore this study along some earlier studies ( chatterjee , nandy & choudhuri 2004 ; chatterjee & choudhuri 2006 ; goel & choudhuri 2009 ; jiang , chatterjee & choudhuri 2007 ; karak 2010 ; karak & choudhuri 2011 ; karak & choudhuri 2012 ) supports the high diffusivity model for solar cycle . chatterjee , p. , nandy , d. , & choudhuri , a. r. 2004 , a&a , 427 , 1019 choudhuri , a. r. , chatterjee , p. , & jiang , j. , 2007 , phys . , 98 , 1103 choudhuri , a. r. , & karak , b. b. 2009 , raa 9 , 953 choudhuri , a. r. , schssler , m. , & dikpati , m. 1995 , a&a , 303 , l29 dikpati , m. , & charbonneau , p. 1999 , apj , 518 , 508 jiang , j. , chatterjee , p. , & choudhuri , a. r. 2007 , mnras , 381 , 1527 hoyt , d. v. , & schatten , k. h. , 1996 , sol . phys . , 165 , 181 karak , b. b. 2010 , apj , 724 , 1021 karak , b. b. , & choudhuri , a. r. 2011 , mnras , 410 , 1503 karak , b. b. , & choudhuri , a. r. 2012 , sol . , 278:137 usoskin , i. g. , solanki , s. k. , & kovaltsov , g. a. 2007 , a&a , 471 , 301 yeates , a. r. , nandy , d. , & mackay , d. h. 2008 , apj , 673 , 544", "summary": "the sunspot number varies roughly periodically time . however the individual cycle durations and the amplitudes are found to vary in an irregular manner . it is observed that the stronger cycles are having shorter rise times and vice versa . this leads to an important effect know as the waldmeier effect . another important feature of the solar cycle irregularity are the grand minima during which the activity level is strongly reduced . we explore whether these solar cycle irregularities can be studied help of the flux transport dynamo model of the solar cycle . we show that suitable stochastic fluctuations in a regular dynamo model , we are able to reproduce many irregular features of the solar cycle including the waldmeier effect and the grand minimum . however , we get all these results only if the value of the turbulent diffusivity in the convection zone is reasonably high ."}
{"article": "in a database containing a solution of the 3d incompressible navier - stokes ( ) equations is presented . the equations were solved numerically standard pseudo - spectral simulation in a periodic domain , using a real space grid of grid points . a large - scale body force drives a turbulent flow taylor microscale based reynolds number . out of this solution , snapshots were stored , spread out evenly over a large eddy turnover time . more on the simulation and on accessing the data can be found at http://turbulence.pha.jhu.edu . in practical terms , we have easy access to the turbulent velocity field and pressure at every point in space and time . one usual way of visualising a turbulent velocity field is to plot vorticity isosurfaces see for instance the plots from . the resulting pictures are usually very `` crowded '' , in the sense that there are many intertwined thin vortex tubes , generating an extremely complex structure . in fact , the picture of the entire dataset from looks extremely noisy and it is arguably not very informative about the turbulent dynamics . in this work , we follow a different approach . first of all , we use the alternate quantity first introduced in . secondly , the tool being used has the option of displaying data only inside clearly defined domains of 3d space . we can exploit this facility to investigate the multiscale character of the turbulent cascade . because vorticity is dominated by the smallest available scales in the velocity , we can visualize vorticity at scale by the curl of the velocity box - filtered at scale . we follow a simple procedure : * we filter the velocity field , using a box filter of size , and we generate semitransparent surfaces delimitating the domains where ; * we filter the velocity field , using a box filter of size , and we generate surfaces delimitating the domains where , but only if these domains are contained in one of the domains from ; and this procedure can be used iteratively several scales ( we use at most 3 scales , since the images become too complex for more levels ) . additionally , we wish sometimes to keep track of the relative orientation of the vorticity vectors at the different scales . for this purpose we employ a special coloring scheme for the isosurfaces : for each point of the surface , we compute the cosine of the angle between the filtered vorticity and the filtered vorticity : the surface is green for , yellow for and red for , following a continuous gradient between these three for intermediate values . the opening montage of vortex tubes is very similar to the traditional visualisation : a writhing mess of vortices . upon coarse - graining , additional structure is revealed . the large - scale vorticity , which appears as transparent gray , is also arranged in tubes . as a next step , we remove all the fine - scale vorticity outside the large - scale tubes . the color scheme for the small - scale vorticity is that described earlier , green representing alignment large - scale vorticity and red representing anti - alignment . clearly , most of the small - scale vorticity is aligned vorticity of the large - scale tube that contains it . we then remove the fine - grained vorticity and pan out to see that the coarse - grained vortex tubes are also intricately tangled and intertwined . introducing a yet larger scale , we repeat the previous operations . the relative orientation properties of the vorticity at these two scales is similar to that observed earlier . next we visualize the vortex structures at all three scales simultaneously , one inside the other . it is clear that the small vortex tubes are transported by the larger tubes that contain them . however , this is not just a passive advection . the small - scale vortices are as well being distorted by the large - scale motions . to focus on this more clearly , we now render just the two smallest scales . one can observe the small - scale vortex tubes being both stretched and twisted by the large - scale motions . the stretching of small vortex tubes by large ones was suggested by orszag and borue as being the basic mechanism of the turbulent energy cascade . as the small - scale tubes are stretched out , they are `` spun up '' and gain kinetic energy . here , this phenomenon is clearly revealed . the twisting of small - scale vortices by large - scale screw motions has likewise been associated to helicity cascade . the video thus allows us to view the turbulent cascade in progress . next we consider the corresponding view three levels of vorticity simultaneously . since the ratio of scales is here 1:15:49 we are observing less than two decades of the turbulent cascade . one must imagine the complexity of a very extended inertial range many scales of motion . not all of the turbulent dynamics is tube within tube . in our last scene we visualize in the right half domain all the small - scale vortices , and in the left domain only the small - scale vortices inside the larger scale ones . in the right half , the viewer can observe stretching of the small - scale vortex structures taking place externally to the large - scale tubes . the spin - up of these vortices must contribute likewise to the turbulent energy cascade . 6ifxundefined ifx#1 ifnum # 1firstoftwo secondoftwo ifx # 1firstoftwo secondoftwo `` `` # 1''''@noop secondoftwosanitize@url + 12$12 & 12#1212 12%12@startlink@endlink@bib@innerbibempty link:\\doibase 10.1080/14685240802376389 @noop * * , in http://ieeexplore.ieee.org/xpls/abs all.jsp?arnumber=1592886 p. @noop , link:\\doibase 10.1017/s0022112097008306 http://journals.cambridge.org / production / action / cjogetfulltext?fulltextid=4% 00523", "summary": "the jhu turbulence database can be used state of the art visualisation tool to generate high quality link : anc / dfdsubmissionquarterres.mpg . in this work we investigate the classical idea that smaller structures in turbulent flows , while engaged in their own internal dynamics , are advected by the larger structures . they are not advected undistorted , however . we see instead that the small scale structures are sheared and twisted by the larger scales . this illuminates the basic mechanisms of the turbulent cascade ."}
{"article": "in recent years electron transfer ( et ) between molecular adsorbates and semiconductor nanomaterials and surfaces has been subject of much research . the injection of an electron into the conduction band is a prototype reaction for a lot of electrochemical and photoelectrochemical interfacial processes such as photography , solar energy conversion , quantum dot devices , etc . interfacial et between discrete molecular levels and a conducting surface is the simplest of all surface reactions : it involves only the exchange of an electron , and so no bonds are broken . the ultrafast nature of the charge injection from adsorbed molecules to the conduction band of semiconductor surfaces was shown in recent experiments . the theoretical description of such experiments demands an adequate treatment of the et dynamics to be able to describe short time - scale phenomena such as coherences . this can be done within the reduced density matrix ( rdm ) description used in the present contribution . recently the electron injection from a chromophore to a semiconductor conduction band was described using the time - dependent schrdinger equation , thus neglecting relaxation processes . the neglect of relaxation processes was motivated by the experimental finding that injected electrons relax only within 150 fs in the perylene - tio system . here we include relaxation to be able to treat a larger class of experiments where , for example , the adsorbed molecule is surrounded by a liquid environment , and longer times . in the rdm theory the full system is divided into a relevant system part and a heat bath . therefore the total hamiltonian consists of three terms the system part , the bath part , and the system - bath interaction : the rdm is obtained from the density matrix of the full system by tracing out the degrees of freedom of the environment . this reduction together second - order perturbative treatment of and the markov approximation leads to the redfield equation : + { \\mathcal r } \\rho = { \\mathcal l } \\rho . \\ ] ] in this equation denotes the redfield tensor . if one assumes bilinear system - bath coupling system part and bath part one can take advantage of the following decomposition : + + . \\ ] ] the operator can be written in the form where is the operator in the interaction representation . the system bath interaction is taken to be linear in the reaction coordinate as well as in the bath coordinates . neither the rotating wave nor the secular approximation have been invoked . the so - called diabatic damping approximation which has numerical advantages is not used because it could lead to wrong results in the present system studied . in the following we direct our attention to et between an excited molecular state and a conduction band . the hamiltonian modeling this system consists of the ground and one excited state of the molecule and a quasi - continuum describing the conduction band together vibrational coordinate here can be equal to for the ground state , for the excited state , and for the quasi - continuum . as in ref . we choose the frequency of the vibrational mode to be . the coupling between the excited state and the continuum states is assumed to be constant : . a box - shaped uniform density of states is used . instead of modeling the excitation from the ground state explicitly we assume a -pulse . the excited state potential energy surface is shifted 0.1 along the reaction coordinate respect to the ground state potential energy surface . this results in an initial vibrational wave packet on the excited state significant population in the lowest 4 - 5 vibrational states . the shift between the excited state energy surface and the continuum parabola is 0.2 . the thermal bath is characterized by its spectral density . because all system oscillators have the same frequency the coupling to the bath can be given by one parameter in the diabatic damping approximation . denoting the effective mass of the harmonic oscillator by the strength of the damping is chosen as . to be able to study the effects of dissipation we do not model the quasi - continuum such a large number of electronic states as in ref . . in that work a band of width 2 ev was described using an energy difference of 2. leading to 801 electronic surfaces . these calculations are already demanding using wave packet propagation but almost impossible using direct density matrix propagation . for doing such a large system one would have to use the monte carlo wave function scheme . we use a much simpler model and describe only that part of the conduction band which really takes part in the injection process . the total width of the conduction band may be significantly larger . in the following , a band of width 0.75 ev is treated 31 electronic surfaces . in each of these electronic states five vibrational states are taken into account . we are aware that this is only a minimal model but hope that it catches the effects of dissipation on the electron injection process . here we look at two different populations arising in the process of electron injection . the time - dependent population of the electronic states in the conduction band is calculated as the sum over the vibrational levels of each electronic surface . as a second quantity we look at the time - dependent population of the vibrational levels of the excited molecular state . these two probability distributions give some hints on the effect of dissipation . figure 1 shows the electronic population for the quasi - continuum , i.e. the probability distribution of the injected electron , versus the energy of the conduction band . as described above , the four lowest vibrational states are populated significantly at . the structure arising in the upper panel of fig . 1 was already explained by ramakrishna et al . it can be estimated using the golden rule . the electronic probabilities in the quasi - continuum are given as where is the initial vibronic distribution in the excited state and and are the vibronic parts of the wave packet in the excited and quasi - continuum states , respectively . the energy denotes the middle of the band . turning on dissipation two effects can be seen . first , the vibrational populations in the excited state of the molecule no longer only decay into the quasi - continuum states but also relax within the excited state ( see fig . 2 ) . second , the vibrational populations also relax within the quasi - continuum states . the recurrences back into the excited state become much smaller . only those parts of the wave packet which are still high enough in energy can go back to the molecule . in summary , we extended the work by ramakrishna , willig , and may by including relaxation processes into the description of electron injection into the conduction band of a semiconductor . this will , at least , become important for modeling electron injection in the presence of a fluid surrounding the attached molecule .", "summary": "electron injection from an adsorbed molecule to the substrate ( heterogeneous electron transfer ) is studied . one reaction coordinate is used to model this process . the surface phonons and/or the electron - hole pairs together internal degrees of freedom of the adsorbed molecule as well as possibly a liquid surrounding the molecule provide a dissipative environment , which may lead to dephasing , relaxation , and sometimes excitation of the relevant system . in the process studied the adsorbed molecule is excited by a light pulse . this is followed by an electron transfer from the excited donor state to the quasi - continuum of the substrate . it is assumed that the substrate is a semiconductor . the effects of dissipation on electron injection are investigated . electron transfer , density matrix theory , molecules at surfaces"}
{"article": "compact x - ray sources exhibit a wide range of temporal variabilities ( from milliseconds to years ) . perhaps none of these is as exotic and diverse as the x - ray temporal variability observed from the black hole microquasar grs 1915 + 105 ( castro - tirado , brandt , & lund 1992 ; greiner , morgan , & remillard 1996 ; morgan , remillard & greiner 1997 ; muno , morgan & remillard 1999 ) . this object is one of two known galactic x - ray sources that exhibit superluminal radio jets ( mirabel & rodrigues 1994 ) . the combination of relativistic constraints and radio measurements at hi indicate that the source lies behind the sagittarius arm at a distance of 12.5 kpc ( mirabel & rodrigues 1994 ) . interstellar extinction limits optical / ir studies to weak detections at wavelengths less than 1 micron ( mirabel et al . the source is suspected to be a black hole binary because of its spectral and temporal similarities other galactic x - ray source superluminal radio jets , gro j1655 - 40 ( zhang et al 1994 ) , which has a binary mass function indicative of a black hole system ( bailyn et al . 1995 ) . estimates for the mass of the compact object in grs 1915 + 105 range from 7 to 33 . even uncertainty in distance , its peak x - ray luminosity is unusually high , i.e. , ergs / , which is around the eddington luminosity for a object . in spite of several attempts it has proven especially illusive to interpret the x - ray light curves of grs1915 . it is not yet clear that even the basic time scales exhibited by the variability have been successfully explained . belloni et al . ( 1997a , b ) accounted for the observations empirical model in which the inner disk region `` disappears '' in the low count rate state , and is then replenished on a viscous time scale . the parameters of their model are : the inner disk radius , ; the corresponding effective temperature of the disk , and an ad - hoc non - thermal power law ( which is possibly produced in the disk corona ) . although no detailed physical model for the instability was given , very interesting patterns of behavior for and , as well as several other observables , were deduced from the data , and the shakura - sunyaev viscosity parameter was found to be unexpectedly low ( which may mean that the standard viscosity prescription is invalid for this source ) . the rather small values of found by these authors can be used to discriminate between different models of the accretion flow in grs 1915 ( see appendix and ) . abramowicz , chen & taam ( 1995 ) suggested a model for the low frequency quasi - periodic oscillations ( qpo ) observed in selected x - ray binaries , in which a corona above the standard accretion disk leads to a mild oscillatory behavior . some modifications , this model could reasonably be expected to account for at least some of the temporal variability in grs 1915 + 105 as well ( taam , chen & swank 1997 ) . however , it appears to us that the analysis of abramowicz et al . ( 1995 ) and taam et al . ( 1997 ) contains an error in the heating / cooling equation for the disk which , when corrected , constrains their model to have the same stability characteristics as a standard shakura - sunyaev disk , and is therefore unlikely to explain the grs 1915 + 105 observations ( see appendix a ) . we show more generally in appendix that neither a hot central region , nor an advection - dominated flow , nor a `` slim '' accretion disk are compatible observations of grs 1915 + 105 . ( `` slim '' accretion disk theory was developed in the most detail by abramowicz et al . 1988 ; it is similar to a standard thin shakura - sunyaev disk , except for the energy equation , which incorporates the radial advection of energy into the black hole . ) in this paper , we attempt to undertake a more systematic study of the variability patterns in grs 1915 + 105 within the context of the `` cold diskhot corona '' picture . in we present a general discussion that will guide us in our selection of a novel ( though somewhat ad - hoc ) prescription for the viscosity in cases where the radiation pressure is substantial . the details of our numerical algorithm to solve the time - dependent disk equations use of this new viscosity prescription are given in . in , we present the results of our time - dependent disk calculations . the calculated light curves are found to agree qualitatively many observational features of grs 1915 + 105 . in particular , the characteristic cycle times and duty cycles are in reasonable agreement observations . moreover , the trend in the cycle time average accretion rate , has the correct sense . however , there are important disagreements as well . we therefore introduce a more elaborate model in , where , in accordance observations ( e.g. , mirabel & rodrigues 1994 ) , the inner disk is allowed to expel some of its energy in the form of a non - steady jet . we assume that the ejected energy is not observed in x - rays , but rather that it ultimately produces radio emission . we show that this more elaborate model agrees grs 1915 + 105 observations much better , perhaps indicating that we are finally developing a zeroth order understanding of the geometry and the most important processes in this enigmatic source . in we discuss our results in the light of the earlier work on grs 1915 , and in we summarize our conclusions . figure 1 shows four examples of typical x - ray light curves from grs 1915 obtained rxte satellite ( see , e.g. , morgan , remillard , & greiner 1997 ) . it appears that the source undergoes a limit - cycle type of instability ; the cycle times in panels ( a ) ( d ) are 2400 , 60 , 1200 , and 800 , respectively . within the cycles shown in panels ( c ) and ( d ) there appear yet other quasi - regular oscillations of still shorter time scale . the shortest time scale over which a substantial change in the x - ray flux occurs is 5 . we will associate the longer cycles viscous time scales of the inner accretion disk , whereas the more rapid behavior will be related to the thermal time scale . the x - ray spectrum of grs 1915 + 105 varies systematically - ray intensity ; usually the spectral hardness is strongly correlated ( or anti - correlated ) intensity ( e.g. , belloni et al . 1997a , b ; taam et al . 1997 ; muno et al . more specifically , the spectrum is typically found to be composed of a multi - temperature disk component , hereafter the thermal component \" , and a power - law component varying spectral index . finally , the source exhibits a wide range of qpos central frequencies in the range of 0.01 - 10 hz . the amplitude and frequency of the qpos appear to be strongly correlated spectral state of grs 1915 + 105 ( chen et al . 1997 ; muno et al . 1999 ) . the idea of using a modified viscosity law to test time - dependent phenomena in accretion disks around black holes is not new ( e.g. , taam & lin 1984 ; chen & taam 1994 ; and further", "summary": "during the past two years , the galactic black hole microquasar grs 1915 + 105 has exhibited a bewildering diversity of large amplitude , chaotic variability in x - rays . although it is generally accepted that the variability in this source results from an accretion disk instability , the exact nature of the instability remains unknown . here we investigate different accretion disk models and viscosity prescriptions in order to provide a basic explanation for the exotic temporal behavior in grs 1915 + 105 . we discuss a range of possible accretion flow geometries . based on the fact that the overall cycle times are very much longer than the rise / fall time scales in grs 1915 , we rule out the geometry of advection dominated accretion flow ( adaf ) or a hot quasi - spherical region plus a cold outer disk for this source . a cold disk extending down to the last inner stable orbit plus a hot corona above it , on the other hand , is allowed . we thus concentrate on geometrically thin ( though not necessarily standard ) shakura - sunyaev type disks ( shakura & sunyaev 1973 ; hereafter ss73 ) . we argue that x - ray observations clearly require a quasi - stable accretion disk solution at high accretion rates where radiation pressure begins to dominate , which excludes the standard -viscosity prescription . to remedy this deficiency , we have therefore devised a modified viscosity law that has a quasi - stable upper branch , and we have developed a code to solve the time - dependent equations to study such an accretion disk . via numerical simulations , we show that the model does account for several gross observational features of grs 1915 + 105 , including its overall cyclic behavior on time scales of 100 - . on the other hand , the rise / fall time scales are not short enough , no rapid oscillations on time scales emerge naturally from the model , and the computed cycle - time dependence on the average luminosity is stronger than is found in grs 1915 + 105 . we then consider , and numerically test , several effects as a possible explanation for the residual disagreement between the model and the observations . a hot corona energy input rate being a function of the local cold disk state and a radius - dependent -parameter do not appear to be promising in this regard . however , a more elaborate model that includes the cold disk , a corona , and plasma ejections from the inner disk region allows us to reproduce several additional observed features of grs 1915 + 105 . we conclude that the most likely structure of the accretion flow in this source is that of a cold disk modified viscosity prescription , plus a corona that accounts for much of the x - ray emission , and unsteady plasma ejections that occur when the luminosity of the source is high . the disk is geometrically thin due to the fact that most of the accretion power is drained by the corona and the jet ."}
{"article": "galaxy clusters , the largest gravitationally - bound structures in the universe , are ideal cosmological tools . accurate measurements of their masses provide a crucial observational constraint on cosmological models . several dynamical methods have been available to estimate cluster masses , such as ( 1 ) optical measurements of the velocity dispersions of cluster galaxies , ( 2 ) measurements of the x - ray emitting gas , and ( 3 ) gravitational lensing . good agreements between these methods have been found on scales larger than cluster cores . however , joint measurements of lensing and x - rays often identify large discrepancies in the gravitational masses within the central regions of clusters by the two methods , and the lensing mass has always been found to be times higher than the x - ray determined mass . this is the so - called `` mass discrepancy problem '' ( allen 1998 ; wu 2000 ) . many plausible explanations have been suggested , e.g. , the triaxiality of galaxy clusters ( morandi et al . 2010 ) , the oversimplification of the strong lensing model for the central mass distributions of clusters ( bartelmann & steinmetz 1996 ) , the inappropriate application of the hydrostatic equilibrium hypothesis for the central regions of clusters ( wu 1994 ; wu & fang 1997 ) , or the magnetic fields in clusters ( loeb & mao 1994 ) . recently richard et al . ( 2010 ) present a sample of strong lensing clusters taken from the local cluster substructure survey ( locuss ) , among which clusters have x - ray data from chandra observations ( sanderson et al . they show that the x - ray / lensing mass discrepancy is at significance clusters larger substructure fractions show greater mass discrepancies , and thus greater departures from hydrostatic equilibrium . on the other hand , lensing observations of the bullet cluster 1e0657 - 56 ( clowe et al . 2006 ) , combined earlier x - ray measurements ( markevitch et al . 2006 ) , clearly indicate that the gravitational center of the cluster has an obvious offset from its baryonic center . furthermore , recent studies ( shan et al . 2010 ) of lensing galaxy clusters reveal that offset between the lensing center and x - ray center appears to be quite common , especially for unrelaxed clusters . among the recent sample of 38 clusters of shan et al . ( 2010 ) , have been found to have offsets greater than , and clusters even have offsets greater than . motivated by such observations , we propose to investigate galaxy cluster models where the center of the dark matter ( dm ) halo does not coincide center of the x - ray gas ( see figure 1 ) . if the x - ray center of a cluster has an offset from its lensing ( gravitational ) center , then the x - rays and lensing are indeed measuring different regions of the cluster . given the same radius , the lensing is measuring the dm halo centered at the gravitational center ( shown by the dark blue sphere in figure 1 ) , while the x - rays are measuring the sphere of the halo that is offset from the true gravitational center ( shown by the red circle in figure 1 ) . in this case , there will always be a natural discrepancy between the lensing and x - ray measured masses or specifically , the x - ray mass will always be lower than the lensing mass , just as the long - standing `` mass discrepancy problem '' has indicated . in this paper , we investigate the lensing - x - ray mass discrepancy caused by the offsets between dm and x - ray gas . to check our predictions , we compile a sample of clusters good lensing and x - ray measurements . we conclude that such `` offset '' effect should not be ignored in our dynamical measurements of galaxy clusters . a flat cdm cosmology is assumed throughout this paper , where =0.3 , =0.7 , and . we model our galaxy cluster fiducial model as the following : ( 1 ) the dm halo is modeled by the navarro - frenk - white ( nfw ) profile ( navarro et al . 1997 ) concentration and scaled radius , ( 2 ) the gas distribution is modeled by a model , the cluster core radius , and the gas fraction , ( 3 ) the mass density of the bcg is described by a singular isothermal sphere ( sis ) velocity dispersion of . the projected mass within a sphere of radius is r ' \\ , dr ' \\ , d{\\theta},\\ ] ] where is the 2-d radius from the halo center , is the 2-d radius from the x - ray gas center , is the 2-d offset between the halo center and x - ray center , and , , and are the projected mass densities of the dm halo , the gas and the bcg , respectively . for a given radius , the gravitational mass measured by lensing can be given by ( as shown by the dark blue sphere in figure 1 ) , while the projected mass measured by x - rays is described by ( the mass within the red circle in figure 1 ) . we now calculate the mass ratio , or equivalently , . figure 2 shows the mass ratio as a function of the 2-d offset , for a typical rich cluster . the solid curves are the mass ratio fiducial model , the dashed and dotted curves are the mass ratio nfw concentration and ( top left ) , the cluster core radius and ( top right ) , the index and ( bottom left ) , the gas fraction and , respectively . for these cases , the three curves from top to bottom are for the three measuring radii , respectively . from figure 2 we have the following conclusions : \\(1 ) the lensing measured mass is always higher than the x - ray measured mass . for typical values of offset and , , comparable to the ratio found in early studies ( allen 1998 ; wu 2000 ; richard et al . 2010 ) . \\(2 ) the `` offset effect '' we are reporting here should contribute significantly to the long - standing `` mass discrepancy problem '' . \\(3 ) the ratio of increases offset . \\(4 ) depends very strongly on . here acts like the arc radius in strong lensing , i.e. , we only measure the enclosed mass within a small region of . when is very small , the offset effect is most prominent and gives large . increasing will reduce . when is very large ( compared ) , the offset effect will be `` smeared out '' , and the - discrepancy introduced by the offset will vanish . \\(5 ) the mass ratio is very sensitive to the nfw concentration , and it increases dramatically . \\(6 ) the mass ratio increases core radius , and decreases index and gas fraction . however , the mass ratio is not very sensitive to the gas model . and the measuring radius . the solid curves are the mass ratio for the fiducial model , , , , and . the dashed and dotted curves are for the nfw concentration and ( top left ) , the cluster core radius and ( top right ) , the index and ( bottom left ) , the gas fraction and , respectively . the three dotted ( dashed , solid as well ) curves from top to bottom in one panel correspond to , respectively.,title=\"fig:\",width=336 ] to compare theoretical predictions , we compile a sample of clusters arc - like images , which have both strong lensing and x - ray measurements . the clusters and their lensing and x - ray data are listed in table 1 . for the arcs that have no redshift information , we estimate their lensing masses by assuming the mean redshifts of and , respectively . the x - ray data are taken from tucker et al . ( 1998 ) , wu ( 2000 ) , bonamente et al . ( 2006 ) , and", "summary": "recent studies of lensing clusters reveal that it might be fairly common for a galaxy cluster that the x - ray center has an obvious offset from its gravitational center which is measured by strong lensing . we argue that if these offsets exist , then x - rays and lensing are indeed measuring different regions of a cluster , and may thus naturally result in a discrepancy in the measured gravitational masses by the two different methods . here we investigate theoretically the dynamical effects of such lensing - x - ray offsets , and compare observational data . we find that for typical values , the offset alone can give rise to a factor of two difference between the lensing and x - ray determined masses for the core regions of a cluster , suggesting that such `` offset effect '' may play an important role and should not be ignored in our dynamical measurements of clusters . dark matter - gravitational lensing - x - rays : galaxies : clusters"}
{"article": "we study the problem to find solutions of non - homogeneous double - confluent heun equations that are monodromy eigenfunctions . our study is motivated by applications to nonlinear equations modeling the josephson effect in superconductivity . the main results , their existence and uniqueness ( theorems and ) are stated in subsection 1.1 . applications to monodromy eigenfunctions and eigenvalues of homogeneous double confluent heun equations and to nonlinear equations modeling josephson effect are presented in subsection 1.1 , sections 4 and 5 . each eigenfunction is the product of a monomial and a function holomorphic on . the heun equation is equivalent to recurrence relations on the laurent coefficients of the function . the proofs of the above - mentioned results are based on studying the latter recurrence relations . we prove existence and uniqueness theorem for converging solutions of a more general class of recurrence relations ( stated in subsection 1.2 and proved in section 2 ) . its proof is based on ideas from hyperbolic dynamics and a fixed point argument for appropriate contracting mapping . we consider the family of double confluent heun equations our goal is to study existence of its eigenfunctions given eigenvalue , : solutions of the form to do this , we study the non - homogeneous equations of type one of our main results is the next theorem for every , there exist holomorphic functions on a neighborhood of zero , such that the functions satisfy equations for appropriate , . the functions are unique up to constant factor ( depending on the parameters ) , and they are entire functions : holomorphic on . for every sign index the corresponding vector is uniquely defined up to scalar factor depending on parameters . the above constant factors can be chosen so that both and depend holomorphically on and are real - valued in for real parameter values . let . the corresponding equation has a monodromy eigenfunction eigenvalue , , if and only if the corresponding vectors are proportional : theorem will be proved in the next subsection and section 2 . the corollary will be proved in the next subsection . the explicit formulas for the functions and , together explicit form for equation will be given in section 3 . for every and there exists a unique function ( up to constant factor ) holomorphic on a neighborhood of zero such that . the latter constant depends only on the parameters . theorem will be proved in the next subsection . theorem is closely related to the question of the existence of a solution holomorphic at 0 of equation ( such a solution is automatically entire , i.e. , holomorphic on ) . this question was studied by v.m.buchstaber and s.i.tertychnyi in . the existence of a solution from theorem and explicit expressions for and the corresponding function ( analytic in ) were given in . the existence result implies that if , then the homogeneous equation , i.e. , has a solution holomorphic on . a conjecture stated by v.m.buchstaber and s.i.tertychnyi in loc . cit . said that the converse is true : if equation has a holomorphic solution at 0 , then . this conjecture was studied in loc . cit and , where it was reduced to a series of conjectures on polynomial solutions of auxiliary heun equations and modified bessel functions of the first kind . all these conjectures were solved in . as the next corollary shows , theorem implies the conjecture of buchstaber and tertychnyi immediately , without using neither polynomial solutions , nor modified bessel functions . ( * ? ? ? * theorem 3.5 ) equation has an entire solution , if and only if , where is the function from loc . cit . , introduced in ( * ? ? ? * formula ( 31 ) , p. 337 ) ; see also formula in subsection 4.3 below . let . then the function from theorem is an entire solution of equation : . conversely , let equation have a solution holomorphic at 0 . if , then there exists a holomorphic function on a neighborhood of zero satisfying the equation , by theorem . this together uniqueness statement of theorem implies that up to constant factor , hence . the contradiction thus obtained proves the corollary . equation is equivalent to the recurrence relations which can be written in the matrix form a function satisfies equation for some , if and only if its taylor coefficients satisfy , or equivalently , for . similarly , a function , satisfies , if and only if its coefficients satisfy for . * of corollary . * let be a solution of equation having type . then the coefficients satisfy for all . this together above remark implies that the functions satisfy . the corresponding expressions should cancel out , since is a solution of the homogeneous equation . this implies . conversely , let be solutions of , and let hold . then we can normalize the latter solutions by constant factors ( not both vanishing simultaneously ) so that . then the function given by is a solution of equation . this proves the corollary . as it is shown below , theorem is implied by the following general theorem consider recurrence relations in unknown sequence , where sequences numerated by satisfy the following conditions : then there exists a unique series satisfying for and having positive converging radius . it converges on all of . theorem will be proved in the next section . in the series from theorem for every the two neighbor coefficients , do not vanish simultaneously : hence , they present a point . each pair of neighbor coefficients determines a unique sequence satisfying . both statements follow from the fact that for every the coefficient is expressed as a linear combination of and by , since . hence , if some two neighbor coefficients vanish , then all the coefficients vanish , and the series is zero , a contradiction . let , then for every such that for every , there exists and unique nonzero one - sided series ( up to multiplicative constant ) converging on some punctured disk centered at 0 that satisfies recurrence relations ( or equivalently , ) for . similarly , for every such that there exists and unique one - sides series ( up to multiplicative constant ) that satisfies recurrence relations for and converges outside some disk centered at 0 . both series converge on the whole punctured complex line . let in the conditions of theorem one have ( cf . ) . then its statements hold for all , since inequalities hold for all . otherwise , if either , or , then the statements of theorem theorem together remark and the first statement of example imply theorem . * of theorems and . * the coefficients of recurrence relations satisfy the conditions of theorem for . indeed , the asymptotics is obvious . inequalities follow from ( respectively , ) . this together theorem proves theorem , and hence , theorem . * of theorem . * let , . inequalities hold for . therefore , there exists a unique series converging on a neighborhood of the origin , whose coefficients satisfy for , and it converges on all of ( theorem ) . the system of relations for is equivalent to the statement that . this proves theorem . our results are motivated by applications to the family of nonlinear equations , which arises in several models in physics , mechanics and geometry : in a model of the josephson junction in superconductivity ( our main motivation ) , see ; in planimeters , see . here is a fixed constant , and are the parameters . set the variable change transforms to a non - autonomous ordinary differential equation on the two - torus coordinates : the graphs of its solutions are the orbits of the vector field on . the rotation number of its flow , see , is a function of parameters . it is given by the formula where is an arbitrary solution of equation . the phase - lock areas are the level subsets of the rotation number in the -plane - empty interior . they have been studied by v.m.buchstaber , o.v.karpov , s.i.tertychnyi et al , see and", "summary": "we study a family of double confluent heun equations that are linearizations of nonlinear equations on two - torus modeling the josephson effect in superconductivity . they have the form , where is a family of differential operators of order two acting on germs of holomorphic functions in one complex variable . they depend on parameters , , . we show that for every and satisfying a certain `` non - resonance condition '' and every parameter values , there exists a unique entire function ( up to multiplicative constant ) such that for some . the latter are expressed as functions of the parameters . this result has several applications . first of all , it gives the description of those parameter values for which the monodromy operator of the corresponding heun equation has given eigenvalues . this yields the description of the non - integer level curves of the rotation number of the family of equations on two - torus as a function of parameters . in the particular case , when the monodromy is parabolic ( has multiple eigenvalue ) , we get the complete description of those parameter values that correspond to the boundaries of the phase - lock areas : integer level sets of the rotation number , which have non - empty interiors ."}
{"article": "nuclear fragmentation resulting from heavy ion collsions is a complex phenomenon . the role of equilibration and dynamics has not yet been determined as a plethora of approaches have been investigated . examples of approaches are evaporative pictures , percolation models , lattice gas models , and dynamical models based on boltzmann simulations . in this paper we consider the statistical approach where one considers sampling all configurations of non - interacting clusters . recently , chase and mekjian derived relations which allow the exact calculation of the canonical partition function for such a system . by eliminating the need for computationally intensive monte carlo procedures and associated approximations , this technique allows a deeper insight into the thermodynamic principles which drive the statistics of fragmentation . in the next section we present the recursive technique of chase and mekjian and review the thermodynamic properties , some of which have already been presented in the literature . we emphasize that the surface energy is the most important parameter in determining the fragmentation and phase transition properties of the model . in the three subsequent sections , we present extensions of the model which are necessary for serious modeling of nuclear systems : excluded volume , coulomb effects , and isospin degrees of freedom . in section we show how a microcanonical distribution may be generated from the canonical distribution . for completeness , we present an outline of the model , which is based on the work of chase and mekjian . the expressions used here are based on a picture of non - interacting liquid drops . mekjian and lee had also applied similar recursion relations to a more algebraically motivated fragmentation model that was not based on a liquid - drop picture . we consider that there are nucleons which thermalize in a volume much larger than where is the ground state volume of a nucleus of nucleons . these nucleons can appear as monomers but also as composites of nucleons . the canonical partition function of this system can be written as where is the partition function of a single composite of size , is the number of such composites and the sum goes over all the partitions which satisfy . a priori this appears to be a horrendously complicated problem but can be computed recursively via the formula , here is 1 . it is this formula and the generalisation of this to more realistic case ( see later ) that makes this model so readily soluble . all properties of the system are determined by the partition functions of indepedent particles . the recursive formula above allows a great deal of freedom in the choice of partition functions for individual fragments , . any function of temperature , density and is allowed . however , explicit dependence on the configuration of the remainder of the system is outside the scope of this treatment . for the illustrative purposes of this section , we assume the form , the first part is due to the kinetic motion of the center of mass of the composite in the volume and the second part is due to the internal structure . following the choice of reference we assume the form here is the volume energy per nucleon(= ) , is the surface tension which is a function of the temperature . the origin of the different terms in eq . is the following : is the ground state energy of the composite of nucleons , and the last term in the exponential arises because the composite can be not only in the ground state but also in excited states which are included here in the fermi - gas approximation . following reference the value of is taken to be . lastly the temperature dependence of in ref is ^{5/4}$ ] and . any other dependence could be used including a dependence on the average density . upon calculation , the model described above reveals a first order phase transition . in figure the specific heat at constant volume , , is displayed as a function of temperature for systems of size , , and . the sharp peak represents a discontinuity in the energy density , which sharpens for increasingly large systems . the usual picture of a liquid - gas phase transition gives a discontinuity in the energy density when pressure is kept constant rather than when the volume is kept constant . to understand this result we consider a system divided into one large cluster and many small clusters . the pressure and free energy may then be approximated as where is the number of clusters . the bulk term depends only on the temperature and not on the way in which the nucleons are partioned into fragments . we have neglected the surface energy term which is proportional to . in this limit , and become the bulk term depends only on the temperature and is therefore continuous across the phase transition . thus , a spike in is equivalent to a spike in since both are proportional to . it is difficult to make a connection between this approach and the standard maxwell construction , since here interactions between particles enter only through the surface term . intrinsic thermodynamic quantities may be calculated in a straightforward manner . for instance the pressure and chemical potentials may be calculated through the relations , calculations of and are displayed in figure as a function of density for a system of size . both the pressure and chemical potential remain roughly constant throughout the region of phase coexistence . of particular note is that the pressure actually falls in the coexistence region due to finite size effects . we now make some comments about influences of various factors in eq . . the bulk terms , , are not affected by the free energy , thus they may be ignored when calculating fragmentation observables . their influence respect to intrinsic thermodynamic quantities is of a trivial character . the surface term is completely responsible for determining all observables related to fragmentation and therefore all aspects of the phase transition . aside from the system size , fragmentation is determined by two dimensionless parameters . the first is the specific entropy , and the second is the surface term . at a given temperature the free energy of nucleons should be minimized . surface tension term , is minmised if the whole system appears as one composite of nucleons but the entropy term encourages break up into clusters . at low temperatures the surface term dominates while at high temperatures entropy prevails and the system breaks into small clusters . the mass distribution may be calculated given the partition function . the mass distribution is displayed in figure for three temperatures , 6.0 , 6.25 and 6. which are centered about the transition temperature of 6. . the distributions have been multiplied by to emphasize the decomposition of the system . the mass distribution changes dramatically in this small temperature range . the behavior is reminiscent of that seen in the percolation or lattice gas models . the volume used to define to the partition functions of individual fragments , given in eq . , should reflect only that volume in which the fragments are free to move . hahn and stcker suggested using to incorporate the volume taken up by the nuclei . by inspecting eq . on can see that this affects the partion function by simply mapping the density or volume used to plot observables . more realistically , the excluded volume could depend upon the multiplicity . nonetheless , in rather complicated calculations not reported here , it was found that for the purpose of obtaining diagrams in the domain of interest in this paper , it is an acceptable approximation to ignore the multiplicity dependence of the excluded volume . incorporating a multiplicity dependence would be outside the scope of the present model , as it would represent an explicit interaction between fragments . however , one could add an -dependence to the volume term to account for the difficulty of fitting fragments of various sizes into a tight volume . this might affect the model in a non - trivial fashion . we like to remind the reader that the parameter in the van der waals eos : also has its roots in the excluded volume . but there plays a crucial role . we could not for example set =0 without creating an instability at high density . furthermore , the phase transition disappears when is set to zero . it has been understood that the coulomb effects alter the phase structure of nuclear matter . although explicit coulomb interactions are outside the scope of this treatment , they may be approximated by considering a screened liquid drop formula for the coulomb energy as has been used by bondorf and donangelo . the addition to the internal free energy given in eq . is this form implies a jellium of uniform density that cancels the nucleons positive charge when averaged over a large volume . this may be more physically motivated for the modeling of stellar interiors where the electrons play the role of the jellium . we display , both without coulomb terms for an system in figure . coulomb forces clearly reduce the temperature at which the transition occurs . for sufficiently large systems , coulomb destroys the transition as large drops become unstable to the coulomb force . the recursive approach employed here is easily generalized to incorporate multiple species of particles . if there exist a variety of particles conserved charges , , one can write a recursion relation for each charge . where is the net conserved charge of type and is the charge of type carried by the fragment noted by . for the nuclear physics example , one would wish to calculate where and were the conserved neutron and proton numbers . to find one must know for all or . to accomplish this one must use both recursion relations . in nuclear collisions , one does not have access to a heat bath , but one can vary the excitation energy . a microcanonical treatment is therefore more relevant for practical calculations , particularly given the existence of a first order phase transition which occupies an infinitesimal ( in the limit of large ) range of temperatures in a canonical calculation , but a finite range of energies in a microcanonical ensemble . the relevant partition function for a microcanonical ensemble is the density of states , where the sum over represents the sum over all many - body states . although is easily calculable given the recursion relations discussed in the previous sections , one must perform the integral over numerically . the true solution for the density of states would be ill - defined given the discreet nature of quantum spectra which can not be combined delta function . however , if one defines the density of states in a finite region of size , the density of states becomes well - behaved even for discreet spectra . for that reason we more pragmatically define the density of states as one might have considered replacing the delta function by a lorentzian rather than by a gaussian , but this would be dangerous given that the density of states usually rises exponentially for a many - body system . the finite range used to sample the density of states might correspond to the range of excitation energies sampled in an experimental binning . in the limit , approaches the density of states . as an example of a quantity one may wish to calculate microcanonical approach , we consider the average multiplicity of a fragment of type in a system whose total energy is within of . where is the number of particles of species within the fragment . the integration over clearly provides an added numerical challenge that increases for small . for the purposes of generating a mass distribution , one must perform this integration for every species . it might be worthwile to consider estimating the integrals over saddle point method , although one should be wary of taking derivatives of respect to in the phase transition region . microcanonical quantities might also be calculated in a completely different manner by discreetizing the energy . for instance one might measure energies in units of 0. . one might then treat energy on the same footing as any other conserved charge . one may then write recursion relations for , the number of ways to arrange nucleons energy , where is an integer . here , is the number of ways of arranging a fragment of type energy . all other relavant microcanonical quantities may be calculated in a similar manner . since one needs to calculate at all energies less than the targeted energy , and must sum over all energies less than to obtain , the length of the calculation is proportional to . typically , nuclear decays occur the order of a of energy deposited in a nucleus . therefore , these calculations may become numerically cumbersome unless the energy is discreetized rather coarsely . the recursive techniques discussed here have several attractive features . they are easy to work , incorporate characteristics of nuclear composites and appear to have standard features of liquid - gas phase transitions . in the present forms these models are resricted to low densities . for modeling nuclear disintegration this is not a serious problem , although for completeness it would be nice to be able to modify the model so that it can be extended to higher density . in this paper we have studied thermal properties of the model , and we emphasize the importance of the surface term in determining these properties . we can associate the discontinuity in the energy density temperature to the discontinuity in the number of clusters . in addition , we have seen that including coulomb effects lowers the temperature at which the fragmentation transition occurs and reduces the sharpness of the phase transition . we have also presented an extension of the formalism for the inclusion of isospin degrees of freedom . for comparing to nuclear physics experiments , development of the microcanonical approaches presented here is of greatest importance . it remains to be seen whether the microcanonical formalisms are tenable , as they have yet to be implemented . p. chomaz , ann . france * 21 * , 669 ( 1996 ) burgio , ph . chomaz and j. randrup , phys . 69 * , 885 ( 1992 ) . h. feldmeier and j. schnack , prog . particle nucl . phys . * 39 * , 393 ( 1997 ) . a. ohnishi and j. randrup , phys . b * 394 * , 260 d. kiderlen and p. danielewicz , nucl . a * 620 * , 346 ( 1997 ) . s. pratt , c. montoya and f. ronning , phys . b*349 * , 261 ( 1995 ) . j. randrup and s. koonin , nucl . a * 356 * , 321 ( 1981 ) . gross , rep . phys . * 53 * , 605 ( 1990 ) . bondorf , a.s . botvina , a.s . iljinov , i.n . mishustin and k. sneppen , physics reports * 257 * , 133 - 221 ( 1995 ) . lee and a.z . mekjian , phys . c*47 * , 2266 ( 1993 ) . lee and a.z . mekjian , phys . c*45 * , 1284 ( 1992 ) lee and a.z . mekjian , phys . c*50 * , 3025 ( 1994 ) . bondorf , a.s . botvina , a.s . ijilinov , i.n . mishustin and k. sneppen , phys . rep . * 257*,133(1995 )", "summary": "the statistical model of chase and mekjian , which offers an analytic solution for the canonical ensemble of non - interacting fragments , is investigated for it s thermodynamic behavior . various properties of the model , which exhibits a first - order phase transition , are studied . the effects of finite particle number are investigated . three extensions of the model are considered , excluded volume , coulomb effects and inclusion of isospin degrees of freedom . a formulation of a microcanonical version of the model is also presented . 2.0 cm"}
{"article": "in the standard model ( sm ) , the only source of cp violation is the kobayashi - maskawa phase , localized in the unitarity triangle ( ut ) of the cabibbo - kobayashi - maskawa ( ckm ) matrix . thanks to the precise measurements at the current -factories , cp violation could be established in , leading to a precise measurement of , where the current world average yields . the extractions of the other two angles and are expected mainly through cp violation in the charmless decays , such as and similar modes . the current -factories measurements have been averaged to yield : on the theoretical side , the analysis is challenging due to the need to know the ratio of penguin - to - tree amplitude contributing to this process . in this talk , we present the result of , where a transparent method of exploring the ut through the cp violation in , combined `` gold - plated '' mode has been proposed . a model independent lower bound on the ckm parameters as functions of and is derived . our estimate of the hadronic parameters are carried out in qcd factorization ( qcdf ) and confronted to other approaches . the time - dependent cp asymmetry in decays is defined by , and and are ckm angles which are related to the wolfenstein parameters and in the usual way . the penguin - to - tree ratio can be written as . the real parameters and defined in this way are pure strong interaction quantities without further dependence on ckm variables . for any given values of and a measurement of and defines a curve in the ( , )-plane , expressed respectively through }{((1-\\bar\\rho)^2+\\bar\\eta^2 ) ( r b^2+r^2 + 2 r\\bar\\rho \\cos\\phi)}\\ ] ] the penguin parameter has been computed in in the framework of qcdf . the result can be expressed in the form } { a 1+a^u 4 + r^\\pi \\chi a^u 6 + r a},\\ ] ] where we neglected the very small effects from electroweak penguin operators . a recent analysis gives where the error includes an estimate of potentially important power corrections . in order to obtain additional insight into the structure of hadronic -decay amplitudes , it will be also interesting to extract these quantities from other -channels , or using other methods . in this perspective , we have considered them in a simultaneous expansion in and ( is the number of colours ) in . expanding these coefficients to first order in and we find that the uncalculable power corrections and do not appear in , to which they only contribute at order . using our default input parameters , one obtains the central value : , which seems to be in a good agreement standard qcdf framework at the next - to - leading order . as a second cross - check , one can extract and from and , leading to the central value , in agreement above results to its experimental value . ] , although their definitions differ slightly from ( see for further discussions ) . it is possible to fix the ut by combining the information from value of , well known from the `` gold - plated '' mode . the angle of the ut is given by the current world average , implies given a value of , is related to by . the parameter may thus be eliminated from in , which can be solved for to yield ,\\nonumber \\ ] ] the two observables ( or ) and determine and once the theoretical penguin parameters and are provided . the determination of as a function of is shown in fig . , which displays the theoretical uncertainty from the penguin parameters and in qcdf . since the dependence on enters in only at second order , it turns out that its sensitivity is rather mild in contrast to . in the determination of and described here discrete ambiguities do in principle arise , however they are ruled out using the standard fit of the ut ( see for further discussions ) . after considering the implications of on the ut , let s explore now . since is an odd function of , it is therefore sufficient to restrict the discussion to positive values of . a positive phase is obtained by the perturbative estimate in qcdf , neglecting soft phases power suppression . for positive also will be positive , assuming , and a sign change in will simply flip the sign of . in contrast to the case of , the hadronic quantities and play a prominent role for , as can be seen in . this will in general complicate the interpretation of an experimental result for . the analysis of becomes more transparent if we fix the weak parameters and study the impact of and . an important application is a test of the sm , obtained by taking and from a sm fit and comparing the experimental result for theoretical expression as a function of and . in fig . , a useful representation is obtained by plotting contours of constant in the ( , )-plane , for given values of and . within the sm this illustrates the correlations between the parameters and observable . as it has been shown in , a bound on the parameter exists , given by and where the maximum occurs at . if , no useful upper bound is obtained . however , if , then is maximized for , yielding the general bound . for the conservative bound , this implies . the bound on can be strengthened by using information on , as well as on , and employing . then and gives . as has been shown in , the following inequality can be derived from for this bound is still exact and requires no information on the phase . assuming now , we have and we emphasize that this lower bound on depends only on the observables and and is essentially free of hadronic uncertainties . since both and are expected to be quite small , we anticipate that the lower limit is a fairly strong bound , close to the actual value of itself ( see for further details ) . we also note that the lower bound represents the solution for the unitarity triangle in the limit of vanishing penguin amplitude , . in other words , the model - independent bounds for and are simply obtained by ignoring penguins and taking when fixing the unitarity triangle from and . let us briefly comment on the second solution for , which has the minus sign in front of the square root in replaced by a plus sign . for positive this solution is always larger than and the bound is unaffected . for the second solution gives a negative , which is excluded by independent information on the ut ( for instance from ) . because we have fixed the angle , or , the lower bound on is equivalent to an upper bound on . the constraint may also be expressed as a lower bound on the angle or a lower bound on ( see for further details ) . in figs . , we represent the lower bound on as a function of for various values of . from fig . we observe that the lower bound on becomes stronger as either or increase . in fig . we illustrate the region in the plane that can be constrained by the measurement of and using the bound in . we finally note that the condition , which is crucial for the bound , could be independently checked by measuring the mixing - induced cp - asymmetry in , the u - spin counterpart of the mode . in this talk , we have proposed strategies to extract information on weak phases from cp violation observables in decays even in the presence of hadronic contributions related to penguin amplitudes . assuming knowledge of the penguin pollution , an efficient use of mixing - induced cp violation in decays , measured by , can be made by combining it corresponding observable from , , to obtain the unitarity triangle parameters and . the sensitivity on the hadronic quantities , which have typical values , , is very weak . in particular , there are no first - order corrections in . for moderate values of its effect is negligible . concerning our penguin parameters , namely and , they were investigated systematically within the qcdf framework . to validate our theoretical predictions , we have calculate these parameters in the and expansion , which exhibits a good framework to control the uncalculable power corrections , in the factorization formalism . as an alternative proposition , we have also considered to extract and from other decay channels , such as and , relying on the su(3 ) argument . using these three different approaches , we found a compatible picture in estimating these hadronic parameters . i thank the organizers for their invitation and i am very grateful to gerhard buchalla for the extremely pleasant collaboration . this work is supported by the dfg under contract bu 1391/1 - 2 . m. kobayashi and t. maskawa , prog . * 49 * ( 1973 ) 652 . n. cabibbo , phys . * 10 * ( 1963 ) 531 . b. aubert et al . , phys . rev . lett . * 87 * ( 2001 ) 091801 . k. abe et al . , phys . * 87 * ( 2001 ) 091802 . heavy flavor averaging group , + http://www.slac.stanford.edu/xorg/hfag/ g. buchalla and a. s. safir , hep - ph/0406016 ; a. s. safir , hep - ph/0311104 . g. buchalla and a. s. safir , phys . * 93 * ( 2004 ) 021801 l. wolfenstein , phys . rev . lett . * 51 * ( 1983 ) 1945 ; a. j. buras , et al . d * 50 * ( 1994 ) 3433 . m. beneke et al . , b*606*(2001)245 ckmfitter working group , lp2003 update , sep . 2003 , http://ckmfitter.in2p3.fr", "summary": "we study the implication of the time - dependent cp asymmetry in decays on the extraction of weak phases taking into account the precise measurement of , obtained from the `` gold - plated''mode . predictions and uncertainties for the hadronic parameters are investigated in qcd factorization . furthermore , independent theoretical and experimental tests of the factorization framework are briefly discussed . finally , a model - independent bound on the unitarity triangle from cp violation in and is derived ."}
{"article": "the natural shape of an isolated self - gravitating fluid is axially symmetric . for this reason , exact axial symmetric solutions of einstein field equations are good candidates to model astrophysical bodies in general relativity . in the last decades , several exact solutions were studied as possible galactic models . static thin disk solutions were first studied by and , where they considered disks without radial pressure . disks radial pressure and radial tension had been considered by and , respectively . self - similar static disks were studied by , and . moreover , solutions that involve superpositions of black holes static disks were analyzed by and . also , relativistic counter - rotating thin disks as sources of the kerr type metrics were found by . counter - rotating models radial pressure and dust disks without radial pressure were studied by , and , respectively ; while rotating disks heat flow were studied by . furthermore , static thin disks as sources of known vacuum spacetimes from the chazy - curzon metric and zipoy - voorhees metric were obtained by . also , found an infinite number of new relativistic static solutions that correspond to the classical galactic disk potentials of kuzmin & toomre and mestel & kalnajs . stationary disk models including electric fields , magnetic fields , and both electric and magnetic fields had been studied . in the last years , exact solutions for thin disks made single and composite halos of matter , charged dust and charged perfect fluid were obtained . for a survey on relativistic gravitating disks , see and . most of the models constructed above were found using the metric to calculate its energy momentum - tensor , i.e. an inverse problem . several exact disk solutions were found using the direct method that consists in computing the metric for a given energy momentum tensor representing the disk . in a first approximation , the galaxies can be thought to be thin , what usually simplifies the analysis and provides very useful information . but , in order to model real physical galaxies the thickness of the disks must be considered . exact axially symmetric relativistic thick disks in different coordinate systems were studied by . also , different thick disks were obtained from the schwarzschild metric in different coordinates systems displace , cut , fill , and reflect \" method . the applicability of these disks models to any structure found in nature lays in its stability . the study of the stability , analytically or numerically , is vital to the acceptance of a particular model . also , the study of different types of perturbations , when applied to these models , might give an insight on the formation of bars , rings or different stellar patterns . moreover , a perturbation can cause the collapse of a stable object posterior appearance of a different kind of structure . an analytical treatment of the stability of disks in newtonian theory can be found in , and", "summary": "the stability of a recently proposed general relativistic model of galaxies is studied in some detail . this model is a general relativistic version of the well known miyamoto - nagai model that represents well a thick galactic disk . the stability of the disk is investigated under a general first order perturbation keeping the spacetime metric frozen ( no gravitational radiation is taken into account ) . we find that the stability is associated thickness of the disk . we have that flat galaxies have more not - stable modes than the thick ones i.e. , flat galaxies have a tendency to form more complex structures like rings , bars and spiral arms . relativity galaxies : kinematics and dynamics"}
{"article": "the open connectome project ( located at http://openconnecto.me ) aims to annotate all the features in a 3d volume of neural em data , connect these features , and compute a high resolution wiring diagram of the brain , known as a connectome . it is hoped that such work will help elucidate the structure and function of the human brain . the aim of this work is to automatically annotate axoplasmic reticula , since it is extremely time consuming to hand - annotate them . specifically , the objective is to achieve an operating point high precision , to enable robust contextual inference . there has been very little previous work towards this end . axoplasmic reticula are present only in axons , indicating the identity of the surrounding process and informing automatic segmentation . the brain data we are working color corrected using gradient - domain image - stitching techniques to adjust contrast through the slices . we use this data as the testbed for running our filters and annotating axoplasmic reticula . the bilateral filter is a non - linear filter consisting of one 2d gaussian kernel , which decays spatial distance , and one 1d gaussian kernel , which decays pixel intensity : p = {w p}\\sum {q\\in s}g {\\sigma {s}}(||p - q||)g {\\sigma {r}}(i p - i q)i q,\\\\ & w p = \\sum {q\\in s}g {\\sigma {s}}(||p - q||)g {\\sigma {r}}(i p - i q ) \\ ] ] is the normalization factor . this filter smooths the data by averaging over neighboring pixels while preserving edges , and consequently important detail , by not averaging over pixels large intensity difference . applying this filter accentuates features like axoplasmic reticula in our data . even narrow gaussian in the intensity domain , the bilateral filter causes some color bleeding across edges . we try to undo this effect through laplacian sharpening . the laplacian filter computes the difference between the intensity at a pixel and the average intensity of its neighbors . therefore , adding a laplacian filtered image to the original image results in an increase in intensity where the average intensity of the surrounding pixels is less than that of the center pixel , an intensity drop where the average is greater , and no change in areas of constant intensity . hence , we use the 3x3 laplacian filter to highlight edges around dark features such as axoplasmic reticula . we use a morphological region growing algorithm on our filtered data to locate and annotate axoplasmic 26.5 mm 26.5 mm 26.5 mm 26.5 mm 26.5 mm 26.5 mm 2 reticula . we implement this by iterating over the filtered image and looking for dark pixels , where a dark pixel is defined as a pixel value less than a certain specified threshold . when a dark pixel is found , we check its 8-neighborhood to determine if the surrounding pixels are also below the threshold . then , we check the pixels surrounding these , and we do this until we find only high intensity pixels , or until we grow larger than the diameter of an axoplasmic reticula . the thresholds we use in our algorithm are biologically motivated and tuned empirically . finally , we track our annotations through the volume to verify their correctness and identify axoplasmic reticula that were missed initially . for each slice , we traverse the annotations and check if an axoplasmic reticulum is present in the corresponding xy - location ( some tolerance ) in either of the adjacent slices . if a previously annotated axoplasmic reticulum object is present , we confirm the existing annotation . otherwise , the adjacent slice locations are checked for axoplasmic reticula less restrictive growing algorithm , and new annotations are added in the corresponding slice . if no axoplasmic reticulum object is found in either of the adjacent slices , then we assume the annotation in the current slice to be incorrect , and delete it . we qualitatively evaluated our algorithm on 20 slices from the kasthuri11 dataset , and quantitatively compared our results against ground truth from a neurobiologist . our algorithm annotates axoplasmic reticulum objects 87% precision , and 52% recall . these numbers are approximate since there is inherent ambiguity even among expert annotators . our current algorithm is designed to detect transverally sliced axoplasmic reticula . in future work , we plan to extend our morphological region growing algorithm to also find dilated axoplasmic reticula , and to incorporate a more robust tracking method such as kalman or particle filtering . additionally , our algorithm can be adapted to annotate other features in neural em data , such as mitochondria , by modifying the morphological region growing algorithm .", "summary": "* abstract : * in this paper , we present a new pipeline which automatically identifies and annotates axoplasmic reticula , which are small subcellular structures present only in axons . we run our algorithm on the kasthuri11 dataset , which was color corrected using gradient - domain techniques to adjust contrast . we use a bilateral filter to smooth out the noise in this data while preserving edges , which highlights axoplasmic reticula . these axoplasmic reticula are then annotated using a morphological region growing algorithm . additionally , we perform laplacian sharpening on the bilaterally filtered data to enhance edges , and repeat the morphological region growing algorithm to annotate more axoplasmic reticula . we track our annotations through the slices to improve precision , and to create long objects to aid in segment merging . this method annotates axoplasmic reticula high precision . our algorithm can easily be adapted to annotate axoplasmic reticula in different sets of brain data by changing a few thresholds . the contribution of this work is the introduction of a straightforward and robust pipeline which annotates axoplasmic reticula high precision , contributing towards advancements in automatic feature annotations in neural em data . + 2"}
{"article": "x - ray studies of fairly normal \" galaxies , high - energy emission not obviously dominated by a luminous active galactic nucleus ( agn ) , have recently been extended to cosmologically interesting distances in the deep field ( cdf ) surveys , which have now reached 1 ms of exposure ( cdf - n : hornschemeier et al . 2001 , hereafter paper ii ; brandt et al . 2001b , hereafter paper v ; cdf - s : tozzi et al . 2001 ; p. rosati et al . , in prep . ) . galaxies are detected in appreciable numbers at 0.52 kev fluxes below erg s ( e.g. , paper ii ) ; the cdf - n survey goes almost two orders of magnitude fainter , detecting significant numbers of normal galaxies among the population of x - ray sources making the diffuse x - ray background ( xrb ; paper ii ; a.j . barger et al . , in prep . ) . these normal galaxies contribute as much as 510% of the xrb flux in the 0.52 kev band . the bulk of the energy density of the xrb is certainly explained by agn , but the investigation of the typical \" galaxy , whether its x - ray emission is dominated by a population of x - ray binaries , hot interstellar gas , or even a low - luminosity agn , is an equally important function of deep x - ray surveys . normal galaxies are likely to be the most numerous extragalactic x - ray sources in the universe and are expected to dominate the number counts at 0.52 kev fluxes of erg s ( ptak et al . 2001 ) . the cdf - n has reached the depths necessary to detect individually many normal galaxies to , corresponding to a look - back time of gyr ( km s mpc , , and are adopted throughout this paper ) . reaching larger look - back times presents the exciting possibility of detecting the bulk x - ray response to the heightened star - formation rate at ( e.g. , madau et al . 1996 ) . one thus expects the x - ray luminosity per unit -band luminosity to be larger at in the past due to the increased energy output of x - ray binary populations at ; this x - ray emission represents a fossil record \" of past epochs of star formation ( e.g. , ghosh & white 2001 ; ptak et al . therefore , measurements of the x - ray luminosities of typical galaxies can constrain models of x - ray binary production in galaxies . while x - ray emission from individual galaxies is not easily detected at , it is possible to estimate the emission at their extremely faint flux levels using statistical methods such as stacking , a technique implemented successfully on the cdf - n survey data in several previous studies . these include the detection of x - ray emission from the average bright galaxy in the hubble deep field - north described in brandt et al . ( 2001a , hereafter paper iv ) and a study of x - ray emission from lyman break galaxies identified in the ( brandt et al . 2001c , hereafter paper vii ) . encouraged by the success of these analyses , we extend here the study of normal galaxies to the entire plus flanking fields region , now concentrating on galaxies at to complement the study of galaxies performed in paper vii . we focus on this redshift range due to the extensive spectroscopic redshift coverage ( cohen et al . 2000 and", "summary": "we present a statistical x - ray study of spiral galaxies in the hubble deep field - north and its flanking fields using the chandra deep field north 1 ms dataset . we find that galaxies have ratios of x - ray to -band luminosity similar to those in the local universe , although the data indicate a likely increase in this ratio by a factor of . we have also determined that typical spiral galaxies at should be detected in the 0.52 kev band in the flux range ( erg s . 1 heao-1"}
{"article": "topological phase of condensed matter systems is a quantum many - body state nontrivial momentum or real space topology in the hilbert spaces . recent newly discovered topological superconductor ( tsc ) has spawned considerable interests since this kind of topological phase supports the emergence of majorana fermion ( mf ) which is a promising candidate for the fault - tolerant topological quantum computation ( tqc ) . there are several proposals for hosting mfs in tsc , for example , chiral -wave superconductor , cu - doped topological insulator , superconducting proximity devices and noncentrosymmetric superconductor ( ncs ) . the signatures of mfs have also been reported in the superconducting insb nanowire , and topological insulator josephson junction . to obtain a readily manipulated majorana platform for tqc , more experimental confirmations and theoretical proposals are therefore highly desirable . in this paper , we study the topological phase and majorana fermion at the edge and in the vortex core of the -wave dresselhaus ( 110 ) spin - orbit ( so ) coupled ncs . it is found that the asymmetric so interaction plays a crucial role in realizing topological phases in the ncs . although the rashba so coupled ncs has been previously investigated , the dresselhaus ( 110 ) so coupled ncs is relatively less discussed theoretically . interestingly , we find that there is a novel semimetal phase in the dresselhaus ncs , where the energy gap closes in the whole region and different kinds of flat andreev bound states ( abss ) emerge . we demonstrate that these flat abss support the emergence of mfs analytically and numerically . it is known that the chern number is not a well - defined topological invariant in the gapless region , however , we find that the topologically different semimetal phases in this gapless region can still be distinguished by the pfaffian invariant of the particle - hole symmetric hamiltonian . several authors have proposed the flat abss in the ncs high order so couplings , -wave superconductor , -wave superconductor and -wave superconductor . instead , our proposal for hosting the flat abss is an -wave dresselhaus ( 110 ) so coupled ncs in an in - plane magnetic field which is more flexible than the previous proposals where one needs to apply a magnetic field in the direction to the materials . our proposal is experimentally more feasible . the flat dispersion implies a peak in the density of states ( dos ) which is clearly visible and has an experimental signature in the tunneling conductance measurements . the zero - bias conductance peak has been observed in recent experiments on the insb nanowire and and argued to be due to the flat abs . thus if the majorana fermion exists in the dresselhaus ncs , the flat abs and the zero - bias conductance peak in the dos predicted here should be detectable . the paper is organized as follows . the model for -wave ncs dresselhaus ( 110 ) so coupling is given in . . the phase diagrams and topological invariants of this model are discussed in . the numerical and analytical solutions to the majorana fermions at the edge of the system are demonstrated in . . the majorana fermions in the vortex core of the system are numerically shown in . . finally , we give a brief summary in . . we begin modeling the hamiltonian in a square lattice for the two dimensional -wave ncs dresselhaus ( 110 ) so interaction in an in - plane magnetic field , which is given by : ,\\\\ \\ ] ] where denotes the creation ( annihilation ) operator of the electron spin at site . is the hopping term hopping amplitude and chemical potential . is the zeeman field induced by the in - plane magnetic field components . is the dresselhaus ( 110 ) so coupling and is the -wave superconducting term function . we assume throughout this paper . in the momentum space , the hamiltonian is , where , is the wave vector in the first brillouin zone and the bogoliubov - de gennes ( bdg ) hamiltonian is where , and are the pauli matrices operating on the particle - hole space and spin space , respectively . the nontrivial topological order in the dresselhaus ncs is characterized by the existence of gapless edge state and majorana fermion . below we shall demonstrate these features in the hamiltonian eq . . for comparison , we first briefly summarize the known results of the -wave rashba ncs , in which the dresselhaus ( 110 ) so coupling in the hamiltonian eq . is replaced by the rashba so coupling 12 & 12#1212 12%12@startlink@endlink@bib@innerbibempty @noop ( , ) link:\\doibase 10.1103/physrevlett.49.405 link:\\doibase 10.1103/physrevlett.61.2015 link:\\doibase 10.1103/physrevlett.96.106802 link:\\doibase 10.1143/jpsj.77.031007 link:\\doibase 10.1103/physrevlett.95.226801 link:\\doibase 10.1103/physrevlett.95.146802 link:\\doibase 10.1103/physrevlett.98.106803 link:\\doibase 10.1103/physrevb.61.10267 link:\\doibase 10.1103/physrevb.82.134521 @noop * * , link:\\doibase 10.1103/physrevlett.100.096407 link:\\doibase 10.1103/physrevlett.105.177002 link:\\doibase 10.1016/s0003 - 4916(02)00018 - 0 link:\\doibase 10.1103/physrevlett.108.107005 @noop * * , @noop * * , link:\\doibase 10.1103/physrevb.81.125318 link:\\doibase 10.1103/physrevb.86.161108 @noop * * , link:\\doibase 10.1103/physrevlett.107.217001 link:\\doibase 10.1103/physrevlett.109.056803 link:\\doibase 10.1103/physrevlett.104.040502 link:\\doibase 10.1103/physrevb.84.060504 link:\\doibase 10.1103/physrevb.84.020501 link:\\doibase 10.1103/physrevb.83.224511 @noop link:\\doibase 10.1103/physrevlett.105.097002 link:\\doibase 10.1103/physrevb.82.184525 link:\\doibase 10.1103/physrevlett.109.150408 link:\\doibase 10.1103/physrevb.86.094512 link:\\doibase 10.1103/physrevb.79.094504 link:\\doibase 10.1016/0031 - 9163(64)90375 - 0 link:\\doibase 10.1103/physrevb.82.155327", "summary": "the asymmetric spin - orbit interactions play a crucial role in realizing topological phases in noncentrosymmetric superconductor ( ncs ) . we investigate the edge states and the vortex core states in the -wave ncs dresselhaus ( 110 ) spin - orbit coupling by both numerical and analytical methods . in particular , we demonstrate that there exists a novel semimetal phase characterized by the flat andreev bound states in the phase diagram of the -wave dresselhaus ncs which supports the emergence of majorana fermions . the flat dispersion implies a peak in the density of states which has a clear experimental signature in the tunneling conductance measurements and the majorana fermions proposed here should be experimentally detectable ."}
{"article": "quantum systems can be correlated in ways that supersede classical descriptions . however , there are degrees of non - classicality for quantum correlations . for simplicity , we consider only bipartite correlations , two , spatially separated , parties being named alice and bob as usual . at the weaker end of the spectrum are quantum systems whose states can not be expressed as a mixture of product - states of the constituents . these are called non - separable or entangled states . the product - states appearing in such a mixture comprise a local hidden state ( lhs ) model for any measurements undertaken by alice and bob . at the strongest end of the spectrum are quantum systems whose measurement correlations can violate a bell inequality , hence demonstrating ( modulo loopholes ) the violation of local causality . this phenomenon commonly known as bell - nonlocality is the only way for two spatially separated parties to verify the existence of entanglement if either of them , or their detectors , can not be trusted . we say that a bipartite state is bell - local if and only if there is a local hidden variable ( lhv ) model for any measurements alice and bob perform . here the ` variables ' are not restricted to be quantum states , hence the distinction between non - separability and bell - nonlocality . in between these types of non - classical correlations lies epr - steering . the name is inspired by the seminal paper of einstein , podolsky , and rosen ( epr ) , and the follow - up by schrdinger , which coined the term `` steering '' for the phenomenon epr had noticed . although introduced eighty years ago , as this special issue celebrates , the notion of epr - steering was only formalized eight years ago , by one of us and co - workers . this formalization was that epr - steering is the only way to verify the existence of entanglement if one of the parties conventionally alice or her detectors , can not be trusted . we say that a bipartite state is epr - steerable if and only if it allows a demonstration of epr - steering . a state is not epr - steerable if and only if there exists a hybrid lhv lhs model explaining the alice bob correlations . since in this paper we are concerned steering , when we refer to a lhs model we mean a lhs model for bob only ; it is implicit that alice can have a completely general lhv model . the above three notions of non - locality for quantum states coincide for pure states : any non - product pure state is non - separable , eps - steerable , and bell - nonlocal . however for mixed states , the interplay of quantum and classical correlations produces a far richer structure . for mixed states the logical hierarchy of the three concepts leads to a hierarchy for the bipartite states : the set of separable states is a strict subset of the set of non - epr - steerable states , which is a strict subset of the set of bell - local states . although the epr - steerable set has been completely determined for certain classes of highly symmetric states ( at least for the case where alice and bob perform projective measurements ) , until now very little was known about what types of states are steerable even for the simplest case of two qubits . in this simplest case , the phenomenon of steering in a more general sense i.e. within what set can alice steer bob s state by measurements on her system has been studied extensively using the so - called steering ellipsoid formalism . however , no relation between the steering ellipsoid and epr - steerability has been determined . in this manuscript , we investigate epr - steerability of the class of two - qubit states whose reduced states are maximally mixed , the so - called t - states . we use the steering ellipsoid formalism to develop a deterministic lhs model for projective measurements on these states and we conjecture that this model is optimal . furthermore we obtain two sufficient conditions for t - states to be epr - steerable , via suitable epr - steering inequalities ( including a new asymmetric steering inequality for the spin covariance matrix ) . these sufficient conditions touch the necessary condition in some regions of the space of t - states , and everywhere else the gap between them is quite small . the paper is organised as follows . in section 2 we discuss in detail the three notions of non - locality , namely bell - nonlocality , epr - steerability and non - separability . section 3 introduces the quantum steering ellipsoid formalism for a two - qubit state , and in section 4 we use the steering ellipsoid to develop a deterministic lhs model for projective measurements on t - states . in section 5 , two asymmetric steering inequalities for arbitrary two - qubit states are derived . finally in section 6 we conclude and discuss further work . two separated observers , alice and bob , can use a shared quantum state to generate statistical correlations between local measurement outcomes . each observer carries out a local measurement , labelled by and respectively , to obtain corresponding outcomes labelled by and . the measurement correlations are described by some set of joint probability distributions , , and ranging over the available measurements . the type of state shared by alice and bob may be classified via the properties of these joint distributions , for all possible measurement settings and . the correlations of a bell - local state have a local hidden variable ( lhv ) model , for some ` hidden ' random variable probability distribution . hence , the measured correlations may be understood as arising from ignorance of the value of , where the latter locally determines the statistics of the outcomes and and is independent of the choice of and . conversely , a state is defined to be bell -nonlocal if it has no lhv model . such states allow , for example , the secure generation of a cryptographic key between alice and bob without trust in their devices . in this paper , we are concerned whether the state is steerable ; that is , whether it allows for correlations that demonstrate epr - steering . as discussed in the introduction , epr - steering by alice is demonstrated if it is not the case that the correlations can be described by a hybrid lhv lhs model , wherein , where the local distributions correspond to measurements on local quantum states , i.e. , .\\ ] ] here denotes the positive operator valued measure ( povm ) corresponding to measurement . the state is said to be steerable by alice if there is no such model . the roles of alice and bob may also be reversed in the above , to define steerability by bob . comparing eqs . and , it is seen that all nonsteerable states are bell - local . hence , all bell - nonlocal states are steerable , by both alice and bob . in fact , the class of steerable states is strictly larger . moreover , while not as powerful as bell - nonlocality in general , steerability is more robust to detection inefficiencies , and also enables the use of untrusted devices in quantum key distribution , albeit only on one side . by a similar argument , a separable quantum state shared by alice and bob , , is both bell - local and nonsteerable . moreover , the set of separable states is strictly smaller than the set of nonsteerable states . it is important that epr - steerability of a quantum state not be confused merely the dependence of the reduced state of one observer on the choice of measurement made by another , which can occur even for separable states . the term ` steering ' has been used reference to this phenomenon , in particular for the concept of ` steering ellipsoid ' , which we will use in our analysis . epr - steering , as defined above , is a special case of this phenomenon , and is only possible for a subset of nonseparable states . we are interested in the epr - steerability of states for all possible projective measurements . if alice is doing the steering , then it is sufficient for bob s measurements to comprise some tomographically complete set of projectors . it is straightforward to show in this case that the condition for bob to have an lhs model , eq . , reduces to the existence of a representation of the form = \\sum \\lambda p(\\lambda)\\ , p(1|e,\\lambda ) \\,\\rho b(\\lambda ) , \\\\ p e & = = \\sum \\lambda p(\\lambda ) p(1|e,\\lambda).\\ ] ] here is any projector that can be measured by alice ; is the probability of result ` ' and is the corresponding probability given ; is the reduced state of bob s component corresponding to this result ; and ] . it follows that if the shared state has maximally - mixed reduced states , then it is completely described , up to local unitaries , by a diagonal , i.e. one may consider without loss of generality . such states are called t - states . they are equivalent to mixtures of bell states , and hence form a tetrahedron in the space parameterised by . entangled t - states necessarily have , and the set of separable t - states forms an octahedron within the tetrahedron . the t - state steering ellipsoid is centred at the origin , , and the ellipsoid matrix is simply , as follows from eqs . and . the semiaxes are for , and are aligned -axes of the bloch sphere . thus , the equation of the ellipsoid surface in spherical coordinates is , we find a remarkable connection between this equation and the epr - steerability of t - states in the following subsection . without loss of generality , consider measurement by alice of hermitian observables on her qubit . such observables can be equivalently represented via projections , , . the probability of result ` ' and the corresponding steered bloch vector are given by eqs . and , i.e. , hence , letting denote the bloch vector corresponding to in eq . , then from eqs . and , it follows there is an lhs model for bob if and only if there is a representation of the form for all unit vectors . noting further that can always be represented as some mixture of unit vectors , corresponding to pure , these conditions are equivalent to the existence of a representation of the form integration over the bloch sphere . thus , the unit bloch vector labels both the local hidden state and the hidden variable . given lhs models for bob for any two t - states , having spin correlation matrices and , it is trivial to construct an lhs model for the t - state corresponding to , for any , via the convexity property of nonsteerable states . our strategy is to find deterministic lhs models for some set of t - states , for which the result ` ' is fully determined by knowledge of , i.e. , . lhs models can then be constructed for all convex combinations of t - states in this set . to find deterministic lhs models , we are guided by the fact that the steered bloch vectors are precisely those vectors that generate the surface of the quantum steering ellipsoid for the t - state . we make the ansatz that is proportional to some power of the function in eq . that defines this surface , i.e. , ^m \\equiv n t\\,\\left^{m/2}\\ ] ] for , where is a normalisation constant . further , denoting the region of the bloch sphere , for which by ] . we note this is automatically satisfied if is a hemisphere , as a consequence of the symmetry for the above form of . hence , under the assumptions that ( i ) is determined by the steering ellipsoid as per eq . , and ( ii ) ] . extensive numerical testing , different values of the exponent , show that this constraint can be satisfied by the choices = \\{{\\boldsymbol}n : { \\boldsymbol}nt^{-1 } { \\boldsymbol}e\\geq 0\\},\\ ] ] for a two - parameter family of t - states . assuming the numerical results are correct , it is not difficult to show , using infinitesimal rotations of about the -axis , that this family corresponds to those t - states that satisfy fortunately , we have been able to confirm these results analytically by explicitly evaluating the integral in eq . for ( see appendix a ) . an explicit form for the corresponding normalisation constant is also given in appendix a , and it is further shown that the family of t - states satisfying eq . is equivalently defined by the condition this may be interpreted geometrically in terms of the harmonic mean radius of the ` inverse ' ellipsoid being equal to . equation defines a surface in the space of possible matrices , plotted in fig . 1(a ) as a function of the semiaxes and . as a consequence of the convexity of nonsteerable states ( see above ) , all t - states corresponding to the region defined by this surface and the positive octant have local hidden state models for bob . also shown is the boundary of the separable t - states , in red , which is clearly a strict subset of the nonsteerable t - states . the green plane corresponds to the sufficient condition for epr - steerable states , derived in . 5 below . it follows that a necessary condition for a t - state to be epr - steerable by alice is that it corresponds to a point above the sandwiched surface shown in fig . note that this condition is in fact symmetric between alice and bob , since their steering ellipsoids are the same for t - states . because of the elegant relation between our lhs model and the steering ellipsoid , and other evidence given below , we conjecture that this condition is also sufficient for epr - steerability . . * top figure ( a ) * : the red plane separates separable ( left ) and entangled ( right ) t - states . the sandwiched blue surface corresponds to the necessary condition for epr - steerability generated by our deterministic lhs model in . 4b : all t - states to the left of this surface are not epr - steerable . we conjecture that this condition is also sufficient , i.e. , that all states to the right of the blue surface are epr - steerable . for comparison , the green plane corresponds to the sufficient condition for epr - steerability in eq . of section 5a : all t - states to the right of this surface are epr - steerable . only a portion of the surfaces are shown , as they are symmetric under permutations of . * bottom figure ( b ) * : cross section through the top figure at , where the necessary condition can be determined analytically ( see . the additional black dashed curve corresponds to the non - linear sufficient condition for epr - steerability in eq . .,title=\"fig:\",width=336 ] . * top figure ( a ) * : the red plane separates separable ( left ) and entangled ( right ) t - states . the sandwiched blue surface corresponds to the necessary condition for epr - steerability generated by our deterministic lhs model in . 4b : all t - states to the left of this surface are not epr - steerable . we conjecture that this condition is also sufficient , i.e. , that all states to the right of the blue surface are epr - steerable . for comparison , the green plane corresponds to the sufficient condition for epr - steerability in eq . of section 5a : all t - states to the right of this surface are epr - steerable . only a portion of the surfaces are shown , as they are symmetric under permutations of . * bottom figure ( b ) * : cross section through the top figure at , where the necessary condition can be determined analytically ( see . the additional black dashed curve corresponds to the non - linear sufficient condition for epr - steerability in eq . .,title=\"fig:\",width=259 ] when we can solve eq . explicitly , because the normalisation constant simplifies . the corresponding equation of the semiaxis , in terms of , is given by ^{-1 } & u < 1 , \\\\ \\left ^{-1 } & u > 1 , \\right.\\ ] ] and for . 1(b ) displays this analytic epr - steerable curve through the t - state subspace , showing more clearly the different correlation regions . the symmetric situation corresponds to werner states . our deterministic lhs model is for in this case , which is known to represent the epr - steerable boundary for werner states . thus , our model is certainly optimal for this class of states . in the previous section a strong necessary condition for the epr - steerability of t - states was obtained , corresponding to the boundary defined in eq . and depicted in fig . 1 . while we have conjectured that this condition is also sufficient , it is not actually known if all t - states above this boundary are epr - steerable . here we give two sufficient general conditions for epr - steerability , and apply them to t - states . these conditions are examples of epr - steering inequalities , i.e. , statistical correlation inequalities that must be satisfied by any lhs model for bob . thus , violation of such an inequality immediately implies that alice and bob must share an epr - steerable resource . our first condition is based on a new epr - steering inequality for the spin covariance matrix , and the second on a known nonlinear epr - steering inequality . both epr - steering inequalities are further of interest in that they are asymmetric under the interchange of alice and bob s roles . suppose alice and bob share a two - qubit state spin covariance matrix given by and that each can measure any hermitian observable on their qubit . we show in appendix that , if there is an lhs model for bob , then the singular values , , of the spin covariance matrix must satisfy the linear epr - steering inequality from , and using and for t - states , it follows immediately that one has the simple sufficient condition for the epr - steerability of t - states ( by either alice or bob ) . the boundary of t - states satisfying this condition is plotted in figs . 1 ( a ) and ( b ) , showing that the condition is relatively strong . in particular , it is a tangent plane to the necessary condition at the point corresponding to werner states ( which we already knew to be a point on the true boundary of epr - steerable states ) . however , in some parameter regions a stronger condition can be obtained , as per below . suppose alice and bob share a two - qubit state as before , where bob can measure the observables , on his qubit , , for any ] , without loss of generality . making the choices and in this representation , then and are given by and the third component of in eqs . and , respectively , . hence , the above inequality simplifies to ,\\ ] ] where and are the third components of alice and bob s bloch vectors and . for t - states , recalling that , the above inequality simplifies further , to the nonlinear inequality hence , since similar inequalities can be obtained by permuting , we have the sufficient condition for the epr - steerability of t - states . the boundary of t - states satisfying this condition is plotted in fig . 1(b ) for the case . it is seen to be stronger than the linear condition in eq . if one semiaxis is sufficiently large . the region below both sufficient conditions is never far above the smooth curve of our necessary condition , supporting our conjecture that the latter is the true boundary . in this paper we have considered steering for the set of two - qubit states maximally mixed marginals ( ` t - states ' ) , where alice is allowed to make arbitrary projective measurements on her qubit . we have constructed a lhv lhs model ( lhv for alice , lhs for bob ) , which describes measurable quantum correlations for all separable , and a large portion of non - separable , t - states . that is , this model reproduces the steering scenario , by which alice s measurement collapses bob s state to a corresponding point on the surface of the quantum steering ellipsoid . our model is constructed using the steering ellipsoid , and coincides optimal lhv lhs model for the case of werner states . furthermore , only a small ( and sometimes vanishing ) gap remains between the set of t - states that are provably non - steerable by our lhv lhs model , and the set that are provably steerable by the two steering inequalities that we derive . as such , we conjecture that this lhv lhs model is in fact optimal for t - states . proving this , however , remains an open question . a natural extension of this work is to consider lhv lhs models for arbitrary two - qubit states . how can knowledge of their steering ellipsoids be incorporated into such lhv lhs models ? investigations in this direction have already begun , but the situation is far more complex when alice and bob s bloch vectors have nonzero magnitude and the phenomenon of `` one - way steering '' may arise . finally , our lhv lhs models apply to the case where alice is restricted to measurements of hermitian observables . it would be of great interest to generalize these to arbitrary povm measurements . however , we note that this is a very difficult problem even for the case of two - qubit werner states . nevertheless , the steering ellipsoid is a depiction of all collapsed states , including those arising from povms ( they give the interior points of the ellipsoid ) and perhaps this can provide some intuition for how to proceed this generalisation . sj would like to thank david jennings for his early contributions to this project . sj is funded by epsrc grant ep / k022512/1 .", "summary": "the question of which two - qubit states are steerable ( i.e. permit a demonstration of epr - steering ) remains open . here , a strong necessary condition is obtained for the steerability of two - qubit states having maximally - mixed reduced states , via the construction of local hidden state models . it is conjectured that this condition is in fact sufficient . two provably sufficient conditions are also obtained , via asymmetric epr - steering inequalities . our work uses ideas from the quantum steering ellipsoid formalism , and explicitly evaluates the integral of over arbitrary unit hemispheres for any positive matrix ."}
{"article": "several decades ago , postulated that the absorption lines observed in the spectra of distant qsos are due to the extended gaseous halos of intervening galaxies . since that time , astronomers have identified the galaxies associated observed absorption ( e.g. , * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) and have used qso spectroscopy of various rest - frame ultraviolet transitions to constrain the nature of baryonic processes in the outer regions of galaxies , e.g. , feedback , accretion , and cooling . these transitions include ly and lines that probe cooler , photoionized gas , and and doublets that trace warmer , more diffuse material . however , while the apparent brightness of qsos enables high signal - to - noise , high spectral resolution datasets , they severely outshine the galaxies projected nearby and therefore limit follow - up analysis , especially at small impact parameters . furthermore , qsos are too rare in the sky to probe numerous individual galaxies multiple sightlines . therefore , constraints on the covering fraction and spatial distribution of halo gas must be statistical ( e.g. , * ? ? ? * ; * ? ? ? the doublet in particular has been studied extensively , as it is easily accessible at optical wavelengths at redshifts and traces cool gas ( temperature ; * ? ? ? * ) in a broad range of neutral hydrogen column densities ( ; * ? ? ? * ; * ? ? ? * ) . in spite of this , the physical origins of the gas giving rise to absorption remain obscure several studies ( e.g. , * ? ? ? * ) suggest an infall origin for this gas ; for example , present an infall model which they reproduce the observed frequency distribution function for systems as well as their clustering properties . other studies suggest instead that these systems arise in gas which has been blown out of star - forming galaxies via superwinds . in support of this latter scenario , a recent study by of kinematics in coadded deep2 spectra of a sample of star - forming galaxies at reveals frequent , perhaps even ubiquitous , outflows of cool gas . also detect very high velocity outflows in post - starburst galaxies traced by absorption . such winds may redistribute absorbing gas , possibly to a galaxy s halo , although the distances to which the winds extend remain uncertain . in one of the only studies addressing this issue , observes cool outflowing gas several kiloparsecs from the nuclei of a sample of ultraluminous infrared galaxies . in principle , galaxy spectra can also probe the halo gas of foreground galaxies along the sightline ( e.g. , * ? ? ? * ; * ? ? ? this novel technique offers several advantages over qso - galaxy pair studies ( d. koo et al . 2009 , in preparation ) . the projected number density of galaxies on the sky is much greater than that of qsos ; therefore the use of galaxies can vastly increase the number of potential background probes for a given galaxy halo . moreover , many galaxies are extended sources which provide the opportunity to study gas along multiple lines of sight through a given foreground halo , including their own ( e.g. , * ? ? ? * ; * ? ? ? integral field unit ( ifu ) spectrographs may then be used to study the morphology of halo absorption and the spatial distribution of outflowing gas . close transverse pairs of galaxies may be identified in large spectroscopic or photometric surveys so that a targeted search for foreground absorption in the background galaxy spectra can be performed . this technique has been used at to study absorbing gas traced by transitions such as near lyman break galaxies by ; but it has not yet been used at lower redshifts where higher resolution imaging and spectroscopy can be obtained for each galaxy . in the process of carrying out a spectroscopic survey to measure outflow properties in galaxies at , we identified a close transverse pair of galaxies in which the spectroscopy of the more distant object allows the detection ( in absorption ) of gas in the environs of a foreground galaxy ( at and at impact parameter kpc ) . this foreground absorber shows signs of recent merger activity , has a stellar continuum consistent that of a post - starburst galaxy , and is host to a low - luminosity agn . here we analyze the spectrum of the background galaxy to examine halo gas in the foreground system . we discuss our observations of the galaxy pair and data reduction in . analysis of the luminous components of the galaxies and the foreground halo absorption is given in . the possible origins of the observed cool halo gas are discussed in , and we conclude in . we adopt a cosmology , , and . where it is not explicitly written , we assume . magnitudes quoted are in the ab system . our targeted galaxy pair is located in the goods - n field ( great observatories origins survey ; * ? ? ? * ) and has been imaged by the hst advanced camera for surveys in 4 optical bands ( f435w , f606w , f775w and f850lp , or , , and ) . galaxy properties derived in previous studies and", "summary": "we study the cool gas around a galaxy at using keck / lris spectroscopy of a bright background galaxy at at a transverse distance of kpc . the background galaxy spectrum reveals strong , , , and absorption at the redshift of the foreground galaxy , rest equivalent width of , indicative of a velocity width exceeding . because the background galaxy is large ( kpc ) , the high covering fraction of the absorbing gas suggests that it arises in a spatially extended complex of cool clouds large velocity dispersion . spectroscopy of the massive host galaxy reveals that it experienced a burst of star formation about 1 gyr ago and that it harbors a weak agn . we discuss the possible origins of the cool gas in its halo , including multiphase cooling of hot halo gas , cold inflow , tidal interactions , and galactic winds . we conclude the absorbing gas was most likely ejected or tidally stripped from the interstellar medium of the host galaxy or its progenitors during the past starburst event . adopting the latter interpretation , these results place one of only a few constraints on the radial extent of cool gas driven or stripped from a galaxy in the distant universe . future studies integral field unit spectroscopy of spatially extended background galaxies will provide multiple sightlines through foreground absorbers and permit analysis of the morphology and kinematics of the gas surrounding galaxies diverse set of properties and environments ."}
{"article": "superconducting josephson junction qubit is one of the most promising candidates for implementing quantum computation . single qubit coherent oscillations in superconducting qubits have been demonstrated experimentally and furthermore two qubit coupling and entanglement have been performed in charge , flux and phase qubits . scalable quantum computing requires controllable and selective coupling between two remote as well as nearest neighbor qubits . recently much theoretical efforts have been devoted on the study about the controllable coupling of charge , charge - phase and flux qubits . for flux qubits the controllable coupling schemes use inductive coupling , but it is too weak to perform efficient two - qubit gate operations . hence , while in superconducting charge qubit two - qubit coherent oscillations and cnot gate operations were experimentally observed , only spectroscopy measurement was done for inductively coupled flux qubit . in this study thus we suggest a scheme to give both strong and tunable coupling between two phase - coupled flux qubits . the phase - coupling scheme , which we previously proposed , has been realized in a recent experiment . the controllable coupling scheme using phase - coupled qubits threading ac magnetic field was also studied theoretically . further , there have been studies about somewhat different phase - coupling schemes . two current states of a flux qubit are characterized by the induced loop current related phase differences across josephson junctions in the qubit loop . if we try to couple two flux qubits using mutual inductance , the coupling strength will be too weak to perform the discriminating cnot gate operations , since the mutual inductance and the induced currents of the left ( right ) qubit is very small . even though the induced currents of flux qubits are weak , the phase differences across josephson junctions are as large as . hence , if two flux qubits are coupled by the phase differences between two josephson junctions of different qubits , we can achieve a strong coupling of the order of josephson coupling energy of the josephson junctions in the connecting loop whose typical value is as large as up to about 200ghz . introducing two dc - squid s interrupting the connecting loop as shown in fig . we can control the coupling between phase - coupled flux qubits . the control fluxes , and , threading two dc - squid loops must be in opposite directions in order to give rise to the controllable coupling . when two fluxes are in the same direction , the change of control fluxes induces an additional current flowing in the connecting loop , causing the shift of qubit states as well as the change of coupling strength . such a dilemma also persists in the case of one dc - squid loop in connecting loop . however , if the control fluxes are in opposite directions , we have found that the additional currents coming from two dc - squid s are cancelled each other and thus the coupling strength can be tunable remaining the qubit states unchanged . the three - josephson junctions qubits in fig . has two current states ; if the qubit current , it is diamagnetic while , if , paramagnetic . introducing the notation for diamagnetic ( paramagnetic ) current state of a qubit in pseudo spin language , there can be four current states of coupled qubits , , , and , of which we show one of the same current states , , and one of the different current states , , in fig . . the phase and of the josephson junctions of the three - josephson junctions qubits have different values if two qubits are in different states . then the phase difference induces the phases in the josephson junctions of dc - squid loops . if we neglect small kinetic inductance , the boundary conditions of the left ( right ) qubit and the connecting loop can be approximately written as where is total flux and external flux and the unit flux quantum is dimensionless reduced flux threading the left ( right ) qubit . here self inductance and the induced current of qubit loop is the induced flux of each qubit and that of the connecting loop and and are integers . we consider that the external fluxes and threading the qubit loops are also in opposite directions , since they are connected in a twisted way in the scalable design of ref . . however , for just two qubit coupling , we can choose the directions of external fluxes threading the qubit loops arbitrary . actually there is no external flux in the connecting loop , but the phase difference in the boundary condition of eq . plays the role of effective flux in the connecting loop , when two qubits are in different current state , i.e. , one is diamagnetic and the other paramagnetic , the value of becomes . since the induced flux of flux qubit is so weak as , large value of in the phase - coupled flux qubits can give a strong coupling compared to the inductive coupling scheme . the hamiltonian of the coupled qubits can be given by which describes dynamics of a particle effective mass in the effective potential . the kinetic part of the hamiltonian comes from the charging energy of the josephson junctions such as where and is the capacitance of the josephson junctions of the left ( right ) qubit loop and the connecting loop , respectively . the number of excess cooper pair charges on josephson junction is conjugate to the phase difference such as =i$ ] , where , and the capacitance of the josephson junctions . here we introduce the canonical momentum and the effective mass to obtain the kinetic part of the hamiltonian . the effective potential of the coupled qubits is composed of the inductive energy of loops and the josephson junction energy terms ; here is the inductive energy of loops current of the right qubit , left qubit and connecting loop . is the energy of the josephson junctions in two qubit loop and that of the connecting loop josephson coupling energies and . introducing another rotated coordinate and using the boundary conditions in eq . to get the josephson junction energy of the connecting loop can also be written as \\cos,\\nonumber\\ ] ] where we set and . first of all we consider the case that the control fluxes , and , have opposite directions such that note that the boundary conditions in eq . already have opposite signs . in order to obtain the effective potential as a function of and , we reexpress as using the boundary conditions in eq . and the expression in eq . . here can be written as neglecting small induced flux in the connecting loop . depending on whether is even or odd , the results will be quantitatively different , but qualitatively the same . here and after , thus , we choose is even and specifically , and for simplicity and then becomes and the energy of josephson junctions in connecting loop in eq . .\\ ] ] since the induced energy can be negligible , the total effective potential in eq . is given by the sum of the energies in eqs . and , the lowest energy level of in plane can be obtained by setting the remaining variable in eq . as when . we plot the effective potential in fig . ( a ) four local minima . the value of local minima of case ( i ) can be obtained from and we have found that two local minima have the same value , , for equal pseudo - spin state . similarly we get of case ( ii ) from for different pseudo - spin state . as a result , we obtain where is the value of at local minima of the same spin states , , and the value of of the different spin states , thus the energy of the same spin states , , is lower than that of different spin states , , as shown in fig . (a ) . here we set , and . for the same spin states we have two solutions , , corresponding to two local minima , and . when , and and thus using from the boundary condition in eq . . since the loop currents of both qubits then are diamagnetic as can be seen from fig . (a ) , this coupled - qubits state can be represented as as shown in fig . (a ) . on the other hand , when , then the qubit current corresponds to the paramagnetic current states , . we would like to note that , since the external fluxes and threading left and right qubit loops are already in opposite directions , diamagnetic ( paramagnetic ) currents of both qubits in state are also in opposite directions . .the values of phase differences of coupled qubits states in several coordinates , , and . for different spin states , two solutions are also obtained for . when , for left and right qubit respectively , which corresponds to the state , in fig . ( a ) . in the same way corresponds to the state . hence we can identify four stable states , and , energies and at the local minima of as shown in fig . ( a ) . even though above four states are stable states in plane , it can be unstable in the other dimensions if they are saddle points . thus we need represent the effective potential in plane . from the expression of in eq . and the relation in eq . , we can get and , following similar procedure as in the plane , we obtain the effective potential as shown in fig . ( b ) , where we can again see local minima . in figs . ( b ) , for the states and of case ( i ) , we can get the values and , for case ( ii ) , the values using eqs . , and and the values of in each case . as a result , we are able to identify the spin states at local minima of figs . ( b ) from fig . ( a ) above values and confirm the stability of the states in both planes . in table we summarize the values of the phase differences for four states , , of coupled qubits in several coordinates . actually we obtained higher energy states in fig . ( a ) , but found that they are unstable in plane . the hamiltonian of coupled qubits can be written as where and and is the identity matrix . first two terms are qubit terms , the third is coupling term and last two terms are tunnelling terms which come from the quantum fluctuation described by the kinetic term of the hamiltonian . then the coupling constant of the coupled qubits is given by in fig . we plot the energies of coupled - qubits for various , and in plane . when in fig . (a ) , the energies of the same spin states , and , are lower than , of the different spin states , and . the positions of four local minima are shown in table . as increases , the energy difference becomes smaller ( upper panel in ( b ) ) and finally at in ( c ) . since and , the coupling strength can be written as therefore the coupling strength between two flux qubits changes as varying the control fluxes threading the dc - squid loop in the connecting loop . from eq . the coupling constant can be represented as a function of by , which gives in fig . (a ) we plot the energies and as a function of , where . when , is of the order of so that we can obtain a sufficiently strong coupling . by adjusting the coupling strength can be tuned from strong coupling to zero at . the coupling strength in eq . depends on as well as . when is small , is proportional to and . recently the phase - coupling scheme has been experimentally implemented , where four - josephson junctions qubits are employed instead of usual three - josephson junctions qubits . in that experiment the josephson junction energy of fourth junction is large so that the value of is about . as a result , the experiment exhibits rather small coupling strength . the current of connecting loop can be written as , which gives the relations , and then integer using the boundary conditions in eq . . then , using eq . and the effective flux in eq . , the current is given by this current - phase relation can be considered as the josephson junction type relation , , effective josephson coupling energy , , of two dc - squid s in the connecting loop and the phase difference . the coupling constant in eq . also can be represented by the effective josephson coupling energy , . thus the large phase difference , , and the josephson coupling energy , , induce the current in the connecting loop and the coupling energy of the phase - coupled qubits . for the same spin states , and , the current of connecting loop becomes zero , since and thus . for a different spin states , and we have from and the relation in eq . . then weak current in the connecting loop flows satisfying current conservation condition between left qubit and connecting loop such that for . when approaches , the effective josephson coupling energy and thus the current in connecting loop become zero , which means that the coupling between two qubits is switched off . now we want to explain the case that two control fluxes are in the same directions and the case that there is only single dc - squid in connecting loop . if two control fluxes are in the same direction such as the josephson junction energy of the connecting loop becomes . \\nonumber\\\\\\ ] ] similar procedure as in the case of opposite directions of control fluxes shows that the same spin states , and , have equal energy such as for . for different spin states , and , the energies and are obtained at two local minima which can be derived from eq . . since the states , and , have different sign for , the second term produces the energy difference where is again one of the values of for the different spin states . figure (b ) ( lower panel ) for shows that , when two control fluxes are in the same direction , the energies and are different while . the energy levels of are plotted in fig . (b ) . in this case the effective fluxes and applied to left and right qubits in the hamiltonian of eq . become different each other , , as increases from zero . for the different current state in fig . (b ) , if the control fluxes and threading the dc - squid loops are in the same direction , the increased current in the connecting loop will flow through the left and right qubit loops . thus the qubit states are influenced by additional effective fluxes , which will makes the two - qubit operations difficult . however , if two control fluxes and are in opposite directions , the energies of different spin states remains equal to each other , , as shown in fig . (a ) . this means that the additional currents coming from two dc - squid s are cancelled each other and total additional current induced by the control fluxes and is vanishing in the connecting loop . as a result , the net effect is just renormalizing the coupling constant of the coupled qubit system . we also calculated energies of coupled qubit states single dc - squid loop whose boundary conditions become instead of those in eqs . and . then we get the josephson junction energies of the dc - squid , which gives results similar to those of two dc - squid s fluxes in the same direction such that for and as shown in fig . (c ) . hence the behaviors of one dc - squid in the connecting loop are qualitatively the same as those of two dc - squid s fluxes in the same direction . therefore we need two control fluxes threading dc - squid s in opposite directions to cancel the additional currents in the connecting loop for obtaining the controllable coupling . in order to obtain the controllable coupling both the qubit operating flux , , and control flux , , of the left qubit become in opposite direction to those of the right qubit , and as shown in fig . . in real experiments it will be very hard to apply magnetic fluxes of different directions simultaneously . we have previously suggested a scalable design for phase - coupled flux qubits , where an arbitrary pair of qubits are coupled in a twisted way . thus just applying all magnetic fluxes in the same direction makes automatically the effect of fluxes in opposite directions , removing the experimental difficulty . the recent experiment on the phase - coupled flux qubits without dc - squid loop has shown that the coupled qubit states are in quantum mechanically superposed regime . the dc - squid loops in the connecting loop of the present tunable coupling scheme may cause a decoherence effect on the coupled qubit states . a recent study argued that the dc - squid based oscillator should be the main source of the decoherence of the flux qubits . for the scalable design in ref . , however , the decoherence from two dc - squid s can be reduced . since two dc - squid s are connected in a twisted way , the fluctuations from tank circuit or flux lines can be cancelled each other . in realistic implementation of qubit operations , operating external fluxes are slightly different from the co - resonance point , , and moreover we can not any more neglect small kinetic inductance and induced fluxes . hence we confirmed the results in this study by numerical calculation using the exact boundary conditions similar to those in eqs . , current - phase relation and current conservation conditions . controllable coupling between two phase - coupled flux qubits can be achieved by using two dc - squid s in the connecting loop threading fluxes in opposite directions . we analytically show at co - resonance point that the coupling strength of the phase - coupled flux qubits can be adjusted by varying the threading fluxes from to ; it can be as strong as o and zero in switching - off limit . when either two control fluxes are in the same directions or there is only one dc - squid in the connecting loop , the coupled qubits can not be described by the coupling hamiltonian . in slightly different parameter regimes of experimental implementations numerical calculations can be done to obtain exact results . 1 y. makhlin , g. schn , and a. shnirman , rev . phys . * 73 * , 357 ( 2001 ) ; a. galindo and m. a. martn - delgado , ibid . * 74 * , 347 ( 2002 ) . y. nakamura , yu . a. pashkin , and j. s. tsai , nature * 398 * , 786 ( 1999 ) . y. yu , s. han , x. chu , s. chu , and z. wang , science * 296 * , 889 ( 2002 ) . i. chiorescu , y. nakamura , c. j. p. m. harmans , and j. e. mooij , science * 299 * , 1869 ( 2003 ) . a. pashkin , t. yamamoto , o. astafiev , y. nakamura , d. v. averin , and j. s. tsai , nature * 421 * , 823 ( 2003 ) . t. yamamoto , yu . a. pashkin , o. astafiev , y. nakamura , and j. s. tsai , nature * 425 * , 941 ( 2003 ) . a. izmalkov , m. grajcar , e. iichev , th . wagner , h .- meyer , a.yu . smirnov , m. h. s. amin , alec maassen van den brink , and a.m. zagoskin , phys . . lett . * 93 * , 037003 ( 2004 ) . m. grajcar , a. izmalkov , s. h. w. van der ploeg , s. linzen , e. iichev , th . wagner , u. hubner , h .- meyer , alec maassen van den brink , s. uchaikin , and a. m. zagoskin , phys . b * 72 * , 020503(r ) ( 2005 ) . j. b. majer , f. g. paauw , a. c. j. ter haar , c. j. p. m. harmans , and j. e. mooij , phys . rev . lett . * 94 * , 090501 ( 2005 ) . a. j. berkley et al . , science * 300 * , 1548 ( 2003 ) . d. v. averin and c. bruder , phys . 91 * , 057003 ( 2003 ) ; j. q. you , j. s. tsai , and f. nori , phys b * 68 * , 024510 ( 2003 ) . a. blais , alec maassen van den brink , and a. m. zagoskin , phys . lett . * 90 * , 127901 ( 2003 ) . b. l. t. plourde et al . , b * 70 * , 140501(r ) ( 2004 ) . p. bertet , c. j. p. m. harmans , and j. e. mooij , phys . b * 73 * , 064512 ( 2006 ) . y .- x . liu , l. f. wei , j. s. tsai , and f. nori , phys . * 96 * , 067003 ( 2006 ) . a. o. niskanen , y. nakamura , and j. s. tsai , phys . b * 73 * , 094506 ( 2006 ) . j. e. mooij et al . , science * 285 * , 1036 ( 1999 ) ; caspar h. van der wal et al . , science * 290 * , 773 ( 2000 ) . t. p. orlando et al . , phys . rev . b * 60 * , 15398 ( 1999 ) . m. d. kim , d. shin , and j. hong , phys . rev . b * 68 * , 134513 ( 2003 ) .", "summary": "we propose a scheme for tunable coupling of phase - coupled flux qubits . the phase - coupling scheme can provide a strong coupling strength of the order of josephson coupling energy of josephson junctions in the connecting loop , while the previously studied inductive coupling scheme can not provide due to small mutual inductance and induced currents . we show that , in order to control the coupling , we need two dc - squid s in the connecting loop and the control fluxes threading the dc - squid s must be in opposite directions . the coupling strength is analytically calculated as a function of the control flux at the co - resonance point ."}
{"article": "in 1985 , hoare s paper a couple of novelties in the propositional calculus was published . in this paper the ternary connective is introduced as the conditional . and denoting programs and a boolean expression . ] a more common expression for a conditional statement is but in order to reason systematically conditional statements , a notation such as is preferable . in a conditional statement , first is evaluated , and depending on that evaluation result , then either or is evaluated ( and the other is not ) and determines the evaluation value . this evaluation strategy is a form of short - circuit evaluation . in , hoare proves that propositional logic is characterized by eleven equational axioms , some of which employ constants and for the truth values and . in 2011 , we introduced proposition algebra in as a general approach to the study of the conditional : we defined several valuation congruences and provided equational axiomatizations of these congruences . the most basic and least identifying valuation congruence is free valuation congruence , which is axiomatized by the axioms in table . ' '' '' ' '' '' these axioms stem from and define the conditional as a primitive connective . we use the name ( for conditional propositions ) for this set of axioms . interpreting a conditional statement as an if - then - else expression , axioms are natural , and axiom ( distributivity ) can be clarified by case analysis : if evaluates to and as well , then determines the result of evaluation ; if evaluates to and evaluates to , then determines the result of evaluation , and so on and so forth . in section we characterize free valuation congruence help of evaluation trees : given a conditional statement , its evaluation tree directly represents all its evaluations ( in the way a truth table does in the case of propositional logic ) . two conditional statements are equivalent respect to free valuation congruence if their evaluation trees are equal . evaluation trees are simple binary trees , proposed by daan staudt in ( that appeared in 2012 ) . free valuation congruence identifies less than the equivalence defined by hoare s axioms in . for example , the atomic proposition and the conditional statement are not equivalent respect to free valuation congruence , although they are equivalent respect to static valuation congruence , which is the valuation congruence that characterizes propositional logic . a valuation congruence that identifies more than free and less than static valuation congruence is repetition - proof valuation congruence , which has an axiomatization that comprises two more ( schematic ) axioms , one of which reads and thus expresses that if evaluates to , a consecutive evaluation of also evaluates to , so the conditional statement at the -position will not be evaluated and can be replaced by any other . as an example , , and the left - hand and right - hand conditional statements are equivalent respect to repetition - proof valuation congruence , but are not equivalent respect to free valuation congruence . in section we characterize repetition - proof valuation congruence by defining a transformation on evaluation trees that yields repetition - proof evaluation trees : two conditional statements are equivalent respect to repetition - proof valuation congruence if , and only if , they have equal repetition - proof evaluation trees . although this transformation on evaluation trees is simple and natural , our proof of the mentioned characterization |which is phrased as a completeness result| is non - trivial and we could not find a proof that is essentially simpler . valuation congruences that identify more conditional statements than repetition - proof valuation congruence are contractive , memorizing , and static valuation congruence , and these are all defined and axiomatized in . in sections , each of these valuation congruences is characterized using a transformation on evaluation trees : two conditional statements are c - valuation congruent if , and only if , their c - transformed evaluation trees are equal . these transformations are simple and natural , and only for static valuation congruence we use a slightly more complex transformation . in section we discuss the general structure of the proofs of these results , which are all based on normalization of conditional statements . the paper ends brief digression on short - circuit logic , an example on the use of repetition - proof valuation congruence , and some remarks about side effects . a spin - off of our approach can be called `` basic form semantics for proposition algebra '' : for each valuation congruence c that we consider ( including the case c = free ) , two conditional statements are c - valuation congruent if , and only if , they have equal c - basic forms , where c - basic forms are obtained by a syntactic transformation of conditional statements , which is a form of normalization . consider the signature constants and for the truth values and , respectively , and constants for atomic propositions , further called atoms , from some countable set . we write for the set of closed terms , or conditional statements , over the signature . given a conditional statement , we refer to as its central condition . we define the dual of as follows : observe that is a self - dual axiomatization : when defining for each variable , the dual of each axiom is also in , and hence a natural view on conditional statements in involves short - circuit evaluation , similar to how we consider the evaluation of an `` '' expression . the following definition is taken from . the set of * evaluation trees over leaves in * is defined inductively by the operator is called * post - conditional composition over *. in the evaluation tree , the root is represented by , the left branch by and the right branch by . we refer to trees in as evaluation trees , or trees for short . post - conditional composition and its notation stem from . evaluation trees play a crucial role in the main results of . in order to define our `` evaluation tree semantics '' , we first define the leaf replacement operator , ` replacement ' for short , on trees in as follows . let and . the replacement of and in , denoted ,\\ ] ] is defined by &= y,\\\\ { }}&= z,\\\\ ( x'{{{\\footnotesize}}}a{{{\\footnotesize}}}x'') & = x'{{{\\footnotesize}}}a{{{\\footnotesize}}}x''.\\ ] ] we note that the order in which the replacements of leaves of is listed is irrelevant and we adopt the convention of not listing identities inside the brackets , e.g. , =x\\;~~\\;\\;~~\\;\\;~~\\; a { }} a { }} { }}\\;\\triangleleft~~\\triangleright\\; ] , and thus . the two remaining cases can be proved in a similar way . for all , we first prove . by lemma , is a congruence relation and it easily follows that all -axioms are sound . for example , soundness of axiom follows from \\\\ & = \\big(se(r)\\big)\\;\\\\ & = se(r) , { }}\\mapsto \\,se(s)]\\\\ & = se(r)\\\\ & = se((p{{{\\footnotesize}}}q{{{\\footnotesize}}}u){{{\\footnotesize}}}r{{{\\footnotesize}}}(p{{{\\footnotesize}}}s{{{\\footnotesize}}}u)).\\ ] ] in order to prove , let . according to lemma there exist basic forms and such that and , so . by soundness we find , so by lemma , . hence , . a consequence of the above results is that for each there is a unique basic form , and that for each basic form , its -image has exactly the same syntactic structure ( replacing by , and by ) . in the remainder of this section , we make this precise . the * basic form function * is defined as follows , where : .\\ ] ] given , the auxiliary function :{ a}} a}} ] is adopted , is defined as follows : &=q,\\\\ { }}&=r,\\\\ ( p 1{{{\\footnotesize}}}a{{{\\footnotesize}}}p 2) & = p 1{{{\\footnotesize}}}a{{{\\footnotesize}}}p 2.\\ ] ] ( the notational overloading leaf replacement functions on valuation trees is harmless ) . so , for given , the auxiliary function ] ) replaces all -occurrences in by , and all -occurrences in by . the following two lemma s imply that is a normalization function . for all , is a basic form . by structural induction . the base cases are trivial . for the inductive case we find \\;\\triangleleft~~\\triangleright\\; ] , and thus . the two remaining cases can be proved in a similar way . before proving that is an axiomatization of the relation , we show that each instance of the axiom satisfies . for all , by definition , the lemma s statement is equivalent \\big)\\;\\\\ & = { }}(p).\\ ] ] by lemma , , ,and are basic forms . we prove by structural induction on the form that can have . if , then \\big)&\\; { }}(p 1) \\ ] ] and & = { }}(q 1{{{\\footnotesize}}}p 1{{{\\footnotesize}}}q 2)\\\\ & = { }}(p 1).\\ ] ] if , then follows in a similar way . the inductive case is trivial ( by definition of the last defining clause of the auxiliary functions a { }} a { }} { }} a { }} a { }} { }} a a a { }} { }} { }} { }} a { }} { }} a b a { }} { }} { }} { }} a b { }} { }} { }}\\;\\triangleleft~~\\triangleright\\;\\;\\triangleleft~~\\triangleright\\;\\;\\triangleleft~~\\triangleright\\;\\;\\triangleleft~~\\triangleright\\;\\;\\triangleleft~~\\triangleright\\;\\;\\triangleleft~~\\triangleright\\;\\;\\triangleleft~~\\triangleright\\;\\;\\triangleleft~~\\triangleright\\;\\;\\triangleleft~~\\triangleright\\; a b a { }} { }} { }} { }} a b { }} { }} b { }} { }} b a { }} { }} a { }} { }} a b { }} { }} b { }} { }} b a { }} { }} a { }} { }} ] and $ ] ( and is also defined for short - circuited disjunction ) , and the associated completeness proof is based on decomposition properties of such evaluation trees . for repetition - proof valuation congruence it is an open question whether a finite , equational axiomatization of the short - circuited binary propositional connectives exists , and an investigation of repetition - proof evaluation trees defined by such connectives might be of interest in this respect . we conclude example on the use of that is based on ( * ? ? ? * ex.4 ) . let be a set of atoms of the form ` ( e==e ' ) ` and ` ( n = e ) ` some initialized program variable and arithmetical expressions over the integers that may contain . assume that ` ( e==e ' ) ` evaluates to if and represent the same value , and ` ( n = e ) ` always evaluates to true effect that s value is assigned to . then these atoms satisfy the axioms of . follow from , e.g. , . we note that a particular consequence of in the setting of short - circuit logic is ( cf . example ) , and that example is related to the work of wortel , where an instance of propositional dynamic logic is investigated in which assignments can be turned into tests ; the assumption that such tests always evaluate to true is natural because the assumption that assignments always succeed is natural . ] notice that if has initial value 0 or 1 , and evaluate to different results , so the atom ` ( n = n+1 ) ` does not satisfy the law , by which this example is typical for the repetition - proof characteristic of . end example . we finally note that all valuation congruences considered in this paper can be used as a basis for systematic analysis of the kind of side effects that may occur upon the evaluation of short - circuited connectives as in example , and we quote these words of parnas : `` most mainline methods disparage side effects as a bad programming practice . yet even in well - structured , reliable software , many components do have side effects ; side effects are very useful in practice . it is time to investigate methods that deal side effects as the normal case . '' bergstra , j.a . and ponse , a. ( 2012 ) . proposition algebra and short - circuit logic . in f. arbab and m. sirjani ( eds . ) , proceedings of the 4th international conference on fundamentals of software engineering ( fsen 2011 ) , tehran . volume 7141 of lecture notes in computer science , pages 15 - 31 . springer - verlag .", "summary": "proposition algebra is based on hoare s conditional connective , which is a ternary connective comparable to if - then - else and used in the setting of propositional logic . conditional statements are provided simple semantics that is based on evaluation trees and that characterizes so - called free valuation congruence : two conditional statements are free valuation congruent if , and only if , they have equal evaluation trees . free valuation congruence is axiomatized by the four basic equational axioms of proposition algebra that define the conditional connective . valuation congruences that identify more conditional statements than free valuation congruence are repetition - proof , contractive , memorizing , and static valuation congruence . each of these valuation congruences is characterized using a transformation on evaluation trees : two conditional statements are c - valuation congruent if , and only if , their c - transformed evaluation trees are equal . these transformations are simple and natural , and only for static valuation congruence a slightly more complex transformation is used . also , each of these valuation congruences is axiomatized in proposition algebra . a spin - off of our approach is `` basic form semantics for proposition algebra '' : for each valuation congruence c considered , two conditional statements are c - valuation congruent if , and only if , they have equal c - basic forms , where c - basic forms are obtained by a syntactic transformation of conditional statements , which is a form of normalization . conditional composition , evaluation tree , proposition algebra , short - circuit evaluation , side effect"}
{"article": "one of the most interesting topic of quantum physics in recent days is the characterization of universal properties of bosonic many - body system in the unitary regime . by using the feshbach resonance the two - body scattering length is tuned to very large values . the unitary regime is characterized by simple universal laws . for weakly interacting dilute bose gas , the gas like state becomes unstable as increases . however the efimov effect in quantum three - body systems leads to different concept of universality . efimov effect appears in the three - body level ( =3 ) where the attractive two - body interaction is such that the scattering length is much larger than the range of the interaction . under such condition , a series of weakly bound and spatially extended states of efimov character appears in the system . although the efimov character and ultracold behaviour of fermi gas is well understood , the exhaustive study of bosonic system large scattering length are few . helium trimer is a well studied quantum three - body system in this direction , its first excited state is theoretically claimed as of efimov state , however no experimental observation is still reported . whereas the recent experimental observations of efimov phenomena in ultracold gases has drawn interest in the study of universality in few - body quantum systems but the extension of efimov physics for larger system is not straightforward . there are several studies in this direction which predicted the universality of the system . though predictions and conclusions made in these works are qualitatively similar quantitative differences exist . this necessitates further study of universal properties of bosonic cluster state having efimov character . + in this work we consider few - bosonic clusters of rb atoms interacting der waals interaction . our motivation also comes from recent experiments of weakly bound molecules created from ultracold bose gas . utilizing the feshbach resonance the effective interatomic interaction can be essentially tuned to any desired value . for weakly interacting dilute systems , the efimov state appears at unitary . our motivation is to study the near threshold behaviour of weakly bound three - dimensional clusters . to characterize this delicate system we prescribe two - body correlated basis function for the many - body cluster interacting through shape - dependent two - body van der waals potential . we expect that our present study will explore the generic behaviour of three - dimensional bosonic cluster near the unitary . the usage of realistic potential short range repulsive core and long - range attractive tail may give qualitative conclusion as before but different quantitative behaviours are expected . the paper is organized as follows . in . ii we discuss the many - body hamiltonian and numerical calculation . iii considers the results and exhibit the signature of universal cluster states efimov character . iv concludes summary . we approximately solve the many - body schrdinger equation by potential harmonic expansion method ( phem ) . we have successfully applied phem to study different properties of bose einstein condensate and atomic clusters . the method has been described in detail in our earlier works . we briefly describe the method below for interested readers . we consider a system of rb atoms , each of mass and interacting via two - body potential . the hamiltonian of the system is given by here is the two - body potential and is the position vector of the th particle . it is usual practice to decompose the motion of a many - body system into the motion of the center of mass where the center of mass coordinate is and the relative motion of the particles in center of mass frame . for atomic clusters , the center of mass behaves like a free particle in laboratory frame and we set its energy zero . hence , we can eliminate the center of mass motion by using standard jacobi coordinates , defined as and obtain the hamiltonian for the relative motion of the atoms here is the sum of all pair - wise interactions expressed in terms of jacobi coordinates . the hyperspherical harmonic expansion method ( hhem ) is an ab - initio complete many - body approach and includes all possible correlations . the hyperspherical variables are constituted by the hyperradius and hyperangular variables which are comprised of spherical polar angles associated jacobi vectors and hyperangles given by their lengths . however the calculation of potential matrix elements of all pairwise potentials becomes a formidable task and the convergence rate of the hyperspherical harmonic expansion becomes extremely slow for , due to rapidly increasing degeneracy of the basis . thus hhem is not suitable for the description of large diffuse atomic clusters . but for a diffuse cluster like rb - cluster , only two - body correlation and pairwise interaction are important . therefore we can decompose the total wave function into two - body faddeev component for the interacting pair as it is important to note that is a function of two - body separation and the global only . therefore for each of the interacting pair of a particle system , the active degrees of freedom is effectively reduced to only four , viz . , and and the remaining irrelevant degrees of freedom are frozen . since is decomposed into all possible interacting pair faddeev components , all two - body correlations are included . thus the physical picture for a given faddeev component is that when two particles interact , the rest of the particles behave as inert spectators.thus the effect of two - body correlation comes through the two - body interaction in the expansion basis . it is to be noted that is symmetric under the exchange operator for bosonic atoms and satisfy the faddeev equation \\phi {ij } = -v( {ij})\\sum {kl > k}^{n}\\phi {kl } \\ ] ] where is the total kinetic energy operator . applying the operator on both sides of eq . , we get back the original schrdinger equation . since we assume that when pair interacts the rest of the bosons are inert spectators , the total hyperangular momentum and the orbital angular momentum of the whole system is contributed by the interacting pair only . next the th faddeev component is expanded in the set of potential harmonics ( ph ) ( which is a subset of hyperspherical harmonic ( hh ) basis and sufficient for the expansion of ) appropriate for the partition as denotes the full set of hyperangles in the -dimensional space corresponding to the interacting pair and is called the ph . it has an analytic expression : is the hh of order zero in the dimensional space spanned by jacobi vectors ; is the hyperangle between the -th jacobi vector and the hyperradius and is given by = . for the remaining noninteracting bosons we define hyperradius as such that . the set of quantum numbers of hh is now reduced to only as for the non - interacting pair and for the interacting pair , and . thus the dimensional schrdinger equation reduces effectively to a four dimensional equation relevant set of quantum numbers : energy , orbital angular momentum quantum number , azimuthal quantum number and grand orbital quantum number for any . substituting eq . in eq . and projecting on a particular ph , a set of coupled differential equation for the partial wave is obtained u {kl}(r ) + }}f {kl}v {kk^{\\prime}}(r ) f {k^{\\prime}l } u {k^{\\prime}l}(r ) = 0&\\\\ \\ ] ] + where , , and . + is a constant and represents the overlap of the ph for interacting partition sum of phs corresponding to all partitions . the potential matrix element is given by we do not require the additional short - range correlation function as mentioned in ref . it is already pointed out that the universal properties of ultracold dilute atomic gas in the unitary regime is characterized when the two - body scattering length is tuned to very large values by using the feshbach resonance . although the unitary fermi gas has been largely investigated both experimentally and theoretically , the bosonic unitary regime is a formidable challenge in the many - body theories . even though the range of the interaction is small compared particle separation , interatomic correlations are very important and the standard mean - field theories are inadequate . + the interaction strength of sufficiently dilute atomic cloud is parameterized by a single parameter - the -wave scattering length . however for our present study to explore the generic behaviour near the unitary , we consider the van der waals potential characterized by two parameters : the cutoff radius of the repulsive hard core and the strength of the long - range tail . thus keeping fixed , it is possible to tune the value of . solving the two - body schrdinger equation it is possible to calculate the scattering length for each choice of . we solve the zero - energy two - body schrdinger equation for the two - body wave function as where for and for . the asymptotic form of is , is the normalization constant . the solution of two - body equation shows that the value of changes from negative to positive passing through an infinite discontinuity . in fig . , we plot the zero - energy scattering length as a function of . at each discontinuity , one extra node in the two - body wave function appears which corresponds to one extra two - body bound state . however for our present study we fix such that it corresponds to zero node in the two - body wave function . we impose the constraint just to avoid the formation of the molecules , otherwise when sufficiently increases , the rate of three - body collisions will increase which deplete the density by forming molecules . + above set of parameters we solve the set of coupled differential equations ( cdes ) by hyperspherical adiabatic approximation ( haa ) . in haa , we assume the hyperradial motion is slow compared to the hyperangular motion . thus the solution of the hyperangular motion is obtained by diagonalizing the potential matrix including the diagonal hypercentrifugal repulsion for a fixed value of . the cde is then decoupled approximately into a single uncoupled differential equation \\zeta {0}(r)=0\\hspace*{.1 cm } , \\ ] ] which is known as extreme adiabatic approximation ( eaa ) and the lowest eigenvalue is the effective potential in which the hyperradial motion takes place . the above equation is solved to obtain the energy and wave function appropriate boundary conditions on . + in fig . , we plot the calculated bosonic cluster ground state energies in the negative scattering length near the unitary for different cluster sizes = 3,4,5,6,7 as a function of the scattering length which represents the universal properties of the bosonic cluster energy at large . it is to be noted that the effective interaction of the bosonic cluster is determined by . increase in particle number , the number of interacting pair also increases and the energy becomes more negative as expected . for two particles the infinite scattering length corresponds to a bound state at zero energy . for three particles the efimov effect appears at or = 0 , infinitely many three - body bound states smaller binding energy and larger radii will appear . moving in the opposite by decreasing the attraction , these states cease to be bound one by one . we have calculated the spectrum of bosonic clusters and in fig . we plot as a function of the state number of the negative energy states . the radii of efimov states as a function of state number is shown in fig . . , we observe that for each of the -body systems there is a series of bound states exceedingly small energies . it is seen that these series of states show exponential dependence upon the state number as . the exponential fits give the numbers as = 0.448 , = 0.278 , = 0.198 , = 0.149 . whereas in fig . , we observe that the spatial extension of efimov states is much larger than the interaction range and the r. m. s. radii of efimov states are well reproduced exponential where the fitted parameters are = 0.18 , = 0.12 , = 0.09 and = 0.068 . the ratio = 0.41 for = 4 , 0.43 for = 5 , 0.46 for = 6 and 0.47 for = 7 , is close to the value of 0.5 as reported in ref . for trapped bosons . finally we analyse the structural properties of the cluster states by calculating the pair - correlation function which determines the probability of finding the pair of particles at a relative separation . presents the pair correlation function for at unitarity . is considered as a more effective quantity in the description of structural properties as the interatomic interaction plays a crucial role . when atoms try to form clusters , due to the attractive part of van der waals interaction , the short range hard core repulsion has the effect of repulsion , thus is zero for smaller than the hard core radius . we calculate by where is the many - body wave function and the integral over the hypervolume excludes the integration over . the position of the maximum is shifted to larger increase in and peak height reduces . however we do not observe any structure in the correlation function . it says that the extremely diffuse cluster behaves just like diffuse liquid blob as observed in earlier work . it is already mentioned that while the universal behaviours of the trimer are quite well understood , much less is known about the larger systems . in this context the investigation of correlations between energies of three and four - particle systems is indeed required . the earlier studies in this direction are mainly focused on the tjon line which refers to the approximately linear correlation between the energies of three - nucleon and four - nucleon systems . it is expected that the bosonic cluster energy close to the unitarity , for different cluster states should follow the generalized tjon line . it says that the energies are linearly correlated to each other and a two - parameter relation is maintained . in fig . , we present the energy ratio as a function of for different cluster sizes = 4,5,6 . solid lines show linear fits of the form . the fitting parameters are summarized in table . we refer the approximate linear fitting of the energy ratios of clusters as the generalized tjon line . we observe that the values of the fitting parameters gradually decreases increasing and this is consistent earlier finding . .values of fitting parameters of tjon line . this definitely opens the possibilities of future investigations of how the behaviour of the generalized tjon lines are related in the description of the universal properties of diffuse bosonic clusters . cc + ( a ) & + & + ( b ) & + + ( c ) & + the physics of weakly bound few - body systems and their universal behaviour near the unitary is a challenging research area in recent days . the recent experimental observation of efimov phenomena in ultracold bose gases has renewed the interest in universal few - body physics . the theoretical study of three - dimensional bosonic cluster more than three particles is also challenging and the numerical treatment becomes complicated . the cluster is weakly bound as the kinetic and potential energy nearly cancel . it needs to include interatomic correlation . in the present study we utilize two - body correlated basis function for the study of -boson systems . use of realistic van der waals potential presents the actual feature of such delicate systems . we calculate the energy spectrum of -body cluster upto 7 atoms . at large scattering length , which is much larger than the range of interaction , the ground state energy of -body cluster shows universal behaviour . next , to exhibit the efimov like character of the energy states we present the exponential dependence on the state number . we also calculate the r.m.s radii of the spatially extended systems and also shows their exponential dependence on the state number . calculation of two - body pair correlation exhibit the expected feature and does not show any structure . it says that the weakly interacting cluster behaves just like a single quantum stuff . we also calculate the energy correlation between two clusters differing by one atom and shows that they maintain a two parameter linear relation . we refer the tjon line as the characteristic of universal behaviour of bosonic cluster . bc would like to thank the university of south africa ( unisa ) for the financial support of visit where part of work was done . bc also acknowledges financial support of dst ( india ) under the research grant sr / s2/cmp-0126/2012 .", "summary": "we study three - dimensional bosonic cluster interacting through van der waals potential at large scattering length . we use faddeev - type decomposition of the many - body wave function which includes all possible two - body correlations . at large scattering length , a series of efimov - like states appear which are spatially extended and exhibit the exponential dependence on the state number . we also find the existence of generalized tjon lines for - body clusters . signature of universal behaviour of weakly bound clusters can be observed in experiments of ultracold bose gases ."}
{"article": "the visionary who first thought of using the spin polarization of a single electron to encode a binary bit of information has never been identified conclusively . folklore has it that feynman mentioned this notion in casual conversations ( circa 1985 ) , but to this author s knowledge there did not exist concrete schemes for implementing spintronic logic gates till the mid . encoding information in spin may have certain advantages . first , there is the possibility of lower power dissipation in switching logic gates . in charge based devices , such as metal oxide semiconductor field effect transistors , switching between logic 0 and logic 1 is accomplished by moving charges into and out of the transistor channel . motion of charges is induced by creating a potential gradient ( or electric field ) . the associated potential energy is ultimately dissipated as heat and irretrievably lost . in the case of spin , we do not have to move charges . in order to switch a bit from 0 to 1 , or vice versa , we merely have to toggle the spin . this may require much less energy . second , spin does not couple easily to stray electric fields ( unless there is strong spin - orbit interaction in the host material ) . therefore , spin is likely to be relatively immune to noise . finally , it is possible that spin devices may be faster . if we do not have to move electrons around , we will not be limited by the transit time of charges . instead , we will be limited by the spin flip time , which could be smaller . in 1994 , we proposed a concrete scheme for realizing a classical universal logic gate ( nand ) using three spins placed in a weak magnetic field . by `` three spins '' , we mean the spin orientations of three conduction band electrons , each confined in a semiconductor quantum dot . the system is shown schematically in fig . exchange interaction is allowed only between nearest neighbor spins ( second nearest neighbor interaction is considered too weak to have any effect ) . because of the magnetic field , the spin orientation in any quantum dot becomes a binary variable . the spin polarization is either along the magnetic field , or opposite to the field . to understand this , consider the hamiltonian of an isolated dot : where is the unperturbed hamiltonian in the absence of the magnetic field , is the magnetic field , is the land g - factor of the quantum dot material , is the bohr magneton , and is the pauli spin matrix . if the magnetic field is directed along the z - direction , then diagonalizing the above hamiltonian yields the eigenspinors ( 1,0 ) and ( 0,1 ) which are + z and -z polarized spins . therefore , the spin orientation is a binary variable ; it is either parallel or anti - parallel to the applied magnetic field . in the presence of exchange interaction between two electrons confined to two separate potentials ( such as two different quantum dots ) , the anti - ferromagnetic ordering , or the singlet state , ( i.e. two neighboring spins are anti - parallel ) is preferred over the ferromagnetic ordering , or triplet state ( two spins are parallel ) . we will assume that the tendency to preserve this anti - ferromagnetic ordering is stronger than the tendency for all spins to line up along the magnetic field . this merely requires that the exchange splitting energy ( energy difference between triplet and singlet states ) exceed the zeeman splitting energy . we ensure this by reducing the potential barrier between neighboring dots to enhance the exchange , while at the same time , making the magnetic field sufficiently weak to reduce the zeeman energy . under this scenario , the ground state of the array has the spin configuration shown in fig . we will call `` upspin '' the spin orientation directed along the magnetic field and `` downspin '' the opposite orientation . we encode logic 1 in the upspin state . furthermore , we will consider the two edge dots in fig . 1(a ) as input ports to a logic gate , and the middle dot as the output port . it is obvious that when the two inputs are logic 1 , the output will be logic 0 when the system reaches ground state ( anti - ferromagnetic ordering ) . next , consider the situation when the two inputs are logic 0 ( see fig . the output must be logic 1 in order to conform to the anti - ferromagnetic ordering . however , there is a subtle issue . 1(b ) is actually not the ground state of the system , fig . this is because of the weak magnetic field . the difference between fig . 1(a ) and fig . 1(b ) is that in the former case , two spins are aligned parallel to the magnetic field , while in the latter , two spins are aligned anti - parallel to the magnetic field . therefore , if the system is left in the state of fig . 1(b ) , it must ultimately decay to the state in fig . 1(a ) , according to the laws of thermodynamics . but that may take a very long time because of three reasons . first , the system must emit some energy carrying entity to decay . this entity is most likely a phonon . however , phonon emissions in quantum dots are suppressed by the `` phonon bottleneck '' effect . second , phonons do not couple easily to spin unless we have a strongly pyroelectric material as the host . finally , if spins flip one at a time ( all three spins flipping simultaneously is very unlikely ) , then in order to access the state in fig 1(a ) , the state in fig . 1(b ) will have to go through a state where two neighboring spins will be parallel . such a state is much higher in energy than either fig . 1(a ) or fig . therefore , fig . 1(a ) and fig . 1(b ) are separated by an energy barrier , making fig . 1(b ) a long lived metastable state . as long as the input bit rate is high enough so that inputs change much more rapidly than the time it takes for the metastable state to decay to the global ground state of fig . 1(a ) , we need not worry about this issue . what happens if one of the inputs is logic 1 , and the other is logic 0 as shown in fig . 1(c ) ? here the magnetic field comes in handy to break the tie . in this case , logic 1 is preferred as the output since the all other things being equal , a spin would prefer to line up parallel to the magnetic field , rather than anti - parallel . thus , when either input is logic 0 , the ouput is logic 1 . we have realized the truth table in table 1 . .truth table of a spintronic nand gate the reader will recognize that this is the truth table of a nand gate , which is one of two universal boolean logic gates . since we can realize a nand , we can realize any arbitrary boolean logic circuit ( combinational or sequential ) by connecting nand gates . a number of different logic devices ( half adders , flip - flops , etc . ) were designed and illustrated in ref . . these devices have been extensively studied by others using time independent simulations . the time - independent simulations address the steady state behaviors and therefore do not directly reveal a serious problem these devices that was already recognized in ref . . in the following section , we explain this problem . at the time these logic gates were proposed , it was also realized that they have a severe shortcoming that precludes their use in pipelined architectures . to understand the nature of the problem , consider three inverters ( not gates ) in series . a single not gate is the simplest device ; it is realized by two exchange coupled spins , one of which is the input and the other is the output . because of the anti - ferromagnetic ordering , the output is always the logic complement of the input . 2(a ) shows three conventional inverters in series and fig . 2(b ) shows the corresponding spintronic realization . the input to the first inverter is logic 1 and the output of the last inverter is logic 0 , as it should be . but now , let us suddenly change the input at the first inverter to logic 0 at time = 0 . the situation at time = 0 + is shown in fig . we expect that ultimately the output of the last inverter will become logic 1 . unfortunately , this can not happen . in fig . 2(c ) , the second spin from the left finds its left neighbor asking it to flip ( because of the exchange interaction that enforces anti - ferromagnetic ordering between two neighboring spins ) while its right neighbor is asking it to stay put because of the same exchange interaction . both influences from the left and from the right are exactly equally strong and the second cell is stuck in a logic indeterminate state that it can not get out of . rolf landauer later termed it a metastable state that prevents decay to the desired ground state . in fact , if we take the external magnetic field into account , then there is a preference for the second cell to actually not flip in response to the input since there is a slight preference for the upspin state because of the external magnetic field . in this case , the logic signal can not propagate from the input to the output and the circuit simply does not work ! similar situations were examined in ref . the real problem is that exchange interaction is bidirectional which can not ensure unidirectional flow of logic signal from the input to the output of the logic device . this unidirectionality is a required attribute of any logic device ( for the five necessary requirements of a classical logic device , see ref . ) . we can think of desperate measures to enforce the unidirectionality . for example , we can claim that if we hold the input at the first inverter ( leftmost cell in fig . 2(c ) ) to logic 0 , and do not let go , then the second cell which is equally likely to follow its left neighbor and right neighbor , will have no option but to ultimately follow its left neighbor since it is adamant and persistent ( we are not letting go of the input ) . this will happen in spite of the magnetic field since the exchange energy is larger than the zeeman splitting . in this case , we are trying to enforce unidirectionality via the input signal itself ( note that the input device does indeed break the inversion symmetry of the system in fig . this possible remedy was studied theoretically in ref . which reached the conclusion that it does not always work . in fact , the process of logic signal propagation under this scenario is inefficient thermally assisted random walk and the final logic state , if reached , can be destroyed by thermal fluctuations . the idea of using the input device to enforce unidirectionality was also implicitly used in the experiment of ref . . while this may work for a few cells ( as it did in ref . ) , it will obviously not work for a large number of cells since the influence of the input decays increasing distance from the input . ultimately , the remote cells that are far from the input , will not feel the input s effect and remain stuck in metastable states , producing wrong answers to simple logic problems . in ref . , one solution that was offered to break this impasse was to progressively increase the distance between cells . this makes the influence of the left neighbor always stronger than that of the right neighbor since the strength of the exchange interaction has an exponential dependence on the separation between neighboring cells . this is not an elegant solution since ultimately the exchange splitting energy will become smaller than the zeeman splitting energy , at which point the paradigm will no longer work . in 1996 , we proposed a more elegant solution . this was inspired by the realization that in charge coupled device ( ccd ) arrays , there is no inherent unidirectionality , yet charge is made to propagate from one device to the next unidirectionally . this is achieved by clocking . we mentioned that unidirectionality can be imposed in time or space and clocking imposes unidirectionality in time . however , a cursory examination revealed that normal clocking will not work in our case . say , we put gate pads on the barriers between neighboring cells . initially , all the the barriers are high and opaque so that there is no overlap between the wavefunctions of adjacent electrons and hence no exchange interaction between neighboring spins . now , we lower the first barrier by applying a positive potential to gate 1 as shown in fig . this allows the wavefunctions of electrons on either side of the gate pad to leak out into the barrier , overlap . and cause an exchange interaction . exchange causes the second spin to assume a polarization anti - parallel to the input spin orientation since the singlet state is lower in energy than the triplet . in other words , the second cell switches . at this point , if we let go of the input , raise the first barrier back up , and lower the second barrier by applying a positive potential to gate 2 , then either the third cell switches in response to the second ( which is shown in the upper branch ) , or the second cell switches in response to the third ( which is shown in the lower branch ) . the upper branch is the desired state , but it is equally likely that the lower branch will result since both branches obey the ant - ferromagnetic ordering between the two exchange coupled cells ( cell 2 and 3 ) . therefore , a simple sequential clock will not work . what is required is that both gate 1 and gate 2 have positive potentials while the input is applied . now the first three cells assume the correct polarizations as shown in fig . then , the input is removed , gate 1 is returned to zero potential and positive potentials are applied to gates 2 and 3 . this causes the first four cells to assume the correct polarization , and so on . this situation is shown in fig . 2(f ) and is the desired configuration . thus by lowering two adjacent barriers pairwise at the same time , we can propagate the input state through a linear array . in other words , we will need a three - phase clock , a single phase will not work . the three clock pulse trains for a three - phase clock are shown in fig . each train is phase shifted from the previous one by radians . such a situation is not unusual since charge coupled device arrays also need a multi - phase clock ( push clock , drop clock ) to work . while , multi - phase clocking can make these devices work , it is hardly an attractive solution since one needs to fabricate gate pads between every two cells . the separation between the cells may need to be 5 nm in order to have sufficient exchange coupling . aligning a gate pad to within a space of 5 nm is a major lithography challenge . furthermore , the gate potentials are lowered and raised by moving charges into and out of the gate pads , leading to considerable energy dissipation that completely negates the advantage of using spins . therefore , these devices present interesting physics , but at this time , do not appear to be serious candidates for practical applications . so far , we have discussed the use of spin in classical irreversible logic gates . these logic gates dissipate a minimum of amount of energy per bit flip . let us assume that we can make quantum dots density of 10 . quantum dots self assembled by electrochemical techniques in our own lab ( and in many other labs ) can achieve this density today . we show a raw atomic force micrograph of quantum dots self assembled in our lab in fig . 3 . the dark areas are the dots and the surrounding light areas are the barriers . the dot diameter in this micrograph is 50 nm and the dot density is close to 10 . by using slightly different synthesis conditions , we can actually achieve densities exceeding 10 . let us now assume that we can flip the spin in a quantum dot in 1 psec . then the minimum power that will be dissipated per unit area will exceed /(1 psec ) = 3 kw/ ( actually most of the power will be dissipated in the clock cycles , which we have ignored ) . this dissipation is at least 30 times more than what the pentium iv chip dissipates . although removal of 1 kw/ of heat from a chip was demonstrated almost two decades ago , removing 3 kw/ from a chip is still a major challenge in heat sinking . the obvious way to overcome ( or , rather , circumvent ) this challenge is to develop reversible logic gates that are not constrained by the landauer barrier . in 1996 , we devised a logically and physically reversible quantum inverter using two exchange coupled spins . this device is very similar to the single electron parametron idea and can be viewed as a single spin parametron . since either spin could exist in a coherent superposition of two orthogonal spin states ( call them `` upspin '' and `` downspin '' states ) , this would also be a `` qubit '' . later , loss and divincenzo devised a universal quantum gate using two exchange coupled spins in two closely spaced quantum dots . recently , experimental demonstration of coherent transfer of electron spins between quantum dots coupled by conjugated molecules has been demonstrated , opening up real possibilities in this area . the idea of using a single electron or nuclear spin to encode a qubit and then utilizing this to realize a universal quantum gate , has taken hold . the motivation for this is the realization that spin coherence times in solids is much larger than charge coherence time . charge coherence times in semiconductors tend to saturate to about 1 nsec as the temperature is lowered . this is presumably due to coupling to zero point motion of phonons which can not be eliminated by lowering temperature . on the other hand , electron spin coherence times of 100 nsec in gaas at 5 k has already been reported and much higher coherence times are expected for nuclear spins in silicon . therefore , spin is obviously the preferred vehicle to encode qubits in solids . using spin to carry out all optical quantum computing has also appeared as a viable and intriguing idea . the advantage of the all - optical scheme over the electronic scheme is that we do not have to read single electron spins electrically to read a qubit . electrical read out is extremely difficult , although some schemes have been proposed for this purpose . recently , some experimental progress has been made in this direction , but reading a single qubit in the solid state still remains elusive , . the difficult part is that electrical read out requires making contacts to individual quantum dots , which is an engineering challenge . in contrast , optical read out does not require contacts . the qubit is read out using a quantum jump technique which requires monitoring the fluorescence from a quantum dot . recently , it has been verified experimentally that the spin state of an electron in a quantum dot can be read by circularly polarized light . therefore , optical read out appears to be a more practical approach . in this article we have provided a brief history of the use of single electron spin in computing . we have indicated where and why spin may have an advantage over charge in implementing the type of devices and architectures discussed here . s. bandyopadhyay and v. p. roychowdhury , proceedings of the international conference on superlattices and microstructures , liege , belgium , 1996 , also in superlat . 3 , 411416 ( 1997 ) . t. calarco , a. datta , p. fedichev , e. pazy and p. zoller , phys . rev . a , vol . 68 , no . 1 , 012310 - 1 012310 - 21 ( 2003 ) ; e. pazy , e. biolattia , t. calarco , i. d amico , p. zanardi , f. rossi and p. zoller , europhys . 62 , 175 ( 2003 ) .", "summary": "this article reviews the use of single electron spins to compute . in classical computing schemes , a binary bit is represented by the spin polarization of a single electron confined in a quantum dot . if a weak magnetic field is present , the spin orientation becomes a binary variable which can encode logic 0 and logic 1 . coherent superposition of these two polarizations represent a qubit . by engineering the exchange interaction between closely spaced spins in neighboring quantum dots , it is possible to implement either classical or quantum logic gates ."}
{"article": "circumstellar material holds clues about the mass - loss history of massive stars . indeed , as the winds interact interstellar medium ( wind - blown bubbles , bow shocks ) , they leave a characteristic signature that depends on the wind properties . moreover , the material ejected during short eruptive phases is visible as nebulae around massive stars . the analysis of these features reveals which material was ejected and in which quantity . recent reduction in mass - loss rates , these episodes of enhanced mass - loss have gained more attention , as they seem more crucial than ever in the evolution of massive stars . another reason to study the close environment of massive stars is to better understand the evolution of supernova remnants ( snrs ) . indeed , the famous rings of sn1987a may only be understood if one considers the previous mass - loss episodes of the progenitor . morphology is not the only snr parameter which is affected , as the snr dynamics in an homogeneous medium or in winds and circumstellat ejecta is not identical . for its study , the ir provides several key diagnostics . continuum emission in this range is provided by heated dust , which may have a range of temperatures depending of the framework ( very close hot features , large , old , and cool bubbles ) . in addition , ir lines probe the many phases of the material : molecules ( e.g. pahs ) for the neutral material , ionized metals for hii regions , ... this summary of sps5 - part iii examines each case of circumstellar environment in turn , and concludes potential offered by current and future facilities . circumstellar structures around bsgs have been predominantely identified as bow shocks around runaway stars . originally discovered iras ( e.g. van buren & mccray , 1988 , apj , 329 , l93 ) , such structures have also been seen wise ( peri et al . 2012 ) . a more general survey of bsgs , i.e. not targeting runaway stars , objects selected from crowther et al . ( 2006 ) and przybilla et al . ( 2010 ) , reveals ir material around six of the 45 targets at 22 m wise , also mostly in the form of bow shocks ( wachter , in prep ) . several examples of bipolar nebulae around bsgs are also known ( e.g. sher 25 , smartt et al . 2002 ; hd 168625 , smith 2007 ) . however , this material could have also been ejected during an lbv phase , since lbvs can exhibit bsg spectra , and we will therefore concentrate on the bow shocks . emission ( greyscale ) of vela x-1 pacs 70 m emission contours shown on top . right : colour composite image of bow shock of bd+43 ( wise 12 m in blue , pacs 70 m in green , and pacs 160 m in red ) . the direction of proper motion is indicated by the arrow in both cases . from cox ( in prep.).,title=\"fig:\",width=226 ] emission ( greyscale ) of vela x-1 pacs 70 m emission contours shown on top . right : colour composite image of bow shock of bd+43 ( wise 12 m in blue , pacs 70 m in green , and pacs 160 m in red ) . the direction of proper motion is indicated by the arrow in both cases . from cox ( in prep.).,title=\"fig:\",width=226 ] runaway stars have large stellar velocities ( above 30kms ) resulting from dynamical interactions in ( dense ) clusters or from a supernova explosion in a binary system . these stars can thus travel at supersonic speeds through the local medium giving rise to `` bow shocks '' as their stellar winds interact surrounding medium , which has been previously ionised by stellar photons from the hot star ( weaver 1977 ) . the occurrence of such bow shocks has been shown to depend primarily on the ism conditions ( huthoff & kaper 2002 ) . for example , even a runaway star may travel at subsonic speeds in the tenuous interior of a superbubble , where the sound speed can be as much as 100kms , hence no ( detectable ) bow shock will be produced in that case . the filling factor of ism is 20% and 75% of o - stars have velocities kms , so the expected fraction of o - stars shocks is % . this is remarkably similar to the values derived from iras and wise observations ( noriega - crespo et al . 1997 , peri et al . 2012 ) . once formed , the size , shape and morphology of a bow shock depends on both stellar ( wind kinetic energy and stellar velocity ) and interstellar parameters ( density and temperature ) . in particular the ratio indicates whether or not instabilities are likely to develop ( dgani et al . 1996 ) , and the stand - off distance between the star and the apex of the shock is determined from the pressure balance between the stellar wind and the ism ( see analytical results by wilkin 1996 and simulations by e.g. comeron & kaper 1998 , blondin & koerwer 1998 ) . independent estimates of the wind parameters can thus be inferred from bow shocks , which serves as a useful check for atmosphere models , but the values are sensitive to the ism properties , which are not always known precision . m of the dust thermal emission obtained by kervella et al . north is up , east to the left , and the field of view is given in the upper right corner of each image . , width=529 ] currently , a small survey herschel - pacs of 5 runaways known bow - shocks is ongoing : cam , oph , cma , vela x-1 and bd+43 ( cox et al . , in preparation ) . for vela x-1 , the peak emission of the dust emission is co - spatial most prominent h arc seen in the supposed direction of space motion ( fig . ) : it is concluded that the outer shock is radiative , but the inner shock is adiabatic , though some h emission possibly related to ( part of ) the inner termination shock is also detected . from the analysis of its `` puffed - up '' bow shock ( fig . ) , the mass - loss rate of bd+43 ( o4if ) was found to be 10myr : this is very high ( by 2 orders of magnitude ) in view of current mass - loss rate estimates of such stars , but the exact value strongly depends on ism density , which need to be refined . the dust temperature , 45 k , is compatible heating by stellar photons only , suggesting there is no additional shock - heating of grains . the thickness of a bow shock ( 1 pc ) suggests a mach number close to unity , implying a ism temperature of 10 10 k. circumstellar structures on scales of a few arcseconds or less around rsgs have been revealed through interferometric techniques ( e.g. monnier et al . stencel et al . ( 1988 , 1989 ) reported the iras detection of resolved shells typical radii of a few arcminutes around rsgs for a significant fraction ( 25% ) of their sample . however , higher resolution spitzer images fail to confirm several of these extended structures ( wachter , in prep ) , indicating that a systematic survey is needed to ascertain the occurrence of large scale circumstellar shells around rsgs . m to 192 m . multitude of molecular lines have been detected . from matsuura et al . ( in prep.).,width=453 ] a few ( famous ) cases have however been studied in depth . one of these is betelgeuse , a cool ( 3600k ) , large ( 700 r ) , rather massive ( 1015 m ) , luminous ( l ) , and nearby ( 150 pc ) star . because of its distance , betelgeuse can be probed on almost all scales , providing a unique panorama of stellar surroundings ( fig . ) . space - based and interferometric instruments ( e.g. hst , iota / ionic and vlti / pionier ) revealed the photosphere , notably the expected non - uniformities due to large convection cells . adaptive optics imaging in the near - ir ( e.g. naco ) and ( radio or ir ) interferometers unveiled the properties of the internal , compact molecular envelope ( 110 r ) . precursors of dust have been found there , as well as an extended `` plume '' reaching 6r and maybe linked to a hot spot on the photosphere . high - res imaging ( e.g. vlt / visir ) shows the envelope at intermediate scales ( 10100 r ) , where the dust forms ( a possible signature of silicates has been found ) . at these small and intermediate scales , betegeuse presents a complex circumstellar envelope ( knots and filaments ) at all wavelengths , which implies an inhomogeneous spatial distribution of the material lost by the star . finally , at the largest scale , ir imagers such as herschel unveil the cool external envelope ( 100 - 10000 r ) , where a bow shock ism is detected ( cox et al . 2012 ) . m ( blue ; blue contours ) and 22 m ( red ; yellow contours ) of ws1 , discovered and initially characterized by gvaramadze et al . the contours for each band help illuminate the morphology of the nebular material , which has an overall se - nw elongation , reminiscent of bipolar structure . bottom left : optical photometric monitoring since discovery show both the r and i light curves have brightened by about 1 magnitude over the last year . arrows indicate times when same night spectroscopy were secured . right panel : optical spectroscopic monitoring indicates evolution to cooler temperature near disappearance of the he i 5876 and 6678 and changes in the line profile . figures from stringfellow et al . ( in preparation).,width=377 ] herschel has also probed the envelope of other red supergiants ( groenewegen et al . turning in particular to the case of vy cma ( matsuura et al . , in prep . ) , the potential of ir spectroscopy is obvious . herschel - spire reveals a rich spectrum , dust continuum and hundreds of lines dues to molecules ( one third linked to water , others to co , cs , sio , ... ) , which constrain the envelope s properties . for example , the isotopic ratio c/c is found to be 6.5 , in agreement observations of other rsgs but at odds theoretical predictions which are four times higher at least . very strong emission of submm molecular lines can be explained if a temperature gradient is present in the envelope , e.g. because of dust formation at a certain radius . because of their spectacular eruptions , lbvs are the most well - known cases of massive stars ejecta . it is not yet certain , however , at what stage ( bsg ? after a rsg phase or not ? ) this material is ejected , and how ( multiple events ? ) . lbvs are rare : in the list of clark et al . ( 2005 ) , there are only 12 confirmed and 23 candidate lbvs . ir has played a key role in recent years . the search , through surveys like mipsgal , of round - shaped nebulae luminous central stars resulted in the discovery of many new nebulae : 62 shells in wachter et al . ( 2010 ) , 115 shells and bipolar nebulae in gvaramadze et al . ( 2010 ) , 416 structures in mizuno et al . many of these nebulae are preferentially detected spitzer 24 m band , indicating relatively cold material . identifying shell - like structures is only the first step . to ascertain a clbv status , the central object needs to be studied spectroscopically . this was done for many of these new detections ( c.f . , gvaramadze et al . 2010 ; wachter et al . 2010 ; stringfellow et al . 2012a , b , and in preparation ) . the classification does not rely on the presence of a particular line , but rather on the morphological resemblance of the spectra to spectra of known lbvs - while not 100% perfect ( some peculiar o and wr stars display similar features ) , this method has the advantage of being simple and rather robust . a more definitive answer can be provided through photometric and/or spectroscopic monitorings . indeed , as their name indicate , lbvs should be variable . near - simultaneous photometric and spectroscopic monitoring in the optical ( and ir ) of about a dozen newly identified candidate lbvs has revealed that ws1 ( discovered by gvaramadze et al . 2012 ) is indeed a bona fide lbv , presently displaying what appears to be s dor type variability as shown in fig . ( stringfellow et al . 2012 , in preparation ) . ir is also useful in revealing details of particular objects . for example , a herschel survey of lbvs undertaken at lige yielded as first result a characterization of the surroundings of wray 15 - 751 ( vamvatira - nakou et al . , submitted ) . ir photometry can only be explained if the star evolves at constant luminosity and dust grains are fe - rich . images also revealed the presence of a second shell , about 4 times larger than the previously known one , which most probably results from an older eruptive event . considering both structures , there is about 0.075 m of dust in the system . ionized gas is responsible for several forbidden lines observed in the herschel - pacs range ( fig . ) , which allow a n / o abundance of about 7 times solar and a mass of ionized gas of 12 m ( 20 times that of dust ) , to be derived . dust can be well studied in the ir , so this range may provide clues on where dust come from in galaxies . two examples of such feedback were presented in the session : car and sn1987a . the latter was observed herschel at 100 - 500 m wavelengths , and 0.4 - 0.7 m of dust was detected - mostly silicates and amorphous carbon ( matsuura et al . it is thought that this dust come from the explosion , but the role played by previous mass - loss episodes , in particular the lbv phase , is not yet clear . for example , about 0.12 m of dust was detected , thanks to 30 m minitao observations , in the famous lbv car . up to 80% of that dust belonged to the torus , hence may not be related to the big 1843 event . only a few percentage ( 4 - 6% ) of wolf - rayet stars displays surrounding nebulosities in the wise survey , and most are found around wn stars ( wachter , in prep ) . the morphological classification scheme of wr nebulae proposed by chu ( 1981 ) has been revised in this meeting by guerrero et al . ( toal et al , in prep . ) using wise ir images and sdss or super cosmos sky survey h images for 35 nebulae associated . two wise bands were particularly used : the one at 12 m , which encompasses pah lines and lines of low excitation ions , and that at 22 m , to which thermal emission from dust and lines of he i as well as high excitation ions contribute . three phases are defined . in the first one , wr nebulae appear as complete shells or bubbles . it corresponds to the star just entering the wr stage , when its powerful wind sweeps up the previous slow and dense winds ( from e.g. lbv or rsg stages ) . the second phase is the clumpy phase . at that point , the nebulae display knots of gas and dust connected by partial shells and arcs . it corresponds to an age of a few 10yr , when instabilities break down the swept - up shell . the stellar motion through the ism has an impact on the morphology , for example one - sided arc may be sometimes seen . finally , the mixed nebular phase ends the cycle , definite morphology nor always a 1-to-1 correspondence between optical and ir images . it corresponds to the last stage , when the circumstellar nebula begins to dissolve into the ism . the close environment of massive stars is the `` missing link '' between the star itself and the large circumstellar features . it plays a key role in understanding the mass - loss , but it is also difficult to probe directly . emission lines arising in the wind and circumstellar material are a classical way to study this region , as well as near - ir excess linked to disk - like features . in this context , be and b stars are targets of choice , and surprises are frequent . for example , graus et al . ( 2012 ) found three new sgb in the smc : they display typical spectra , forbidden lines , but the line strengths as well as the ir excess appear reduced compared to usual objects of this class . it suggests that either the disks have less material or less dust than usual , or maybe that these stars are transitional objects . another case intriguingly shows the opposite situation : cd displays forbidden lines and appreciable ir excess , but is a main - sequence be star away from any star - forming region ( lee and chen 2009 ) . a possibility may be that this star is in fact a weak b , rather than a classical be . the environment close to the star can also be studied , directly , by means of interferometry , which is usually performed at long wavelengths . most optical / ir interferometric measurements rely on the measurements of `` visibilities '' , which are directly linked to the size of the object . recently , several massive stars , including nine lbvs , were observed vlti ( groh et al . , in prep . ) . amongst these , hd316285 ( fig . ) : the recorded visibilities implied a size of 0.002 for the source of continuum radiation , and 0.004 for the source of the br line . a cmfgen fit to the spectrum yields a stellar model which one can estimate the wind size in ir , and it agrees well vlti observations . the asymetric shape of the measured differential phases ( red vs blue side ) favors a prolate shape for the rotating star wind , but it could also be explained by clumps or binarity . since the latter imply in time variability , a monitoring will be needed to ascertain the exact nature of the asymmetry . = 0.19 , rather than 0.25 as von zeipel predicted in 1924.,width=377 ] while visibilities provide valuable data , `` real '' images are always more impressive . interferometric instruments such as michigan infrared combiner ( mirc ) and pionier are beginning to provide such data . mirc was the first to image altair ( monnier et al . 2007 ) and several other rapidly rotating stars as shown in fig . it has also imaged circumstellar disks and multi - object systems . for example , the disk contribution of sco was shown to remain stable during the periastron in 2011 ( che et al . 2012 ) , and the mass - exchange in the lyr system can be clearly imaged ( zhao et al . 2008 ) , as well as the 3 components of algol ( baron et al . 2012 ) or the disk of the eclipsing companion of aur ( kloppenborg et al . , 2010 ) . this session has demonstrated the usefulness of studies in the ir in studying the environment of massive stars . recent advances in this domain are notably provided by surveys , as they enable discovery of new objects to study , thereby improving the census of nebular features associated stars . furthermore , ir diagnostics unveil the properties of these neighbouring nebulosities : morphology , temperature , composition , density are the necessary keys paving the way of a better understanding of the mass - loss in massive stars . yn acknowledges comments from augusto daminelli and support from fnrs and prodex herschel / xmm - integral contracts . nljc thanks fwo and prodex - herschel for financial support . jhg is supported by an ambizione fellowship of the swiss national science foundation . cdl has been supported financially by grant nsc-101 - 2922-i-008 - 120 of the national science council of taiwan .", "summary": "the last part of sps5 dealt circumstellar environment . structures are indeed found around several types of massive stars , such as blue and red supergiants , as well as wrs and lbvs . as shown in the last years , the potential of ir for their study is twofold : first , ir can help discover many previously unknown nebulae , leading to the identification of new massive stars as their progenitors ; second , ir can help characterize the nebular features . current and new ir facilities thus pave the way to a better understanding of the feedback from massive stars ."}
{"article": "this paper presents data for the last two patches ( c and d ) of the sky observed by the public eso imaging survey ( eis ) , being carried out in preparation for the first year of regular operation of vlt . the i - band data reported here covers a total area of 12 square degrees , down to , corresponding to two patches probing separated regions of the sky , 6 square degrees each . the present work complements earlier papers in the series ( nonino 1998 ; paper i , prandoni 1998 ; paper iii ) and completes the presentation of the data accumulated by the eis observations carried out in the period july 1997-march 1998 as part of the wide - angle imaging survey originally described by renzini and da costa ( 1997 ) and in paper i. the primary science goal for surveying patches c and d was to search for and produce a list of distant galaxy cluster candidates that would complement those of the other two patches ( a and b ) reported earlier ( olsen 1998a , b : paper ii and v ) , providing vlt targets nearly year - round . patches c and d were also selected to overlap ongoing 92 cm westerbork survey in the southern hemisphere ( wish ) being carried out in the region and . originally , the eis observations were expected to be carried out in two passbands ( v and i ) . however , because of time constraints and the prospect of supplementing the eis observations at the ntt new wide - field imager for the 2.2 m eso / mpia telescope , preference was given to increase the area covered by the i - band observations , more suitable for identifying distant clusters ( see paper v ) . this decision allowed the full coverage of the selected patches , yielding a total coverage of 12 square degrees . combined for patches a and b the eis i - band data covers a total area of about 17 square degrees , currently the largest available survey of its kind in the southern hemisphere . the goal of the present paper is to describe the characteristics of the i - band observations of patches c and d. in section 2 , the observations , calibration and the quality of the data are described . in section 3 , the object catalogs extracted from the images are examined and compared from the other patches and other data sets to comparable depth . concluding remarks are presented in section 4 . the observations of patches c and d were carried out over several months in the period november ( december for patch d ) 1997 to march 1998 , using the red channel of the emmi camera on the 3.5 m new technology telescope ( ntt ) at la silla . the red channel of emmi is equipped tektronix 2046 2046 chip pixel size of 0.266 arcsec and a useful field - of - view of about . the observations were carried out as a series of overlapping 150 exposures , each position on the sky being sampled at least twice , using the wide - band filter wb829#797 described in paper i , and for which the color term relative to the cousins system is small . the data for patches c and d consist of 1348 frames but only 1203 were accepted for final analysis , discarding 145 frames obtained in poor seeing condition ( arcsec ) . the frames actually accepted have a seeing in the range 0.5 to 1.6 arcsec , considerably better than the data available for patches a and b obtained at the peak of el nio . figure shows the seeing distribution of all observed frames in each patch . for comparison the figure also shows the seeing distribution of the accepted frames , vertical lines in each panel indicating the median seeing and the quartiles of the distribution . from the figure one finds that the median seeing for both patches is sub - arcsec ( arcsec ) only 25% of the area covered by frames seeing larger than 1 arcsec . the good quality of the observations can also be seen from figure which shows the limiting isophote within 1 arcsec for each patch . apart from one subrow in patch c , in both cases the limiting isophote is typically 25.3 mag arcsec . the two - dimensional distributions of the seeing and limiting isophote are shown in figures and . comparison similar distributions presented in earlier papers ( paper i and iii ) shows that the data for patches c and d are significantly better . note that for each patch tables are available listing the position of each accepted frame , its seeing , limiting isophote and photometric zero - point and can be found at `` http://www.eso.org/eis '' . in late february 1998 , a realignment of the secondary mirror was carried out by the ntt team in an attempt to minimize the image distortions seen in the upper part , especially the upper - right corner , of the emmi frames . some frames for patch c and most of the frames in patch d were observed new setup of the ntt . examination of the point spread function for these frames showed no significant improvement in the quality of the images . this points out the need to introduce a position - dependent estimator for the point - spread function to assure uniformity in the star / galaxy separation across the frame . this is particularly important for images observed under good seeing conditions . in fact , examining the uniformity of the classification as a function of position on the chip it is found that there is a 10% increase in the density of galaxies at the upper edge of the chip , due to misclassifications , significantly larger than that seen in paper i. in the last three runs ( january - march ) it was also noticed faint ( at the level of the background noise ) linear features aligned along the east - west direction ( perpendicular to the readout axis ) associated moderately bright stars located in the lower half of the ccd not previously seen . the cause for the these features are at the present time unclear but are probably due to the electronic of the old - generation ccd controller of emmi , when used in a dual - port readout mode . these affects two - thirds of the patch c frames and essentially all the patch d frames . these light trails occur randomly in the patch and there is no obvious way of correcting for them a priori . an important consequence of this problem is that it leads to a localized increase in the detection of low - surface brightness objects over a range of magnitudes ( typically ) which can have a significant impact in the cluster detection algorithm ( scodeggio 1998 , paper vii ) . this is unfortunate because both patches c and d are located at lower galactic latitudes almost an order of magnitude larger density of stars than the previous patches . the photometric calibration of the patch was carried out , as described in papers i and iii , by determining a common zero - point for all frames from the solution of a global least - squares fit to all the relative zero - points , constraining their sum to be equal to zero . the absolute zero - point was determined by a simple zero - point offset determined from the common zero - point of all frames observed in photometric conditions . there are 340 and 290 such frames , covering about 80% and 60% of the surveyed area , in patches c and d , respectively ( see figure ) . the zero - points for these frames were determined using a total of 10 fields containing of the order of 45 standard stars taken from landolt ( 1992 a , b ) , observed in 10 nights for patch c and in 11 nights for patch d. altogether 215 independent measurements of standards in the three passbands were used in the calibration . comparison external data suggests that a zero - point offset provides an adequate photometric calibration for the entire patch . in order to check the photometric calibration and the uniformity of the zero - points , strips from the denis survey ( epchtein 1996 ) crossing the surveyed area the regions of overlap of these data are shown in figure , which shows that there are five strips crossing patch c and two strips crossing patch d. in the figure the regions observed under photometric conditions are also indicated . comparison of this figure their counterparts presented in papers i and iii , clearly shows that the data for patches c and d are of superior quality , much larger fraction of frames taken under photometric conditions . in order to investigate possible systematic errors in the photometric zero - point over the scale of the patch , the eis catalogs were compared object catalogs extracted from the denis strips that cross the survey regions ( see figure ) . comparison of the catalogs allows one to investigate the variation of the zero - point over the patch . the results are shown in figure . the domain in which the comparison can be made is relatively small because of saturation of objects in eis at the bright end and the shallow magnitude limit of denis . still , within the two magnitudes where comparison is possible one finds a roughly constant zero - point offset of less than 0.02 mag for both strips and a scatter of mag that can be attributed to the errors in the denis magnitudes ( deul 1998 ) . in order to evaluate the quality of the data simple statistics computed from the object catalogs extracted from the images are compared in this section model predictions and other data sets . the catalogs derived from individual frames are used to generate the even , odd and best seeing catalogs , described in earlier papers . the spatial distribution of stars and galaxies , defined using similar star / galaxy classification criteria as in previous papers of the series , are shown in figures and down to and for stars and galaxies , respectively . the latter corresponds roughly to the completeness limit of the object catalog . this limit was established using the object catalog extracted from the co - addition of images of a reference frame taken periodically during the observations of a patch . note that because of the much better seeing star / galaxy classification is possible down to and the completeness is about 0.5 mag deeper . some improvement in the classification is expected from a new estimator being implemented in sextractor based on a position - dependent psf fitting scheme currently being tested . this new version should also improve the uniformity of the classification across the chip . the distribution of the stars and galaxies shown in figures and is remarkably homogeneous and considerably better than those seen in the previous eis patches due to the much better observing conditions . this is true except for a small region of about 0.2 square degrees in patch c which has been removed , as indicated in figure . the only problem seen galaxy catalogs in these patches is the presence of several relatively thin linear features clearly seen at high resolution ( see eis release page ) . these features are a consequence of the electronic problem mentioned above and are not easily corrected for at the image level . in order to evaluate the data the general properties of the extracted object catalogs are investigated and compared model predictions and other data sets . note that patches c and d are located at lower galactic latitude and the number of stars is considerably larger . in addition , the seeing is considerably better than in previous patches . therefore , it is of interest to re - evaluate the overall performance of the eis pipeline reduction under these new conditions . figure , shows the comparison of the star counts for patches c and d derived using the stellar sample extracted from the object catalogs , predicted counts based on a galactic model composed of an old - disk , a thick disk and a halo . the star - counts have been computed using the model described by mndez and van altena ( 1996 ) , using the standard parameters described in their table 1 and an of 0.015 and 0.010 for patches c and d , respectively . it is important to emphasize that no attempt has been made to fit any of the model parameters to the observed counts . the model is used solely as a guide to evaluate the data . as can be seen there is a good agreement at bright magnitudes , but the observed counts show an excess at fainter magnitudes . even though it is unlikely that this excess is due to misclassified galaxies at these relatively bright magnitudes , a better agreement can be achieved if a higher stellarity index is assumed . on the other hand , it is also possible that the model underestimates the contribution of the thick - disk which makes a significant contribution in this magnitude range . the steep drop in the stellar counts beyond is partially due to the relatively high stellarity index adopted , which was chosen to minimize the losses of galaxies . by adopting a stellarity index of 0.5 the drop in the counts may be avoided down to . however , at these magnitudes and this value of the stellarity index contamination by galaxies may be significant . another potential problem at these faint magnitudes is the misclassification of stars as a consequence of the distortion effects in emmi , that can have some impact for images taken in good seeing conditions . in order to evaluate the depth of the galaxy samples , galaxy counts in patches c and d are compared those of previous patches in figure . there is a remarkable agreement among the counts derived for the different patches , indicating that the identification of galaxies has not been affected by the observations at lower galactic latitudes . the galaxy counts obtained from the different patches have been combined to compute the mean galaxy counts and the variance . this is also shown in figure where it is compared to other ground - based counts ( postman 1998 ) and those from hdf ( williams 1996 ) , appropriately converted to the cousins system ( see paper iii ) . as can be seen the eis galaxy counts agree extremely well ground - based data covering comparable area over the entire magnitude range down to and bright end of the hdf counts . the excellent internal and external agreement of the i - band galaxy counts serves as a confirmation of the reliability of the eis galaxy catalogs . extraction from co - added images should allow reaching about 0.5 mag deeper . one way of examining the overall uniformity of the galaxy catalogs is to use the two - point angular correlation function , , as departures from uniformity should affect the correlation function especially at faint magnitudes . the latter should be sensitive to artificial patterns , especially to the imprint of the individual frames , or possible gradients in the density over the field , which could result from large - scale gradients of the photometric zero - point . note that any residual effect due to the improper association of objects in the border of overlapping frames would lead to a grid pattern ( see the weight map in the eis release page ) that could impact the angular correlation function . figure shows obtained for different magnitude intervals for both patches , using the estimator proposed by landy & szalay ( 1993 ) . the calculation has been done over the entire area of patch d and most of the area of patch c , only one subrow ( 10 consecutive frames ) removed according to the discussion above ( see section ) . for comparison , computed for the other patches are also shown ( papers i and iii ) from which the cosmic variance can be evaluated directly from the data . as can be seen there is a remarkable agreement for all the magnitude intervals considered . moreover , the larger contiguous area of patches c and d allows to estimate the angular correlation function out to degree . in all cases is well described by a power law in the range 0.7 - 0.8 . note that for patch b the results refer to the galaxy sample obtained after removing the foreground cluster ( see paper iii ) . in particular , there is no evidence for any underlying pattern associated overlap of different frames . the effect on was evaluated by carrying out simulations by adding to the observed galaxy distribution a grid pattern different density contrast . it was found that for high contrast this would lead to local depressions in the angular correlation function on scales of half the size of the diagonal of the grid and its multiples , depth of depression depending on the relative density . none such features are seen further indicating the uniformity of the derived galaxy catalogs . finally , note that the good agreement of for the different patches confirms that the observed small - scale linear features associated faint light trails , mentioned in section , have very little impact in the angular correlation function . as shown in paper iii the dependence of the amplitude of the correlation function on the limiting magnitude of the sample is consistent earlier estimates based on significantly smaller areas and the recent results reported by postman ( 1998 ) . these results show that the eis galaxy catalogs are spatially uniform and form a homogeneous data set independent of the patch , yielding reproducible results . finally , note that even though a single power - law slope between 0.7 - 0.8 gives a reasonable fit for the correlation computed in all magnitude bins , there is some indication that for fainter samples the angular correlation function may be better represented by two distinct power - laws . on small scales the slope remains the same while on larger scales it becomes gradually flatter . a similar behavior is seen in the computed for all four patches . this flattening seems to be consistent earlier claims by campos ( 1995 ) and neuschaefer and windhorst ( 1995 ) using significantly smaller samples , and more recently by postman ( 1998 ) sample of similar size to eis but covering a single contiguous area . one year after the first observations , the full data set accumulated by eis is being made public in the form of astrometrically and photometrically calibrated pixel maps and object catalogs extracted from individual images . in addition , separate papers have presented derived catalogs listing candidate targets for follow - up work . the eis data set consists of about 6000 science and calibration frames , totaling 96 gb of raw data and over 200 gb of reduced images and derived products . all the information regarding these frames are maintained in a continuously growing database . together science archive group a comprehensive interface has been built to provide users broad range of products and information regarding the survey . from the verification of the object catalogs and their comparison against model predictions and other observations , it has been found that the extracted catalogs are reliable and uniform . when all patches are included , the combined eis galaxy catalog contains about one million galaxies and it is by far the largest data set of faint galaxies currently available in the southern hemisphere . the star counts show a good agreement current galactic models , especially at high - galactic latitudes , and the galaxy counts agree remarkably well other ground - based observations as well as counts derived from hdf . the data from the different patches seem to be rather homogeneous , as strongly suggested from measurements of the angular two - point correlation function which should be sensitive to large - scale gradients in a patch or to relative offsets of the photometric zero - points for the different patches . as expected eis - wide has provided large samples ( 50 to over 200 candidates ) of distant clusters of galaxies ( olsen 1998a , b , scodeggio 1998 ) and of potentially interesting point sources ( zaggia 1998 ) , more than adequate for the first year of observations , the main goal of eis . some of the targets can also be observed nearly year round . in order to expedite the delivery of the products all the results refer to single exposure frames as discussed in the previous papers of the series . even though co - addition has been done for all the patches some problems have been uncovered during the verification of the object catalogs extracted from them and require further work . however , the samples already public are sufficiently deep and large for programs to be conducted in the first year of operation of the vlt . the results obtained from the co - added images will become available before the vlt proposal deadline . this paper completes the first phase of eis which will now focus on the deep observations of the hdf - south and axaf deep fields . the results presented so far show the value of a public survey providing the community at large basic data and tools required to prepare follow - up observations at 8-m class telescopes . the experience acquired by eis in pipeline processing , data archiving and mining will now be transferred to the pilot survey , a deep wide - angle imaging survey to be conducted wide - field camera mounted on the eso / mpia 2.2 m telescope . we thank all the people directly or indirectly involved in the eso imaging survey effort . in particular , all the members of the eis working group for the innumerable suggestions and constructive criticisms , the eso archive group and the st - ecf for their support . we also thank the denis consortium for making available some of their survey data . the denis project development was made possible thanks to the contributions of a number of researchers , engineers and technicians in various institutes . the denis project is supported by the science and human capital and mobility plans of the european commission under the grants ct920791 and ct940627 , by the french institut national des sciences de lunivers , the education ministry and the centre national de la recherche scientifique , in germany by the state of baden - wurttemberg , in spain by the dgicyt , in italy by the consiglio nazionale delle richerche , by the austrian fonds zur frderung der wissenschaftlichen forschung und bundesministerium fr wissenschaft und forschung , in brazil by the fundation for the development of scientific research of the state of so paulo ( fapesp ) , and by the hungarian otka grants f-4239 and f-013990 and the eso c & ee grant a-04 - 046 . our special thanks to the efforts of a. renzini , vlt programme scientist , for his scientific input , support and dedication in making this project a success . finally , we would like to thank eso s director general riccardo giacconi for making this effort possible in the short time available .", "summary": "this paper presents the i - band data obtained by the eso imaging survey ( eis ) over two patches of the sky , 6 square degrees each , centered at , , and , . the data are being made public in the form of object catalogs and , photometrically and astrometrically calibrated pixel maps . these products together other useful information can be found at `` http://www.eso.org/eis '' . the overall quality of the data in the two fields is significantly better than the other two patches released earlier and cover a much larger contiguous area . the total number of objects in the catalogs extracted from these frames is over 700,000 down to , where the galaxy catalogs are 80% complete . the star counts are consistent model predictions computed at the position of the patches considered . the galaxy counts and the angular two - point correlation functions are also consistent those of the other patches showing that the eis data set is homogeneous and that the galaxy catalogs are uniform . 1 # 1"}
{"article": "over the past 70 years , there have been multiple attempts to dynamically model the movement of polymer chains brownian dynamics , which have more recently been used as a model for dna filament dynamics . one of the first and simplest descriptions was given as the rouse model , which is a bead - spring model , where the continuous filament is modelled at a mesoscopic scale beads connected by springs . the only forces exerted on beads are spring forces from adjacent springs , as well as gaussian noise . hydrodynamic forces between beads and excluded volume effects are neglected in the model in favour of simplicity and computational speed , but the model manages to agree several properties of polymer chains from experiments . other models exist , for example the zimm model introduces hydrodynamic forces between beads , or bending potentials can be introduced to form a wormlike chain and give a notion of persistence length , see , for example , review article or books on this subject . most of the aforementioned models consider the filament on only a single scale . in some applications , a modeller is interested in a relatively small region of a complex system . then it is often possible to use a hybrid model which is more accurate in the region of interest , and couple this model which is more computationally efficient in the rest of the simulated domain . an application area for hybrid models of polymer chains is binding of a protein to the dna filament , which we study in this paper . the model which we have created uses rouse dynamics for a chain of dna , along freely diffusing particle to represent a binding protein . as the protein approaches the dna , we increase the resolution in the nearby dna filament to increase accuracy of our simulations , whilst keeping them computationally efficient . in this paper we use the rouse model for analysis due to its mathematical tractability and small computational load . such a model is applicable to modelling dna dynamics when we consider relatively low resolutions , when hydrodynamic forces are negligible and persistence length is significantly shorter than the kuhn length between each bead . the situation becomes more complicated when we consider dna modelling at higher spatial resolutions . inside the cell nucleus , genetic information is stored within strands of long and thin dna fibres , which are separated into chromosomes . these dna fibres are folded into structures related to their function . different genes can be enhanced or inhibited depending upon this structure . folding also minimises space taken up in the cell by dna , and can be unfolded when required by the cell for different stages in the cell cycle or to alter gene expression . the folding of dna occurs on multiple scales . on a microscopic scale , dna is wrapped around histone proteins to form the nucleosome structure . this in turn gets folded into a chromatin fibre which gets packaged into progressively higher order structures until we reach the level of the entire chromosome . the finer points of how the nucleosome packing occurs on the chromatin fibre and how these are then packaged into higher - order structures is still a subject of much debate , long - held views regarding mesoscopic helical fibres becoming less fashionable in favour of more irregular structures in vivo . in the most compact form of chromatin , many areas of dna are not reachable for vital reactions such as transcription . one potential explanation to how this is overcome by the cell is to position target dna segments at the surface of condensed domains when it is needed , so that transcription factors can find expressed genes without having to fit into these tightly - packed structures . this complexity is not captured by the multiscale model of protein binding presented in this paper . however , if one uses the developed refinement of the rouse model together more detailed modelling approach in a small region of dna next to the binding protein , then such a hybrid model can be used to study the effects of microscopic details on processes over system - level spatial and temporal scales . when taking this multiscale approach , it is necessary to understand the error from including the less accurate model in the hybrid model and how the accuracy of the method depends on its parameters . these are the main questions studied in this paper . the rest of the paper is organized as follows . in section , we introduce a multi - resolution bead - spring model which generalizes the rouse model . we also introduce a discretized version of this model which enables the use of different timesteps in different spatial regions . in section , we analyze the main properties of the multi - resolution bead - spring model . we prove two main lemmas giving formulas for the diffusion constant and the end - to - end distance . we also study the appropriate choice of timesteps for numerical simulations of the model and support our analysis by the results of illustrative computer simulations . our main application area is studied in section where we present and analyze a dna binding model . we develop a method to increase the resolution in existing segments on - the - fly using the metropolis - hastings algorithm . in section , we conclude our paper by discussing possible extensions of the presented multiscale approach ( by including more detailed models of dna dynamics ) and other multiscale methods developed in the literature . we generalize the classical rouse bead - spring polymer model to include beads of variable sizes and springs variable spring constants . in definition , we formulate the evolution equation for this model as a system of stochastic differential equations ( sdes ) . we will also introduce a discretized version of this model in algorithm , which will be useful in sections and where we use the multi - resolution bead - spring model to develop and analyze multiscale models for dna dynamics . let be a positive integer . a multi - resolution bead - spring polymer of size consists of a chain of beads of radius , for , connected by springs which are characterized by their spring constants , for . the positions ] is a wiener process , is absolute temperature , is boltzmann s constant and we assume that each spring constant can be equivalently expressed in terms of the corresponding kuhn length by we assume that the behaviour of boundary beads ( for and ) is also given by equation simplified by postulating and ] in figure , we schematically illustrate a multi - resolution bead - spring polymer for . the region between the -th and the -th bead is described highest resolution by considering smaller beads and springs larger spring constants ( or equivalently smaller kuhn lengths ) . the scalings of different parameters in definition are chosen so that we recover the classical rouse model if we assume and . then equation simplifies to where , and we again define and in equations for boundary beads . in the polymer physics literature , the rouse model is equivalently written as where random thermal noises exerted on the beads from brownian motion are characterized by the moments where and . for the remainder of this paper , we will use the sde notation as given in , because we will often study numerical schemes for simulating polymer dynamics models . the simplest discretization of is given by the euler - maruyama method , which uses the finite timestep and calculates the position vector of the -th bead , , at discretised time by for , where is normally distributed random variable zero mean and unit variance ( i.e. ) for . in order to discretize the multi - resolution bead - spring model , we allow for variable timesteps . let and let , be positive integers such that or for . let us assume that at least one of the values of is equal to 1 . we define for and we call a timestep associated -th spring . definition specifies that all timesteps must be integer multiples of the smallest timestep . the timesteps associated adjacent springs are also multiples of each other . the time evolution of the multi - resolution bead - spring model is computed at integer multiples of . one iteration of the algorithm is shown in algorithm . the position of the -th bead is updated at integer multiples of by calculating the random displacement due to brownian motion , displacement caused by springs attached to the bead also updated at integer multiples of the timesteps associated each spring , i.e. or considering the situation that all beads , springs and timesteps are the same , then one can easily deduce the following result . update positions of internal beads which are connected to two springs : + update of the first bead : + update of the last bead : + let , , and be positive constants and be an integer . consider a multi - resolution bead - spring polymer of size , , for , and , for . let the timesteps associated each spring be equal to , i.e. in definition then algorithm is equivalent to the euler - maruyama discretization of the rouse model given as equation . lemma shows that the multi - resolution bead - spring model is a generalization of the rouse model . in the next section , we will study properties of this model which will help us to select the appropriate parameter values for this model and use it in multiscale simulations of dna dynamics . we have formulated a multiscale rouse model which varies the kuhn lengths throughout the filament , but we would like to keep properties of the overall filament constant regardless of the resolution regime being considered for the filament . we consider a global statistic for the system to be consistent if the expected value of the statistic is invariant to the resolution regime being considered for the filament . we consider the self diffusion constant and root mean squared ( rms ) end - to - end distance as two statistics we wish to be consistent in our system , which can be ensured by varying the bead radius and the number of beads respectively . the precise way to vary these properties will be explored in this section . the self diffusion constant is defined as where is the centre of mass of the polymer chain at time , which is defined by definition is an extension to the definition given by doi and edwards for the centre of mass of a continuous chain on only one scale . if all beads have the same radius ( i.e. if for ) , then equation simplifies to the centre of mass definition for the classical rouse model . in this case , the self diffusion constant is given by where is the number of beads . this result explains the , on the face of it , counterintuitive scaling of equation . if we suppose that each bead had the same density , then the mass of each bead would be proportional to its volume , i.e. to . however , in definition , we have used weights instead of because beads do not represent physical bead objects like nucleosomes , but representations of the filament around it , so the bead radius scales amount of surrounding filament , which is linear in bead radius in this formulation . if we consider dna applications , we could imagine each bead as a tracker for individual base pairs at intervals of , say , thousands of base pairs away from each other along the dna filament . the filament in the model is then drawn between adjacent beads . this linear scaling can also be confirmed using equation for the classical rouse model . if we describe the same polymer using a more detailed model consisting of twice as many beads ( i.e. if we change to ) , then we have to halve the bead radius ( i.e. change to ) to get a polymer model same diffusion constant . in particular , the mass of a bead scales ( and not ) . in the next lemma , we extend result to a general multi - resolution bead - spring model . let us consider a multi - resolution bead - spring polymer of size and a set of timesteps associated each spring satisfying the assumptions of definitions and . then the self diffusion constant of the polymer evolution described by algorithm is given by algorithm describes one iteration of our numerical scheme . multiplying the steps corresponding to the -th bead by and summing over all beads , we obtain how changes during one timestep . since , tension terms cancel after summation and the evolution rule for simplifies to where ] , where we used the fact that the sum of normally distributed random variables is again normally distributed . dividing equation by , we obtain .\\ ] ] using definition , we obtain . the formula is a generalization of equation obtained for the rouse model . it is invariant to the resolutions provided that the mass of the filament remains constant through selection of the number of beads and bead radius , therefore the self diffusion constant is consistent . we define the end - to - end vector from one end of the filament to the other . an important statistic to consider related to this is the root mean squared ( rms ) end - to - end distance of the filament . the expected value of the long - time limit of the rms end - to - end distance , denoted , for the classical rouse model is given by we generalize this result in the following lemma . let us consider a multi - resolution bead - spring polymer of size satisfying the assumptions of definition . then and the long - time limit of the rms end - to - end distance is given by equations describe a system of linear sdes . however , the sdes corresponding to different spatial dimensions are not coupled . we therefore restrict our investigation to the behaviour of the first coordinates of each vector in . let us arrange the differences of the first coordinates of subsequent beads into the -dimensional vector .\\ ] ] then sdes can be rewritten to the system of sdes for in the matrix form where is a three - diagonal matrix given by is a two - diagonal matrix given by and is -dimensional noise vector ^t . ] of the protein from the middle bead of the filament . we estimate as a fraction of simulations which end up protein bound to dna . each data point in figure represents the value of estimated from independent realizations of the process . if , then the protein is immediately bound to dna , i.e. for . if , then the probability of binding is nonzero , because the initial placement , , is the distance of the protein from the centre of the filament . in particular , the minimum distance from protein to filament is less than or equal to the initial placement distance , , and the simulations ( possibility of binding ) take place even if . , depending on starting distance , , from the filament for the single - scale ( black points ) and omr ( blue line ) models . error bars give a 95% confidence interval based on the wilson score interval for binomial distributions . ] due to computational constraints of the single - scale model we consider a selection of initial distances at points m , ( black points ) , where error bars give a 95% confidence interval based on the wilson score interval for binomial distributions . we run simulations for more initial distances , m , ( blue line ) , using the computationally efficient omr model and present our results as the blue line in figure . we see that is very similar between the single - scale and omr models . the model also succeeds in reducing computational time . for simulations protein starting from the middle bead , parameters given in table , the omr model represented a 3.2-times speedup compared to the detailed model , only a 3-times resolution difference . we expect for larger resolution differences to see greater improvements in speed . in this paper we have extended basic filament modelling techniques to multiple scales by developing omr methods . we have presented an mcmc approach for increasing the resolution along a static filament segment , as well as an extension to the rouse model to dynamically model a filament which considers multiple scales . the bead radius , as well as the number of beads associated each resolution , is altered to maintain consistency end - to - end distance and diffusion of a filament across multiple scales , as well as the timestep to ensure numerical convergence . we have then illustrated the omr methodology using a simple model of protein binding to a dna filament , in which the omr model gave similar results to the single - scale model . we have also observed a 3.2-times speed - up in computational time on a model which considers only a 3-times increase in resolution , which illustrates the use of the omr approach as a method to speed up simulations whilst maintaining the same degree of accuracy as the more computationally intensive single - scale model . the speed - up in computational time could be further increased by replacing brownian dynamics based on time - discretization by event - based algorithms such as the fpkmc ( first passage kinetic monte carlo ) and gfrd ( green s function reaction dynamics ) methods . when considering the zooming out of the dna binding model , note that it is generally possible to zoom in and out repetitively , as long as the dynamics are such that we can generate a high resolution structure independent from the previous one ( i.e. , once we zoom out , the microscopic structure is completely forgotten ) . however , particularly in the case of chromatin , histone modification and some dna - binding proteins may act as long - term memory at a microscopic scale below the scales currently considered . to reflect the effect of the memory , some properties of the microscopic structure should be maintained even after zooming out . fractal dimension may serve as a candidate of indices , which can be also estimated in living cells by single - molecule tracking experiments . the omr method could be applied to modern simulations of dna and other biological polymers which use the rouse model in situations where certain regions of the polymer require higher resolutions than other regions . the model considered in this report uses rouse dynamics , which is moderately accurate given its simplicity , but as we zoom in further towards a binding site , then we will need to start to consider hydrodynamic forces and excluded volume effects acting between beads . models which include hydrodynamic interactions such as the zimm model have previously been used to look at filament dynamics . therefore it is of interest to have a hybrid model which uses the rouse model in low resolutions and the zimm model in high resolutions . the combination of different dynamical models might give interesting results regarding hierarchical structures forming as we move between resolutions . as we go into higher resolutions , strands of dna can be modelled as smooth , unlike the fjc model where angles between beads are unconstrained . the wormlike chain model of kratky and porod , implemented via algorithm by hagermann and zimm , gives a non - uniform probability distribution for the angles between each bead . allison then implements the zimm model dynamics on top of the static formulation to give bending as well as stretching forces . another interesting open multiscale problem is to implement this at higher resolutions , rouse model at lower resolutions , in order to design a hybrid model . to introduce even more realism , we would see individual histones and consider forces between these as in the model of rosa and everaers which includes lennard - jones and fene forces between beads . as we approach an atomistic level , it may be interesting to consider a molecular dynamics approach to modelling the dna filament . coarser brownian dynamics models can be estimated from molecular dynamics models either analytically or numerically , depending on the complexity of the molecular dynamics model . a variety of structure - based coarse - grained models have been used for chromatin ( e.g. ) , also transcription factors . multiscale modelling techniques ( e.g. iterative coarse - graining ) , as well as adaptive resolution models ( e.g. for solvent molecules ) , have been developed . we expect these studies will connect polymer - like models at a certain appropriate length and time scale . on top of this , models for the target searching process by proteins such as transcription factors could be improved ( for example , by incorporating facilitated diffusion under crowded environment ) . the need for developing and analyzing multiscale models of dna which use one of the above detailed simulation approaches for small parts of the dna filament is further stimulated by recent experimental results . chromosome conformation capture ( 3c)-related techniques , particularly at a genome - wide level using high - throughput sequencing ( hi - c ) , provide the three - dimensional structure of the chromosomes in an averaged manner . moreover , recent imaging techniques have enabled us to observe simultaneously the motion and transcription of designated gene loci in living cells . simulated processes could be compared such experimental results . recent hi - c experiments also revealed fine structures such as loops induced by dna - binding proteins . to develop more realistic models , information about the binding sites for these proteins may be utilized when we increase the resolution in our scheme . s. shinkai , t. nozaki , k. maeshima , and y. togashi . dynamic nucleosome movement provides structural information of topological chromatin domains in living human cells . biorxiv doi:10.1101/059147 , 2016 .", "summary": "a multi - resolution bead - spring model for polymer dynamics is developed as a generalization of the rouse model . a polymer chain is described using beads of variable sizes connected by springs variable spring constants . a numerical scheme which can use different timesteps to advance the positions of different beads is presented and analyzed . the position of a particular bead is only updated at integer multiples of the timesteps associated connecting springs . this approach extends the rouse model to a multiscale model on both spatial and temporal scales , allowing simulations of localized regions of a polymer chain high spatial and temporal resolution , while using a coarser modelling approach to describe the rest of the polymer chain . a method for changing the model resolution on - the - fly is developed using the metropolis - hastings algorithm . it is shown that this approach maintains key statistics of the end - to - end distance and diffusion of the polymer filament and makes computational savings when applied to a model for the binding of a protein to the dna filament . polymer dynamics , dna , rouse model , brownian dynamics , multiscale modelling 60h10 , 60j70 , 82c31 , 82d60 , 92b99"}
{"article": "a geodesic flow in a given direction on a translation surface induces on a transverse segment an interval exchange map . dynamic of such transformations has been extensively studied during these last thirty years providing applications to billiards in rational polygons , to measured foliations on surfaces , to teichmller geometry and dynamics , etc . interval exchange transformations are closely related to abelian differentials on riemann surfaces . it is well known that the continued fractions encode cutting sequences of hyperbolic geodesics on the poincar upper half - plane . similarly , the rauzy - veech induction ( analogous to euclidean algorithm ) provides a discrete model for the teichmller geodesics flow . using this relation h. masur in and w. a. veech in have independently proved the keane s conjecture ( unique ergodicity of almost all interval exchange transformations ) . using combinatorics of rauzy classes , kontsevich and zorich classified the connected components of strata of the moduli spaces of abelian differentials . more recently , avila , gouzel and yoccoz proved the exponential decay of correlations for the teichmller geodesic flow also using a renormalization of the rauzy - veech induction ( see ) . avila and viana used combinatorics of rauzy - veech induction to prove the simplicity of the essential part of the lyapunov spectrum of the teichmller geodesic flow on the strata of abelian differentials ( see ) . recently bufetov and gurevich proved the existence and uniqueness of the measure of maximal entropy for the teichmller geodesic flow on the moduli space of abelian differentials . avila and forni proved the weak mixing for almost all interval exchange transformations and translation flows . these examples show that rauzy - veech induction which was initially elaborated to prove ergodicity of interval exchange transformations and ergodicity of the teichmller geodesic flow is , actually , very efficient far beyond these initial problems . however , all the aforementioned results concern only the moduli space of abelian differentials . the corresponding questions for strata of strict quadratic differentials ( i.e. of those , which are not global squares of abelian differentials ) remain open . note that the ( co)tangent bundle to the moduli space of curves is naturally identified moduli space of quadratic differentials . from this point of view , the strata of abelian differentials represent special orbifolds of high codimension in the total space of the tangent bundle . our interest in teichmller dynamics and geometry of the strata of strict quadratic differentials was one of the main motivations for developing rauzy - veech induction for quadratic differentials . natural generalizations of interval exchange transformations were introduced by danthony and nogueira in ( see also ) as cross sections of measured foliations on surfaces . they introduced the notion of linear involutions , as well as the notion of rauzy induction on these maps . studying lyapunov spectrum of the teichmller geodesic flow kontsevich and zorich have performed series of computer experiments linear involutions corresponding to quadratic differentials . these experiments indicated appearance of attractors for the rauzy - veech induction , as well as examples of generalized permutations such that the corresponding linear involutions are minimal for a domain of parameters of positive measure , and non minimal for a complementary domain of parameters also of positive measure ( examples of this type are presented in figure and figure in appendix ) . but at this point , there was no combinatorial explanation . thus , in order to generalize technique of rauzy - veech induction to quadratic differentials in a consistent way it was necessary to find combinatorial criteria allowing to identify generalized permutations , which belong to attractors and those ones , which represents cross sections of vertical foliations of quadratic differentials . it was also necessary to distinguish those generalized permutation which give rise to minimal linear involution , and to specify the domains of appropriate parameters . in this paper we establish corresponding combinatorial criteria , which enable us to develop technique of rauzy - veech induction for quadratic differentials . partial results in this direction were obtained by the second author in . we also study relations between combinatorics , geometry and dynamics of linear involutions . to compare similarities and differences between linear involutions corresponding to abelian and to quadratic differentials let us first briefly review the situation in the classical case . an interval exchange transformation is encoded by a combinatorial data ( permutation on elements ) and by a continuous data ( lengths of the intervals ) . recall that the keane s property ( see below ) is a criterion of `` irrationality '' ( which , in particular , implies minimality ) of an interval exchange transformation . this property is satisfied for almost all parameters when the permutation is irreducible ( i.e. , while when is reducible , the corresponding interval exchange map is never minimal . on the other hand the irrational interval exchange maps are precisely those that arise as cross sections of minimal vertical flows on well chosen transverse intervals . the rauzy - veech induction consists in taking the first return map of an interval exchange transformation to an appropriate smaller interval . this induction can be viewed as a dynamical system on a finite - dimensional space of interval exchange maps . the behavior of an orbit of the induction provides important information on dynamics of the interval exchange transformation representing the starting point . this information is especially useful when all iterates are well defined and when the length of the underlying subintervals tends to zero . an interval exchange transformation satisfying the latter conditions is said to have property . for a given irreducible permutation , the subset of parameters which give rise to interval exchange transformations satisfying keane s property contains all irrational parameters , and so it is a full lebesgue measure subset . moreover , for the space of interval exchange transformations irreducible combinatorial data , the renormalized induction process is recurrent respect to the lebesgue measure ( and even ergodic by a theorem of veech ) . note that the corresponding invariant measure has infinite total mass . in this paper we use the definition of linear involution be the involution of given by . a linear involution is a map , from into itself , of the form , where is an involution of without fixed point , continuous except in finitely many points , and which preserves the lebesgue measure . in this paper we will only consider linear involutions additional condition . the derivative of is at if and belong to the same connected component , and otherwise ; see also convention . ] proposed by danthony and nogueira ( see ) . as above , a linear involution is encoded by a combinatorial data ( `` generalized permutation '' ) and by continuous data . a generalized permutation of type ( ) is a two - to - one map to an alphabet . a generalized permutation is called irreducible if there exists a linear involution associated to this generalized permutation , which represents an appropriate cross section of the vertical foliation of some quadratic differential . a generalized permutation is called dynamically irreducible if there exists a minimal linear involution associated to this generalized permutation . it is easy to show that any irreducible generalized permutation is dynamically irreducible ; the converse is not true in general as we will see . irreducible and dynamically irreducible generalized permutations can be characterized by natural criteria expressed in elementary combinatorial terms . the corresponding criteria are stated as definitions and definition respectively . consider a dynamically irreducible generalized permutation . the parameter space of normalized linear involutions associated to is represented by a hyperplane section of a simplex . we describe an explicit procedure which associates to each generalized permutation an open subset in the parameter space defined by a system of linear inequalities determined by . this subset is called the set of admissible parameters . when is irreducible , the set of admissible parameters coincides entire parameter space ; in general it is smaller . the next result gives a more precise statement than theorem in the dynamically irreducible case . 1 . if is not dynamically irreducible , or if is dynamically irreducible , but does not belong to the set of admissible parameters , the linear involution is not minimal . if is dynamically irreducible , then for almost all admissible parameters the linear involution satisfies the keane s property , and hence is minimal . since the rauzy - veech induction commutes dilatations , it projectivizes to a map on the space of normalized linear involutions ; we shall call this map the renormalized rauzy - veech induction . let t be a linear involution on the unit interval and let us consider a sequence of iterates by the renormalized rauzy - veech induction . 1 . if has the keane s property , then there exists such that is irreducible for all . the renormalized rauzy - veech induction , defined on the set , is recurrent . having a generalized permutation we can define one or two other generalized permutations and reflecting the possibilities for the image of the rauzy - veech induction . these combinatorial rauzy operations define a partial order in the set of irreducible permutations represented by an oriented graph . rauzy class is a connected component of this graph . note that geometry of the rauzy graphs is very different and more complicated than in the case of `` true '' permutations since for some irreducible generalized permutations one of the rauzy operations might be not defined . from theorem we will deduce that a rauzy class is an equivalence class for the equivalence relation given by these combinatorial operations ( see proposition ) . in analogy case of the `` true '' permutations , we introduce one more combinatorial operation on generalized permutations and define extended rauzy classes as minimal subsets of irreducible generalized permutations invariant under these corresponding three operations . the moduli spaces of abelian differentials and of quadratic differentials are stratified by multiplicities of the zeroes of the corresponding differentials . we denote a stratum of the moduli space of strict quadratic differentials ( most simple poles ) by , where are the multiplicities of the zeroes ( corresponds to a pole ) . extended rauzy classes of irreducible generalized permutations are in one - to - one correspondence connected components of strata in the moduli spaces of quadratic differentials . historically , extended rauzy classes where used to prove the non - connectedness of some strata of abelian differentials . for permutations of a small number of elements , it is easy to construct explicitly the subset of irreducible permutations and then using the rauzy operations to decompose it into a disjoint union of extended rauzy classes . using this approach veech proved that the minimal stratum in genus has two connected components and arnoux proved that the minimal stratum in genus has three connected components ( for abelian differentials ) . having established an explicit combinatorial criterion of irreducibility of a generalized permutation ( namely theorem ) one can apply theorem to classify the connected components of all strata of quadratic differentials of sufficiently small dimension . this justifies , in particular , the following experimental result of zorich . each of the following four exceptional strata of quadratic differentials and contains exactly two connected components . note that a theorem of the second author classifies all connected components of all other strata of meromorphic quadratic differentials most simple poles . these strata are either connected , or contain exactly two connected components one of which being hyperelliptic . the same theorem proves that each of the remaining four exceptional strata might have at most two connected components . however , the only currently available proof of the fact they are disconnected is the one based on explicit calculation of the extended rauzy classes and corresponds to the theorem of zorich . it would be interesting to have an algebraic - geometrico proof of the last theorem ; namely a topological invariant as in the kontsevich - zorich s classification . note also that a paper of zorich gives explicits representatives elements for each extended rauzy class . see also for programs concerning calculations of these rauzy classes . in section we recall basic properties of flat surfaces , moduli spaces and interval exchange maps . in particular we recall the rauzy - veech induction and its dynamical properties . we relate these properties to irreducibility . + in section we recall the definition of a linear involution and give basics properties . then in section we define a combinatorial notion of irreducibility , and prove the first part of theorem . the main tool we use to prove this theorem is the presentation proposed by marmi , moussa and yoccoz which appears in + in section we introduce the keane s property for the linear involutions and prove the second part of theorem , that is theorem . for that we prove that satisfies the keane s property if and only if the rauzy - veech induction is always well defined and the length parameters tends to zero . then if does not satisfy the keane s property we show that there exists such that is dynamically reducible which then implies that is also dynamically reducible . + in section , we study the dynamics of the renormalized rauzy - veech map on the space of the linear involutions , and prove theorem . for that we use the teichmller geometry and the finiteness of the volume of the strata proved by masur and veech ( see ) . + section is devoted to a proof of theorem on extended rauzy classes ; we present a result of zorich based on an explicit calculation of these classes in low genera . + in the appendix we present some explicit rauzy classes as illustration of the problems which appear in the general case . we also give a property concerning the extended rauzy classes . we thank anton zorich for useful discussions . we thank arnaldo nogueira for comments and remarks on a preliminary version of this text . + this work was partially supported by the anr `` teichmller projet blanc '' anr-06-blan-0038 . in this section we review basic notions concerning flat surfaces , moduli spaces and interval exchange maps . for general", "summary": "interval exchange maps are related to geodesic flows on translation surfaces ; they correspond to the first return maps of the vertical flow on a transverse segment . the rauzy - veech induction on the space of interval exchange maps provides a powerful tool to analyze the teichmller geodesic flow on the moduli space of abelian differentials . several major results have been proved using this renormalization . danthony and nogueira introduced in a natural generalization of interval exchange transformations , namely the linear involutions . these maps are related to general measured foliations on surfaces ( orientable or not ) . in this paper we are interested by such maps related to geodesic flow on ( orientable ) flat surfaces linear holonomy . we relate geometry and dynamics of such maps to the combinatorics of generalized permutations . we study an analogue of the rauzy - veech induction and give an efficient combinatorial characterization of its attractors . we establish a natural bijection between the extended rauzy classes of generalized permutations and connected components of the strata of meromorphic quadratic differentials most simple poles , which allows , in particular , to classify the connected components of all exceptional strata ."}
{"article": "cataclysmic variables ( cvs ) are short - period binaries containing a white dwarf ( wd ) primary ( mass ) and a low mass main sequence secondary ( mass ) . the secondary fills its roche lobe and transfers mass to the wd through the inner lagrangian point . the main features of the orbital period distribution of cvs hydrogen rich donors are the lack of systems in the 2 - 3 hr period range ( the so - called period gap ) and the sharp cut off of the distribution at around 77 minutes , as can be seen in figure ( upper frame ; e.g. ritter & kolb 1998 ) . so far theoretical models have been unable to reproduce the precise position of the observed short - period cut - off and observed shape of the cv orbital period distribution near this cut - off . this is summarised in figure . systems that evolve under the influence of gravitational radiation ( gr ; kraft et al . 1962 ) as the only sink of orbital angular momentum ( am ) reach a minimum period at minutes ( figure , middle frame ; paczyski 1971 ; kolb & baraffe 1999).the probability of finding a system within a given period range is proportional to the time taken to evolve through this region . we thus have n(p ) , for the number of systems found within a given orbital period range around , and is the secular period derivative at this period . we thus expect an accumulation of systems ( a spike ) at where ( figure , lower frame ) , while no such spike is present in the observed distribution ( figure , upper frame ) . the orbital period evolution reflects the radius evolution of the mass donor , which in turn is governed by two competing effects . mass transfer perturbs thermal equilibrium and expands the star . thermal relaxation reestablishes thermal equilibrium and contracts the star back to its equilibrium radius . the minimum period occurs where the two corresponding time scales , the mass transfer time and the thermal ( kelvin - helmholtz ) time are about equal ( e.g. paczyski 1971 ; king 1988 ) . if then the star is able to contract in response to mass loss , but if the star will not shrink rapidly enough and will become oversized for its mass . the position of the minimum period is therefore affected by the assumed mass transfer rate , and in particular by the assumed rate of orbital angular momentum ( am ) losses . in this paper we investigate ways to increase the period minimum by increasing the mass transfer rate , and investigate ways to `` hide '' the spike by introducing a spread of values in the cv population . in particular , we study the effect of a form of consequential am loss ( caml ) where the am is lost as a consequence of the mass transferred from the secondary , i.e. ( see e.g. webbink 1985 ) . in section we outline our general model assumptions and introduce the prescription for caml . in section we present detailed calculations of the long - term evolution of cvs , and in section we compare the observed short period cv period distribution various theoretically synthesized model distributions based on the calculations in section 2 . in this section we investigate possible solutions to the mismatch between the theoretical and observed minimum orbital period in cvs . the orbital am loss rate of a cv can be written as the sum of two terms , = sys+ caml , where denotes the `` systemic '' am loss rate , such as gravitational wave radiation , that is independent of mass transfer , while is an explicit function of the mass transfer rate . we have = 0 and caml0 20 we consider the general case in which the caml mechanism , along nova mass ejections , causes a fraction of the transferred mass to leave the system . this fraction may be greater than unity as the primary may lose more mass during a nova outburst than was accreted since the last outburst . we employ a generic prescription of the effect of a caml mechanism , thus avoiding the need to specify its physical nature . possible caml mechanisms include a magnetic propeller , i.e. a system containing a rapidly spinning magnetic wd where some of the transferred material gains angular momentum from the wd spin by interaction wd s magnetic field ( see e.g. wynn , king & horne 1997 ) , and an accretion disc wind ( see e.g. livio & pringle 1994 ) . our caml prescription largely follows the notation of king & kolb ( 1995 ) . the am is assumed to be lost via mass loss that is axis - symmetrical respect to an axis a fixed at the wd centre but perpendicular to the orbital plane . we define as the total fraction of mass lost from the secondary that leaves the system . we assume further that a fraction of the transferred mass leaves the system some fraction of the angular momentum it had on leaving the point . we also consider mass that is lost from the system via nova mass ejections , which over the long term can be considered as an isotropic wind from the primary ( see e.g. kolb et al . this material will carry away the specific orbital angular momentum of the primary and will account for the fraction of the mass loss . we thus obtain caml = b^2 2 + , where we define as the caml efficiency . for comparison king & kolb ( 1995 ) we equate this to caml = j , > 0 , and obtain = ( 1+q)^2 + . for our calculations shown below we use the approximation 1-+-,^3=. this is an adaptation of the expression given in kopal ( 1959 ) and is accurate to within 1% over the range . in this subsection we present calculations of the long - term evolution of cvs as they approach and evolve beyond the period minimum . for the computations we used the stellar code by mazzitelli ( 1989 ) , adapted to cvs by kolb & ritter ( 1992 ) . some of these evolutionary sequences are the basis for the theoretical cv period distributions we present in section below . we calculated the evolution of individual systems that are subject to caml according to equations and . we chose and initial donor mass , range of caml efficiencies as shown in figure . the systems initially evolve from longer periods towards the period bounce ( right to left ) at almost constant mass transfer rate . the minimum period increases increasing caml efficiency to a maximum of around 70 min for . mass transfer stability sets an upper limit on the caml efficiency . an obvious upper limit is 1 , where all the angular momentum of the transferred material is ejected from the system . although the ejected material may carry more angular momentum than was transferred ( as in the case of a propeller system where additional angular momentum is taken from the spin of the wd ) this does not affect the net loss of orbital angular momentum . the maximum caml efficiency still compatible mass transfer stability could be smaller than unity . the stability parameter which enters the expression for steady - state mass transfer , equation ( e.g. king & kolb 1995 ) must be greater than zero ; this defines an upper limit on . - 2=m 2 a plot of against for an initially marginally stable system ( , and ) is given in figure . the system initially exhibits cycles of high mass transfer rate ( close to 0 ) and very low mass transfer rate . the high states are short lived , on the order of years ( see figure ) . the system finally stabilizes . at around starts to decrease further but always remains positive , settling at a value around . the tidal deformation of the secondary may have an effect on the period minimum . calculations by renvoiz , baraffe , kolb & ritter ( 2002 ) , using 3dimensional sph models suggest that the secondary is deformed in the non - spherical roche lobe such that its volume equivalent radius is around 1.06 times that of the same star in isolation . we mimic this effect in our 1-dimensional stellar structure code by multiplying the calculated radius by a deformation factor before the mass transfer rate is determined from the difference between the radius and the roche lobe radius via - 2= 0(- ) . here is the mass transfer rate of a binary in which the secondary just fills its roche potential and is the photospheric pressure scale height of the secondary ( see e.g. ritter 1988 ) . figure shows the effect on the minimum period and mass transfer rate for systems various deformation factors , ranging from 1 ( no deformation ) to 1.24 . the mass transfer rate is seen to decrease increasing deformation . this can be understood from the functional dependence on orbital period and donor mass in the usual quadrupole formula for the am loss rate due to gravitational radiation ( see e.g. landau & lifschitz 1958 ) . although the quadrupole formula is strictly valid only if both components are point masses , rezzolla , ury & yoshida ( 2001 ) found that the gr rate obtained using a full 3-dimensional representation of the donor star differs from the point mass approximation by less than a few percent . it can be seen from the figure that deformation factor 1.06 the minimum period increases from around 65 min to around 69 min , consistent renvoiz et al ( 2002 ) for geometrical effects alone . a deformation factor of around 1.18 was required to raise the minimum period to the observed value of min . this is somewhat larger than the intuitive expectation ^=^=1.12 from kepler s law and roche geometry . in our calculations we consider the simple case in which only the geometrical deformation effects are taken into account . the inclusion of the thermal effects considered by renvoiz et al ( 2002 ) have the likely effect of reducing , possibly by around 2% compared to the case purely geometrical effects one possible physical mechanism that could cause a deformation factor above the value of 1.06 is magnetic pressure inside the star , as suggested by dantona ( 2000 ) . we note that patterson ( 2000 ) claims to find observational evidence for `` bloated '' secondaries in short period cvs . on the basis of donor mass estimates from the observed superhump excess period he finds that the donors have larger radii than predicted from 1 dimensional . , non deformed stellar models if gravitational radiation is the only am sink . even if true , this observation can not distinguish between an intrinsic deformation of the donor star or the non - equilibrium caused by orbital am losses in excess of the gr rate . to test the statistical significance of the theoretically predicted accumulation of systems near the period minimum ( `` period spike '' ) we calculated the period distributions of model populations for various assumptions about evolutionary parameters . for each parameter a series of evolutionary tracks were generated , typically around 20 . as systems evolve after the minimum period a point is reached ( typically when falls below ) where numerical fluctuations in become so large that the henyey scheme no longer converges . the stellar code uses tables to interpolate / extrapolate the opacities and equation of state for each iteration , and in this region the extrapolations become very uncertain . to extend the tracks we used a semi - analytical method as follows . the tracks were terminated at a value of , where is the mass transfer rate at the minimum period for the track . the radius of the star for the final part of the track is approximated by r 2=r 0m 2^ , where and are assumed to be constant . the values of and were determined from the final few data points for each track . ( takes a typical value of around 0.15 for systems beyond the period bounce . ) to generate the extension to the track we then calculated from the roche lobe condition , and by assuming stationarity as in section ( see figure , middle frame for an example of an extended track ) . we weight the chances of observation to the brighter systems by assuming , 1.0 . for the detection probability . we tested the calculated model parent distributions for various values of the free parameter against the observed cv period distribution . a k - s ( kolmogorov - smirnov ) test is insensitive to the differences between the parent distributions . the greatest difference in the cumulative distribution functions ( cdfs ) of the observed and modelled distributions occur at the boundaries of the cdfs , i.e. in the least sensitive region for the k - s test ( press et al 1992 ) . we thus decided to use the following modified test . for each parent distribution 10000 model samples each containing 134 systems were generated . ; ritter & kolb 1998 , internal update june 2001 , as of july 2002 the number of systems in this period range is now 152 though this does alter the values given by the test , the trends and hence the results remain unaltered ] each sample was tested against the model parent distribution using a test , 1 , 2 and 4 minute bins . this range bridges the need for good resolution and significance of the test which requires a minimum number of cvs per bin . the observed period distribution was tested against the model parent distribution also , giving the reduced value . the fraction of generated samples reduced value less than was used as a measure of the significance level of rejecting the hypothesis that the observed distribution is drawn from the parent distribution . in the following we quote the rejection probability pr= . kolb & baraffe ( 1999 ) noted that the observed distribution of non - magnetic cvs ( figure , middle frame ) , and the observed distribution of magnetic cvs ( figure , lower frame ) show no significant difference below the period gap . to test and quantify this we compared these distributions for min , giving a reduced probability of 0.1213 . hence we can not rule out that the distributions are drawn from the same underlying parent distribution . this is borne out by the results of comparing both distributions parent distribution that is flat in ( see also table , entries f and g ) which give similar rejection probabilities ( pr=0.709 and pr=0.781 , respectively ) . we thus find no significant difference between the two distributions . in the following we therefore test models against the combined magnetic and non - magnetic distribution of observed systems . the lack of any distinct features in the combined observed period distribution ( figure , upper frame ) does indeed suggest an essentially flat distribution for the underlying parent distribution . the flat distribution gives pr = 0.552 ( for the 1 minute bin width , see table ) . we use this value as a benchmark for the models discussed below . king , schenker & hameury ( 2002 ) constructed a ( nearly ) flat period distribution by superimposing individual idealized pdfs different bounce periods according to a suitably tailored weighting . for the double box - shaped idealised pdfs modelled on the pdf shown in our figure ( lower frame ) the required weighting is ] , but this still gives the fairly large value ( see also figure ) . however , such a parent population is inconsistent observed distribution for longer periods . as can be seen from figure systems that are subject to larger deformation factors would evolve into the period gap , hence the gap would be populated in this model . for completeness we show in figure the result of the superposition suggested by king , schenker & hameury ( 2002 ) if realistic rather than idealised pdfs are used . this model assumes additional systemic am losses ( ; no caml , no deformation factor , ) as the control parameter for varying , and the weighting as in king et al . the pronounced feature just above 2 hrs orbital period is the result of the adiabatic reaction of the donor stars at turn - on of mass transfer ( see e.g. ritter & kolb 1992 ) . such a feature is absent in the observed distribution . if deformation effects are taken into account the additional am losses required to wash out the spike would cover a similar range but at a smaller magnitude . the resulting period distribution would be similar to the one shown in figure we have investigated mechanisms that could increase the bounce period for cvs from the canonical theoretical value min to the observed value min , and ways to wash out the theoretically predicted accumulation of systems near the minimum period ( the period spike ) . unlike king , schenker & hameury 2002 we focussed on effects other than increased systemic angular momentum ( am ) losses , i.e. we assume that gravitational radiation is the only systemic sink of orbital am . we find that even a maximal efficient consequential am loss ( caml ) mechanism can not increase the bounce period sufficiently . as the real cv population is likely to comprise systems range of caml efficiencies we would in any case expect to have a distribution of systems down to min , rather than the observed sharp cut - off . we considered donor stars that are `` bloated '' due to intrinsic effects , such as the tidal deformation found in 3-dim . sph simulations of roche - lobe filling stars . an implausibly large deformation factor of around 1.18 is needed to obtain a bounce period of min . a possible alternative identification of as an age limit rather than a period bounce ( king & schenker 2002 ) would limit the donor mass in any cv in a cv population dominated by hydrogen rich , unevolved systems to . any system donor mass much less than this would either have an orbital period less than 78 minutes or would have already evolved beyond the period minimum . there are indeed systems suspected ; good candidates are wz sge ( ; patterson et al 1998 ) and oy car ( ; pratt et al . 1999 ) . it is also possible that systems die or fade before reaching the period bounce , and hence become undetectable as cvs . the fact that the very different groups of non - magnetic and magnetic cvs show almost identical values of ( see figure ) strongly suggests that the physical cause for the potential fading would have to be rooted in the donor stars or the evolution rather than the accretion physics or emission properties of the systems . even if the bounce period problem is ignored we find in all synthesized model populations ( except for the age limit model ) a pronounced remaining feature due to the accumulation of systems near the bounce . we employ a modified test to measure the `` goodness '' of fit against the observed sample . an f - test ( press et al 1992 ) was also applied to the majority of models and the same general trends observed . none of our synthesised model populations fits as well as the distribution which is simply flat in orbital period ( rejection probability ) . only models where brighter systems carry a far greater weight than expected in a simple magnitude limited sample ( selection factor rather than ) achieve similar values for . however , most of our models canot be rejected unambiguously on the basis of this test . models designed to `` wash out '' the period spike by introducing a large spread of the caml efficiency do generally better than population models based on donor stars that are subject to a large spread of intrinsic deformation factors . for all models the rejection probability decreases if the full wd mass spectrum is taken into account , as this introduces an additional spread in the bounce period . model populations where all cvs form at long orbital periods ( chiefly above the period gap ) give a much better fit than models that include newborn cvs small donor mass . adding these systems to the population introduces a general increase of the orbital period distribution towards short periods , thus making the period spike more pronounced . this suggests that most cvs must have formed at long periods and evolved through the period gap to become short - period cvs . this is consistent independent evidence that cv secondary stars are somewhat evolved ( baraffe & kolb 2000 ; schenker et al . 2002 ; thorstensen et al 2002 ) . recently , king , schenker & hameury ( 2002 ) constructed a flat orbital period distribution by superimposing idealised pdfs that describe subpopulations of cvs fixed initial donor mass and initial wd mass , but different bounce periods . this superposition required a strongly declining number of systems increasing bounce periods . we repeated this experiment realistic pdf , but failed to obtain a markedly improved fit . in conclusion , we find that the period minimum problem and the period spike problem remain an open issue . it is possible to construct cv model populations where the period spike is washed out sufficiently so that it can not be ruled out unambiguously on the basis of an objective statisticial test against the observed cv period distribution . we thank graham wynn , andrew king and isabelle baraffe for useful discussions . andrew conway and chris jones who gave advice on the statistical analysis . we also thank andrew norton for a critical reading of the paper and the referee jean - marie hameury for useful comments .", "summary": "we investigate if consequential angular momentum losses ( caml ) or an intrinsic deformation of the donor star in cvs could increase the cv bounce period from the canonical theoretical value min to the observed value min , and if a variation of these effects in a cv population could wash out the theoretically predicted accumulation of systems near the minimum period ( the period spike ) . we are able to construct suitably mixed cv model populations that a statisticial test can not rule out as the parent population of the observed cv sample . however , the goodness of fit is never convincing , and always slightly worse than for a simple , flat period distribution . generally , the goodness of fit is much improved if all cvs are assumed to form at long orbital periods . the weighting suggested by king , schenker & hameury ( 2002 ) does not constitute an improvment if a realistically shaped input period distribution is used . binaries : close stars : evolution stars : mass - loss novae , cataclysmic variables ."}
{"article": "the properties of the relativistic fermi gas ( rfg ) model of the nucleus have inspired the idea of superscaling . in the rfg model , the responses of the system to an external perturbation are related to a universal function of a properly defined scaling variable which depends upon the energy and the momentum transferred to the system . the adjective universal means that the scaling function is independent on the momentum transfer , this is called scaling of first kind , and it is also independent on the number of nucleons , and this is indicated as scaling of second kind . the scaling function can be defined in such a way to result independent also on the specific type of external one - body operator . this feature is usually called scaling of zeroth - kind . one has superscaling when the three kinds of scaling are verified . this happens in the rfg model . the theoretical hypothesis of superscaling can be empirically tested by extracting response functions from the experimental cross sections and by studying their scaling behaviors . inclusive electron scattering data in the quasi - elastic region have been analyzed in this way . the main result of these studies is that the longitudinal responses show superscaling behavior . the situation for the transverse responses is much more complicated . the presence of superscaling features in the data is relevant not only by itself , but also because this property can be used to make predictions . in effect , from a specific set of longitudinal response data , an empirical scaling function has been extracted , and has been used to obtain neutrino - nucleus cross sections in the quasi - elastic region . we observe that the empirical scaling function is quite different from that predicted by the rfg model . this indicates the presence of physics effects not included in the rfg model , but still conserving the scaling properties . we have investigated the superscaling behavior of some of these effects . they are : the finite size of the system , its collective excitations , the meson exchange currents ( mec ) and the final state interactions ( fsi ) . the inclusion of these effects produce scaling functions rather similar to the empirical one . our theoretical universal scaling functions , , and the empirical one , have been used to predict electron and neutrino cross sections . the definitions of the scaling variables and functions , have been presented in a number of papers therefore we do not repeat them here . the basic quantities calculated in our work are the electromagnetic , and the weak , nuclear response functions . we have studied their scaling properties by direct numerical comparison ( for a detailed analysis see ref . ) . we present in fig . the experimental longitudinal and transverse scaling function data for the c , ca and fe nuclei given in ref . for three values of the momentum transfer . we observe that the functions scale better than the ones . the scaling functions of c , especially for the lower values , are remarkably different from those of ca and fe . the observation of the figure , indicates that the scaling of first kind , independence on the momentum transfer , and of zeroth kind , independence on the external probe , are not so well fulfilled by the experimental functions . these observations are in agreement those of refs . . , and transverse , , scaling functions obtained from the experimental electromagnetic responses of ref . . the numbers in the panels indicate the values of the momentum transfer in / c . the full circles refer to c , the white squares to ca , and the white triangles to fe . the thin black line in the panel at / c , is the empirical scaling function obtained from a fit to the data . the thick lines show the results of our calculations when all the effects beyond the rfg model have been considered . the full lines have been calculated for c , the dotted lines for o , and the dashed lines for ca . the dashed thin lines show the rfg scaling functions.,height=604 ] to quantify the quality of the scaling between a set of scaling functions , each of them known on a grid of values of the scaling variable , we define the two indexes : \\ , - \\ , \\min {\\alpha=1,\\ldots , m } \\left \\right\\ } \\ , , \\ ] ] and \\ , - \\ , \\min {\\alpha=1,\\ldots , m } \\left \\right\\ } \\ ] ] where is the largest value of the . the two indexes give complementary information . the index is related to a local property of the functions : the maximum distance between the various curves . since the value of this index could be misleading if the responses have sharp resonances , we have also used the index which is instead sensitive to global properties of the differences between the functions . since we know that the functions we want to compare are roughly bell shaped , we have inserted the factor to weight more the region of the maxima of the functions than that of the tails . .values of the and indexes , for the experimental scaling functions of fig . . in tab . we give the values of the indexes calculated by comparing the experimental scaling functions of the various nuclei at fixed value of the momentum transfer . we consider that the scaling between a set of functions is fulfilled when 0.096 and 0.11 . these values have been obtained by adding the uncertainty to the values of and for at / c . from a best fit of this last set of data we extracted an empirical universal scaling function represented by the thin full line in the lowest left panel of fig . . this curve is rather similar to the universal empirical function given in ref . . let s consider now the scaling of the theoretical functions . the thin dashed lines of fig . show the rfg scaling functions . the thick lines show the results of our calculations when various effects beyond the rfg are introduced , i.e. : nuclear finite size , collective excitations , final state interactions , and , in the case of the functions , meson - exchange currents . we have studied the effects of the nuclear finite size , by calculating scaling functions within a continuum shell model . at q= / c , these scaling functions are very similar to those of the rfg model . at lower values of the momentum transfer , the shell model scaling functions show sharp peaks , produced by the shell structure , not present in the rfg model . we found that shell model scaling functions fulfill the scaling of first kind , the most likely violated , down to / c . we have estimated the effects of the collective excitations by doing continuum rpa calculations different residual interactions . the rpa effects become smaller the larger is the value of the momentum transfer . at / c , the rpa effects are negligible if calculated finite - range interaction . collective excitations breaks scaling properties , but we found that scaling of first kind is satisfied down to about / c . the presence of the mec violates the scaling of the transverse responses . we included the mec by using the model of ref . . in our calculations only one - pion exchange diagrams are considered , including those virtual excitation of the . in our model mec effects start to be relevant for / c . we found that mec do not destroy scaling in the kinematic range of our interest . the main modification of the shell model scaling functions , are produced by the fsi , we have considered by using the model developed in ref . we obtained scaling functions very different from those predicted by the rfg model , and rather similar to the empirical ones . in any case , the fsi do not heavily break the scaling properties . we found that the scaling of first kind is conserved down to = / c . the same type of scaling analysis applied to reaction leads to very similar results . to investigate the prediction power of the superscaling hypothesis , we compared responses , and cross sections , calculated by using rpa , fsi and eventually mec , those obtained by using and . we show in fig . double differential electron scattering cross sections calculated complete model ( full ) and those obtained ( dashed lines ) and ( dotted lines ) . these results are compared of refs . . c data have been measured at a scattering angle of =37.5 , the o data at =32.0 and the ca data at =45.5 . the full lines show the results of our complete calculations . the cross sections obtained by using are shown by the dashed lines , and those obtained by the dotted lines.,height=566 ] the excellent agreement between the results of the full calculations and those obtained by using , indicates the validity of the scaling approach in this kinematic region where the values are larger than / c . the differences cross sections obtained by using the empirical scaling functions , reflect the differences between the various scaling functions shown in fig . . the disagreement experimental data is probably due to the fact that our models do not consider the excitation of the real resonance , and the pion production mechanism . o . in all the panels the full lines show the result of our complete calculation , the dashed ( dotted ) lines the result obtained universal ( empirical ) scaling function . the results shown in panels ( a ) , ( b ) and ( c ) have been obtained for neutrino energy of . panel ( a ) : double differential cross sections calculated for the scattering angle of 30 as a function of the nuclear excitation energy . panel ( b ) : cross sections integrated on the scattering angle , always as a function of the nuclear excitation energy . panel ( c ) : cross sections integrated on the nuclear excitation energy , as a function of the scattering angle . panel ( d ) : total cross sections , as a function of the neutrino energy.,height=566 ] the situation for the double differential cross sections is well controlled , since all the kinematic variables , beam energy , scattering angle , energy of the detected lepton , are precisely defined , and consequently also energy and momentum transferred to the target nucleus . this situation changes for the total cross sections which are of major interest for the neutrino physics . the total cross sections are only function of the energy of the incoming lepton , therefore they consider all the scattering angles and of the possible values of the energy and momentum transferred to the nucleus , only limitation of the global energy , and momentum , conservations . this means that , in the total cross sections , kinematic situations where the scaling is valid and also where it is not valid are both present . we show in the first three panels of fig . various differential charge - exchange cross sections obtained for neutrinos on o target . in the panel ( a ) we show the double differential cross sections calculated for a scattering angle of 30 , as a function of the nuclear excitation energy . the values of the momentum transfer vary from about 150 to / c . this is not the quasi - elastic regime where the scaling is supposed to hold , and this explains the large differences between the various cross sections . the cross sections integrated on the scattering angle are shown as a function of the nuclear excitation energy in the panel ( b ) of the figure , while the cross sections integrated on the excitation energy as a function of the scattering angle are shown in the panel ( c ) . the first three panels of the figure illustrate in different manner the same physics issue . the calculation scaling functions fails in reproducing the results of the full calculation in the region of low energy and momentum transfer , where surface and collective effects are important . this is shown in panel ( b ) by the bad agreement between the three curves in the lower energy region , and in panel ( c ) at low values of the scattering angle , where the valued are minimal . total charge - exchange neutrino cross sections are shown in panel ( d ) as a function of the neutrino energy . the scaling predictions for neutrino energies up to are unreliable . these total cross sections are dominated by the giant resonances , and more generally by collective nuclear excitation . we have seen that these effects strongly violate the scaling . at = the cross section obtained universal function is still about 20% larger than those obtained full calculation . this difference becomes smaller increasing energy and is about the 7% at = . this is an indication that the relative weight of the non scaling kinematic regions becomes smaller increasing neutrino energy .", "summary": "superscaling analysis of electroweak nuclear response functions is done for momentum transfer values from 300 to / c . some effects , absent in the relativistic fermi gas model , where the superscaling holds by construction , are considered . from the responses calculated for the c , o and ca nuclei , we have extracted a theoretical universal superscaling function similar to that obtained from the experimental responses . theoretical and empirical universal scaling functions have been used to calculate electron and neutrino cross sections . these cross sections have been compared those obtained complete calculation and , for the electron scattering case , experimental data ."}
{"article": "one of the oldest problems of algebra is the equation solvability problem over a given algebraic structure . nowadays , many such classical problems arise in a new perspective , namely to consider their computational complexity . in this paper we investigate the complexity of the equation solvability problem over finite groups and rings . the equation solvability problem over a finite group asks whether or not two group expressions ( i.e. products of variables and elements of ) can attain the same value for some substitution over . in other words , for the equation solvability problem , one needs to find if there exists at least one substitution satisfying the equation . another interesting problem is whether or not all substitutions satisfy the equation . the equivalence problem over a finite group asks whether or not two group expressions and are equivalent over ( denoted by ) , that is whether or not and determine the same function over . first burris and lawrence investigated the complexity of the equivalence problem over finite groups . they proved that if a group is nilpotent or , the dihedral group for odd , then the equivalence problem for has polynomial time complexity . they conjectured that the equivalence problem for is in polynomial time if is solvable , and conp - complete otherwise . horvth and szab confirmed the conjecture for , where and are abelian groups such that the exponent of is squarefree and . later horvth generalized this result to semidirect products , where and are abelian groups ( here denotes the centralizer of in ) . horvth , lawrence , mrai and szab proved the conp - complete part of the conjecture . but the complexity of the equivalence problem over many solvable , not nilpotent groups is not determined , yet . three of the smallest groups , for which this complexity is not known , are , and a non - commutative group of order . see for a more comprehensive list . even less is known about the equation solvability problem . goldmann and russel proved that if is nilpotent then the equation solvability problem over is solvable in polynomial time , while if is not solvable , then the equation solvability problem is np - complete . little is known for solvable , not nilpotent groups . horvth proved in ( * ? ? ? * corollary 2 ) that the equation solvability problem over is solvable in polynomial time for certain groups , where or or and is commutative . note that all results for both the equivalence and the equation solvability problem over solvable , not nilpotent groups are about groups , where is abelian . one of the groups of small order , for which the equation solvability problem is unknown , is the group . here , denotes the noncommutative group of upper unitriangular matrices over . horvth explicitly asks in ( * ? ? ? * problem 4 ) the complexity of the equivalence and equation solvability problems over this group . the group is isomorphic to a special subgroup of the upper triangular matrices over . motivated by the definition of pattern groups from , we call a group a semipattern group , if is a subgroup of the group of upper unitriangular matrices , and is a subgroup of the diagonal matrices . we give the precise definition of semipattern groups in section . the main result of the paper is the following . the equation solvability problem over semipattern groups is solvable in polynomial time . the group defined in ( * ? ? ? * problem 4 ) is in fact a semipattern group , thus theorem answers horvth s question completely . further , from theorem the equivalence problem over semipattern groups is solvable in polynomial time , as well . indeed , it is known that for a group if the equation solvability problem is solvable in polynomial time , then the equivalence problem is solvable in polynomial time , as well . in the proof of theorem we reduce the solvability of the input equation over a matrix group over a finite field to the solvability of a system of equations over the same field . then we apply some results over finite rings . therefore , we summarize the known results over rings . the equation solvability problem over a finite ring asks whether or not two polynomials can attain the same value for some substitution over . the equivalence problem over a finite ring asks whether or not two polynomials are equivalent over i.e. if they determine the same function over . the complexity of these questions was completely characterized in the past two decades . hunt and stearnes investigated the equivalence problem for finite commutative rings . later burris and lawrence generalized their result to non - commutative rings . they proved that the equivalence problem for is solvable in polynomial time if is nilpotent , and is conp - complete otherwise . the proof of burris and lawrence reduces the satisfiability ( sat ) problem to the equivalence problem by using long products of sums of variables . nevertheless , if we expand this polynomial into a sum of monomials then the length of the new polynomial may become exponential in the length of the original polynomial . such a change in the length suggests that the complexity of the equivalence problem might be different if the input polynomials are restricted to be written as sums of monomials . this motivated lawrence and willard to introduce the sigma equivalence and sigma equation solvability problems , where the input polynomials are given as sums of monomials . lawrence and willard conjectured that if the factor by the jacobson radical is commutative then the sigma equivalence problem is solvable in polynomial time , and is conp - complete otherwise . szab and vrtesi proved the conp - complete part of the conjecture in . horvth confirmed the conjecture for commutative rings in . the polynomial part of this conjecture is completely proved in the manuscript . most of the results for the equation solvability problem follow from the corresponding result for the equivalence problem . in particular , from the argument of szab and vrtesi follows that if the factor by the jacobson radical is not commutative then the sigma equation solvability problem is np - complete . horvth , lawrence and willard proved that if this factor is commutative then the sigma equation solvability problem is solvable in polynomial time . thus , the sigma equation solvability problem is completely characterized . for the general equation solvability , arguments of burris and lawrence from yield that if the ring is not nilpotent then the problem is np - complete . horvth in proved that the equation solvability problem is solvable in polynomial time otherwise . if is a finite , nilpotent ring then the equation solvability problem over is solvable in polynomial time . horvth uses ramsey s theorem in the proof of theorem . he defines a number that depends only on the ring . then he proves that the image of every polynomial can be obtained by substituting into all but -many variables . thus one can decide whether or not is solvable over in time . however , this number is huge in the size of the ring . in fact , is greater than , where the height of the tower in the exponent is the nilpotency class of . horvth specifically asks in ( * ? ? * problem 3 ) whether or not this number can be decreased . in the second half of the paper we give a new proof of theorem . our algorithm is much more efficient than horvth s . wilson characterizes nilpotent rings help of special kind of nilpotent matrix rings . we can decide the equation solvability problem over these special matrix rings similarly as we do over semipattern groups in theorem . in particular , we show that over a nilpotent ring we can decide in time whether or not is solvable , thus providing a partial answer to problem 3 in , as well . we mention that in a completely independent way , krolyi and szab also found a way to decrease the exponent in . in section we summarize the notations , definitions and theorems , that we use in the paper . in particular , in section we review the definition of pattern groups , then we define semipattern groups . in section we discuss the generalization of the equation solvability problem over rings for systems of equations . we are going to apply these results in order to prove theorems and . in section we lay the groundwork for the proof of theorem . in section we prove theorem . we use ideas of this proof in section , where we prove theorem . let denote the finite field of elements . let us consider the group of upper triangular matrices , that is those matrices whose elements under the diagonal are zero and the elements in the diagonal are non - zero : here the group operation is the matrix multiplication . let the identity matrix denoted by . let denote the matrix whose elements are all zero except for the element in the row , which is 1 . let . let thus , contains all those upper triangular matrices , where every element in the diagonal is , and every element whose position is not occurring in p has to be . if is a subgroup of , then we call a pattern group . for more details on pattern groups , see e.g. . let be subgroups of and let be the set of matrices over whose element in the diagonal is from : if is a pattern group then is a subgroup of . then we call a semipattern group and we denote such a group by . further , we note that and . the group defined in ( * ? ? ? * problem 4 ) is in fact a semipattern group : let be a commutative , unital ring , be subsets of . for nonnegative integers , let , , , be pairwise disjoint sets of variables . we say that is solvable over for substitutions from ( and write is solvable over ) if there exist , , , such that the two polynomials attain the same value on this substitution : for proving theorem , we will directly apply the following result of horvth . let be a finite field . let be subgroups of . let ] be polynomials , written as sums of monomials . then it can be decided whether the system of equations is solvable over in time . the complexity of the equation solvability problem over finite nilpotent rings is known . horvth proved that the equation solvability problem is solvable in polynomial time . we give a new algorithm in section that is much more efficient than horvth s . in this part we show that we can characterize the complexity of the equation solvability problem over nilpotent rings using the sigma equation solvability problem over special kind of nilpotent matrix rings . hence we can apply the same ideas that we used in the proof of theorem . horvth proved theorem using ramsey s theory . he defined a number that depends only on the ring . then he proved that the image of every polynomial can be obtained by substituting into all but -many variables . thus one can decide whether or not is solvable over in time . but the number is huge in the size of the ring . let be the characteristic of and be the nilpotency class of . let furthermore . then is greater than , where the height of the tower in the exponent is . we give a new proof of theorem in section . our algorithm is much more efficient than horvth s . we prove that time is enough . first , we show that we can handle the equation solvability problem over nilpotent rings using the sigma equation solvability problem over special kind of nilpotent matrix rings . if is a nilpotent ring then the complexity of the general equation solvability problem over is the same as the complexity of the sigma equation solvability over . indeed , we can rewrite every polynomial over as a sum of monomials in time , where is the nilpotency class of . now , . hence , at the cost of an extra factor in the exponent , we may assume that every input polynomial is given as a sum of monomials . furthermore it is enough to consider the equation solvability problem over nilpotent rings prime power characteristic , because every ring is a direct sum of rings of prime power characteristic , and the equation solvability problem can be handled componentwise . wilson characterizes finite nilpotent rings prime power characteristic . let be a finite nilpotent ring characteristic , and let have an independent generating set consisting of generators over . then is a homomorphic image of a ring of matrices over where every entry on or below the main diagonal is a multiple of . in fact for nilpotent rings it is enough to consider the equation solvability problem over such a matrix ring , since if the equation solvability problem is solvable in polynomial time for , then it is solvable in polynomial time for a factor , as well . indeed , let be a polynomial over and be any polynomial over whose factor by is . then is solvable over if and only if is solvable over for some . this gives an extra factor to the running time . however , , and we have , . thus , , which only depends on , and thus can be forgotten about . thus it is enough to consider the sigma equation solvability problem over such a matrix ring of matrices over where every entry on or below the main diagonal of each matrix is a multiple of . we can handle such matrix rings similarly as we do semmipattern groups . hence we can use ideas of the proof described in section . we give a new , efficient algorithm that decides the equation solvability problem over nilpotent matrix rings in section . in this section we consider the equation solvability problem over semmipattern groups . first we characterize the multiplication of matrices from in lemma . we use this formula in our algorithm . let n be a natural number . for every let let then * for every we have * for every we have + the length of is , and in particular is polynomial in . the lemma can be proved by induction on . however , instead of giving the technical induction proof , we explain how one can arrive at this formula . let us consider the element of the row of the matrix . we can express this element sum of some appropriate products . in every such product we multiply one element from each matrix . ( in the notation the index appears as the last index . ) furthermore the index of the column of a term must equal index of the row of the following term in every such product . ( therefore a term of the form or follows the term of the form or . ) the row index of the first term is , the column index of the last term is . the matrices are upper triangular matrices , hence the row index of every term of every product is less than or equal to the column index . ( thus for every term of the form , that are above the diagonal , we have . ) thus the element of the row of the matrix is a sum of products of terms such that * the row index of the first term is , the column index of the last term is ; * the column index of every term equals to the row index of the next term ; * the row index of a term is at most the row index of the next term . notice , that every -term product is uniquely determined by those terms where the row index differs from the column index . let two such consecutive terms of the product be and . ( here and . ) the product of the terms between these two terms have row and column index and their last index is more than and less than . thus between the terms and can only be the product . thus formula is proved . now , we calculate the length of formula . formula is a sum of products . the length of every product is , thus we need to calculate the number of products . notice , that every product is uniquely determined by the column indices of the terms . more exactly we need to know the column indices of the first terms , because the column index of the last term is . we can choose these indices from the set . the order of the selected elements does not matter . we only need to determine how many indices are equal to or to , etc , or to . thus we need to choose element from a set of elements such that repetitions are allowed . hence the number of products is since every product has length , the length of is thus the length of is at most for every index . let be a semipattern group . let be a polynomial over . thus can indicate a constant or a variable over . of course and can indicate the same constant or variable . let if indicates constant then is a constant in and is a constant in . if is a variable , then is a variable , that we can substitute from , and is a variable that we can substitute from . furthermore if and only if ( for every ) and for every . we can rewrite the polynomial this notation as after multiplying these matrices using lemma we obtain where the polynomial can attain the unit matrix for a substitution if and only if attains and attains for the same substitution . thus is solvable over if and only if the system of equations is solvable over . this is a system of equations over where the polynomials are given as sums of monomials . hence we can decide the solvability of this system of equations in polynomial time by theorem . the rewriting of over into the system of equations over can be done in time by lemma , and the length of each equation is . the number of equations is , which does not depend on , only on the group . by theorem one can decide whether this system has a solution in time . let be a ring of matrices over where every entry on or below the main diagonal of each matrix in is a multiple of . let be a polynomial over given as a sum of monomials . let denote a monomial in the sum . let if indicates constant then are constants in . if is a variable , then are variables , that we can substitute from . furthermore , if and only if and for every . first is a polynomial given as a sum of monomials over . in every such monomial we multiply one term from each matrix . hence the length of every monomial is . there are at most monomials in every polynomial according to the usual multiplication of matrices . however , every nonzero monomial contains at most terms from on or below the main diagonal , since the characteristic of is . therefore every nonzero monomial is of the form where and . notice that holds as well . indeed , every term is from above the main diagonal , hence . therefore and thus . similarly . hence the length of every nonzero monomial is at most . in particular , if then every monomial in equals . therefore there are at most monomials in every polynomial and thus . the input polynomial is a sum of at most monomials . let then is the sum of at most -many polynomials for every . thus , as and depend only on the ring . the polynomial can attain the zero matrix for a substitution if and only if attains zero for the same substitution for every . thus is solvable over if and only if the system of equations is solvable over . this is a system of equations over where the polynomials are given as sums of monomials . hence we can decide the solvability of this system of equations in polynomial time by theorem . the rewriting of over into the system of equations can be done in time , and . the number of equations is , which does not depend on , only on the ring . by theorem one can decide whether this system has a solution in time . finally , we explain how this result can be applied to determine if an equation is solvable over an arbitrary nilpotent ring of characteristic . let be the matrix ring as in theorem , and let . further , let denote the polynomial in corresponding to . notice , that was the characteristic of in theorem , hence . furthermore and . therefore . hence , one can decide if is solvable over in time . thus , one can decide if the equation is solvable over in time . now , , which only depends on . therefore , if is given as a sum of monomials , then , and one can decide over an arbitrary nilpotent ring in time , as well . if , however , is an arbitrary polynomial over , then after rewriting it as a sum of monomials we have , giving an extra factor in the exponent . thus , one can decide over an arbitrary nilpotent ring in time . mikael goldmann and alexander russell . the complexity of solving equations over finite groups . in proceedings of the 14th annual ieee conference on computational complexity , pages 8086 , atlanta , georgia , 1999 .", "summary": "the complexity of the equation solvability problem is known for nilpotent groups , for not solvable groups and for some semidirect products of abelian groups . we provide a new polynomial time algorithm for deciding the equation solvability problem over certain semidirect products , where the first factor is not necessarily abelian . our main idea is to represent such groups as matrix groups , and reduce the original problem to equation solvability over the underlying field . further , we apply this new method to give a much more efficient algorithm for equation solvability over nilpotent rings than previously existed ."}
{"article": "in the last years wireless communication systems coped problem of delivering reliable information while granting high throughput . this problem has often been faced resorting to channel codes able to correct errors even at low signal to noise ratios . as pointed out in table i in , several standards for wireless communications adopt binary or double binary turbo codes and exploit their excellent error correction capability . however , due to the high computational complexity required to decode turbo codes , optimized architectures ( e.g. , ) have been usually employed . moreover , several works addressed the parallelization of turbo decoder architectures to achieve higher throughput . in particular , many works concentrate on avoiding , or reducing , the collision phenomenon that arises parallel architectures ( e.g. ) . although throughput and area have been the dominant metrics driving the optimization of turbo decoders , recently , the need for flexible systems able to support different operative modes , or even different standards , has changed the perspective . in particular , the so called software defined radio ( sdr ) paradigm made flexibility a fundamental property of future receivers , which will be requested to support a wide range of heterogeneous standards . some recent works ( e.g. , , ) deal implementation of application - specific instruction - set processor ( asip ) architectures for turbo decoders . in order to obtain architectures that achieve both high throughput and flexibility multi - asip is an effective solution . thus , together flexible and high throughput processing elements , a multi - asip architecture must feature also a flexible and high throughput interconnection backbone . to that purpose , the network - on - chip ( noc ) approach has been proposed to interconnect processing elements in turbo decoder architectures designed to support multiple standards , , , , , . in addition , noc based turbo decoder architectures have the intrinsic feature of adaptively reducing the communication bandwidth by the inhibition of unnecessary extrinsic information exchange . this can be obtained by exploiting bit - level reliability - based criteria where unnecessary iterations for reliable bits are avoided . in , , ring , chordal ring and random graph topologies are investigated whereas in previous works are extended to mesh and toroidal topologies . furthermore , in butterfly and benes topologies are studied , and in binary de - bruijn topologies are considered . however , none of these works presents a unified framework to design a noc based turbo decoder , showing possible complexity / performance trade - offs . this work aims at filling this gap and provides two novel contributions in the area of flexible turbo decoders : i ) a comprehensive study of noc based turbo decoders , conducted by means of a dedicated noc simulator ; ii ) a list of obtained results , showing the complexity / performance trade - offs offered by different topologies , routing algorithms , node and asip architectures . the paper is structured as follows : in section the requirements and characteristics of a parallel turbo decoder architecture are analyzed , whereas in section noc based approach is introduced . section summarizes the topologies considered in previous works and introduces generalized de - bruijn and generalized kautz topologies as promising solutions for noc based turbo decoder architectures . in section three main routing algorithms are introduced , whereas in section the turbo noc framework is described . section describes the architecture of the different routing algorithms considered in this work , section presents the experimental results and section draws some conclusions . a parallel turbo decoder can be modeled as processing elements that need to read from and write to memories . each processing element , often referred to as soft - in - soft - out ( siso ) module , performs the bcjr algorithm , whereas the memories are used for exchanging the extrinsic information among the sisos . the decoding process is iterative and usually each siso performs sequentially the bcjr algorithm for the two constituent codes used at the encoder side ; for further details on the siso module the reader can refer to . as a consequence , each iteration is made of two half iterations referred to as interleaving and de - interleaving . during one half iteration the extrinsic information produced by siso at time is sent to the memory at the location , where and are functions of and derived from the permutation law ( or interleaver ) employed at the encoder side . thus , the time required to complete the decoding is directly related to the number of clock cycles necessary to complete a half iteration . without loss of generality , we can express the number of cycles required to complete a half iteration as where is the total number of trellis steps in a data frame , is the number of trellis steps processed by each siso , is the siso output rate , namely the number of trellis steps processed by a siso in a clock cycle , and is the interconnection structure latency . thus , the decoder throughput expressed as the number of decoded bits over the time required to complete the decoding process is where is the clock frequency , is the number of iterations , for binary codes and for double binary codes . when the interconnection structure latency is negligible respect to the number of cycles required by the siso , we obtain thus , to achieve a target throughput and satisfactory error rate performance , a proper number of iterations should be used . the minimum to satisfy iterations can be estimated from for some asip architectures available in the literature . if we consider , as in , , ranges in to achieve mb / s ( see table ) . it is worth pointing out that the values in table represent the average numbers of cycles required by the siso to update the soft information of one bit ( see table vi in and table i in ) . moreover , strongly depends on the internal architecture of the siso and in general tends to increase code complexity . as a consequence , several conditions can further increase , namely 1 ) interconnection structures larger ; 2 ) higher values ; 3 ) higher ; 4 ) higher ; 5 ) lower clock frequency . thus , we consider as relevant for investigation a slightly wider range for : . .parallelism degree required to obtain mb / s for some asip architectures available in the literature the area and the percentage are not really zero , but they are negligible compared i m and lm contribution to the total area . the most important conclusions that can be derived from results in table and are : 1 . the asp - ft routing algorithm is the best performing solution both in terms of throughput and area when . 2 . the routing memory overhead of the asp - ft algorithm ( see fig . ( b ) ) becomes relevant as decreases and ssp solutions become the best solutions mainly for and . 3 . in most cases topologies =4 achieve higher throughput lower complexity overhead than topologies =2 when . 4 . in most cases , generalized de - bruijn and generalized kautz topologies are the best performing topologies . as a significant example , in fig . , we show the experimental results obtained and asp - ft routing algorithm for the wimax interleaver ( a ) and the circular shifting interleaver ( b ) . each point represents the throughtput and the area obtained for a certain topology certain parallelism degree . results referred to the same value are bounded into the same box and a label is assigned to each point to highlight the corresponding topology , namely topologies are identified as r - ring , h - honeycomb , t - toroidal mesh , k - generalized kautz corresponding value ( k2 , k3 , k4 ) . as it can be observed , generalized kautz topologies ( k4 ) are always the best solutions to achieve high throughput minimum area overhead . in fig . significant results extracted from table and are shown in graphical form . in particular , for the asp - ft routing algorithm is the best solution , whereas for ssp routing algorithms , implemented as in fig . ( c ) , tend to achieve the same performance as the asp - ft routing algorithm lower complexity overhead ( see fig . ( a ) and ( b ) for the wimax interleaver , and fig . ( c ) and ( d ) for the circular shifting interleaver , ) . an interesting phenomenon that arises increasing the interleaver size is the performance saturation that can be observed in the table for topologies , namely the throughput tends to saturate and increasing has the effect of augmenting the area negligible increase or even decrease of throughput . as an example , the generalized kautz topology and asp - ft routing algorithm achieves more than 180 mb / s , , . however , the solution smallest area is the one obtained . the throughput flattening of low topologies can be explained by observing that high values of tend to saturate the network . furthermore , high values of lengthen the input fifos as highlighted in table , where the total area of the network is given as the breakdown of the building blocks , namely the input fifos , the crossbars ( cb ) , the output registers , the routing algorithm / memory ( ra / m ) , the identifier memory ( i m ) and the location memory ( lm ) is given for some significant cases : the highest throughput ( light - gray ) , the highest area ( mid - gray ) , and lowest area ( dark - gray ) points for each value in table . in this work a general framework to design network on chip based turbo decoder architectures has been presented . the proposed framework can be adapted to explore different topologies , degrees of parallelism , message injection rates and routing algorithms . experimental results show that generalized de - bruijn and generalized kautz topologies achieve high throughput limited complexity overhead . moreover , depending on the target throughput requirements different parallelism degrees , message injection rates and routing algorithms can be used to minimize the network area overhead . a. giulietti , l. v. der perre , and m. strum , `` parallel turbo coding interleavers : avoiding collisions in accesses to storage elements , '' iet electronics letters , vol . 38 , no . 5 , pp . 232234 , feb 2002 . m. j. thul , f. gilbert , and n. wehn , `` optimized concurrent interleaving architecture for high - throughput turbodecoding , '' in ieee international conference on electronics , circuits and systems , 2002 , pp . 10991102 . c. neeb , m. j. thul , and n. wehn , `` network - on - chip - centric approach to interleaving in high throughput channel decoders , '' in ieee international symposium on circuits and systems , 2005 , pp . 17661769 . h. moussa , o. muller , a. baghdadi , and m. .jezequel , `` butterfly and benes - based on - chip communication networks for multiprocessor turbo decoding , '' in design , automation and test in europe conference and exhibition , 2007 , pp . 654659 . s. benedetto , d. divsalar , g. montorsi , and f. pollara , `` soft - input soft - output modules for the construction and distributed iterative decoding of code networks , '' european transactions on telecommunications , vol . 9 , no . 2 , pp . 155172 , mar / apr 1998 . o. muller , a. baghdadi , and m. jezequel , `` asip - based multiprocessor soc design for simple and double binary turbo decoding , '' in design , automation and test in europe conference and exhibition , 2006 , pp . 13301335 . o. muller , a. baghdadi , and m. jezequel , `` exploring parallel processing levels for convolutional turbo decoding , '' in ieee international conference on information and communication technologies : from theory to applications , 2006 , pp .", "summary": "this work proposes a general framework for the design and simulation of network on chip based turbo decoder architectures . several parameters in the design space are investigated , namely the network topology , the parallelism degree , the rate at which messages are sent by processing nodes over the network and the routing strategy . the main results of this analysis are : i ) the most suited topologies to achieve high throughput limited complexity overhead are generalized de - bruijn and generalized kautz topologies ; ii ) depending on the throughput requirements different parallelism degrees , message injection rates and routing algorithms can be used to minimize the network area overhead ."}
{"article": "model selection is an important problem in many areas including machine learning . if a proper model is not selected , any effort for parameter estimation or prediction of the algorithm s outcome is hopeless . given a set of candidate models , the goal of model selection is to select the model that best approximates the observed data and captures its underlying regularities . model selection criteria are defined such that they strike a balance between the goodness - of - fit ( gof ) , and the generalizability or complexity of the models . goodness - of - fit measures how well a model capture the regularity in the data . generalizability / complexity is the assessment of the performance of the model on unseen data or how accurately the model fits / predicts the future data . models higher complexity than necessary can suffer from overfitting and poor generalization , while models that are too simple will underfit and have low gof . cross - validation , bootstrapping , akaike information criterion ( aic ) , and bayesian information criterion ( bic ) , are well known examples of traditional model selection . in re - sampling methods such as cross - validation and bootstraping , the generalization error of the model is estimated using monte carlo simulation . in contrast - sampling methods , the model selection methods like aic and bic do not require validation to compute the model error , and are computationally efficient . in these procedures an information criterion is defined such that the generalization error is estimated by penalizing the model s error on observed data . a large number of information criteria have been introduced different motivations that lead to different theoretical properties . for instance , the tighter penalization parameter in bic favors simpler models , while aic works better when the dataset has a very large sample size . kernel methods are strong , computationally efficient analytical tools that are capable of working on high dimensional data arbitrarily complex structure . they have been successfully applied in wide range of applications such as classification , and regression . in kernel methods , the data are mapped from their original space to a higher dimensional feature space , the reproducing kernel hilbert space ( rkhs ) . the idea behind this mapping is to transform the nonlinear relationships between data points in the original space into an easy - to - compute linear learning problem in the feature space . for example , in kernel regression the response variable is described as a linear combination of the embedded data . any algorithm that can be represented through dot products has a kernel evaluation . this operation , called kernelization , makes it possible to transform traditional , already proven , model selection methods into stronger , corresponding kernel methods . the literature on kernel methods has , however , mostly focused on kernel selection and on tuning the kernel parameters , but only limited work being done on kernel - based model selection . in this study , we investigate a kernel - based information criterion for ridge regression models . in kernel ridge regression ( krr ) , tuning the ridge parameters to find the most predictive subspace respect to the data at hand and the unseen data is the goal of the kernel model selection criterion . in classical model selection methods the performance of the model selection criterion is evaluated theoretically by providing a consistency proof where the sample size tends to infinity and empirically through simulated studies for finite sample sizes . other methods investigate a probabilistic upper bound of the generalization error . proving the consistency properties of the model selection in kernel model selection is challenging . the proof procedure of the classical methods does not work here . some reasons for that are : the size of the model to evaluate problems such as under / overfitting is not apparent ( for data points of dimension , the kernel is , which is independent of ) and asymptotic probabilities of generalization error or estimators are hard to compute in rkhs . researchers have kernelized the traditional model selection criteria and shown the success of their kernel model selection empirically . kobayashi and komaki extracted the kernel - based regularization information criterion ( kric ) using an eigenvalue equation to set the regularization parameters in kernel logistic regression and support vector machines ( svm ) . rosipal et al . developed covariance information criterion ( cic ) for model selection in kernel principal component analysis , because of its outperformed results compared to aic and bic in orthogonal linear regression . demyanov et al . , provided alternative way of calculating the likelihood function in akaike information criterion ( aic , and bayesian information criterion ( bic , ) , and used it for parameter selection in svms using the gaussian kernel . as pointed out by van emden , a desirable model is the one fewest dependent variables . thus defining a complexity term that measures the interdependency of model parameters enables one to select the most desirable model . in this study , we define a novel variable - wise variance and obtain a complexity measure as the additive combination of kernels defined on model parameters . formalizing the complexity term in this way effectively captures the interdependency of each parameter of the model . we call this novel method kernel - based information criterion ( kic) . model selection criterion in gaussian process regression ( gpr ; ) , and kernel - based information complexity ( icomp ; ) resemble kic in using a covariance - based complexity measure . however , the methods differ because these complexity measures capture the interdependency between the data points rather than the model parameters . although we can not establish the consistency properties of kic theoretically , we empirically evaluate the efficiency of kic both on synthetic and real datasets obtaining state - of - the - art results compared to leave - one - out - cross - validation ( loocv ) , kernel - based icomp , and maximum log marginal likelihood in gpr . the paper is organized as follows . in section , we give an overview of kernel ridge regression . kic is described in detail in section . section is provides a brief explanation of the methods to which kic is compared , and in section we evaluate the performance of kic through sets of experiments . in regression analysis , the regression model of the form : where can be either a linear or non - linear function . in linear regression we have , , where is an observation vector ( response variable ) of size , is a full rank data matrix of independent variables of size , and , is an unknown vector of regression parameters , where denotes the transposition . we also assume that the error ( noise ) vector is an -dimensional vector whose elements are drawn i.i.d , , where is an -dimensional identity matrix and is an unknown variance . the regression coefficients minimize the squared errors , , between estimated function , and target function . when , the problem is ill - posed , so that some kind of regularization , such as tikhanov regularization ( ridge regression ) is required , and the coefficients minimize the following optimization problem where is the regularization parameter . the estimated regression coefficients in ridge regression are : in kernel ridge regression ( krr ) , the data matrix is non - linearly transformed in rkhs using a feature map . the estimated regression coefficients based on are : where is the kernel matrix . equation does not obtain an explicit expression for because of ( the kernel trick enables one to avoid explicitly defining that could be numerically intractable if computed in rkhs , if known ) , thus a ridge estimator is used ( e.g. ) that excludes : using in the calculation of krr is similar to regularizing the regression function instead of the regression coefficients , where the objective function is : and denotes the relevant rkhs . for , and we have : where is the kernel function , and . the main contribution of this study is to introduce a new kernel - based information criterion ( kic ) for the model selection in kernel - based regression . according to equation kic balances between the goodness - of - fit and the complexity of the model . gof is defined using a log - likelihood - based function ( we maximize penalized log likelihood ) and the complexity measure is a function based on the covariance function of the parameters of the model . in the next subsections we elaborate on these terms . the definition of van emden for the complexity measure of a random vector is based on the interactions among random variables in the corresponding covariance matrix . a desirable model is the one fewest dependent variables . this reduces the information entropy and yields lower complexity . in this paper we focus on this definition of the complexity measures . considering a -variate normal distribution , the complexity of a covariance matrix , , is given by the shannon s entropy , where , are the marginal and the joint entropy , and is the diagonal element of . if and only if the covariates are independent . the complexity measure in equation changes orthonormal transformations because it is dependent on the coordinates of the random variable vectors . to overcome these drawbacks , bozodgan and haughton introduced icomp information criterion complexity measure based on the maximal covariance complexity , which is an upper bound on the complexity measure in equation : this complexity measure is proportional to the estimated arithmetic and geometric mean of the eigenvalues of the covariance matrix . larger values of , indicates higher dependency between random variables , and vice versa . zhang introduced a kernel form of this complexity measure , that is computed on kernel - based covariance of the ridge estimator : the complexity measure in gaussian process regression ( gpr ; ) is defined as , a concept from the joint entropy ( as shown in equation ) . in contrast to icomp and gpr , the complexity measure in kic is defined using the hilbert - schmidt ( hs ) norm of the covariance matrix , . minimizing this complexity measure obtains a model more independent variables . in the next sections , we explain in detail how to define the needed variable - wise variance in the complexity measure , and the computation of the complexity measure . + in kernel - based model selection methods such as icomp , and gpr , the complexity measure is defined on a covariance matrix that is of size for of size . the idea behind this measure is to compute the interdependency between the model parameters , which independent of the number of the model parameters . in the other words , the concept of the size of the model is hidden because of the definition of a kernel . to have a complexity measure that depends on , we introduce variable - wise variance using an additive combination of kernels for each parameter of the model . let be the parameter vector of the kernel ridge regression : where and , and the solution of krr is given by . the quantity = \\sigma^2 ] , and =e ] , and ] . we compared kic loocv , kernel - based icomp , and maximum log of marginal likelihood in gpr ( abbreviated as gpr ) to find the optimal ridge regressors . the reason to compare kic icomp and gpr is that in all of these methods the complexity measure computes the interdependency of model parameters as a function of covariance matrix in different ways . loocv is a standard and commonly used methods for model selection . * loocv : * re - sampling model selection methods like cross - validation is time consuming . for instance , the leave - one - out - cross - validation ( loocv ) has the computational cost of the number of parameter combinations ( is the processing time of the model selection algorithm ) for training samples . to have cross - validation methods faster processing time , the closed form formula for the risk estimators of the algorithm under special conditions are provided . we consider the kernel - based closed form of loocv for linear regression introduced by : ^{-1}y\\| 2 ^ 2}{n}\\ ] ] where is the hat matrix . * maximizing the log of marginal likelihood ( gpr ) * is a kernel - based regression method . for a given training set , and , a multivariate gaussian distribution is defined on any function such that , , where is a kernel . marginal likelihood is used as the model selection criterion in gpr , since it balances between the lack - of - fit and complexity of a model . maximizing the log of marginal likelihood obtains the optimal parameters for model selection . the log of marginal likelihood is denoted as : where denotes the model s fit , , denotes the complexity , and is a normalization constant . without loss of generality in this paper gpr means the model selection criterion is used in gpr . * icomp : * the kernel - based icomp introduced in is an information criterion to select the models and is defined as , where , and elaborated in equations , and . in this section we evaluate the performance of kic on synthetic , and real datasets , and compare competing model selection methods . kic was first evaluated on the problem of approximating from a set of 100 points sampled at regular intervals in $ ] . to evaluate robustness to noise , normal random noise was added to the function at two noise - to - signal ( nsr ) ratios : , and . figure shows the sinc function and the perturbed datasets . the following experiments were conducted : ( 1 ) shows how kic balances between gof and complexity , ( 2 ) shows how kic and mse on training sets change when the sample size and the level of noise in the data change ( 3 ) investigates the effect of using different kernels , and ( 4 ) evaluates the consistency of kic in parameter selection . all experiments were run 100 times using randomly generated datasets , and corresponding test sets of size 1000 . * experiment 1 . * the effect of on complexity , lack - of - fit and kic values was measured by setting , models being generated using a gaussian kernel different standard deviations , , computed over the 100 data points . the results are shown in figure . the model generated overfits , because it is overly complex , while gives a simpler model that underfits . as the ridge parameter increases , the model complexity decreases while the goodness - of - fit is adversely affected . kic balances between these two terms , which yields a criterion to select a model that has good generalization , as well as goodness of fit to the data . * experiment 2 . * the influence of training sample size was investigated by comparing sample sizes , , of 50 , and 100 , for a total of four sets of experiments : : , , , . the gaussian kernel was used . the kic value and mean squared error ( mse , ) , for different is shown in figure . the data nsr= has larger mse values , and larger error bars , and consequently larger kic values compared to data nsr= . in both cases , kic and mse change similar profiles respect to . the noise and the sample size have no effect on kic for selecting the best model ( parameter ) . * experiment 3 . * the effect of using a gaussian kernel , , versus the cauchy kernel , , was investigated , where , and in the computation of the kernel - based model selection criteria icomp , kic , gpr , and loocv . the results are reported in figures and . the graphs show box plots markers at , and of the empirical distributions of mse values . as expected , the mse of all methods is larger when nsr is high , , and smaller for the larger of the two training sets ( 100 samples ) . loocv , icomp , and kic performed comparably , and better than gpr using a gaussian kernel for data . in the other cases , the best results ( smallest mse ) was achieved by kic . all methods have smaller mse values using the gaussian kernel versus the cauchy kernel . gpr cauchy kernel obtains results comparable , but standard deviation close to zero . * experiment 4 . * we assessed the consistency of selecting / tuning the parameters of the models in comparison loocv . we considered four experiment of sample size , , and nsr . the parameters to tune or select are , and for the gaussian kernel . the frequency of selecting the parameters are shown in figure for loocv , and in figure for kic . the more concentrated frequency shows the more consistent selecting criterion . the diagrams show that kic is more consistent in selecting the parameters rather than loocv . loocv is also sensitive to sample size . it provides a more consistent result for benchmarks samples . + we used three benchmarks selected from the delve datasets ( www.cs.toronto.edu/~delve/data ) : ( 1 ) abalone dataset ( 4177 instances , 7 dimensions ) , ( 2 ) kin - family of datasets ( 4 datasets ; 8192 instances , 8 dimensions ) , and ( 3 ) puma - family of datasets ( 4 datasets ; 8192 instances , 8 dimensions ) . for the abalone dataset , the task is to estimate the age of abalones . we used normalized attributes in range . the experiment is repeated 100 times to obtain the confidence interval . in each trial 100 samples were selected randomly as the training set and the remaining 4077 samples as the test set . the kin - family and puma - family datasets are realistic simulations of a robot arm taking into consideration combinations of attributes such as whether the arm movement is nonlinear ( n ) or fairly linear ( f ) , and whether the level of noise ( unpredictability ) in the data is : medium ( m ) , or high ( h ) . the kin - family includes : kin-8fm , kin-8fh , kin-8 nm , kin-8nh datasets , and the puma - family contains : puma-8fm , puma-8fh , puma-8 nm , and puma-8nh datasets . in the kin - family of datasets , having the angular positions of an 8-link robot arm , the distance of the end effector of the robot arm from a starting position is predicted . the angular position of a link of the robot arm is predicted given the angular positions , angular velocities , and the torques of the links . we compared kic 1 , kic 2 , and kic loocv , icomp , and gpr on the three datasets . the results are shown as box - plots in figures , , and for abalone , kin - family , and puma - family datasets , respectively . the best results across all three datasets were achieved using kic , and the second best results were for loocv . for the abalone dataset , comparable results were achieved for kic and loocv , that are better than icomp , and the smallest mse value obtained by sgpr . kic 1 , and kic 2 had similar mse values , which are larger than for the other methods . for the kin - family datasets , except for kin-8fm , kic gets better results than gpr , icomp , and loocv . kic 1 , and kic 2 obtain better results than gpr , and loocv for kin-8fm , and kin-8 nm , which are datasets medium level of noise , but larger mse value for datasets high noise ( kin-8fh , and kin-8nh ) . for the puma - family datasets , kic got the best results on all datasets except for on puma-8 nm , where the smallest mse was achieved by loocv . the result of kic is comparable to icomp and better than gpr for puma-8 nm dataset . for puma-8fm , puma-8fh , and puma-8nh , although the median of mse for loocv and gpr are comparable to kic , kic has a more significant mse ( smaller interquartile in the box bots ) . the median mse value for kic 1 , and kic 2 are closer to the median mse values of the other methods on puma-8fm , and puma-8 nm , where the noise level is moderate compared to puma-8fh , and puma-8nh , where the noise level is high . the sensitivity of kic 1 , and kic 2 to noise is due to the existence of variance in their formula . kic 2 has a larger interquartile of mse than kic 1 in datasets high noise , which highlights the effect of in its formula ( equation ) rather than in equation . we introduced a novel kernel - based information criterion ( kic ) for model selection in regression analysis . the complexity measure in kic is defined on a variable - wise variance which explicitly computes the interdependency of each parameter involved in the model ; whereas in methods such as kernel - based icomp and gpr , this interdependency is defined on a covariance matrix , which obscures the true contribution of the model parameters . we provided empirical evidence showing how kic outperforms loocv ( kernel - based closed form formula of the estimator ) , kernel - based icomp , and gpr , on both artificial data and real benchmark datasets : abalon , kin family , and puma family . in these experiments , kic efficiently balances the goodness of fit and complexity of the model , is robust to noise ( although for higher noise we have larger confidence interval as expected ) and sample size , is consistent in tuning / selecting the ridge and kernel parameters , and has significantly smaller or comparable mean squared values respect to competing methods , while yielding stronger regressors . the effect of using different kernels was also investigated since the definition of a proper kernel plays an important role in kernel methods . kic had superior performance using different kernels and for the proper one obtains smaller mse . this work was funded by fnsnf grants ( p1tip2 148352 , pbtip2 140015 ) . we want to thank arthur gretton , and zoltn szab for the fruitful discussions .", "summary": "this paper introduces kernel - based information criterion ( kic ) for model selection in regression analysis . the novel kernel - based complexity measure in kic efficiently computes the interdependency between parameters of the model using a variable - wise variance and yields selection of better , more robust regressors . experimental results show superior performance on both simulated and real data sets compared to leave - one - out cross - validation ( loocv ) , kernel - based information complexity ( icomp ) , and maximum log of marginal likelihood in gaussian process regression ( gpr ) ."}
{"article": "wimps captured by the gravitational field of the sun that are slowed through collisions solar matter can accumulate in the solar core . there , wimp annihilation may produce neutrinos much larger energy than solar neutrinos . the signal would be an excess of high - energy ( ) neutrino events pointing back to the sun . the cleanest signature at noa will be from cc events producing upward - going muons that can be reconstructed in the noa detector . the large and unique noa far detector , excellent granularity and energy resolution , and relatively low - energy neutrino thresholds , is an ideal tool for these indirect dark matter searches . at noa , the neutrino analyses simply store events synchronous numi beam . for non - beam exotic physics searches , so - called data - driven triggers are required to select events of interest . only the upward - going flux will be considered in order to suppress the cosmic - ray background . the downward - going muon rate in the noa far detector is approximately 100,000 hz . we expect to keep the upward - going muon trigger rate to about 10 hz or less , so a rejection of at least four orders of magnitude is required by the trigger . of course , this rejection must be accomplished while keeping the acceptance for upward - going muons relatively high . the neutrino flux from dark matter annihilation is model dependent ; however , energies from . to many should be detected high acceptance . for high - mass signal hypothesis , noa will not be able to compete high acceptance of the icecube detector . for lower - mass scenarios ( below ) the super - kamiokande experiment currently has the best sensitivity . if an efficient upward - going muon trigger and sufficient cosmic ray background rejection can be achieved , noa will be competitive super kamiokande for wimp mass hypotheses below / c . one advantage that noa has compared to past experiments that performed similar searches for dark matter annihilation is the relatively low energy threshold for muons . a muon track travels approximately 5 meters in the noa detector resulting in an energy threshold well below . the challenge for the dark matter search is triggering efficiently on these low - energy muons . for shorter track lengths , the timing information will not be as powerful for rejecting downward - going backgrounds . using stopping or fully - contained events and using the top and sides of the detector to veto downward - going events can provide an additional two orders of magnitude rejection . in this note we focus on using the timing information from all of the hits on a track to reject the downward - going muon background and efficiently select upward - going events . a trigger for upward - going muons based on timing information required a minor upgrade to the readout of the noa far detector . this upgrade to the so - called `` multipoint '' readout occurred on september 11 , 2014 , and resulted immediately in a single - hit timing resolution of about ( note that the timing resolution previous algorithm was about , so this is a significant improvement ) . dozens of hits per track , it is possible to reject downward - going muons by many orders of magnitude using hit timing information alone . to resolve the directionality of the muon track , the upward - going muon trigger takes advantage of the timing information from each individual hit in the reconstructed tracks . the tracks are reconstructed using the hough transform algorithm , and are required to match in both xz and yz views . we start from the hit lowest cell value , , in the track in the yz view . the measured time of the corresponding hit is defined as . the observed and expected time of each hit on the track in the yz view is therefore : similarly , for the xz view : where and are the cell numbers in xz and yz view , and is the time measurement in tdc units , which is converted to using the factor of 15. / tdc . is the time - of - flight of the muon track defined as : where is track length in cm , and 29.97cm / is the expected speed assuming that the muon is relativistic . since we require that each track is reconstructed and matched in both views , ( ; ) and ( ; ) must correspond to the lowest and highest points of the track respectively . in addition , we can estimate the missing coordinate for a particular hit in either view using 3d requirement . for the yz view , track coordinates can be calculated as such : similarly , for the xz view : where cm and cm are the widths of detector cells and planes . the cell and plane id=0 have coordinates cm and cm . since for each hit in each view we can estimate ( x ; y ; z ) coordinates , we can calculate the distance from the hit to the apd readout end . the further the hit is located from the readout the longer it takes for the light to propagate and be detected by the apd . we are interested in the hit time of the muon passing through the extrusion , so we have to correct for the light propagation time in the fiber . the speed of light in the fiber is measured to be 15.3 cm / . the light level in each channel in the noa detector is independently sampled every . the electronic response to an incident particle depositing energy in a cell can be parameterized in terms of two intrinsic timing values ( and ) , the number of photoelectrons , and a timing `` offset '' , or the elapsed time between a read - out and the time of incidence of the particle : here , is a proportionality factor that does not affect the timing fit . the parameters and correspond to the intrinsic falling and rising time of the response curve , respectively . as such , they are approximately known . for the purpose of determining hit timing , the parameter of note is . by performing a simple minimization , the data - preferred value of can be extracted from multiple readouts on a single channel . for the purposes of the trigger , where hit processing time must be minimized , fit results were pre - calculated and tabulated such that the computationally expensive minimization need not be repeated for each individual hit . an example of fitting the electronics response curve to multiple readouts from a single cell hit . the time coordinate of the inflection point where the curve begins to rise is the fitted parameter .,width=192 ] single - hit timing resolution as observed in noa far detector data four - point readout , before ( left ) and after ( right ) fine timing implementation . see ref . for more details.,width=576 ] each time measurement has an uncertainty , which varies amount of energy deposited . the time uncertainty on a given hit from a reconstructed muon track affects the determination of track directionality , so a parameterization of uncertainty in terms of energy deposition is necessary for the timing - based trigger . single - hit time resolution is plotted against energy deposition in fig . . for high energy hits the is measured to be approximately in the data using the four - point readout scheme , which is consistent that observed in simulation . we can use equations and to produce the distribution of the expected v / s observed time for each track . the expected versus observed time distribution for an upward - going muon track reconstructed in the noa far detector , using fine timing . the linear unconstrained fit ( red solid line ) has slope value close to `` 1 '' . the fit upward - going track hypothesis ( slope = 1 ) is shown as the blue - dashed line . the fit downward - going hypothesis is shown in the green dashed line and has a very poor probability . , width=384 ] an example of expected v / s observed time distribution is shown in fig . . the distribution is produced using a reconstructed upward - going muon track simulated wimpsim . as can be seen , the points follow a rising trend slope value consistent upward - going track hypothesis . it is clear from the figure that the fitted slope value can be used to estimate the muon direction ( up or down ) . as shown in fig . , the slope values for cosmics and wimpsim mc samples are consistent downward- and upward - going hypothesis , respectively . in the relativistic limit , it is safe to assume that there are only two options for the slope values . therefore , we can fit the time distribution on fig . fixed values of slopes . for the upward - going track the fit slope constrained to `` 1 '' results in a good probability value of the fit , . however the fit slope of `` -1 '' yields a low probability value , . using the probability values from the fits fixed slope value , we can form a log - likelihood ratio ( llr ) : the llr distributions for the cosmic and wimpsim mc samples are shown in fig . . from this distribution , it is clear that a cut on llr slightly above zero will reduce the cosmic background by the desired amount while preserving a high signal acceptance . note that the wimpsim sample used is for dark matter mass annihilating through the channel . as such the neutrinos from the b - meson decay produce muons which , on average , have a much lower energy compared to the cosmic ray muons . this explains why the llr for the signal has a larger component close to zero than the cosmic sample . the llr yields better performance for cosmic background rejection for the same signal acceptance in the regime where the cosmic rejection is sufficient ( at least four orders of magnitude ) , compared to a cut on the best - fit slope . for example , for a signal acceptance of 0.7 the background rejection is about a factor of three better for the llr . at this point the mc predicts background rejection of close to five orders of magnitude . in addition to being a more powerful discriminator as observed in the mc studies , the llr estimator is more robust to mis - reconstructed tracks which will be an important feature in real data . since mis - reconstructions will result in time distributions that follow neither the upward- nor the downward - going hypothesis , the result of mis - reconstruction will yield llr values close to `` 0 '' , and not values consistent high - probability for being upward - going . the slope distributions for cosmics ( red ) and wimpsim ( blue ) mc samples.,width=576 ] the llr distributions for cosmics ( red ) and wimpsim ( blue ) mc samples . note that only tracks longer then 5 m and more than 50 hits are included.,width=384 ] a timing - based upward - going muon trigger was implemented for the noa far detector and was deployed in november 2014 . triggering at hz , the algorithm suppresses cosmic ray muons by five orders of magnitude . on the left is a display of a triggered event that is a strong candidate , based on its topology , for an upward - going muon . the activity at the bottom right indicates a cc scattering interaction . the curving at the other end probably indicates that the muon ranged out . there is also evidence for a michel electron , based on the timing information on the right . this event confirms that the llr algorithm is successfully selecting upward - going muons in the data.,title=\"fig:\",width=384 ] on the left is a display of a triggered event that is a strong candidate , based on its topology , for an upward - going muon . the activity at the bottom right indicates a cc scattering interaction . the curving at the other end probably indicates that the muon ranged out . there is also evidence for a michel electron , based on the timing information on the right . this event confirms that the llr algorithm is successfully selecting upward - going muons in the data.,title=\"fig:\",width=192 ] as can be seen in fig . , events probable michel electrons and contained vertices have been used to confirm upward - going muons in the triggered sample . atmospheric neutrinos generated on the other side of the earth are also capable of producing upward - going muons in the detector . these events represent an irreducible background in this search . the only method of discriminating atmospheric neutrino events from wimp events is to reconstruct the directionality of the incident neutrinos , which has yet to be attempted in noa . the accumulating data sample opens the door to a program to study atmospheric neutrinos and sets the stage for a competitive dark matter search by the noa experiment . this conference presentation was made possible by a grant from the university of virginia college of arts and sciences . additional financial support was provided by the jefferson trust , the uva physics department , and the fermilab particle physics division . the authors also acknowledge that support for this research was carried out by the fermilab scientific and technical staff . fermilab is operated by fermi research alliance , llc under contract no . de - ac02 - 07ch11359 united states department of energy . the university of virginia particle physics group is supported by de - sc0007838 . 7 j. s. hagelin , k. w. ng and k. a. olive , phys . b * 180 * , 375 ( 1986 ) . j. buckley , d. f. cowen , s. profumo , a. archer , m. cahill - rowley , r. cotta , s. digel and a. drlica - wagner , arxiv:1310.7040 . m. fischler , c. green , j. kowalkowski , a. norman , m. paterno and r. rechenmacher , j. phys . ser . * 396 * , 012020 ( 2012 ) .", "summary": "the noa collaboration has constructed a 14,000 ton , fine - grained , low - z , total absorption tracking calorimeter at an off - axis angle to an upgraded numi neutrino beam . this detector , excellent granularity and energy resolution and relatively low - energy neutrino thresholds , was designed to observe electron neutrino appearance in a muon neutrino beam , but it also has unique capabilities suitable for more exotic efforts . in fact , if an efficient upward - going muon trigger sufficient cosmic ray background rejection can be demonstrated , noa will be capable of a competitive indirect dark matter search for low - mass wimps . the cosmic ray muon rate at the noa far detector is about 100 khz and provides the primary challenge for triggering and optimizing such a search analysis . the status of the noa upward - going muon trigger is presented ."}
{"article": "shape memory alloys ( sma ) have attracted a great deal of attention due to their important technological applications , including mechanical actuator devices and medical stents . the shape memory effect also gives rise to superelasticity , which finds applications in stents and spectacle frames . the shape memory effect is related to a reversible martensitic ( diffusionless ) phase transformation . it has been shown that the martensitic transformation can be induced by applied fields , temperature or both , and the mechanical properties of materials , therefore , can be controlled accordingly . in many systems , including those discussed in the present work , alloying can dramatically change the properties and transition temperatures of the materials , reflecting the importance of electronic features , specifically fermi surface effects , in the structural energetics of sma . there are several complementary approaches to modelling of the shape memory effect . continuum modelling allows investigation of the microstructural behavior , specifically martensitic twins , at the relevant long length scales . material - specific behavior is incorporated through an empirical functional for the free energy in terms of strain and a twin boundary energy to set the length scale . in atomistic models , the individual atoms are considered explicitly and their interaction given by an interatomic potential , which may be determined empirically , from first - principles density - functional - theory ( dft ) calculations , or a combination of the two . crystal symmetry and defect energies emerge from this approach , which gives microstructures both natural length scales ( from defect energies ) and time scales ( since the atoms have definite newtonian forces and masses ) . however , in atomistic models , the electronic degrees of freedom do not appear explicitly . first principles dft methods are so computationally intensive that direct studies of microstructural behavior are impossible , but they are valuable both for obtaining quantitative atomic - level information regarding energies , forces and stresses independent of empirical input , and for understanding the electronic origin of this behavior . thus , first - principles investigation of the energetic instability of the high - temperature structure towards the low - symmetry martensitic structure is in itself quite illuminating . the resulting information can then also be used as inputs to atomistic and continuum modelling of shape memory behavior . typically , martensitic transformations are described using the strain as an order parameter , the classic example being the bain bcc - fcc transformation of iron . however , there is an alternative approach appropriate for cases where the strain degrees of freedom are coupled to atomic degrees of freedom ( phonons ) . following the soft - mode theory of structural transitions, we start from a high - symmetry reference structure ( here ) and freeze in unstable phonons of this structure , corresponding lattice relaxation , to produce the ground - state structure . the symmetry of the phonons determines the symmetry of the low temperature structure . this approach has been successfully used in the study of minerals and ferroelectric materials and has been extended to shape memory alloys in our previous study of niti . closely related to niti , pdti and ptti are shape memory materials reasonable structural simplicity and extraordinary mechanical behavior . they undergo a martensitic transformation at tunable temperatures : pdti transforms at 810k , but this can be reduced to 410k 8% substitution of cr for pd . the high - temperature `` austenitic '' phase has a simple cubic structure ( space group ) , while the ambient temperature `` martensitic '' phase has been reported as the orthorhombic structure ( space group : ) . previous first - principles studies in pdti and ptti have shown that the observed electronic and elastic properties of the structure are well reproduced by density - functional theory calculations assuming the experimentally determined structure . in this paper , we investigate the structural energetics of pdti and ptti from first - principles calculations of phonon frequencies as well as total energies . this allows us to examine local as well as global stability and to investigate transition mechanisms , drawing on the strong analogy between the - and bcc - hcp transformations and showing that coupling of unstable modes to the strain is a crucial aspect of the structural energetics . in . ii , we describe the first - principles calculations . in . iii , we present and discuss the results for the phonon dispersion of pdti and ptti in the structure and for the relaxed structures in which unstable modes and strains are coupled , yielding a low - symmetry ground state . in addition , we present results of calculations of the electronic structure , identifying and discussing features that affect the relative stability of the phases . v concludes the paper . first - principles total energy calculations were carried out within density - functional theory plane - wave pseudopotential approach . the calculations were performed vienna ab - initio simulations package , using the perdew - zunger parametrization of the local - density approximation ( lda ) . vanderbilt ultrasoft pseudopotentials were used . our pseudopotentials include nonlinear core corrections and for ti , we treated the occupied levels as valence . the electronic wave functions were represented in a plane - wave basis set kinetic energy cutoff of 278ev . the brillouin zone ( bz ) integrations were carried out by the hermite - gaussian smearing technique smearing parameter of 0.1ev . the unit cells contain two atoms in the cubic structure and four atoms in the orthorhombic and monoclinic structures . the calculations were performed monkhorst - pack ( mp ) point mesh for the cubic structure and a mp point mesh for both orthorhombic and monoclinic structures ( space group : ) , corresponding to 120 points in the irreducible bz of the simple cubic cell , 288 points in the irreducible bz of the orthorhombic cell and 576 points in the irreducible bz of the monoclinic cell . this choice of parameters converges the total energy to within / atom . the density of states ( dos ) for the and structures were calculated using the tetrahedron method blchl corrections . the bz s for the orthorhombic and monoclinic structures are different . to compare the band structure of the two structures , we label the band structure by regarding the structure as a special case of . the phonon dispersion relations were obtained pwscf and phonon codes , using the perdew - zunger parametrization of the lda , as above . ultrasoft pseudopotentials for pd , pt and ti were generated according to a modified rappe - rabe - kaxiras - joannopoulos ( rrkj ) scheme three bessel functions . the electronic wave functions were represented in a plane - wave basis set kinetic energy cutoff of 408ev . the augmentation charges were expanded up to 9000ev . the brillouin zone ( bz ) integrations were carried out by the hermite - gaussian smearing technique using a 56 k -point mesh ( corresponding to regular divisions along the , and axes ) in the irreducible wedge . the value of the smearing parameter was =0.2ev . these parameters yield phonon frequencies converged within 5 . the dynamical matrix was computed on a q -point mesh commensurate k -point mesh . the complete phonon dispersion relation was obtained through the computation of real - space interatomic force constants within the corresponding box . the choice to use two different first - principles codes was dictated by the individual strengths of each . vasp has a highly efficient scheme for calculating total energies , forces , and stresses , and relaxing to the minimum energy structure , but does not have the density - functional perturbation theory capabilities of pwscf / phonon . even slightly different pseudopotentials and k -point sampling , the results of the two codes are quite compatible . for example , the difference between the computed lattice parameters for the structure of pdti is less than 0.2% , and for ptti the difference is less than 0.1% . comparisons of normalized eigenvector components computed by vasp using the frozen phonon method and by pwscf / phonon also show good agreement , generally within 5% . for the cubic structure , our calculations yield the equilibrium lattice parameters of 3.112 and 3.125 for pdti and ptti respectively . for comparison , we also performed full - potential linearized - augmented - plane - wave calculations ( flapw ) within the lda . the results are in excellent agreement flapw results of 3.113 ( pdti ) and 3.127 ( ptti ) and in in good agreement experimental values of 3.18 and 3.17 . the phonon dispersion relations along high symmetry lines , computed at the theoretical lattice parameters , are shown in figure . the frequencies are obtained by taking the square root of the eigenvalues of the dynamical matrix . imaginary frequencies , as plotted as negative , are obtained from negative eigenvalues of the dynamical matrix . thus , the structure is dynamically unstable against distortions following the corresponding eigenvector . it should be noted that the phonon frequency is not the reciprocal of the period of oscillation of this mode ( as measured in molecular dynamics ) nor is it the energy difference between adjacent quantum levels ( as measured in neutron scattering experiments ) . these three quantities are equal only for a stable harmonic crystal . in the materials studied here the unstable modes may be related to a soft mode ( as defined by md or neutron scattering ) at high temperature , and even the stable modes are expected to be significantly renormalized as a function of temperature by anharmonic effects . phonon dispersion relations for pdti ( upper ) and ptti ( lower ) in the structure calculated at the lda equilibrium parameters 3.112 and 3.125 respectively . the negative slope of the acoustic branch corresponds to a pure elastic instability . symmetry labels are assigned according to the conventions of ref . / pt at the origin . the imaginary frequencies of the unstable modes are plotted as negative values.,title=\"fig : \" ] + phonon dispersion relations for pdti ( upper ) and ptti ( lower ) in the structure calculated at the lda equilibrium parameters 3.112 and 3.125 respectively . the negative slope of the acoustic branch corresponds to a pure elastic instability . symmetry labels are assigned according to the conventions of ref . / pt at the origin . the imaginary frequencies of the unstable modes are plotted as negative values.,title=\"fig : \" ] the dynamical matrices are related by mass factors to the force constant matrix : the second derivatives of the internal energy respect to atomic displacements . the eigenmodes of the force constant matrix describe the potential energy landscape , and a negative eigenvalue indicates a static instability against a distortion following the corresponding eigenvector . while the actual normalized displacements of these eigenmodes are in general slightly different they carry the same symmetry labels as the eigenmodes of the dynamical matrix . either choice is expected to serve as a useful pointer to a lower energy structure if the distorted structure obtained by freezing in \" an unstable mode is relaxed using first - principles forces and stresses , as we describe below . the phonon dispersion relations shown in figure show instability of the structure similar to and even stronger than that of niti . there are large regions of reciprocal space where one , two or even three modes are unstable , dominant instabilities at and along - . the phonon instability shows that the observed high - temperature phases of pdti and ptti are dynamically stabilized by anharmonic phonons , and should be characterized by large fluctuating local distortions . the calculated phonon dispersions are also reminiscent of those of unstable bcc materials such as zr and ti , which undergo martensitic transformations to hcp or ( via the and - bcc - phonon equivalents respectively ) phases . the analogy based on the view of phases of pdti and ptti as chemically ordered hcp will be further strengthened below . in the soft mode approach , we search for local energy minima by choosing an unstable mode of the high symmetry structure , freezing in the distortion varying amplitude , and relaxing the resulting structure . in many cases , the mode largest negative eigenvalue will generate the lowest energy structure . however , this is by no means generally true , as the energy gain is determined not only by the curvature of the energy surface but by higher order terms as well as the strength of coupling to strain and other modes , both unstable and stable , of appropriate symmetry . indeed , in pdti this `` most unstable '' mode ( i.e. largest negative eigenvalue ) lies in the - branch rather than at . this mode is typically unstable in dynamically - stabilized bcc materials such as titanium and zirconium where it is associated phase transition to the ideal phase . the fact that in the chemically ordered analog ( pd / pt)ti , the observed phase transition is to rather than illustrates the importance of anharmonic effects and strain coupling in the energetics of these materials . eigenmode of the doubly - degenerate unstable phonon in the structure . this mode generates the structure in pdti and ptti . the structure is shown projected along the direction , / pt represented by filled circles and ti by open circles . ] in the soft - mode approach , there is no guarantee that the energy - minimizing freezing - in of one unstable mode will stablize the other unstable modes of the high - symmetry structure . in the present case , the undistorted doubled unit cell contains two sets of ( 110) planes each of which is unstable to strain - coupled shuffling at all q- points . the simplest such mode in the structure is , which lowers the symmetry to monoclinic . the resulting structure has three additional free parameters : the monoclinic angle and two internal parameters and . these values are given for the relaxed structure in table , and compared normalized eigenvector displacements in table . however , it is important to note that the computed phonon modes in the structures are in fact all stable ( table ) . the lowering of energy by distortion to can not be obtained by a pure phonon distortion , but only if the strain is allowed to relax simulataneously ( table ) . this may be the reason that in a previous calculation , was reported to be the minimum energy structure . the relative energies of the various relaxed structures are given in table . the total energy is lower than . a simple estimate of the transition temperature is given by which suggest of 1050k ( pdti ) and 1755k ( ptti ) . these rough values are significantly larger than the experimental data for the hysteretical transition region ( approximately 800k and 1400k respectively ) , but show the correct material trend . for neither system has a phase yet been observed experimentally . the small computed energy differences between and , translated into temperature , are 28k and 39k for pdti and ptti , respectively . this suggests that the transition to the phase should occur at temperatures well below those at which the experiments were performed , so that our results are fully consistent available experimental work . + + the binary - hcp phase interpretation also suggests that we should examine the binary - fcc equivalent , which is the phase . is accessible from by a simple ( 001 ) shear and has lower energy , however we find that has slightly higher energy than . we consider one further structure : at the special values and , orthorhombic symmetry is restored . the side of the conventional cell of this body centered orthorhombic ( bco ) ( space group ) structure is doubled in the * b * direction , though the primitive cell still contains four atoms . although at relatively high energy , this provides us a reference point for structures large . note that a further shear to would give the structure once more . the potential energies of continuous paths between the structures identified above are important for understanding the transformation mechanism . we compute the energies of three paths : - , - and -bco . in keeping timescale separation between bulk strain and atomic motion , we define intermediate configurations by relaxing the atoms to their minimum energy configuration consistent applied symmetry and strain on the cell . the remaining four strain degrees of freedom are reduced to a single parameter by taking interpolations between the strains of the endpoint structures . for the structure , we minimize the energy assuming the space group , which gives a smooth evolution of the structure along the path . > from figure , it is clear that there is no total energy barrier along the -- path , and that represents the total energy barrier between martensitic variants . the phase can be viewed as the binary equivalent of hcp , and the transformation path as the binary equivalent of the nishiyama - wassermann ( nw ) path . using the analogy nw mechanism for the bcc - hcp transition , we can attribute the transition to a shuffling of ( 110) planes . structural instabilities in metals are typically related to details of the fermi surface , and we have calculated the band structures of , and to investigate this . in pdti / ptti the band structure is dominated by the d -bands , pd / pt bands lying below the fermi level and almost fully occupied , and the ti -bands lying above the fermi level ( figure and ) , the band centers being offset by some 6ev . the free - electron like bands are very broad , and play little role in the bonding except to donate some electrons to the ti - d band . the large strain involved in the transition means that the fermi surfaces are quite different ( having the lowest dos at ) and this transition can not be related directly to the band structure . by contrast , the - transition is accompanied by the opening of a pseudogap at the fermi level , a typical signature of increased stability . the band structures are very similar , the small difference which stabilises being traceable to the shifting above the fermi level of a pocket of electrons around . the distortion to is just enough to complete the topological phase transition which eliminates this pocket of electrons in both materials . in conclusion , we have performed ab initio calculations of the structural energetics of pdti and ptti . in each case we predict that the low temperature ground state structure will be , ( observed ) and phases being dynamically stabilized . there are no total energy barriers between the structures , meaning that the phase space microstates that belong to the structure also belong to the and structures . in contrast to niti , the entire phonon branch is unstable . we showed that the structure can be obtained by a `` freezing in '' of phonons of the structure coupled to the shear associated elastic constant , but that no single dynamical - matrix or force - constant - matrix eigenvector leads to the low - symmetry phase . the then corresponds to a further strain coupled to a phonon of the phase . tracing the atomic motions of these instabilities shows that they are both related to shears of alternate phases , and hence that the transition mechanism is the binary equivalent of the nishiyama - wassermann bcc - hcp mechanism . we thank r. d. james , i. i. naumov , and k. bhattacharya for valuable discussions .", "summary": "the structural energetics of pdti and ptti have been studied using first - principles density - functional theory pseudopotentials and a plane - wave basis . we predict that in both materials , the experimentally reported orthorhombic phase will undergo a low - temperature phase transition to a monoclinic ground state . within a soft - mode framework , we relate the structure to the cubic structure , observed at high temperature , and the structure to via phonon modes strongly coupled to strain . in contrast to niti , the structure is extremely close to hcp . we draw on the analogy to the bcc - hcp transition to suggest likely transition mechanisms in the present case ."}
{"article": "consider a network which evolves under the removal and addition of vertices . in each unit of time we add vertex and remove vertices . removal of a vertex also implies that all the edges incident on that vertex vanish and consequently the degree of vertices at the end of those edges decrease . here can be interpreted as the ratio of vertices removed to those added , so represents a growing network , a shrinking one , while implies vertex turnover but fixed network size . the equations to follow represent the completely general case . however , for the purposes of this paper we will specialize to networks of constant size as we assume that the network already exists and we would like to preserve its original structure , by balancing the rate of attack against the rate of repair . let be the fraction of nodes in the network that at a given time have degree . by definition then it has the normalization : in addition to this we would like to have freedom over the degree of the incoming vertex . let be the probability distribution governing this , constraint . we also have to consider how a newly arriving vertex chooses to attach to other vertices extant in the network and how a vertex is removed from the same . let be the probability that a given edge from a new node is connected to a node of degree , multiplied by the total number of nodes . then is the probability that an edge from a new node is connected to some node of degree . similarly , let be the probability that a given node degree fails or is attacked during one node removal also multiplied by . then is the total probability to remove a node degree during one node removal . note that the introduction of the deletion kernel is what sets our model apart from previous models describing the network evolution process . since each newly attached edge goes to some vertex degree , we have the following normalization conditions : armed given definitions and building on the work done previously by , we are now in a position to write down a rate equation governing the evolution of the degree distribution . for a network of nodes at a given unit of time , the total number of nodes degree is . after one unit of time we add one vertex and take away vertices , so the number is , where is the new value of . therefore we have , where is the conditional probability of following an edge from a node of degree and reaching a node of degree . alternatively , it is the degree distribution of nodes at the end of an edge emanating from a node of degree . note that and are always zero , and for an uncorrelated network , . the terms involving describe the flow of vertices degree to and to as a consequence of edges gained due to the addition of new vertices . the first two terms involving describes the flow of vertices degree to and to as vertices lose edges as a result of losing neighbors . the term represents the direct removal of a node of degree at rate . finally represents the addition of a vertex degree . processes where vertices gain or lose two or more edges vanish in the limit of large and are not included in eq . . the rate equation described above presents a formidable challenge due to the appearance of from the terms representing deleted edges from lost neighbors . rate equations for recovery schemes based on edge rewiring are slightly easier to deal . upon failure , all edges connected to that node are rewired so that the degrees of the deleted node s neighbors do not change , and this term does not appear . the specific case of preferential failure in power - law networks was considered previously in this context by . however , this recovery protocol can only be used on strictly growing networks , because a network of constant size would become dense under its application . moreover , it is dependent on the power - law structure of the network . the methods described here are general and are applicable to arbitrary degree distributions . apart from edge rewiring , the special case of random deletion also leads to a significant simplification . uniform deletion amounts to setting . doing so , then leads to the following , which renders eq . independent of and thus independent of any degree - degree correlations . random deletion hence closes equation for , enabling us to seek a solution for the degree distribution for a given and . - uniform deletion , the degree distribution depends on a two - point probability distribution , and as we shall see in section , the two - point probability distribution will depend on the three - point probability distribution and so on . this hierarchy of distributions , where the -point distribution depends on the -point distribution , is not closed under non - uniform failure and hence it is difficult to seek an exact solution for the degree distribution . nevertheless , in the following , we demonstrate a method that allows us to navigate our way around this problem . as mentioned before , for the purposes of this paper we will be interested in a network of constant size , where the rate of attack is compensated by the rate of repair . assuming that the network reaches ( or already is ) a stationary distribution and does not possess degree - degree correlations , we set and can further simplify eq . . let be the mean degree of nodes removed from the network ( i.e. ) , and the mean degree of the original degree distribution . then we have , the evolution process , specifically non - uniform removal of nodes , can and in many cases will introduce degree - degree correlations into our networks . in order to confront this issue , we will first find choices for and that satisfy the solutions to the rate equation , for a given , in a network that is uncorrelated . we will then demonstrate that a special subset of those solutions for and is an uncorrelated fixed point of the rate equation for the degree - degree correlations . this opens up the possibility , that a network that initially has no degree - degree correlations will not develop correlations from the evolution process . although the rate equation described in eq . is fairly complicated , it is a relatively straightforward exercise to determine the relation between edges added to those removed . multiplying eq . by , summing over and rearranging yields . this equation is simple to interpret . since the network has a constant fixed - point degree distribution , the average degree of the network remains constant , and therefore edges are removed and added at the the same rate . in this section we describe our method under which networks can recover from various forms of attack . the types of attack we consider are those studied generally by most authors ( though in static networks ) , namely preferential and targeted attacks . random failures are the most generally studied schemes in both static and evolving networks , in view of the fact that they lend themselves to relatively simple analysis . these types of failures may be representative , say , of disruption of power lines or transformers in a power grid owing to extraneous factors such as weather . however , the functionality of most networks often depends on the performance of higher degree nodes , consequently non - uniform attack schemes focus on these . for example , in a peer - to - peer network , a high degree node could be a central user large amounts of data . high degree could also be indicative of the amount of load on a node during its operation , or on the public visibility of a person in a social network . it is reasonable to assume that a malicious entity such as a computer virus is more likely to strike these important nodes . et al have employed this removal strategy ( among others ) on a variety of simulated and real networks and have found it to be highly effective in disrupting the structure of the attacked network . nodes ) mean , under preferential attack and uniform attachment using .,width=302 ] we simulate these kinds of attacks using preferential failure , that sample nodes in proportion to their number of connections , and through an outright attack on the highest degree nodes represented by , where is the heaviside step function . our method of compensation will involve control over two processes : the first where our newly incoming / repaired vertex chooses a degree for itself drawn from some distribution , and second , the process by which this vertex decides to attach to any other vertex in the network , governed by the attachment kernel . our goal here is to solve for the attachment kernel , that will preserve the original probability distribution , subject to a deletion kernel for some choice of . we will assume that the final network is uncorrelated and work . , keeping in mind that any arbitrary choice of and is probably not consistent that assumption . introducing the cumulative distribution for the attacked and newly added vertices , and respectively , we sum eq . from to , noting that for our steady state network . this leads to the following relation , dividing both sides by gives us an expression for the attachment kernel , . \\nonumber\\\\ \\ ] ] nodes ) , under high degree attack and uniform attachment using .,width=302 ] equation represents the set of possible solutions for the attachment kernel that will lead to the desired degree distribution , given that the final network is uncorrelated . the correct choice of solution from the above set , must obey the consistency condition , that when inserted into the rate equation for the degree - degree correlations , the correlations vanish . in section , we will show that the following ansatz chosen from the above set is such a choice : equation was previously derived by for the case of random deletion . here we posit that it works more generally for the case of non - uniform attack when our initial network is uncorrelated ( some caveats that will be explained shortly ) . the choice of makes intuitive sense because the quantity is the probability distribution governing the number of edges belonging to a node , reached by following a randomly chosen edge to one of its ends , not including the edge that was followed . this is one less than the total degree of the node and is also referred to as the excess degree distribution . note that in our model we specify the degree of incoming nodes . therefore the appearance of the excess degree distribution is a signature of an uncorrelated network , implying the newly arriving edges are being introduced in an uncorrelated fashion . there are basically two conditions for the existence of a solution given by eq . ; must be a valid probability distribution , and must be finite . these are not very stringent conditions and are typically satisfied by most degree distributions . in other words , barring some pathological cases , it is always possible to find a solution of the form of eq . . there is an additional consideration , the deletion process may lead to nodes of degree zero in a network that originally did not have any such nodes . while the fraction of such nodes is vanishingly small for networks , poisson degree distributions , they may be non - trivial for power - law networks . as such , it is important to set ( the probability to attach to a node of degree zero ) to a generous value in order to reconnect these nodes to the network . we are now in a position to effect our repair on the network . given the original degree distribution and the form of the attack , eq . gives us the precise recipe for recovering the degree distribution . we need to sample the degrees of the newly introduced nodes in proportion to the product of the deletion kernel and the degree distribution , and then attach these edges in proportion to the excess degree distribution of the network . to test our repair method , we provide four examples for initially uncorrelated networks nodes generated using the configuration model . in the configuration model , only the degrees of vertices are specified , apart from this sole constraint the connections between vertices are made at random . nodes ) under targeted attack using from eq . after setting .,width=302 ] the simulation results show the initial degree distribution and the compensated one subject to two types of attacks on poissonian networks degree distribution given by , in fig . we show the resulting degree distribution where nodes were attacked preferentially , i.e. , while in fig . we show the case for targeted attack only on high degree nodes represented by where is the minimum degree of the node attacked . the degrees of newly added nodes were chosen from the distribution attachment kernel set to one , corresponding to the solution of equation after substituting in the appropriate . the data points in all the figures are averaged over multiple realizations of the network each subject to iterations of addition and deletion . the points along corresponding error bars represent the final degree distribution , whereas the solid line represents the initial network . as the figures show , the final networks are in excellent agreement initial degree distribution . nodes ) exponent and exponential cutoff , under preferential attack using from eq . after setting .,width=302 ] we employ the same attack kernels , and a targeted attack only on high degree nodes represented by on two other examples . our first example network has links distributed according to a power - law exponential cutoff , is a normalization constant which in this case is , where the function is the poly - logarithm function defined as : the exponential cut - off has been introduced for three reasons . first , many real world networks appear to show this cutoff and second , it renders the distribution normalizable for ranges of the exponent . finally , for a pure power - law network it is in principle possible to assign a degree to a node that is greater than the system size . the exponential cutoff ensures that the probability for this to happen is vanishingly small . in the other examples that we consider , the functional form of the distribution already ensures this property . the second network has an exponential distribution given by , fig . shows the results for the exponentially distributed network undergoing targeted attack . in fig . we show the resulting degree distribution for the power - law network ( and ) where nodes were attacked preferentially . both figures indicate the initial and final networks are in excellent agreement . at this point , aside from the technical details , it is worth reminding ourselves of the big picture . we have demonstrated above that if a network certain degree structure is subjected to an attack that aims to destabilize that structure , one can recover the same , by manipulating the rules by which vertices are introduced to the network . the rules that we employ in our repair method are dependent on the types of attacks that our networks are subject to . in the following section we give a detailed justification of the employment of our method . in order for our results from the previous sections to be valid , we must demonstrate that our initially uncorrelated networks remain uncorrelated under our repair scheme . to accomplish this , we will define a rate equation for the degree - degree correlations and demonstrate that the uncorrelated network is a fixed point of this equation . our rate equation will describe the evolution of the expected number of edges in the network ends of degree and . let the expected number of such edges in the network be , where , and is the probability that a randomly selected edge has degree at one end and degree in the other . the expected number of edges after one time step where we add and take away edges is then , e' {l , k } = m e {l , k } + \\delta , \\ ] ] where represents all other edge addition and removal processes . we have already established that in the steady state case , irrespective of the degree distribution , so our goal is equivalent to showing that is equal to zero for an uncorrelated network generated / repaired special choices of and . as a result , implying that the degree - degree correlations ( if any ) remain constant over time . we will assume that our network is locally tree - like , something which holds true for most random graphs . in addition we will only consider processes out to second nearest - neighbors of a node . these assumptions allows us to avoid including terms in the rate equation representing removal of nodes neighbors that are connected to each other . nevertheless , there are a large number of remaining processes that we will need to consider . to start things off , note that the rate equation is symmetric in the indices and . any process that contributes to changing while holding constant also contributes to changing while holding constant . we can therefore consider contributions to from , and and add on the corresponding symmetric terms at the end . the first process we need to take into account is a direct addition of a node of degree . this contributes two flows to the rate equation , and . similarly , the direct deletion of a node of degree contributes and . next , we will have to take into account second nearest - neighbor processes . we can be certain that these terms are of the same order by merely counting the number of unsummed probability distributions that go into each process . there will be two terms for the attachment process representing the situation where a new node of any degree attaches to a node of degree or , that was previously attached to a node of degree . these terms are and . similarly there are two removal processes , where a node of any degree that is removed from the network was previously attached to a node of degree or that has neighbor(s ) of degree . unfortunately these terms introduce three - point correlations into the rate equation . analogous to methods employed in similar hierarchy problems , we use a moment - closure approximation to represent these processes as a product of two two - point correlations in the following manner , adding all of these terms together our final equation for is , in addition to terms where and are interchanged . after inserting the appropriate and from eq . along uncorrelated solution , it can be shown that , according to eq . , there exist a set of solutions such that an initially uncorrelated network will not develop any degree - degree correlations as a consequence of the evolution process . the attachment kernel that was employed in the network evolution process , described in section , was a subset of these solutions . this allowed the repair method to be employed by maintaining negligible correlations in the network . one must point out , that we have not explicitly demonstrated the stability of the uncorrelated solution to perturbations . for example fluctuations in or in the number of edges may drive the network away from the uncorrelated steady - state . an analytical approach to determine this , say using linear stability analysis is difficult , due to the numerous related probability distributions involved . so instead we resort to a numerical approach . we measured the pearson correlation coefficient between the degrees of nodes at both ends of an edge for all our model networks . for the poisson and exponential cases , the correlations remained negligible during the evolution process . on the other hand , the power - law network developed non - trivial correlations . we have not been able to determine whether the appearance of these correlations was due to finite - size effects , or instability in the uncorrelated solution , or to some other cause . the results show that the agreement between the initial and final degree distributions is very good , and it seems that in this particular case , the correlations did not demonstrate a significant effect on the final state of the network . in this paper , we have shown how to preserve a network s degree distribution from various forms of attack or failures by allowing it to adapt via the simple manipulation of rules that govern the introduction of nodes and edges . we based our analysis on a rate equation describing the evolution of the network under arbitrary schemes of addition and deletion . in addition to choosing the degree of incoming nodes , we allow ourselves to choose how nodes attach to the existing network . to deal special case of non - uniform deletion we have introduced a rate equation for the evolution of degree - degree correlations and have used that in combination equation for the degree distribution to come to our solution . we have provided examples of the applicability of this method using a combination of analytical techniques and numerical simulations on a variety of degree distributions , yielding excellent results in each case . the structure of many networks in the real world is crucially related to their performance . many authors have seized on the fact that technological networks such as the internet and peer - to - peer networks are power - law in nature , and have used this to design efficient search schemes among other things . loss of structural properties of these networks then lead to severe constraints on their performance . recent empirical studies have suggested that node removal , for example , in the world wide web , is typically non - uniform in nature . in view of this , it is crucial for researchers to come up effective solutions to try and manage these types of disruptions . to the best of our knowledge , there is a considerable gap in understanding the non - uniform deletion process of nodes and edges and corresponding methods to deal them . this paper begins to address this gap . it must be pointed out that the methods we have described depends crucially on the assumption of negligible correlations as the network evolves . curiously enough , in our example power - law network , we were able to get very good agreement between the initial and final degree distributions , in spite of the appearance of non - trivial correlations . it will certainly be interesting to see if our methods can be extended to the case of networks strong correlations , and other metrics describing network structure . perhaps it is possible to directly confront the rate equation for the degree - degree correlations , although this seems a difficult prospect at the moment . the idea of preserving the structure of networks from attacks by allowing it to react in real - time is a relatively nascent one and the authors look forward to more developments in this area .", "summary": "there has been a considerable amount of interest in recent years on the robustness of networks to failures . many previous studies have concentrated on the effects of node and edge removals on the connectivity structure of a static network ; the networks are considered to be static in the sense that no compensatory measures are allowed for recovery of the original structure . real world networks such as the world wide web , however , are not static and experience a considerable amount of turnover , where nodes and edges are both added and deleted . considering degree - based node removals , we examine the possibility of preserving networks from these types of disruptions . we recover the original degree distribution by allowing the network to react to the attack by introducing new nodes and attaching their edges via specially tailored schemes . we focus particularly on the case of non - uniform failures , a subject that has received little attention in the context of evolving networks . using a combination of analytical techniques and numerical simulations , we demonstrate how to preserve the exact degree distribution of the studied networks from various forms of attack . recent years have witnessed a substantial amount of interest within the physics community in the properties of networks . techniques from statistical physics coupled widespread availability of computing resources have facilitated studies ranging from large scale empirical analysis of the worldwide web , social networks , biological systems , to the development of theoretical models and tools to explore the various properties of these systems . a relatively large body of work has been devoted to the study of degree distributions of networks , focusing both on their measurement , and formulation of theories to explain their emergence and their effects on various properties such as resilience and percolation . these studies are mostly aimed at networks in the real world that evolve naturally , in the sense that they are driven by dynamical processes not under our control . representative examples being social , biological networks and information networks like the world wide web , which though manmade , grows in a distributed fashion . there are however different classes of infrastructure related networks such as the transportation and power grids , communication networks such as the telephone and internet , that evolve under the direction of a centrally controlled authority . in addition to these is a relatively new class of networks which fall in between these two types , the classic example being peer - to - peer file - sharing networks . these networks grow in a collaborative , distributed fashion , so that we have no direct influence over their structure . however , we can manipulate some of the rules by which these form , giving us a limited but potentially useful influence over their properties . it is a well established fact , that the structure of such networks is directly related to their performance . in view of this , a certain degree of effort has been made to tailor these designer networks towards structures that optimize certain properties such as robustness to removal of nodes and efficient information transfer among other things . these networks typically experience a significant amount of vertex / edge turnover , users joining and leaving the network voluntarily , possible failures of key components and resources , or intentional attacks such as denial of service . these factors can lead to severe disruption of the network structure and as a result , loss of its key properties . in the face of this , it is natural to extend our analysis to the effects of these failures / attacks and use our limited control to attempt to adaptively restore the original structure of these networks . previous work has focused on the effects of disruption on static networks , where authors have studied the connectivity structure under the random / targeted removal of nodes and edges . the network is considered static in that no compensatory measures , such as the introduction of new edges or nodes , are permitted . the effect of these removals have been measured against the existence of the giant component : the largest set of vertices in the network of o , where is the number of nodes , that are connected to each other by at least one path . a representative example can be found in the paper by albert et al , where they studied the size of the giant component of scale free networks such as the internet , under simulated random failures and targeted attacks on high degree nodes . one of the interesting things they found was that , while these networks were remarkably robust to random failures , they were extremely fragile to targeted attacks . this emphasizes the importance of non - uniform removal strategies . unlike in the static case , the networks considered in this paper evolve in time sustained node and edge removals . the network is allowed to react to these disruptions via the introduction of new nodes and edges , chosen to be attached in a manner such that the network retains it original form , at least in terms of the degree distribution . such models , conventionally referred to in the literature as reactive networks have been discussed before , see for instance . here we assume that the designers of the network are only aware of the statistical properties of the removed nodes and have no ability to influence the existing network beyond the introduction of new nodes or reattachment of those removed . consequently they have two processes under their control to compensate for the attack . the first is the degree of the introduced vertices and the second is the process by which a newly introduced vertex chooses to attach to a previously extant vertex on the network . failure is thus compensated by adding nodes and edges chosen from an appropriate degree distribution and attaching them to the network via specially tailored schemes . note that in our model , one can re - introduce nodes that have been removed or introduce completely new sets of nodes . the former case could be indicative of say a computer in a peer - to - peer network that loses its connection , and would like to reconnect . the latter could represent the permanent loss of web - pages from the world wide web and the introduction of a new web - page . we use the attachment kernel of krapivsky and redner , to simulate the introduction of nodes and edges , and via the introduction of a deletion kernel we analyze the interesting and neglected case of non - uniform deletion . a variety of models have been proposed to simulate network evolution and growth where vertices are both added and deleted , but these have concentrated on the relatively simple case of uniform deletion . we will show that under uniform failures , the appearance of degree - degree correlations , that typically arise as a result of growth processes , as discussed in , can be neglected . previous models have taken advantage of precisely this fact to circumvent the difficulty of dealing degree - degree correlations . for the case of non - uniform deletion , correlations can not be ignored . in this paper we confront this issue by demonstrating how to preserve an initially uncorrelated network throughout the evolution process introduction of an additional rate equation for the degree - degree correlations . we give analytical results and numerical simulations for a variety of degree distributions under various forms of attack . in all the cases that we study , we recover the exact degree distributions ."}
{"article": "at a continuous transition , the expression for the leading critical behavior of a thermodynamic observable has the well known form where and are the transition temperature and the critical exponent respectively . for the concrete analysis of numerical data , a normalization factor - critical behavior at must be introduced . the simplest and most traditional convention , which will be referred to below as scaling , is to normalize each by a temperature independent constant . for obvious reasons this constant is chosen to be for each observable ; one then writes the normalized leading term as the familiar text - book expression : ^{-\\rho f } = { \\cal c} {f}t^{-\\rho f } , \\ ] ] where and is the critical amplitude ( see for a detailed review ) . an alternative and a priori equally valid choice is to write ^{-\\rho f } = { \\cal c} {f}^{-\\rho f}\\nonumber \\\\ & = & { \\cal c} {f}\\left^{-\\rho f } = { \\cal c} {f}\\tau^{-\\rho f } , \\ ] ] where is the inverse temperature and . note that the temperature dependence of the normalization is now different for each observable . this `` scaling '' form has become the standard normalization for theoretical work on the critical properties of ferromagnets and analogous systems , see for instance , although more complex normalizations have been used in special cases . at higher order , confluent and analytic correction terms ( such as temperature independent constants ) are introduced . thus including the confluent correction terms , the critical behavior , , is written in terms of the scaling as where being the confluent correction exponent , and is the confluent correction amplitude . in the scaling form , in the above equation is replaced by . this critical scaling form is firmly established by field theory in the limit of temperatures very close to . ratios of the for different observables are universal . the exponent is common in both scaling forms so long as . however , no general argument seems to have been given which would show that either the or the scaling is optimal for all ( or any ) observables when a much wider temperature range is considered . recently we have proposed an extended scaling scheme for normalizing observables such that the leading critical expressions remain good approximations right up to the trivial fixed point at infinite temperature . our extended scaling scheme is based on a consideration of high - temperature series expansions ( htse ) , and so is naturally formulated in terms of the scaling . the most important ingredient of the scheme is the introduction of non - critical prefactors in the normalizations , where each exponent is uniquely chosen such that the normalized tends to the correct asymptotic form in the limit . in the present work our aim is to further develop our extended scaling scheme to include explicitly the confluent and analytical correction terms . we then validate our scheme by analyzing data for three canonical ferromagnets : the ising , xy and heisenberg models on simple cubic lattices in dimension three . these models have been intensively studied over many years and their main critical parameters : , the critical exponents , , and certain critical amplitudes are known to high precision . careful accounts of studies using different complementary approaches are given for instance in refs . accurate simulation and htse results have been published in the form of tabulated data . the present analyses show that the appropriately normalized leading terms are good approximations over the entire temperature range , small but identifiable corrections due to confluent and non - critical terms . we obtain estimates of non - universal critical parameters like critical amplitudes and confluent correction amplitudes from the high precision numerical data . our extended scaling analyses are in each case entirely consistent field theoretical and htse estimates of the critical parameters . an important result of the present analysis is to demonstrate that the prefactors which have been introduced play a crucial role in extracting accurate values of the critical exponents from simulation data even in a temperature range close to , such as . in the standard scalings without the prefactors the estimates of the leading critical term and of the confluent term from analyses of numerical data turn out to be modified to order ( note ) . the same approach based on the htse should be directly applicable to a wide class of systems having the same intrinsic htse structure as the simple ferromagnets . extensions to more complex systems such as spin glasses are in principle straightforward . the paper is organized as follows . in . we explain our extended scaling scheme for various thermodynamic observables , and discuss confluent corrections to scaling terms in our scheme . in . we give methods of analysis for numerical data using our extended scaling scheme . we show how they work in practice for ising , xy and heisenberg ferromagnets in . , and , respectively . in . we make concluding remarks and discuss related problems . let us suppose htse of an observable is given by the most important ingredient of our extended scaling scheme is then to write as where . in particular , the leading contribution without the confluent correction is represented as the idea here is to let not only represent the correct power - law divergence critical amplitude ( and certain confluent correction terms ) at temperatures close to but also have an asymptotic form consistent htse in the high temperature limit . the observable is then approximated as here the second term represents the analytic ( non - critical ) correction term in the present scheme . its coefficients and are determined in such a way that eq . , combined . and , coincides . termwise as a function of ; for example , and a similar expression for . the above set of equations minimum number of the confluent and analytic correction terms is an optimized expression we propose for the function which is analytic in the range and is singular at . an important quantity for analyzing our extended scaling scheme is defined by it is the ratio of the measured values of observable to its leading critical term including the prefactor but without the critical amplitude . explicitly , in the vicinity of where , it behaves as the plot versus near thus becomes a straight line intercept and slope , where the values of , and are assumed to be known ( and are given by htse analysis ) . in the limit , on the other hand , it becomes between these limits the form of will depend on the entire collection of unspecified higher order corrections to scaling . the `` true '' susceptibility , naturally defined through the magnetization response to an infinitesimal applied field , is given by the fluctuation - dissipation theorem as the reduced susceptibility is ( confusingly ) almost always referred to in the literature as `` the susceptibility '' . for consistency we will follow this convention and write the reduced susceptibility as , but we will refer systematically in the text to `` reduced susceptibility '' . the htse for the reduced susceptibility in ferromagnets is of the form and , or abbreviation of , then the leading divergent expression , eq . , is written as . the ratio of eq . is reduced to where is eq . for . note that at , near , and near infinite temperature . if remains close to 1 over the whole temperature range ( which is the case for the systems we consider as we will see below ) , the leading critical contribution without the correction terms , , is a good approximation for the reduced susceptibility , . furthermore , the small difference of the ising and xy ferromagnets in the whole temperature range turns out to be reproduced surprisingly well by our optimized expression , of eq . , only confluent and two non - critical correction terms . there are different alternative definitions for the correlation length , but any correlation length diverges at criticality as . the second moment correlation length is defined through the second moment the space dimensionality . from now on we will refer to simply as . the htse results show that for -vector spins , the series for is of the form and is well behaved , where is the number of nearest neighbors . this yields and . we then reduce eq . to where being the standard critical amplitude in eq . for . the non - standard normalization prefactor for is our main result . the mean - field calculation of the correlation length through the fluctuation - dissipation theorem provides an example confirming the extended scaling form of eq . . see also the analysis of fisher and burford , particularly their temperature dependent `` effective interaction range '' parameter . the critically divergent part of confluent correction terms is represented by and is written as the ratio becomes again , because of the confluent correction , it becomes near and \\beta + \\cdots ] replacing ] against assuming the central values for the exponents and as mentioned above . figures and show and respectively against . from the intercept and the initial slope one can estimate , , and . these are all reasonably close to the quite independent htse values , , and , but are probably more reliable as they are consistent independent ft estimate of the universal ratio , see comments in ref . . also , the values of and in eq . calculated from thus obtained set of the parameters reproduce well the data as shown in fig . . this agreement again validates the extended scaling protocol and demonstrates that a combination of information from ft , htse , and simulations analyzed using this protocol can lead to consistent high precision critical parameter measurements . for comparison , we plot the standard scaling ratio introduced in . also in fig . . its coincidence will only hold for . as is the case for the ising system , the slope of is opposite to that of and the magnitude of is much larger than the corresponding magnitude of the extended ratio already at , or . in fig . , we also show the scaling and the by -scaling . the true leading term plus confluent correction holds extended scaling form , of eq . up to while other forms of scaling the correct limit will hold only for . in particular , the comparison of scaling extended scaling demonstrates the importance of the prefactor in eq . of the extended scaling scheme . these results imply that even close to the extended scaling is a considerable improvement over the standard scaling analysis for estimating critical parameters including the correction terms . the curve in fig . represents our optimized estimates up to the second order of non - critical corrections . it reproduces about 5 percents change in , from about 1.05 at to 1 at , to a very good approximation . the corresponding relative change in is only less than 2 percents as seen in fig . . to reproduce this change by to an approximation as good as in fig . , however , more than third order non - critical correction terms are required . the same analysis has been carried out for the heisenberg model . high precision numerical data were published by holm and janke , and are supplemented here by higher temperature data calculated using the tabulated series of butera and comi . the critical point is and the exponents and are close to and . a recent exponent set gives , and . figure shows the log - log plot , which gives an estimate of consistent that of ref . . figure shows the plot of ^{2-\\eta}$ ] against assuming the exponent values as and . from this plot it appears that the initial slope is very small , corresponding to almost zero values for and . figures and show respectively and against , assuming the values of and in ref . . the mc and htse points may not appear to connect smoothly in these figures , because the manner in which the plots are presented enhances small deviations from the leading term form . however , the change in the values of both in fig . and in fig . are limited to within a few percent of their absolute magnitude in a whole range of as is the case for the other two ferromagnets studied . from the straight line fit of the mc data at small , one can estimate , , and . in this case the parameters are slightly less consistent htse estimates , , , and , but it should be noted that the estimates for these parameters depend very sensitively on the precise values taken for the critical exponents . we certainly need more precise data near to fix the values of these critical parameters for the heisenberg ferromagnet . we have outlined a systematic rule for the scaling and normalization of thermodynamic observables having critical behavior at continuous phase transitions . this `` extended scaling '' rule corresponds for ferromagnets to scaling of the leading term of the reduced susceptibility above as in agreement standard practice , for the leading term of the second moment correlation length as and for the leading term of the specific heat in bipartite lattices plus strong non - critical correction terms which we explicitly evaluate by linking to the htse . analyses are made of high precision numerical data on three canonical ferromagnets using these expressions allowing for confluent scaling correction terms , plus non - critical corrections for the specific heat . near the results are entirely consistent critical parameter sets ( including the confluent corrections ) which have been obtained independently using sophisticated ft , htse and simulation techniques . the most important result found in the present work is that , for and the leading critical expressions extended scaling normalizations of eq . agree to a very good approximation true up to infinite temperature . to demonstrate this fact more in details we have introduced the ratio defined by eq . . for of the ising ferromagnet , for example , it is equal to the critical amplitude at and to unity at infinite temperature by definition . evaluated from the true data are represented by the data points in fig . , while evaluated through the leading expression is independent of and equal to . the difference between the two is , however , at most 13 percent in this case . the corresponding differences for s of the two other ferromagnets as well as for s of the all three ferromagnets are less than several percent . this is our first result mentioned just above . we have next demonstrated that our extended scaling scheme , in terms of the scaling and temperature dependent prefactor , is of crucial importance in precisely extracting the small amplitude of the leading confluent correction term . the result is represented by the solid line in fig . as well as those in figs . , , and . in addition , we have also checked that the optimized expression of eq . , consisting of and one confluent and two non - critical correction , yield which reproduces the true surprisingly well as shown the curves in figs . and , though more than third non - critical correction terms would be required for equally good agreement in other observables . the large non - critical terms in the specific heat are also incorporated explicitly within our extended scaling scheme further adjustable input parameters . for the ising ferromagnet on the simple cubic lattice is calculated to a good approximation over the entire temperature range ( see eq . ) . although the non - critical correction terms are large for , the principle of the analysis is the same as the one applied above to and , for which the corrections to scaling are quite small . namely , each critically - divergent observable is represented by of eq . over the whole range of to a good approximation . the input consists of , a confluent correction term and a very limited numbers of non - critical correction terms derived from htse . together these results can be taken as validating the `` extended scaling '' approach . the approach could be systematically implemented in numerical work so as to improve yet further the accuracy of critical parameter sets derived for standard systems , possibly incorporating where necessary further higher order correction terms . perhaps a more fruitful application would concern the analyses of numerical data in more complex systems , where the present accuracy of the critical parameter sets is much poorer . for instance , it has been pointed out that for the analysis of data on spin glasses symmetric interaction distributions should be replaced by in all expressions as all terms in the htse in these spin glasses are strictly even in . the extended scaling protocol allowing for this and appropriate normalization factors has indeed been shown to significantly improve the consistency of critical exponent values derived from numerical simulations on ising spin glasses . we would like to thank p. butera for all his careful and patient advice , h. arisue for providing extensive tabulated series data , m. hasenbusch for allowing us to use his unpublished high - precision numerical data , and w. janke for helpful discussions .", "summary": "a simple systematic rule , inspired by high - temperature series expansion ( htse ) results , is proposed for optimizing the expression for thermodynamic observables of ferromagnets exhibiting critical behavior at . this `` extended scaling '' scheme leads to a protocol for the choice of scaling variables , or depending on the observable instead of , and more importantly to temperature dependent non - critical prefactors for each observable . the rule corresponds to scaling of the leading of the reduced susceptibility above as in agreement standard practice scaling variable , and for the leading term of the second - moment correlation length as . for the specific heat in bipartite lattices the rule gives ^{-\\alpha}$ ] . the latter two expressions are not standard . the scheme can allow for confluent and non - critical correction terms . a stringent test of the extended scaling is made through analyses of high precision numerical and htse data , or real data , on the three - dimensional canonical ising , xy , and heisenberg ferromagnets . for the susceptibility and the correlation length of the three ferromagnets , their optimized expression , which consists of the leading term ( respectively and ) and a quite limited number of confluent and non - critical correction terms , represents real data to surprisingly good approximations over the entire temperature range from to infinity . the temperature dependent prefactors introduced are of crucial importance not only in fixing the optimized expression at relatively high temperatures but also in determining appropriately the small amplitude correction terms . for the specific heat of the ising ferromagnet , combined non - critical correction terms which are calculated free parameters once the correlation length critical parameters are known , reproduces real data nicely also over the whole temperature range ."}
{"article": "laser - cooling allows to cool ions and atoms to very low temperatures . for this purpose , the full knowledge of the effects of the various physical parameters determining the cooling process is very important . among the various schemes , raman sideband cooling has been demonstrated to be a very successful technique for preparing atoms in the ground state of a harmonic potential . this cooling method exploits two stable or metastable atomic internal levels , which we call and , connected by dipole transitions to a common excited state . the transitions are usually driven by alternating pulses . a typical sequence alternates a coherent pulse , in which the atom is coherently transferred from to via a properly designed raman pulse , re - pumping pulse , in which the atom is incoherently re - scattered to by means of a laser resonant . a change of the motional state during the repumping is a process of higher order in the ratio of the recoil frequency and the trap frequency , being the mass of the atom and the wave vector of the one - photon transition . in the lamb - dicke regime , where , the probability for a change of the motional state is negligible and therefore , on the average , the system is cooled at a rate of one phonon of energy per cooling cycle . since there is a finite probability for the atom to be returned to the state instead of being repumped , a number of incoherent scattering events may be required before the atom is finally scattered into , which significantly increases the motional energy at the end of the optical pumping , reducing the cooling efficiency . furthermore , since two and three level schemes are realized using zeeman or hyperfine substates , decays from into other electronic substates can occur , leading to additional heating . + in this work we quantify the effect of a finite branching ratio in pulsed raman sideband cooling by calculating the average shift and diffusion of the vibrational energy distribution at the end of an incoherent pumping pulse . it should be pointed out that theoretical studies on laser - cooling for multilevel ions exist , which systematically include the branching ratio in their treatments . those studies have focussed on the lamb - dicke regime and on certain cooling schemes . here , we single out the effect of the branching ratio on cooling for an arbitrary ratio by applying sum rules . hence , we infer the cooling efficiency in the lamb - dicke regime and we discuss the result outside the lamb - dicke regime in connection proposal in . in particular , we show that in some parameter ranges the average effect of the multiple photon scattering can be described effective wave vector for the `` effective '' two - level transition . + this article is organized as follows . in section 2 we introduce the model for the evolution of a trapped ion during the repumping pulse in a raman transition , and we evaluate the average shift and variance of the ion energy at the end of the pulse . in section 3 we extend our analysis to cases where the channels of decay are multiple . in section 4 we draw some conclusions , and in the appendix we report the details of our calculations . we consider a three level atom as in fig . , whose internal levels are a ground state , stable or metastable state and excited state of radiative width ; , are dipole transitions , respective probabilities of decay , , where . a laser resonantly drives the transition rabi frequency . in the following we assume the wave vectors for both transitions to be equal to , which is a good approximation if , e.g. , and are hyperfine components of the ground state . we study the ion motion in one - dimension . + the master equation for the atomic density matrix is written as : +l\\rho 3 , \\ ] ] where has the form : here , is the detuning of the laser on the transition , which we take to be zero , and is the frequency of the harmonic oscillator which traps the ion along the -direction , annihilation and creation operator , respectively . the interaction of the ion laser light is described in the dipole approximation by the operator : ( ) dipole raising operator , its adjoint , and the position of the atom . in writing , we have applied the rotating wave approximation and we have moved to the inertial frame rotating at the laser frequency . finally , the relaxation super operator has the form where is the dipole pattern of the spontaneous emission , which we take . + in the limit we can eliminate the excited state in second order perturbation theory , and reduce the three - level scheme to a two level one , excited state and linewidth . in the limit the master equation for the density matrix , projection of on the subspace , can be rewritten as : +\\gamma e\\left , \\ ] ] effective hamiltonian , jump operators , defined as : where and where the solution of eq . can be written as follows : , and is the propagator for the effective hamiltonian : in eq . the successive contributions to the multiple scattering event are singled out : the first term on the rhs corresponds to the case in which at time no spontaneous decay has occurred . the second term describes a single scattering event , and the -th term scattering events . the trace of each term corresponds to the probability associated each event , and we can thus interpret eq . as the sum over all the possible paths of the scattering event weighted by their respective probabilities . at , , the atom is in and . for a pulse of duration we can replace by in the integrals of eq . and assume that the atom has been scattered into at the end of the pulse . now , each term on the rhs of eq . corresponds to the path associated certain number of scattering events into before the atom is finally scattered into . through we can evaluate the shift and the variance of the energy distribution at the end of the repumping pulse , which are defined as : where and is the initial motional energy of the atom . for simplifying the form of the discussion presented below , we rewrite the operator as follows : where , are defined as : |l\\rangle\\langle l|,&\\\\ & \\rho=\\sum l\\sum {l 1,l 1\\neq l } and where is the basis of eigenstates of the harmonic oscillator . for , initial distribution over the motional states , and according to eq . the steady state distribution has the form : where is the final distribution over the motional states . the first term in the rhs of is the sum over all paths from into , where after each jump the density operator is diagonal in the basis , whereas the second term contains all other paths . these latter terms can be neglected , and for the following relation holds : |s\\rangle = d n(s ) . \\ ] ] here , is the probability for the atom to be found in the state at , given the initial state at . using the explicit form of in , has the form : where we have used the relation , size of the ground state of the harmonic oscillator . substituting into eqs . , , and applying the commutation properties of , we find : , \\ ] ] where is the lamb - dicke parameter . equation represents the average shift to the vibrational energy at the end of the repumping pulse . for it corresponds to the average recoil energy associated incoherent raman scattering into . in this case , the second term in the rhs of eq . vanishes , and eqs . , describe the scattering of one photon of wave vector on the effective two - level transition . similarly for an effective wave vector can be defined for the incoherent scattering on the two - level transition , which has the form thus , describes the average mechanical effect on the ion resulting from the multiple scattering of photons during the repumping pulse in a raman transition branching ratio : this description is valid in the limit in which we may neglect the second term in the rhs of , i.e. for and/or sufficiently small . in fig . 2 the first term of rhs of eq . is compared complete expression for , for different values of the lamb - dicke parameter and as a function of . here , we see that characterizes the scattering process for almost any branching ratio in the lamb - dicke regime , whereas for an appreciable difference is already visible at . + from we can define the effective lamb - dicke parameter describing an incoherent scattering into the state . this parameter provides an immediate estimate of the effect of the branching ratio on cooling . for , if the system is still in the lamb - dicke regime once it has been finally scattered into . furthermore , the coarse - grained dynamics of the system can be described by a rate equation for the motional states projected onto , where the rate of cooling ( heating ) is the real part of the sum of two terms : one corresponding to the component of the fluctuation spectrum of the dipole force at frequency , the other to the diffusion coefficient due to spontaneous emission from the excited state . this latter term is proportional to the squared lamb - dicke parameter for the incoherent scattering , and thus in our case to . from the well - known solution of the rate equation , the diffusion term affects the steady state average vibrational number , which is proportional to the diffusion coefficient . + outside the lamb - dicke regime , when is comparable to , or larger than , , there are no estabilished ground - state laser - cooling techniques for trapped atoms . here , we discuss our result in connection to the proposal in . there , a cooling scheme similar to raman sideband cooling has been presented , where pulses which pump the atoms to the ground state alternate pulses confining the atoms to a limited region of motional energy . these confinement pulses have two - photon detuning to the red of the two - photon resonance frequency , where . then , the presence of a branching ratio must be taken into account by choosing . in this regime , pulses which efficiently counteract the average kick can be designed , provided that the following condition is fulfilled : where is the projection on of the two - photon wave vector of the coherent pulse . for two counterpropagating beams parallel to , and is fulfilled for , i.e. up to branching ratios . finally , outside the lamb - dicke regime the second term in the rhs of eq . can not be neglected . hence , the diffusion is larger , and the efficiency of cooling may decrease dramatically as increases . in the following , we show that the average heating associated repumping pulse in multilevel - schemes can be described in the same way as discussed in the previous sections . + let us consider the level - scheme of fig . 3(a ) , where we have added to the scheme of fig . 1 a further channel of decay from into the stable or metastable state , probability of decay such that , where , are the probability of decay onto , respectively . a laser resonantly drives the transition rabi frequency . for the state can be adiabatically eliminated from the equations of motion . in this limit the master equation aquires the form \\\\ & & + p e'\\gamma^{\\prime}j e\\rho + p 1\\gamma^{\\prime}j 1\\rho + p g'\\gamma^{\\prime}j g\\rho,\\nonumber\\ ] ] where , . the effective hamiltonian is now : . the solution at can be written as : hence , the shift and variance have the form evaluated in eqs . , where now the probability , are defined as , . in a similar way we have evaluated these quantities for schemes like the one shown in fig . 3(b ) , where a second excited state is coupled to via the same recycling laser tuned on the transition . for simplifying the treatment , we assume that a fourth laser resonantly drives the transition rabi frequency ( grey arrow in fig . 3(b ) ) . thus , for low saturation eq . describes the dynamics , where now , being the rate of scattering through the excited state . assuming that is such that , the solution in eqs . , applies to this case too , where now is defined as : and the probability of decaying into is . + the result shows that the total heating is minimum for , which can be obtained by choosing properly the laser intensity of the repumping lasers , or simply by removing degeneracies in the zeeman multiplet , for example help of a magnetic field . we have studied the motional heating associated finite branching ratio and in the presence of multiple decay and excitation channels at the end of a repumping pulse in raman sideband cooling . the first and second moments of the final energy distribution has been evaluated analytically , and the effect of the branching ratio has been singled out . we have shown that in a certain range of parameters the diffusion can be described effective wave vector , corresponding to an effective lamb dicke parameter for the incoherent scattering on the two - level transition . finally , on the basis of this result we have discussed the efficiency of raman sideband cooling and of a recent proposal of ground - state cooling outside the lamb - dicke regime . + analogous sum rules and considerations can be applied to raman cooling for free atoms . in that case the calculations are much simpler , since the total momentum of radiation and atom is a conserved quantity in the scattering event . + in general , these results can be applied to cooling schemes in multilevel atoms . the authors acknowledge many stimulating discussions s. khler and v. ludsteck . g.m . thanks j.i . cirac , j. eschner and p. lambropoulos for many stimulating discussions . this work is supported in parts by the european commission within the tmr - networks erb - fmrx - ct96 - 0087 and erb - fmrx - ct96 - 0077 . using , we rewrite and as : the sum over can be contracted by observing that . then , using the commutation properties of the bosonic operators and the closure relation for the eigenstates of the harmonic oscillator , eq . takes the form : c. monroe , d.m . meekhof , b.e . king , s.r . jefferts , w.m . itano , d.j . wineland , and p. gould , phys . lett . * 75 * , 4011 ( 1995 ) ; h. perrin , a. kuhn , i. bouchoule , c. salomon , europhys 42 * , 395 ( 1998 ) ; s.e . hamann , d.l . haycock , g. klose , p.h . pax , i.h . deutsch , and p.s . jessen , phys . lett . * 80 * , 4149 ( 1998 ) ; v. vuletic , c. chin , a.j . kerman , and s. chu , phys . 81 * , 5768 ( 1998 ) . r. dum , p. zoller , and h. ritsch , phys . rev . a * 45 * , 4879 ( 1992 ) . it can be shown that the terms in eq . containing at some time coherences between vibrational states are of order respect to the terms that contain the populations only . this condition alone would not be sufficient , as the number of terms of corresponding to scattering events increases . however , these term are oscillating functions of the intermediate vibrational states , and thus their sum is much smaller than the first term of . m. kasevich and s. chu , phys . * 69 * , 1741 ( 1992 ) ; n. davidson , h.j . less , m. kasevich , and s. chu , phys . 72 * , 3158 ( 1994 ) ; j. reichel , o. morice , g.m . tino , and c. salomon , europhys . lett . * 28 * , 477 ( 1994 ) . ( a ) level scheme , , , stable or metastable states , excited state of radiative width and probability of decaying in the three ground states , and , respectively . two lasers couple and to ; ( b ) level scheme as in ( a ) addition of the excited state decay probability on , equal to , , respectively , . two lasers couple and to .", "summary": "we have investigated the efficiency of pulsed raman sideband cooling in the presence of multiple decay and excitation channels . by applying sum rules we identify parameter regimes in which multiple scattering of photons can be described by an effective wave vector . using this method we determine the rate of heating caused by optical pumping inside and outside the lamb - dicke regime . on this basis we discuss also the efficiency of a recently proposed scheme for ground - state cooling outside the lamb - dicke regime ."}
{"article": "nuclei in interaction external fields display a wide variety of collective vibrations known as giant resonances , associated various degrees of freedom and multipolarities . the giant isovector dipole resonance and the giant isoscalar quadrupole resonance are the most studied examples in this class of phenomena . a particular mode , that is associated vibrations in the number of particles , has been predicted in the and discussed , under the name of giant pairing resonance , in the middle of the in a number of papers . this phenomenon , despite some early efforts aimed to resolve some broad bump in the high - lying spectrum in ( p , t ) reactions , is still without any conclusive experimental confirmation . for a discussion , in particluar in connection - particle transfer reactions , on many aspects of pairing correlations in nuclei we refer to a recent review . we have studied the problem of collective pairing modes at high excitation energy in two neutron transfer reactions aim to prove the advantage of using unstable beam as a new tool to enhance the excitation of such modes . the main point is that standard available beams one is faced large energy mismatch that strongly hinders the excitation of high - lying states and favours the transition to the ground state of the final system . instead the optimum q - value condition in the ( he,he ) stripping reaction suppresses the ground state and should allow the transition to 10 - energy region . we have performed particle - particle rpa calculations on lead and bcs+rpa on tin , as paradigmatic examples of normal and superfluid systems , evaluating the response to the pairing operator . subsequently the two - neutron transfer form factors have been constructed in the framework of the macroscopic model and used in dwba computer codes . we have estimated cross - sections of the order of some millibarns , dominating over the mismatched transition to the ground state . recently we added similar calculations on other much studied targets to give some guide for experimental work . the formal analogy between particle - hole and particle - particle excitations is very well established both from the theoretical side and from the experimental side for what concern low - lying pairing vibrations around closed shell nuclei and pairing rotations in open shells . the predicted concentration of strength of a character in the high - energy region ( 8 - for most nuclei ) is understood microscopically as the coherent superposition of 2p ( or 2h ) states in the next major shell above the fermi level . we have roughly depicted the situation in fig . . in closed shell nuclei the addition of a pair of particles ( or holes ) to the next major shell , total energy , is expected to have a high degree of collectivity . also in the case of open shell nuclei the same is expected for the excitation of a pair of particles energies . for normal nuclei the hamiltonian monopole strength interaction reads : where annihilates a pair of particles coupled to total angular momentum . getting rid of all the technicalities of the solution of the pp - rpa equations ( that may be found in the already cited work by the author ) we merely state that the pairing phonon may be expressed as a superposition of 2p ( or 2h ) states proper forward and backward amplitudes ( and ) . the pair transfer strength , that is a measure of the amount of collectivity of a each state , is given by : . \\ ] ] this quantity is plotted in the first column of fig . for the removal ( upper panel ) and addition mode ( lower panel ) . in the same figure are reported the pairing strength parameters for the states of sn . to obtain these last quantities for superfluid spherical nuclei one has to rewrite the hamiltonian according to the bcs transformation and has to solve more complex rpa equations . in this case the pairing strength for the addition of two particles is given , for each state , by : {00}|0\\rangle = \\sum {j } \\ ] ] where the and are the usual occupation probabilities . the amount of collectivity is a clear signal of the structural existence of giant pairing vibrations in the high - lying energy region . we also report here a number of analogous results for other commonly studied targets = 9.4pc = 9.4pc = 9.4pc aim of giving some indications to experimentalists on the reasons why we think that lead and tin are some of the most promising candidates . we have studied two isotopes of calcium closed shells . even if the absolute magnitudes of the is lower , it is worthwhile to notice that some enhancement is seen in the more neutron - rich ca respect to ca . an important role in this change is certainly due to the different shell structure of the two nuclei as well as to the scheme that we implemented to obtain the set of single particle levels . the latter is responsible for the collectivity of the removal modes in both ca isotopes and also for the difficulty in finding out a collective state in the addition modes . we display also results for zr where the strength is much more fragmented and the identification of the gpv is more difficult . in the work of broglia and bes estimates for the energy of the pairing resonance are given as and for normal and superfluid systems respectively . our figures follow roughly these prescriptions based on simple arguments ( and much more grounded in the case of normal nuclei ) as evident from table . .comparison of position of gpv between our calculation and the broglia and bes estimate . = 13.8pc = 13.8pc these cross - sections have been derived for sharp states , and we refer to the numbers in the last table when speaking of order of magnitude estimates . obviously cross - section in the high - lying energy region have a finite ( and large ) width that should be inserted for a more realistic description of the spectrum . we have chosen a simple scheme that gives a lorentzian distribution width that grows quadratically excitation energy , , adjusted to give a width of for the gpv . this could seem rather arbitrary since there is no reason for an a priori assignment of this quantity . we have been brought to this simple prescription because other collective states ( of different nature ) lying in the same energy region display similar values for their width , and it is reasonable to assume some rule to narrow the low - energy states and to broaden the high - energy ones . the final achievements for the four reactions studied in detail are presented in figure where the areas corresponding to the cross - sections given above have been shaded to give a feeling of the relative magnitudes of the transition to the ground states and to the gpv s . it is worthwhile to note that in the case of pb there is a considerable gain in using unstable beams , while in sn is much less evident . one sees the need for unstable helium when compares the magnitude for the pairing resonance in the right a ) and b ) panels peak at zero energy : in the first panel the transition to the ground state is extremely hindered . a he beam is currently available ( or it will be available in the very near future ) in many radioactive ion beams facilities around the world and the calculations that we have presented could allow a planning for future experiments aimed to study the not yet completely unraveled role of pairing interaction in common nuclei , using exotic weakly bound nuclei as useful tools . the author wishes to gratefully acknowledge discussions andrea vitturi , hugo sofia and wolfram von oertzen on various aspects of theoretical and experimental nuclear physics . the participation at the vii international school - seminar on heavy ion physics , dubna , russia 2002 has been supported by the infn . xxxx r.a.broglia and d.r.bes , plb691291977 . m.w.herzog , r.j.liotta and l.j.sibanda , phys . c * 31 * , 259 , ( 1985 ) . et al , prl 3914511977 . w.von oertzen and a.vitturi , rep . phys . * 64 * , 1247 - 1337 , ( 2001 ) . l.fortunato , w.von oertzen , h.m.sofia and a. vitturi , eur . a * 14 * , ( 2002 ) , in press . c.h.dasso and a.vitturi ( editors ) , collective aspects in pair transfer phenomena , sif proc . 18 , ( editrice compositori bologna , 1987 ) . d.r.bes and r.a.broglia , phys . c * 3 * , 2349 , ( 1971 ) . c.h.dasso and g.pollarolo , plb 1552231985 . c.h.dasso and a.vitturi , prl 596341987 .", "summary": "we investigate the possible signature of the presence of giant pairing states at excitation energy of about via two - particle transfer reactions induced by neutron - rich weakly - bound projectiles . performing particle - particle rpa calculations on pb and bcs+rpa calculations on sn , we obtain the pairing strength distribution for two particles addition and removal modes . estimates of two - particle transfer cross sections can be obtained in the framework of the macroscopic model. the weak - binding nature of the projectile kinematically favours transitions to high - lying states . in the case of reaction we predict a population of the giant pairing vibration cross sections of the order of a millibarn , dominating over the mismatched transition to the ground state ."}
{"article": "the physical content of general relativity is contained in einstein s equation , which has a well - posed initial value formulation ( see , e.g. , ) . in principle , therefore , to determine the motion of bodies in general relativity such as binary neutron stars or black holes one simply needs to provide appropriate initial data ( satisfying the constraint equations ) on a spacelike slice and then evolve this data via einstein s equation . however , in practice , it is generally impossible to find exact solutions of physical interest describing the motion of bodies by analytic methods . although it now is possible to find solutions numerically in many cases of interest , it is difficult and cumbersome to do so , and one may overlook subtle effects and/or remain unenlightened about some basic general features of the solutions . therefore , it is of considerable interest to develop methods that yield approximate descriptions of motion in some cases of interest . in general , the motion of a body of finite size will depend on the details of its composition as well as the details of its internal states of motion . therefore , one can expect to get a simple description of motion only in some kind of `` point particle limit '' . however , einstein s equation is nonlinear , and a straightforward analysis shows that it does not make any mathematical sense to consider solutions of einstein s equation distributional stress - energy tensor supported on a worldline . physically , if one tried to shrink a body down to zero radius at fixed mass , collapse to a black hole would occur before the point particle limit could be reached . distributional stress - energy tensors supported on a world - line do make mathematical sense in the context of the linearized einstein equation . therefore , one might begin a treatment of gravitational self - force by considering a metric perturbation , , in a background metric , , sourced by the stress - energy tensor of a `` point particle '' of mass m , given in coordinates by (t , x^i ) = 8 \\pi m u a(t ) u b(t ) (x^i - z^i(t))}{ } {dt}\\,\\ , .\\ ] ] where is the unit tangent ( i.e. , 4-velocity ) of the worldline defined by , and is the proper time along . ( here is the `` coordinate delta function '' , i.e. , . the right side also could be written covariantly as where is the covariant 4-dimensional delta - function and denotes the proper time along . ) however , this approach presents two major difficulties . first , the linearized bianchi identity implies that the point particle stress - energy must be conserved . however , as we shall see explicitly in section below , this requires that the worldline of the particle be a geodesic of the background spacetime . therefore , there are no solutions to equation for non - geodesic source curves , making it hopeless to use this equation to derive corrections to geodesic motion . this difficulty has been circumvented in and other", "summary": "there is general agreement that the misataquwa equations should describe the motion of a small body \" in general relativity , taking into account the leading order self - force effects . however , previous derivations of these equations have made a number of ad hoc assumptions and/or contain a number of unsatisfactory features . for example , all previous derivations have invoked , without proper justification , the step of `` lorenz gauge relaxation '' , wherein the linearized einstein equation is written down in the form appropriate to the lorenz gauge , but the lorenz gauge condition is then not imposed thereby making the resulting equations for the metric perturbation inequivalent to the linearized einstein equations . ( such a `` relaxation '' of the linearized einstein equations is essential in order to avoid the conclusion that `` point particles '' move on geodesics . ) in this paper , we analyze the issue of `` particle motion '' in general relativity in a systematic and rigorous way by considering a one - parameter family of metrics , , corresponding to having a body ( or black hole ) that is `` scaled down '' to zero size and mass in an appropriate manner . we prove that the limiting worldline of such a one - parameter family must be a geodesic of the background metric , . gravitational self - force as well as the force due to coupling of the spin of the body to curvature then arises as a first - order perturbative correction in to this worldline . no assumptions are made in our analysis apart from the smoothness and limit properties of the one - parameter family of metrics , . our approach should provide a framework for systematically calculating higher order corrections to gravitational self - force , including higher multipole effects , although we do not attempt to go beyond first order calculations here . the status of the misataquwa equations is explained ."}
{"article": "the schwinger - dyson ( sd ) equation is one of the most popular approaches to investigate the non - perturbative features of quantum field theory . the analyses by making use of the sd equation for quark propagator are well - known . recently , the coupled sd equations for the gluon and ghost propagators in yang - mills theory have been studied mainly in the lorentz ( landau ) gauge. in this paper , we derive the sd equations for the yang - mills theory in the maximal abelian ( ma ) gauge and solve them analytically in the infrared ( ir ) asymptotic region . the ma gauge is useful to investigate the yang - mills theory from the view point of the dual superconductivity . in the ma gauge , in contrast to the ordinary lorentz gauge , we must explicitly distinguish the diagonal components of the fields from the off - diagonal components . this is indeed the case even in the perturbative analysis in the uv region. therefore , we must take account of the four propagators for the diagonal gluon , off - diagonal gluon , diagonal ghost and off - diagonal ghost . numerical behaviors of gluon propagators in the ma gauge are also investigated on a lattice simulation. first , we derive the sd equations from the yang - mills action in the ma gauge . the graphical representation of sd equations are shown in figure . = .001 in ( 6000,1800 ) ( 0,-200)(0,500)(0,150)(450,300)(600,160)(800,200)(1250,300)(1400,160)(1600,0)(2000,350)(2200,160)(2400,160)(3600,160)(3800,160)(0,1000)(0,150)(450,300)(600,160)(800,200)(1250,300)(1400,160)(1600,100)(2000,350)(2200,160)(2400,160)(3600,160)(3800,160)(0,1500)(0,150)(0,250)(450,300)(600,160)(800,200)(1000,250)(1250,300)(1400,160)(1600,0)(1570,230)(2200,160)(2400,0)(2370,230)(3000,160)(3200,160)(4400,160)(4600,160)(0,0)(0,150)(0,250)(450,300)(600,160)(800,200)(1000,250)(1250,300 ) for the diagonal gluon propagator , we adopt the landau gauge so that the diagonal gluon propagator has only the transverse part where we defined the form factor . while , the off - diagonal gluon propagator has both the transverse and longitudinal parts \\delta^{ab},\\ ] ] where we defined the form factors and . the form factor for the off - diagonal ghost propagator is defined the diagonal ghost propagator is decoupled from the other fields so that we omit it hereafter . now , we write down the sd equations : and here the contributions from the two - loop graphs have been omitted . the full form of sd equations will be given in a separate paper . is the full vertex function for the diagonal gluon , off - diagonal ghost and off - diagonal antighost interaction , while is the full vertex function for an interaction of the diagonal gluon and two off - diagonal gluons , and the superscript `` '' means a bare propagator or vertex function . in the ma gauge , we obtain the slavnov - taylor ( st ) identities in order to solve the sd equations analytically , we employ the following approximations . we neglect the two - loop contributions . instead of the full vertex functions , we adopt modified vertex functions which are compatible st identities . we adopt approximations for vertex functions as and here , we adopt the feynman gauge for the off - diagonal gluon for simplicity , that is , and . substituting the bare form factors , which are , into the right hand side of the ansatz and , we obtain the bare vertex functions . moreover , these ansatz are compatible st identities and in the limit of . in the momentum integration , we use the higashijima - miransky approximation as now we adopt the ansatz for the form factors in the ir region : g(p^2 ) = b(p^2)^v+\\cdots,\\\\ f {\\rm t}(p^2 ) = c(p^2)^w+\\cdots . \\ ] ] substituting the ansatz for the form factors , and the ansatz and for vertex functions into the sd equations , and , and comparing the leading term in the both sides of each equation , we obtain the following results for . from eqs . and , we obtain the relations and . in the case of and , from the eq . , we obtain the relation so that is less than . in the case of and , we need redefine the form factor as since contributions from the leading term of are canceled each other in the ansatz . therefore we need the information of next leading term of the form factor . in this case we obtain the relation from the eq . so that is also less than . next , we consider the case of and . as well as the above case , we need redefine the form factor as and we obtain the relation . similarly , in the case of , we obtain the relation . the results are summarized in table . & & & in the gauge other than the feynman gauge , that is , , the calculation and discussion are very tedious . however , the qualitative results are identical to the above case except for the following one point . in this case , even if , there occurs no cancellation as in the above two cases 2c and 2d . this is because the off - diagonal gluon propagator has the momentum dependent tensor structure for , while it is proportional to for . therefore , we obtain the relation in the case of . ( see table . ) & & & & in the ir limit , the form factors of each propagator behave as therefore the solution shows that the diagonal gluon propagator is enhanced in the ir limit , while the off - diagonal gluon and off - diagonal ghost propagators are suppressed in the ir region . our results are compatible hypothesis of abelian dominance .", "summary": "we derive the schwinger - dyson equations for the yang - mills theory in the maximal abelian gauge and solve them in the infrared asymptotic region . we find that the infrared asymptotic solutions for the gluon and ghost propagators are consistent hypothesis of abelian dominance ."}
{"article": "if a word can be written as , then words , , and are called the prefix , factor , and suffix of , respectively . a word over is called a de bruijn sequence of order , if each word in appears exactly once in as a factor . for example , is a binary de bruijn sequence of order since each binary word of length two appears in it exactly once as a factor : . the de bruijn sequence can be understood by the following game . suppose there are infinite supplies of balls , each of which is labeled by a letter in , and there is a glass pipe that can hold balls in a vertical line . on the top of that pipe is an opening , through which one can drop balls into that pipe , and on the bottom is a trap - door , which can support the weight of at most balls . when there are more than balls in the pipe , the trap - door opens and those balls at the bottom drop off until only balls remain . if we put balls as numbered as in a de bruijn sequence on the alphabet of order , then every ball sequence will appear exactly once in the pipe . it is easy to see that a de - bruijn sequence of order , if exists , is of length and its suffix of length is identical to its prefix of length . so , sometimes a de - bruijn sequence is written in a circular form by omitting the last letters , which can be viewed as the equivalence class of words under the conjugate relation . the de bruijn sequence is also called the de bruijn - good sequence , named after de bruijn and good who independently studied the existence of such words over binary alphabet ; the former also provided a formula for the total number of those words of order . the study of the de bruijn sequence , however , dates back at least to 1894 , when flye sainte - marie studied the words and provided the same formula . for an arbitrary alphabet , van aardenne - ehrenfest and de bruijn provided the formula for the total number of de bruijn sequences of order . besides the total number of de bruijn sequences , another interesting topic is how to generate a de bruijn sequence ( arbitrary one , lexicographically least one , lexicographically largest one ) . for generating de bruijn sequences , see the surveys . the de bruijn sequence is some times called the full cycle , and has connections to the following concepts : feedback shift registers , normal words , generating random binary sequences , primitive polynomials over a galois field , lyndon words and necklaces , euler tours and spanning trees . in this paper , we consider a generalization of the de bruijn sequence . to understand the concept , let us return to the glass pipe game presented at the beginning . now the trap - door can support more weight . when there are or more balls in the pipe , the trap - door opens and the balls drop off until there are only balls in the pipe . is there an arrangement of putting the balls such that every ball sequence appears exactly once in the pipe ? the answer is `` yes '' for arbitrary positive integers . the solution represents a multi - shift de bruijn sequence . we will discuss the existence of the multi - shift de bruijn sequence , the total number of multi - shift de bruijn sequences , generating a multi - shift de bruijn sequence , and the application of the multi - shift de bruijn sequence in the frobenius problem in a free monoid . let be the alphabet and let be a word over . the length of is denoted by and the factor of is denoted by . if for some non - negative integer , we say factor appears in at a modulo position . the set of all words of length is denoted by and the set of all finite words is denoted by , where is the empty word . the concatenation of two words is denoted by , or simply . a word over is called a multi - shift de bruijn sequence of shift and order , if each word in appears exactly once in as a factor at a modulo position . for example , one of the -shift de bruijn sequence of order is , which can be verified as follows : the multi - shift de bruijn sequence generalizes the de bruijn sequence in the sense de bruijn sequences are exactly -shift de bruijn sequences of the same order . it is easy to see that the length of each -shift de bruijn sequence of order , if exists , is equal to . by the definition of multi - shift de bruijn sequence , the following proposition holds . let be one -shift de bruijn sequence of order , . then the suffix of length of is identical to the prefix of length of . let be one -shift de bruijn sequence of order over and let . write such that . if , then we compare the set of all factors and the set of all factors for . the former covers factors and the latter covers factors for every . since the two are identical , we have . now we assume . consider the set of all factors and the set of all factors for and . by the same argument , we have for . finally , comparing the set of all and the set of all for , we have the equality . therefore , we have the equality . from proposition , we know that when , every multi - shift de bruijn sequence can be written as a circular word and the discussion on multi - shift de bruijn sequences of the two different forms are equivalent . in this paper , we discuss the multi - shift de bruijn sequence in the form of ordinary words . a ( non - strict ) directed graph , or digraph for short , is a triple consisting of a set of vertices , a set of arcs , and an incidence function . here we do not take the convention , since we allow a digraph contains self - loops and multiple arcs regarding the same pair of vertices . when , we say the arc joins to , where vertex and vertex are called tail and head , respectively . the indegree ( outdegree , respectively ) of a vertex is the number of arcs being the head ( the tail , respectively ) . a walk in is a sequence such that for each . the walk is closed , if . two closed walks are regarded as identical if one is the circular shift of the other . an euler tour is a closed walk that traverses each arc exactly once . hamilton cycle is a closed walk that traverses each vertex exactly once . an ( spanning ) arborescence is a digraph particular vertex , called the root , such that it contains every vertices of , its number of arcs is exactly one less than the number of vertices , and there is exactly one walk from the root to any other vertex . we denote the total number of euler tours , hamilton cycles , and arborescence of by , , and , respectively . an ( undirected ) graph is defined as a digraph such that for any pair of vertices , there is an arc , , if and only if there is a corresponding arc , . in this case , we write and a spanning arborescence is just a spanning tree . the arc - graph of is defined as such that for every pair of arcs , , there is an arc , and those arcs are the only arcs in . euler tours exist in a graph if and only if hamilton cycles exist in the arc - graph . we define the word graph by , where for . then by definition , the following lemmas are straightforward . the digraph is the digraph . by definition , where , and so for every pair of arcs of , there is an arc of ; and for every arc of , hence , by definition , is the arc - graph of . suppose . ( 1 ) there is a -to- mapping from the set of -shift de bruijn sequences of order onto the set of hamilton cycles in . ( 2 ) there is a -to- mapping from the set of -shift de bruijn sequences of order onto the set of euler tours in . let . ( 1 ) notice that any hamilton cycle together starting arc uniquely determines one -shift de bruijn sequences of order specified by and vice versa . so the -to- mapping exists . ( 2 ) applying lemma , this part follows from ( 1 ) . for any alphabet , positive integers , the -shift de bruijn sequences of order over exist . first we assume . let be any permutation of the words in for . then the word is one -shift de bruijn sequence of order over . now we assume and prove there exists an euler tour in . then by lemma , the existence of -shift de bruijn sequences of order over is ensured . to show the existence of an euler tour , we only need to verify that is connected and that for every vertex , both of which are straightforward : for every vertex in , is connected to the vertex in both directions and . since -shift de bruijn sequence of order exists , in this section we discuss the total number of different -shift de bruijn sequence of order , and we denote the number by . first , we study the degenerated case . for , , where . let . by the definition of the multi - shift de bruijn sequence , in the case , -shift de bruijn sequences of order are exactly those of the form , where and is a permutation of all words in . therefore , the total number of such words is . to study the case , we need a theorem by van aardenne - ehrenfest and de bruijn , which describes the relation between the number of euler tours in a particular type of digraph and the number of euler tours in its arc - graph . let be a digraph such that for every . then . the digraph satisfies the conditions in theorem . so , by the relation between the multi - shift de bruijn sequences and the euler tours in the word graph , we have the following recursive expression on . for , , where , . let , . by lemma , to finish the last step of obtaining for , we again need two theorems , which are often used in the literature to count the number of euler tours in various types of digraphs . in a digraph , . in a graph , the number of spanning trees is equal to any cofactor of the laplacian matrix of , which is the diagonal matrix of degrees minus the adjacency matrix . for , , where . let and . then . by definition , so from any vertex to any vertex , there are -many arcs in . we convert into a undirected graph by omitting all self - loops ; there are -many of them for each vertex . since for every pair of vertices there are -many arcs joins to and correspondingly there are -many arcs joins to , the graph is indeed an undirected graph by our definition . each vertex in is of degree . then the laplacian matrix of is by theorem , the number of arborescence is equal to the cofactor of , which is . then by theorem , the number of euler tours in digraph is . finally , by lemma , the number of -shift de bruijn sequence of order is . for , , and for , , where . for , the equality is shown in lemma . now we assume . let . then by lemmas , , we have . in this section , we study the problem of generating one -shift de bruijn sequence of order for arbitrary alphabet and positive integers . when , a -shift de bruijn sequence of order is easy to construct as given in theorem . now we consider the case . we will present two algorithms for generating a -shift de bruijn sequence of order . we claim that -shift de bruijn sequences of order can be generated using the ordinary de bruijn sequence generating algorithm , such as described by fredricksen . to do this , we first generate a de bruijn sequence of order over the alphabet . then we replace each letter of in by the corresponding word of length over . it is easy to see that the new word is a -shift de bruijn sequence of order . the first algorithm of generating multi - shift de bruijn sequence is to generate -shift de bruijn sequences of order for before rearranging the words to obtain an arbitrary -shift de bruijn sequence of order . let be two integers , and , where . the case is already discussed and the case is trivial . so we assume and . we define , and generate such that is a -shift de bruijn sequence of order and ; and define , and generate such that is a -shift de bruijn sequence of order and . let , , . we define , , , . then the following word is one -shift de bruijn sequence of order , where and . to show the correctness , we claim that every word in appears in as a factor at a modulo position exactly once . furthermore , since , every word in appears in as a factor at a modulo position exactly once . therefore , the generated word is indeed a -shift de bruijn sequence of order . now , we will see an example . consider generating a -shift de bruijn sequence of order . then and we can obtain two words , which is , and , which is . so one -shift de bruijn sequence of order is as follows where the subscripts and denote whether the letter is from the word ( words ) or from the word ( words ) . now we present the second algorithm , which uses the same idea of `` prefer one '' algorithm for generating ordinary de bruijn sequences . let be two positive integers . the following algorithm generates a -shift de bruijn sequence of order : 1 . start the sequence zeros ; 2 . append to the end of current sequence the lexicographically largest word of length such that the suffix of length of new sequence has not yet appeared as factor at a modulo position ; 3 . repeat the last step until no word can be added . to show the correctness , first we claim that when the algorithm stops , the suffix of length of contains only zeros . to see this , suppose is not . since no word can be added , all words of length prefix appear in and thus appears in as a factor at a modulo position times . so there are words of length suffix that appear in at a modulo position , which contradicts the definition of the multi - shift de bruijn sequence . therefore , furthermore , word appears in as a factor at a modulo position times and thus all words in appear in as a factor at a modulo position . by the algorithm , no word of length can appear twice in at a modulo position . so , in order to prove the correctness of the algorithm , it remains to show every word of length appears in as a factor at a modulo position . suppose a word does not appear in at a modulo position . then and the word does not appear in as a factor at a modulo position as well ; otherwise , there are appearance of in at a modulo position , which means appears in as a factor at a modulo position . repeat this procedure , none of the words , , , appears in as a factor at a modulo position . but for , we proved that appears in as a factor at a modulo position , a contradiction . therefore , every word of length appears at a modulo position . now , we use the algorithm to generate one -shift de bruijn sequence of order . starting from , since does not appear as a factor at a modulo position , we append to the current sequence . repeating this procedure and appending words , , , , , finally we obtain the word : if we circularly move the prefix to the end , the sequence generated by the second algorithm is the lexicographically largest -shift de bruijn sequence of order . the study of multi - shift de bruijn sequences is inspired by a problems of words , called the frobenius problem in a free monoid . given integers , such that , then there are only finitely many positive integers that can not be written as a non - negative integer linear combination of . the integer frobenius problem is to find the largest such integer , which is denoted by . for example , . if words , instead of integers , are given such that there are only finitely many words that can not be written as concatenation of words from the set , the frobenius problem in a free monoid is to find the longest such words . if all are of length either or , , there is an upper bound : the length of the longest word that can not be written as concatenation of words from the set is less than or equal to , where . furthermore , the upper bound is tight and the construction is based on the multi - shift de bruijn sequences . we denote the set of all words that can be written as concatenation of words in , including the empty word , by . there exists , , such that is finite and the longest words in constitute exactly the language , where is a -shift de bruijn sequence of order . for example , for any set of words such that is finite , the longest words in are of length less than or equal to . to construct to reach the upper bound , we first choose an anbitrary -shift de bruijn sequence of order as . then based on , we construct the set , , , , , , , , , , , , , , . we have and one of the longest words in of length exactly is given below : in this paper , we generalized the classic de bruijn sequence to a new multi - shift setting . a word is a -shift de bruijn sequence of order , if each word of length appears exactly once as a factor at a modulo position . an ordinary de bruijn sequence is a -shift de bruijn sequence . we showed the total number of distinct -shift de bruijn sequences of order is for and is for , where . this result generalizes the formula for the number of ordinary de bruijn sequences . here we use an ordinary word form ; if counting the sequences in a circular form , then the number is to be divided by . we provided two algorithms for generating a -shift de bruijn sequence of order . the first algorithm is to rearrange factors from two simpler multi - shift de bruijn sequences , where the order is a multiple of the shift . the second is the analogue of the `` prefer one '' algorithm ( for example , see ) for generating ordinary de bruijn sequence . the multi - shift de bruijn sequence has application in the frobenius problem in a free monoid by providing constructions of examples . it will be interesting to see that this generalized concept of the de bruijn sequence can help in other fields of theoretical computer science and discrete mathematics .", "summary": "a ( non - circular ) de bruijn sequence of order is a word such that every word of length appears exactly once in as a factor . in this paper , we generalize the concept to a multi - shift setting : a -shift de bruijn sequence of order is a word such that every word of length appears exactly once in as a factor that starts at an index for some integer . we show the number of the -shift de bruijn sequences of order is for and is for , where is the size of the alphabet . we provide two algorithms for generating a multi - shift de bruijn sequence . the multi - shift de bruijn sequence is important in solving the frobenius problem in a free monoid ."}
{"article": "information encoded in qubits can be used for reliable quantum communication or efficient quantum computing . this information is encoded in a quantum state which in the case of a qubit can be parameterized as |(,)= |0 + e^i |1 ; where and are basis vectors of the 2-dimensional space of the qubit and ; . qubits are very fragile , that is the state of a qubit can easily be changed by the influence of the environment or a random error . one ( very inefficient ) way to protect the quantum information encoded in a qubit is to measure it . help of an optimal measurement one can estimate the state of a qubit , average fidelity equal to 2/3 ( see below ) . in this way a quantum information is transformed into a classical information which can be stored , copied , and processed according the laws of classical physics arbitrarily high precision . however , in order to utilize the full potential of quantum information processing we have to keep the information in states of quantum systems , but then we are forced to face the problem of decoherence . recently it has been proposed that quantum information and quantum information processing can be stabilized via symmetrization . in particular , the qubit in an unknown state is entangled set of ( ancilla ) qubits in a specific reference state ( let us say ) so the symmetric state of qubits , |(|,0 ,0+|0,, ,0+ + |0,0 , ) , is generated . if we introduce a notation for completely symmetric states of qubits of them being in the state and of them in the state , then the state can be expressed in the simple form |(,|)= |n;0 + e^i| |n;1 where the parameters and are specified by the relations = ; and , while . we see that symmetric qubit state is isomorphic to a single qubit state . but in this case the information is spread among entangled qubits - the original quantum information is `` diluted '' . each of the qubits of the -qubit state is in the state . we define the average fidelity between the single state and the original qubit as = d(;)| j(,| ) |(;) where is the invariant measure on the state space of the original qubit ( i.e. we assume no prior knowledge about the pure state ) . for this fidelity we find the expression 0 = . we see that for the fidelity is equal to unity ( as it should , because in this case ) while in the limit we find . in fact in this limit density operators of individual qubits are approximately equal to . in other words , individually the qubits of the symmetric state in the large limit do not carry any information about the original single - qubit state . so how can we extract the information from the -qubit symmetric state ? the ideal possibility would be to have have a perfect universal disentangler which would perform a unitary transformation type of disentangling transformation . while the perfect transformation is impossible , there are a number of things we can do to concentrate the information from the -qubit state back into a single qubit . in principle , we have the following possibilities : * i ) * we can either optimally measure the qubit state and based on the information obtained prepare a single - qubit state . * ii ) * we can design a quantum disentangler which would perform a transformation as close as possible to the ideal disentangling . in this quantum scenario we have several options - the process of disentanglement can be input - state dependent . this means that states for some values of the parameters and will be disentangled better than for other values of these parameters . alternatively , we can construct a quantum device which disentangles all the state same fidelity . * iii ) * finally , we propose a probabilistic disentangler , such that when a specific projective measurement over an ancilla is performed at the output , the desired single - qubit state is generated . the probability of the outcome of the measurement in this case is state - dependent . in what follows we shall investigate all these possibilities . before proceeding we note that a different type of disentangler has been considered by terno and mor - . they considered two different operations . the first would take the state of a bipartite quantum system and transform it into a state that is just the product of the reduced density matrixes of the two subsystems . the second , which is a generalization of the first , would again start state of a bipartate quantum system , and map it into a separable state which has the same reduced density matrixes as the original state . they showed that while both of these processes are impossible in general , they can be realized for particular sets of input states . an approximate disentangler of the first type has been considered by bandyopadhyay , et . al . . the disentanglers we are considering extract , to some degree of approximation , an unknown state from an entangled state formed from that state and a known state . here we first describe a measurement scenario utilizing a set of specific projection operators . then we present the optimal measurement - based approach to quantum disentanglement and we derive an upper bound on the fidelity of the measurement - based disentangler . we utilize the fact that the qubit system prepared in the state is isomorphic to a single qubit . therefore we first consider a strategy based on a a projective measurement projectors | 0(,)&= & and , where the angles and are chosen randomly if no prior information about the measured -qubit state is available . we can use the result of the measurement to manufacture a a single - qubit state . specifically , if the result of the measurement is positive for then the single qubit is prepared in the state then the single qubit is prepared in the orthogonal state . for a particular orientation of the measurement apparatus ( i.e. the angles ) this measurement - based scenario gives us a single qubit prepared in the state described by the density operator ^(meas ) ( , |;,)= j=0 ^ 1 || j|^2 | j j| after we average over all possible orientations of the measurement apparatus we obtain on average a single qubit prepared in the state ^(est ) ( , |)= |(,|)(,|)| + . to find the average fidelity of this measurement - based disentangling procedure we have to evaluate the mean fidelity , that is the overlap between the state and the original input state averaged over all possible orientations of the input qubit : 1 = d (,)|^(est ) ( , |)| ( , ) . taking into account the relation we perform the integration in eq. and we find 1 = ( 1+f n ) where the function reads f n= . for : which is the optimal fidelity of estimation of the state of a single qubit . from fig . we see that the fidelity is a decreasing function of and in the limit we find , which is equal to the fidelity of a random guess associated binary system such as the two projectors under consideration . in other words , when the original qubit is diluted into an infinite qubit state of the form no relevant information can be gained from the measurement . the estimated density operator in this case is simply equal to , which is understandable , because as we have shown earlier in this limit the -qubit state is approximately in the state , so information about the original is `` almost '' totally lost . we now want to find an upper bound for the average fidelity which can be achieved by a wide class of measurement - based disentanglement procedures . we assume that it is a priori known that our -qubit is prepared in the symmetric state unknown parameters and associated single - qubit state . the integration measure on the state space of the single qubit is and the corresponding prior probability density distribution on this state space is constant . our strategy is to measure the input state along the vector ) ] , where the angles and are chosen according to the distribution , which will be left unspecified for the moment . if the answer is positive , we produce the output density matrix , and if it is negative we produce , where and given by eq . . we shall also leave the conditional probabilities , unspecified , as this allows us to consider a wide range of strategies . for a fixed , the probability of the output being is and the probability of it being is . averaging over all vectors , gives us ^(out)(,| ) & = & d^ q(^ , ^ ) . in order to find the average fidelity of the output produced by this procedure , we compute the fidelity for a particular input state and average over the input ensemble where is a function of ) ] . this can be expressed as where is a normalized joint probability distribution , and where and the supremum is taken over the variables . we then have that , \\ ] ] where the supremum is now taken over and . in order to calculate this upper bound we must find explicit expressions for and . after performing the necessary calculations we find for the expression ^max= . this fidelity for is equal to 2/3 while in the limit is equal to 1/2 . for any other is larger than the fidelity of the measurement given by eq. as discussed in our previous example . nevertheless , as we will show later it is alway smaller than the fidelity of the universal quantum device . in what follows we show that a quantum disentangler which preserves quantum coherences can distill the information back to a single qubit more efficiently than can the measurement - based method . as we have already said in the introduction quantum mechanics does not allow one to construct a perfect disentangler which would perform transformation for an arbitrary ( unknown ) state diluted in the qubit symmetric state . nevertheless , we can try to design optimal disentanglers which perform best under given constraints . so let us assume our quantum disentangler , , is a quantum system -dimensional hilbert space spanned by basis vectors . the disentangler is always initially prepared in the state , and then it interacts -qubit system in the state . at the output we want to disentangle the ancilla qubits from the original qubit , so we expect to have |(,|)|d 0|n-1;0 k=1^k j=0 ^ 1 c j(,| ) |j|d k . as seen from eq. during the disentanglement process the entanglement between the ancilla qubits and the original qubit is transferred ( swapped ) into the entanglement between the original qubit and the disentangler itself . by tracing over the disentangler we then expect to obtain the best possible disentangled qubit in the state . now we impose several constraints which would specify what we mean by the optimal covariant ( universal ) disentangler : the fidelity between the output of the disentangler and the original state has to be invariant respect to rotations of the original qubit , so the fidelity has to be input - state independent . this universality of the disentangler would then guarantee that the information from the symmetric state is extracted for all states equally well . we are looking for the optimal disentangler which would disentangle the information highest fidelity . imposing these two conditions we have found the unitary transformation which realizes the optimal covariant disentangler , i.e. which disentangle the qubit - state from the -qubit state in the optimal and the -state independent way ( see appendix ) . this disentangler is described by the transformation : |n;0|d 0 & & |n-1;0 ; + basis vectors of the disentangler . the amplitudes and given by the relation n=^1/2 ; n=. we can directly verify , that the fidelity is input - state independent and equal to . moreover , it can be shown that the transformation is optimal , i.e. among all unitary transformations satisfying the given conditions the transformation has the largest fidelity . we see that for the fidelity , which is obvious , because the original qubit has not been entangled ancilla qubits . we plot in fig . we see , that it is always larger than the fidelity of the disentanglement via measurement . in the limit even the quantum disentangler gives us a totally random outcome . so in this limit , even optimal quantum entangler on which we impose the universality condition , is not able to extract information from the state . this is one of the main results of our paper - the optimal covariant quantum disentangler operates better than if the information is extracted ( disentangled , distilled ) from the symmetrized state help the of optimal measurement . this is due to the fact that . one can also ask the opposite question , how can we generate out of a qubit in an unknown state the symmetric state of the form . it can be shown that within quantum mechanics perfect universal entanglers , which would realize the inverse of the relation do not exist . if one wants to create a state from a qubit in an unknown state and ancilla qubits in the known state again two scenarios are possible , the measurement - based and quantum scenarios . it is not surprising that the quantum scenario works better . we have found the optimal universal ( covariant respect to rotations of the input qubit ) quantum entangler given by the transformations : |0|n-1;0|e 0 & & ; + basis states of the quantum entangler , is its initial state and the parameters and are given by eq. . one can check that the fidelity between the output of this entangler described by the density operator and the ideally entangled state is input - state independent ( i.e. does not depend on the parameters ) and is equal to . this is the best possible universal ( covariant ) entangler . the universal disentangler gives a higher fidelity than does the best measurement - based procedure , but it is not obvious that this is the best that one can do . in the case of quantum cloning , the universal cloners are the ones which maximize the average fidelity . as we shall see , however , in the case of disentanglers this is no longer the case ; there are state - dependent devices which are better . consider the general disentangler transformation , are states of the disentangler itself and need not be orthogonal . they must , however , satisfy the constraints imposed by the unitarity of the above transformation . the input state for the device is assumed to be , and the ideal output state , to which the actual output should be compared , is . the output state is calculated by starting input state , using the above transformation , and then tracing over the disentangler to obtain an output density matrix , . one then finds the average fidelity for this process , which we shall call , from note that we are assuming a specific ensemble of input states ; the probability of the one - qubit state is assumed to be constant on the bloch sphere . our result for the average fidelity for a state - dependent device depends on our choice of input ensemble , while for a state - independent device the average fidelity is independent of this ensemble . the calculation of the average fidelity is given in the appendix , and will not be given in detail . we find that and . this implies that the final state is just a product of the state of the particles and the entangler state , which means that the entangler states can be dropped from the problem . therefore , the transformation which maximizes the average fidelity is just a kind of state swapping transformation . the average fidelity itself is given by , where the coefficient is given by eq. . this average fidelity is larger than the fidelity of the optimal universal disentangler ( see fig . ) . in this case , the fact that the universality condition forces us to use an additional quantum device , the disentangler , which the qubit at the output becomes partially entangled , results in a net loss of information . as a result the fidelity of the universal ( covariant ) entangler is smaller . analogously , we find that quantum state - dependent entanglement can also be performed by a kind of state swapping transformation , i.e. |(,)|n;0|0 . nevertheless , when averaged over all values of we find the mean fidelity of this state - dependent entangler to be equal to which on average is larger than the fidelity of the state - independent entangler . let us examine a simple quantum network which takes as an input the -qubit state . the network is composed of a sequence of c - not gates where is the c - not being the control bit and being the target bit . this sequence of the c - not gates acts on the two vectors and as p n|n;0 & & |n-1;0|0 + p n |n;1 & & ( |n-1;1+|n-1;0 ) |1from which it follows that the input vector is transformed as |(,| ) & & ( |v +| ( , ) + & & + |v -|0 ) where is the normalization constant . in eq. we have introduced two orthogonal vectors of qubits . measurement on the first qubits is performed in order to determine whether they are in the state or . if the result is obtained , then the th qubit is in the desired state . the probability of this outcome is given by p |v += . this probability is input - state - dependent , and it decreases . there is a difference between this probabilistic process and those considered previously , such as probabilistic cloning . those only work for set of input states which is finite . the process considered above , however , works for a continuous , and hence infinite , set of input states . it , in fact , works for all input states of the type we are considering . therefore , we can conclude that the range of applicability of probabilistic devices depends on the process being considered . we have considered a number of different methods of extracting an unknown state from an entangled state formed from that state and a known state . measuring the state is , as expected , the least effective method . in the case of quantum devices , the universal device was not best one , at least if average fidelity is used as the criterion . probabilistic quantum devices were seen to work very well for this operation in that they can be used for the entire set of input states .", "summary": "it is not possible to disentangle a qubit in an unknown state from a set of ancilla qubits prepared in a specific reference state . that is , it is not possible to perfectly perform the transformation . the question is then how well we can do ? we consider a number of different methods of extracting an unknown state from an entangled state formed from that qubit and a set of ancilla qubits in an known state . measuring the whole system is , as expected , the least effective method . we present various quantum `` devices '' which disentangle the unknown qubit from the set of ancilla qubits . in particular , we present the optimal universal disentangler which disentangles the unknown qubit fidelity which does not depend on the state of the qubit , and a probabilistic disentangler which performs the perfect disentangling transformation , but probability less than one . * pacs number : 03.67.-a , 03.65.bz * 2"}
{"article": "in the past decade many neutrino oscillation results have been presented by different collaborations , and a phenomenological extension of the standard model has been proposed that involves three neutrino mass states , over which the three flavors of neutrinos are distributed . despite its successful predictions , this can be considered as an extension of the standard model that does not address fundamental questions , e.g. , small masses and large mixing angles compared to quark sector , and has raised a large debate over other possible unexpected properties of neutrinos that could lead to a more complete understanding of neutrino physics . to gain a deeper understanding of neutrino phenomenology the reduction of uncertainties in baseline neutrino oscillation experiments is mandatory . because of the interest in oscillation measurements , in recent years various neutrino - nucleus differential cross sections have been presented and are planned in the near future . differential cross sections are important to obtain a complete kinematical determination of neutrino - nucleus scattering and a clear understanding of neutrino - nucleus reactions is crucial for the analysis of experimental measurements . the argoneut collaboration has recently reported a measurement of the muon neutrino charged - current ( cc ) flux - averaged differential cross section on ar in an energy range up to . a liquid argon detector is very interesting because it has excellent potentialities to make precise measurements of a very large class of neutrino interactions from the energy scale to multi - events . the argoneut measurement has proven the validity of this experimental technique and , hoperfully , new data will be available in the future . for instance , a calculation of neutrino capture cross sections for solar neutrinos that could be addressed by this new generation of detectors is presented in . the energy region considered in the argoneut experiment , average neutrino energy of , requires the use of a relativistic model , where not only relativistic kinematics is considered , but also nuclear dynamics and current operators are described within a relativistic framework . the first measurement of the charged - current quasielastic ( ccqe ) flux - averaged double - differential muon neutrino cross section on c by the miniboone collaboration has raised extensive discussions . in particular , the experimental cross section is usually underestimated by the relativistic fermi gas model and by other more sophisticated models based on the impulse approximation , unless the nucleon axial mass is significantly enlarged respect to the world average value of 1./ . it is reasonable to assume that the larger axial mass obtained from the miniboone data on c can be interpreted as an effective way to include medium effects that are not taken into account by the models ; this is another indication that a precise knowledge of lepton - nucleus cross sections , where uncertainties on nuclear effects are reduced as much as possible , is necessary . moreover , any model aimed to describe neutrino - nucles scattering should first be tested against electron scattering data in the same kinematic region . at intermediate energy , quasielastic ( qe ) electron scattering calculations , which were able to successfully describe a wide number of experimental data , can provide a useful tool to study neutrino - induced processes . there are , however , indications that the reaction can have significant contributions from effects beyond the impulse approximation ( ia ) in some energy regions where the neutrino flux has still significant strength . for instance , in the models of the contribution of multinucleon excitations to ccqe scattering has been found sizable and able to bring the theory in agreement experimental miniboone cross sections without increasing the value of . the role of processes involving two - body currents compared to the ia models has been discussed in . a careful evaluation of all nuclear effects and of the relevance of multinucleon emission and of some non - nucleonic contributions would be , without a doubt , useful for a deeper understanding of the reaction dynamics . the relevance of final state interactions ( fsi ) has been clearly stated for the exclusive reaction , where the use of a complex optical potential ( op ) in the distorted - wave impulse approximation ( dwia ) is required . the imaginary part of the op produces an absorption that reduces the cross section and accounts for the loss of part of the incident flux in the elastically scattered beam to the inelastic channels which are open . in the inclusive scattering only the emitted lepton is detected , the final nuclear state is not determined and all elastic and inelastic channels contribute . thus , a different treatment of fsi is required , where all final - state channels are retained and the total flux , although redistributed among all possible channels , is conserved . different approaches have been used to describe fsi in relativistic calculations for the inclusive qe electron- and neutrino - nucleus scattering . in the relativistic plane - wave impulse approximation ( rpwia ) , fsi are simply neglected . in other approaches fsi are included in dwia calculations where the final nucleon state is evaluated real potentials , either retaining only the real part of the relativistic energy - dependent complex optical potential ( rrop ) , or using the same relativistic mean field potential considered in describing the initial nucleon state ( rmf ) . although conserving the flux , the rrop is unsatisfactory from a theoretical point of view . on the contrary , the rmf , where the same strong energy - independent real potential is used for both bound and scattering states , fulfills the dispersion relations and also the continuity equation . in a different description of fsi relativistic green s function ( rgf ) techniques are used . in the rgf model , under suitable approximations , which are basically related to the ia , the components of the nuclear response are written in terms of the single particle optical model green s function ; its spectral representation , that is based on a biorthogonal expansion in terms of a non - hermitian optical potential and of its hermitian conjugate , can be exploited to avoid the explicit calculation of the single particle green s function and obtain the components of the hadron tensor . calculations require matrix elements of the same type as the dwia ones of the exclusive process in , but involve eigenfunctions of both and , where the imaginary part has an opposite sign and gives in one case a loss and in the other case a gain of strength . the rgf formalism allows us to reconstruct the flux lost into nonelastic channels in the case of the inclusive response starting from the complex optical potential which describes elastic nucleon - nucleus scattering data and to include contributions which are not included in the rmf and in other models based on the ia . moreover , use of the same complex optical potential , it provides a consistent treatment of fsi in the exclusive and in the inclusive scattering . in addition , because of the analyticity properties of the optical potential , it fulfills the coulomb sum rule . these different descriptions of fsi have been compared in for the inclusive qe electron scattering , in for the ccqe neutrino scattering , and in ccqe and nce miniboone data . both rmf and rgf are able to describe the shape of the ccqe experimental data , only the rgf gives cross sections of the same magnitude as the experimental ones without the need to increase the value of . similar results are obtained in , where the rgf results and their interpretation in comparison nce data from miniboone are discussed . in this paper the results of different relativistic descriptions of fsi for cc -nucleus scattering are presented and discussed for the differential cross section averaged over the argoneut flux . we are aware of the interpretative questions that may be connected to the use of models developed for the qe regime in a kinematic situation , argoneut flux up to , where other processes beyond the ia , which are not included in the models considered here , can give significant contributions . nevertheless we believe that our calculations can give useful information about the role of nuclear effects in the analysis of ar scattering and about the uncertainties which are related to their evaluation . for the reaction ar as a function of the muon scattering angle . the data are from argoneut . , title=\"fig : \" ] -0.2 cm for the reaction ar as a function of the muon momentum . the data are from argoneut . , title=\"fig : \" ] -0.2 cm and on ar calculated in rpwia . the data are from argoneut . , title=\"fig : \" ] + and on ar calculated in rpwia . the data are from argoneut . , title=\"fig : \" ] -0.2 cm but in rmf . , title=\"fig : \" ] + but in rmf . , title=\"fig : \" ] -0.2 cm in all the calculations presented in this work the bound nucleon states are taken as self - consistent dirac - hartree solutions derived within a relativistic mean field approach using a lagrangian containing , , and mesons , medium dependent parameterizations of the meson - nucleon vertices that can be more directly related to the underlying microscopic description of nuclear interactions . the same relativistic mean field approach has been used to calculate the bound state wave functions in , where the cross sections of the exclusive quasi - free and inclusive qe reactions have been presented and discussed for oxygen and calcium isotopic chains . in the rgf calculations we have used three parameterizations for the relativistic op of ar : the energy - dependent and a - dependent edad1 ( where the represents the energy and the the atomic number ) op of and the more recent democratic ( dem ) and the undemocratic ( undem ) phenomenological ops of . we note that all these three parameterizations are global ones , since they are obtained through a fit to elastic proton - scattering data on a wide range of nuclei and , as such , they depend on the atomic number and are not constructed to reproduce the ar phenomenology . in fig . the cc differential cross section integrated over the argoneut flux is shown as a function of the muon scattering angle . all the calculations give results in reasonable agreement experimental shape but generally underpredict the magnitude of the experimental cross section . we note that in the rpwia fsi are completely neglected , while in the rmf the same strong energy - independent real potential is used for bound and scattering states . the comparison between the rgf results obtained edad1 , dem , and undem potentials can give an idea of how the predictions of the model are affected by uncertainties in the determination of the phenomenological op . the differences depend on the energy and momentum transfer and are essentially due to the different imaginary part of the three potentials , which accounts for the overall effects of inelastic channels and is not univocally determined from the elastic phenomenology . in contrast , the real term is similar for different parameterizations and gives similar results . we observe that the dem and undem potentials give in general close results ; in fact , even if they are obtained using very different fitting procedures , they are based on the same dataset of elastic - scattering data . in constrast , the edad1 potential produces somewhat smaller results and larger differences in comparison results of the dem and undem potentials : for instance , in the peak region deg , the rgf - dem and rgf - edad1 cross sections differ by about . the rgf cross sections are generally larger than the rpwia and the rmf ones , but they are in general significantly lower than the data , but for deg and deg . in the rgf the imaginary part of the optical potential redistributes the flux in all the final - state channels and , in each channel , the flux lost towards other channels is compensated by the flux gained from the other channels . the larger cross sections in the rgf arise from the translation to the inclusive strength of the overall effects of inelastic channels which are not included in the other models such as , for instance , rescattering processes of the nucleon in its way out of the nucleus , non - nucleonic excitations which may arise during nucleon propagation , or also some multinucleon processes . these contributions are not included explicitly in the rgf , but they can be recovered , to some extent , by the imaginary part of the phenomenological op . we note that in all the calculations presented in this work we have used the standard value of the axial mass . a larger value of would increase the cross section and improve the agreement . in fig . the cc differential cross section integrated over the argoneut flux is shown as a function of the muon momentum . also in this case the rpwia and the rmf results are lower than the experimental data , while the rgf produces larger cross sections which are in better agreement . anyway , the first two measurements in the low energy bins of are underestimated by all the results by a factor of . all the models which have been adopted for the present calculations are based on the ia , where the cross section is given by an incoherent sum of interactions between the incident neutrino and all the single nucleons of the nucleus . also the rgf , which is a more complex model and , use of the complex op , is able to recover contributions of channels which are not included in the other models , is essentially based on the ia . models based on ia have been successful in the description of qe exclusive and inclusive electron scattering . moreover , the rgf is able to give a reasonable description of ccqe and nce miniboone cross sections . in the inclusive cc neutrino - nucleus scattering at energies larger than a few gevs , however , all these models may neglect important contributions of reaction processes which can be included in the experimental cross sections . it is therefore not surprising that the calculated cross sections in figs . and are generally lower than the experimental data . but in rgf - dem . , title=\"fig : \" ] + but in rgf - dem . , title=\"fig : \" ] -0.2 cm aim to give a more quantitative information we have tried to estimate the uncertainties of our calculations . the most obvious source of uncertainty is the neutrino flux : it is usually known sufficient precision but its errors are not negligible . for energies up to the argoneut flux is given in bins of resolution of or and , for each bin , we compute an averagecross section starting from five or more calculations at different energies . it is straightforward to assume that this procedure introduces additional uncertainties in our results . in figs . and we show our results for the and differential cross section in rpwia and in rmf . the bands in the figures represent these two errors added in quadrature . in the interval of and covered by the argoneut kinematics the two errors are generally small and neither the rpwia nor the rmf cross sections can reproduce the experimental data within the error bands . this is a reasonable result since the rpwia and rmf cross sections in each bin are stable and the uncertainties on the neutrino flux are generally small . in the case of the rgf we consider two additional sources of errors . the rgf results presented here contain the contribution of both terms of the hadron tensor in eq . ( 25 ) of . the calculation of the second term , which is entirely due to the imaginary part of the op , is a hard and time consuming numerical task which requires the integration over all the eigenfunctions of the continuum spectrum of the optical potential . numerical uncertainties on this term are anyhow under control and , from many calculations in different kinematics , have been estimated at most within . the fact that in actual rgf calculations we have to use a phenomenological energy dependent op introduces additional complications . the ops in have been tested for energies up to and to provide results up to we have to extend the range of validity of these parameterizations . this has been done multiplying each term of the op by a realistic function of the energy that has been chosen to carefully reproduce the behavior of the op around . we have checked that our results do not depend significantly on the multiplying function . the rgf - dem and differential cross sections are shown in fig . , where the error bands represent all the uncertainties that we have considered added in quadrature . similar results similar uncertainties are obtained in the case of rgf - undem and rgf - edad1 . the error bands for the rgf results are larger than for rpwia and rmf and , as a consequence , the upper limits of the rgf cross sections are closer to the data . this outcome can be ascribed to the moderately large uncertainties on the cross sections in each experimental bin of neutrino energy , in particular for neutrino energies of and small energy transferred to the nucleus . the large error bands in fig . do not allow us to draw any definite conclusion . however , the results presented in this work indicate that the rgf , as well as the other models based on the ia , generally underpredict argoneut data , but they are able to reproduce the shape and the correct order of magnitude of the experimental cross section . in this paper we have compared the predictions of different relativistic descriptions of fsi for cc neutrino - nucleus scattering in the argoneut kinematics . in the rpwia fsi are neglected ; in the rmf they are described using the same relativistic mean field potential considered in describing the initial nucleon state ; in the rgf the full complex op , real and imaginary parts , is used to account for fsi . all final - state channels are included in the rgf , the flux lost in each channel is recovered in the other channels by the imaginary part of the op making use of the dispersion relations and the total flux is conserved . the rgf gives a good description of the data in the qe region and it is also able to describe both ccqe and nce miniboone data . in the rgf cross sections the contribution of reaction channels that are neglected in the other models , e.g. , rescattering processes of the nucleon in its way out of the nucleus , non - nucleonic excitations , which may arise during nucleon propagation , without real pion production , or also multinucleon processes , is translated , to some extent , into the inclusive strength by the imaginary part of the phenomenological op . however , the role of the various reaction channels included in the phenomenological op , can not be disentangled and the enhancement of the cross section can not be attributed to a specific process . in order to clarify this point , a careful evaluation of all nuclear effects and of the relevance of multinucleon emission and of some non - nucleonic contributions , as well as a better determination of the relativistic op , which closely fulfills the dispersion relations , would reduce the theoretical uncertainties on the rgf . our results give a clear indication that ia - based models are able to reproduce the correct order of magnitude and the shape of the argoneut data but they generally underpredict the experimental cross sections , in particular for lower values of and for values of between deg and deg . a careful evaluation of all nuclear effects is required to recover some important contributions to the cc inclusive strenght . in particular , a careful study of medium effects in the few - energy region that takes into account quasielastic , inelastic , as well as deep - inelastic processes , is highly desirable . 89ifxundefined ifx#1 ifnum # 1firstoftwo secondoftwo ifx # 1firstoftwo secondoftwo `` `` # 1''''@noop secondoftwosanitize@url + 12$12 & 12#1212 12%12@startlink@endlink@bib@innerbibempty link:\\doibase 10.1103/physrevd.83.052010 link:\\doibase 10.1103/physrevlett.107.241801 link:\\doibase 10.1140/epjc / s10052 - 013 - 2345 - 6 @noop * * , @noop * * , @noop * * , link:\\doibase 10.1103/physrevlett.110.161801 link:\\doibase 10.1103/physrevd.85.032007 link:\\doibase 10.1103/physrevd.86.052009 link:\\doibase 10.1103/physrevlett.108.131801 link:\\doibase 10.1103/physrevlett.108.171803 link:\\doibase 10.1088/1674 - 1137/37/1/011001 link:\\doibase 10.1103/physrevlett.108.191802 link:\\doibase 10.1103/physrevd.74.072003 link:\\doibase 10.1103/physrevd.64.112007 link:\\doibase 10.1155/2013/163897 link:\\doibase 10.1155/2013/852987 link:\\doibase 10.1103/physrevd.85.083522 link:\\doibase 10.1103/physrevd.83.073006 http://stacks.iop.org/1475-7516/2011/i=09/a=034 link:\\doibase 10.1103/physrevd.70.073004 @noop * * , @noop * * , @noop , link:\\doibase 10.1103/physrevd.83.012005 link:\\doibase 10.1103/physrevlett.108.161802 miniboone , @noop minera , @noop t2k , @noop @noop , link:\\doibase 10.1103/physrevc.87.014607 link:\\doibase 10.1103/physrevlett.105.132301 link:\\doibase 10.1016/j.physletb.2011.07.032 link:\\doibase 10.1103/physrevc.82.055501 link:\\doibase 10.1103/physrevc.84.015501 @noop * * , link:\\doibase 10.1016/0370 - 1573(93)90132-w @noop , , vol . ( , , ) link:\\doibase 10.1103/physrevc.80.065501 link:\\doibase 10.1103/physrevc.81.045502 link:\\doibase 10.1103/physrevc.84.055502 link:\\doibase 10.1103/physrevc.83.045501 link:\\doibase 10.1016/j.physletb.2011.11.061 link:\\doibase 10.1016/j.physletb.2013.03.002 link:\\doibase 10.1016/j.physletb.2010.12.007 link:\\doibase 10.1103/physrevd.84.033004 link:\\doibase 10.1103/physrevlett.108.152501 link:\\doibase 10.1140/epjc / s10052 - 011 - 1726-y @noop , link:\\doibase 10.1103/physrevc.79.034601 link:\\doibase 10.1103/physrevc.81.064614 link:\\doibase 10.1103/physrevc.83.054616 link:\\doibase 10.1016/j.physletb.2011.02.043 link:\\doibase 10.1103/physrevc.48.2731 link:\\doibase 10.1103/physrevc.64.014604 link:\\doibase 10.1103/physrevc.64.064615 link:\\doibase 10.1103/physrevc.65.044601 link:\\doibase 10.1140/epja / i2002 - 10137 - 2 link:\\doibase 10.1103/physrevc.84.024615 link:\\doibase 10.1103/physrevc.68.048501 link:\\doibase 10.1103/physrevc.74.015502 link:\\doibase 10.1016/j.physletb.2010.03.078 link:\\doibase 10.1016/j.nuclphysa.2004.04.108 link:\\doibase 10.1103/physrevc.67.054601 link:\\doibase 10.1016/j.nuclphysa.2004.08.023 http://th-www.if.uj.edu.pl/acta/vol37/pdf/v37p2279.pdf link:\\doibase 10.1016/j.nuclphysa.2006.05.005 link:\\doibase 10.1103/physrevc.77.034606 @noop * * , link:\\doibase 10.1103/physrevc.80.024605 link:\\doibase 10.1103/physrevc.83.064614 link:\\doibase 10.1051/epjconf/20123814004 @noop * * , link:\\doibase 10.1016/0375 - 9474(91)90269-c link:\\doibase 10.1016/j.aop.2004.12.005 link:\\doibase 10.1016/j.nuclphysa.2005.04.007 @noop * * , @noop , link:\\doibase 10.1103/physrevlett.107.172501 link:\\doibase 10.1103/physrevd.85.093002 link:\\doibase 10.1103/physrevd.84.113003 @noop * * , link:\\doibase 10.1016/j.nuclphysa.2004.02.001 `` , '' in link:\\doibase 10.1142/9789812701985 0005 , ( , , ) chap . , link:\\doibase 10.1016/j.nuclphysa.2006.02.007 link:\\doibase 10.1103/physrevc.85.024322 link:\\doibase 10.1088/1742 - 6596/366/1/012019 link:\\doibase 10.1103/physrevc.47.297 link:\\doibase 10.1103/physrevc.80.034605", "summary": "the analysis of the recent charged - current neutrino - nucleus scattering cross sections measured by the argoneut collaboration requires relativistic theoretical descriptions also accounting for the role of final - state interactions . in this work , we evaluate differential neutrino - nucleus cross sections relativistic green s function model , where final - state interactions are described in the inclusive scattering consistently exclusive scattering using a complex optical potential . the sensitivity to the parameterization adopted for the phenomenological optical potential is discussed . the predictions of the relativistic green s function model are compared results of different descriptions of final - state interactions ."}
{"article": "as in our previous analysis of run 1a data , we conduct a general search for new particles narrow natural width that decay to dijets . in addition , we search for the following particles summarized in fig . : axigluons from chiral qcd , excited states of composite quarks , color octet technirhos , new gauge bosons ( , ) , and scalar diquarks ( and ) . using four triggers from run 1a and 1b , we combine dijet mass spectra above a mass of / c , / c , / c , and / c integrated luminosities of = 7.5 in = 3.3 in = 3.3 in .089 pb , 1.92 pb , 9.52 pb , and 69.8 pb respectively . jets are defined fixed cone clustering algorithm ( r=0.7 ) and then corrected for detector response , energy lost outside the cone , and underlying event . we take the two highest jets and require that they have pseudorapidity and a cms scattering angle | < 2/3 $ ] . the cut provides uniform acceptance as a function of mass and reduces the qcd background which peaks at . in fig . the dijet mass distribution is presented as a differential cross section in bins of the mass resolution ( % ) . at high mass the data is systematically higher than a prediction from pythia plus a cdf detector simulation , similar to the inclusive jet spectrum . to search for new particles we determine the qcd background by fitting the data to a smooth function of three parameters ; fig . shows the fractional difference between the data and the fit . we note upward fluctuations near / c , / c and / c . for narrow resonances it is sufficient to determine the mass resolution for only one type of new particle because the detector resolution dominates the width . in fig . we show the mass resolution for excited quarks ( q * ) from pythia plus a cdf detector simulation ; the long tail at low mass comes from gluon radiation . for each value of new particle mass in / c steps , we perform a binned maximum likelihood fit of the data to the background parameterization and the mass resonance shape . in fig . we display the best fit and 95% confidence level upper limit for a / c resonance . for the mass region / c , there are 2947 events in the data , events in the background for the fit without a resonance , events in the background for the fit that includes the resonance , and the value of the resonance cross section from the fit is pb ( statistical ) . in fig . we study the angular distribution of the fluctuation in the mass region / c . the angular distribution is compatible both qcd alone , and = 3.3 in = 3.3 in qcd + 5% excited quark ( best fit ) . this amount of excited quark is coincidentally the same as found in the mass fit . although the fluctuation is interesting , we conclude it is not yet = 3.3 in = 3.3 in statistically significant , and proceed to set limits on new particle production . = 3.3 in = 3.3 in from the likelihood distribution including experimental systematic uncertainties we obtain the 95% cl upper limit on the cross section for new particles shown in fig . . we compare this to the cross section for axigluons ( excluding / c ) , excited quarks ( excluding / c ) , technirhos ( excluding / c ) , w ( excluding / c ) , z ( excluding / c ) , and e6 diquarks ( excluding / c ) . the calculations are lowest order using cteq2l parton distributions and one - loop and require and . the large mass of the top quark suggests that the third generation may be special . topcolor assumes that the top mass is large mainly because of a dynamical condensate generated by a new strong dynamics coupling to the third generation . here the of qcd is a low energy symmetry arising from the breaking of an coupling to the third generation and an coupling to the first two generations only . there are then massive color octet bosons , topgluons , which couple largely to and . the topgluon is strongly produced and decays mainly to the third generation relatively large natural width . here we search for the topgluon in the channel . an additional symmetry is introduced to keep the quark light while the top quark is heavy ; this leads to a topcolor , which again couples largely to and . the topcolor is electroweakly produced and decays mainly to the third generation narrow natural width . here we search for the topcolor in both the the and channel ; the channel is the most sensitive because the coupling to is larger . we start dijet search in 19 pb of run 1a data and additionally require at least one of the two leading jets be tagged as a bottom quark . the b - tag requires a displaced vertex in the the secondary vertex detector . the event efficiency is % independent of dijet mass . from fits to the distribution , we estimate that the sample is roughly 50% bottom , 30% charm , and 20% mistags of plain jets . pythia predicts that 1/5 of these bottom quarks are direct , and the rest are from gluon splitting and flavor excitation . consequentially , only about % 10% of our sample is direct . we expect both the purity and efficiency to increase when we use the run 1b dataset and a new tagging algorithm . higher tagging efficiency we should be able to make better use of double b - tagged events like the one in fig . . = 2.6 in = 2.6 in in fig . we show the b - tagged dijet mass distribution corrected for the efficiency . also shown is the untagged dijet mass distribution from run 1a , and both are well fit standard parameterization . the b - tagged dijet data has an upward fluctuation near / c . we model the shape of a narrow resonance using pythia z production and a cdf detector simulation . in fig . we fit the b - tagged data to a / c narrow resonance , and find a cross section of pb ( statistical ) . note that this is comparable to the dijet fluctuation in both mass and rate . however , there are only 8 events in the last two data bins of fig . , and the fluctuation is only a effect , so we proceed to set limits on new particle production . we perform two kinds of fits for the limits . first , narrow resonances are modelled as described above , and the mass resolution in the cdf detector is shown in fig . . second , wide resonances characteristic of topgluons , including interference normal gluons , was incorporated into pythia and a cdf detector simulation . the mass resolution in fig . displays destructive interference to the left of the resonance ; models destructive interference on the right side of the resonance will be considered in the future . = 3.2 in = 3.2 in limits on new particle production are shown in fig . . the theoretical cross sections are lowest order and use cteq2l parton distributions . for narrow resonances the production cross sections are nt large enough for us to set mass limits at this time . for topgluons the production cross sections are larger , and we are able to exclude at 95% cl topgluons of width in the mass region / c , for / c , and for / c . = 3.0 in = 3.0 in = 7.7 in to search for new particles decaying to we start sample from the top mass measurement . there we used top decays to w + four jets least one b - tag , and found 19 events on a background of , resulting in a top mass of (stat)(sys ) / c . that analysis fit the entire event for the top hypothesis , discarding events ( poor fit ) . here we add the additional constraint that the top mass is / c , which significantly enhances our resolution of the mass . two of the 19 events fail the cut when the top mass constraint is added to the fit , leaving us 17 events . the mass distribution expected from a narrow resonance , normalized to the topcolor predicted rate , is shown in fig . . here we used pythia . also in fig . is the monte carlo distribution of the background , on the left standard model top production from herwig , and on the right qcd w + jets background from vecbos parton showers from herwig . all monte carlos include a cdf detector simulation . on the left in fig . , the comparison of the topcolor z to sm simulations illustrates that in this data sample we are sensitive to topcolor up to a mass of roughly / c . finally , on the right in fig . , we present the candidate mass distribution from cdf compared to the total standard model prediction . given the statistics the agreement is quite good overall . the small shoulder of 6 events on a background of in the region / c is in an interesting mass region , given the dijet and search results , but is not statistically significant . upper limits on the cross section as a function of mass , and on a topcolor , are currently in progress . = 3.1 in = 3.1 in we have searched for new particles decaying to dijets , , and . in the dijet channel we set the most significant direct mass exclusions to date on the hadronic decays of axigluons ( excluding / c ) , excited quarks ( excluding / c ) , technirhos ( excluding / c ) , w ( excluding / c ) , z ( excluding / c ) , and for the first time e6 diquarks ( excluding / c ) . in the channel we set the first limits on topcolor , excluding a model of topgluons for width in the mass region / c , for / c , and for / c . the search for topcolor in the channel has just begun and limits are in progress . limits are only a consolation prize ; the main emphasis of our search is to explore the possibility of a signal . although we do not have significant evidence for new particle production , the / c region shows upward fluctuations in all three channels . we can not ignore the exciting possibility that these apparently separate fluctuations may be the first signs of a new physics beyond the standard model . the remaining integrated luminosity for run 1b , currently being accumulated and analyzed , has the potential to either kill the fluctuations or reveal what may be the most interesting new physics in a generation . + f. abe et al . ( cdf ) , phys . lett . * 74 * , 3538 ( 1995 ) . p. frampton and s. glashow , phys . b190 * , 157 ( 1987 ) . u. baur et al . , int . j. mod . phys a2 , 1285(1987 ) & pr*d42 * , 815(1990 ) . k. lane et al . , pr*d44 * , 2768(1991 ) & phys . lett . * b327 * , 129(1994 ) . j. hewett and t. rizzo , phys . rep . * 183 * , 193 ( 1989 ) . talk by anwar bhatti in these proceedings . parameterization parameters a , n and p. for new gauge bosons we use a k - factor to account for higher order terms . j. botts et al . ( cteq collaboration ) phys . lett . * b304 * , 159 ( 1993 ) . c. hill and s. parke , phys . rev . * d49 * , 4454 ( 1994 ) . c. hill , phys . b345 * , 483 ( 1994 ) . f. abe et al . ( cdf ) , phys . rev . * d50*,2966 ( 1994 ) . f. abe et al . ( cdf ) , phys . lett . * 74 * , 2626 ( 1995 ) . we model the interference between normal gluons and topgluons using hybrid model c in phys . rev . * d49 * , 4454 ( 1994 ) . g. burdman , c. hill , and s. parke private communication .", "summary": "we present three searches for new particles at cdf . first , using 70 pb of data we search the dijet mass spectrum for resonances . there is an upward fluctuation near / c ( 2.6 ) angular distribution that is adequately described by either qcd alone or qcd plus 5% signal . there is insufficient evidence to claim a signal , but we set the most stringent mass limits on the hadronic decays of axigluons , excited quarks , technirhos , w , z , and e6 diquarks . second , using 19 pb of data we search the b - tagged dijet mass spectrum for resonances . again , an upward fluctuation near / c ( 2 ) is not significant enough to claim a signal , so we set the first mass limits on topcolor bosons . finally , using 67 pb of data we search the top quark sample for resonances like a topcolor . other than an insignificant shoulder of 6 events on a background of 2.4 in the mass region 475 - / c , there is no evidence for new particle production . mass limits , currently in progress , should be sensitive to a topcolor z near / c . in all three searches there is insufficient evidence to claim new particle production , yet there is an exciting possibility that the upward fluctuations are the first signs of new physics beyond the standard model . fermilab - conf-95/152-e + cdf / pub / exotic / public/3192 + + * search for new particles decaying to dijets , + , and at cdf + * fermilab ms 318 + batavia , il 60510 +"}
{"article": "it is common accepted that braking of pulsars is caused by the magneto - dipole radiation of the rotating magnetic star . in this case the rate of losses of the neutron star rotation energy can be equated to the power of its magneto - dipole radiation : + where i is the moment of inertia of the neutron star , - the angular speed of its rotation , - its magnetic moment , - the angle between the rotation axis and the magnetic moment , c - speed of light . for standard parameters of neutron stars : masses of order of the solar mass and radii r of order of cm we can put i = . for the magnetic moment we have + here is the magnetic induction at the magnetic pole , ? the induction at the magnetic equator . instead of the rotation period is usually measured and we can obtain from ( 1 ) and ( 2 ) : + this equality is used usually to calculate magnetic inductions of pulsars assuming that for all objects . the known catalogs ( see , for example manchester et al . , 2005 ) contain as a rule instead of . here we propose to decline the assumption on the constancy of and use some estimations of this parameter to calculate more accurate values of pulsar magnetic inductions . in a number of our works ( malov & nikitina , 2011a , b , 2013 ) some methods for calculations of the angle have been put forward and applied to some catalogs of pulsars ( keith et al . , 2010 ; van ommen et al . , 1997 ; weltevrede & johnston , 2008 ) at approximately 10 , 20 and 30 cm . basic equations for this aim are ( manchester & taylor , 1977 ) : + here is the angle between the line of sight and the rotation axis , - the angular radius of the emission cone , - a half of the angular width of the observed pulse , - the position angle of the linear polarization , - longitude . the simplest case for the calculations of the angle is realized when the line of sight passes through the center of the emission cone , i.e. + in this case we can use the dependence of the observed pulse width at the level on the rotation period and determine the lower boundary in the corresponding diagram to obtain + as the result we have from ( 4 ) , ( 5 ) and ( 7 ) ( malov & nikitina , 2011a ) : + the values of angles calculated by this method are denoted as and given in the table 1 . usually polarization measurements are made inside the pulse longitudes only . in this case we can use the maximal derivative of the position angle . from ( 5 ) we have we can obtain from the dependence of on p by the least squares method + the third equation for the calculations of the angle is ( 4 ) . from these three equations we obtain y^2 + 2c(d - b^2)y+c^2d^2-b^2(1+c^2)=0.\\\\\\ ] ] + here + we can transform the equation ( 9 ) to the following form + then finding the value of y from the equation ( 11 ) we can calculate from ( 13 ) . we have calculated values of by this method and list them in the table 1 as . here we correct the misprint in the equation ( 11 ) made in our papers ( malov & nikitina , 2011a , b , 2013 ) . there is an additional way to calculate angles . this way uses observable values of position angles and shapes of average profiles for individual pulsars . in this case , original equations form the closed system for calculations of the angles , and : as the observed pulsar profiles have various forms , the coefficient n has a different value depending on a profile structure . we put arbitrary the following values of n ( fig.1 ) . if the ratio of the intensity in the center of the pulse to the maximal intensity is zero then . for , , , and for . it is worth noting that the solution of the system ( 14 ) can be obtained numerically for any value of n . for example , if , the solution for can be obtained from the equation : at n = 2 : y^4 + 2c \\left y^3 + \\left y^2 + 2c \\left y + c^2 d^2 ( 1 + c^2 ) - ( c^2 - 1)^2 = 0;\\\\ \\ ] ] at n = 3/2 : {}}{2 } } - c y^2 ( 1 - d ) - y - cd = 0;\\ ] ] at n = 5/4 : this method gives angles ( see the table 1 ) . for some pulsars calculations were made by one method only . when it was possible we used two or all three methods . in these cases , the mean value of the angle has been calculated . the resulting values are listed in the table 1 . some other authors ( for example , kuzmin & dagkesamanskaya , 1983 ; kuzmin et al . , 1984 ; lyne & manchester , 1988 ) carried out calculations of the angle earlier for the shorter samples of pulsars using some additional assumptions . we will use further our estimations to calculate magnetic inductions at the surface of the neutron stars . the distribution of the angles from the table 1 ( fig.2 ) shows that the majority of pulsars have rather small inclinations of the magnetic moments . these pulsars are old enough , and we can conclude that they evolve to the aligned geometry . the average characteristic age for our sample of pulsars is years . we must note however that the angles calculated by the method * 1 ) * are the lower limits of this parameter . this explains partly the predominance of the small values of . from the table 1.,width=453 ] .values of the angle ( deg ) . 1 . some methods for calculations of the angle between rotation and magnetic axes were applied to obtain the values of for 376 radio pulsars . the distribution of these values shows the predominance of small inclinations of the magnetic axes . 2 . magnetic inductions at the surface of 375 pulsars considered were calculated . there is no the measured derivative for the pulsar j1713 - 3949 and it is excluded from the consideration . the distribution of the calculated magnetic inductions can be described by the gaussian maximal value of and the width in the logarithmic scale nearly 1 . the calculated inductions are higher than the catalog equatorial inductions mean value of the ratio of these quantities of 5 . for the pulsar j1410 - 7404 . the maximal value of the ratio for the pulsar j2007 + 0809 . this work has been carried out financial support of basic research program of the presidium of the russian academy of sciences * transitional and explosive processes in astrophysics * ( p-41 ) . we thank a.v.biryukov for very useful comments and discussions . 99 keith m.j . , johnston s. , weltevrede p. and kramer m. , 2010 , mnras , 402 , 745 kuzmin a.d . , dagkesamanskaya i.m . , 1983 , soviet astron . letters , 9 , 80 kuzmin a.d . , dagkesamanskaya i.m . , pugachev v.d . , 1984 , soviet astron . letters , 10 , 357 lyne a.g . , manchester r.n . , 1988 , mnras , 243 , 477 manchester r.n . , taylor j.h . , 1977 , pulsars . w.h.freeman and company , san francisco manchester r.n . et al . , 2005 , j. , 129 , 1993 . malov i.f . , nikitina e.b . , 2011a , astron.rep . , 55 , 19 malov i.f . , nikitina e.b . , 2011b , astron.rep . , 55 , 878 malov i.f . , nikitina e.b , 2013 , astron.rep . , 57 , 833 van ommen t.d . et al . , 1997 , mnras , 287 , 1210 weltevrede p. , johnston s. , 2008 , mnras , 391 , 1210", "summary": "we used the magneto - dipole radiation mechanism for the braking of radio pulsars to calculate the new values of magnetic inductions at the surfaces of neutron stars . for this aim we estimated the angles between the rotation axis and the magnetic moment of the neutron star for 376 radio pulsars using three different methods . it was shown that there was the predominance of small inclinations of the magnetic axes . using the obtained values of the angle we calculated the equatorial magnetic inductions for pulsars considered . these inductions are several times higher as a rule than corresponding values in the known catalogs . * keywords * magnetic fields ; methods : data analysis ; methods : statistical ; ( stars : ) pulsars : general"}
{"article": "the exotic hydrogen like atoms are formed in highly excited states , when negative particles are stopped in hydrogen . the deexcitation of exotic atoms proceeds via many intermediate states until the ground state is reached or a nuclear reaction takes place . despite a long history of theoretical and experimental studies the kinetics of this atomic cascade is not yet fully understood . the present experiments exotic hydrogen - like atoms addresses a number of fundamental problems using precision spectroscopy methods , the success of which relies crucially on a better knowledge of the atomic cascade . the experimental data are mainly appropriate to the processes at the last stage of the atomic cascade ( x - ray yields and the products of the weak or strong interaction of the exotic particle in the low angular momentum states hydrogen isotopes ) . so the reliable theoretical backgrounds on the processes both in low - lying and in highly excited states are required for the detailed and proper analysis of the experimental data . in this paper we present the ab initio quantum - mechanical treatment of non - reactive scattering processes of the excited exotic hydrogen atom in collisions hydrogenic atom in the ground state : elastic scattering , stark transitions , and coulomb deexcitation ( cd ) . here are hydrogen isotopes and ; are the principal and orbital quantum numbers of exotic atom . while the deexcitation processes are obviously essential for the atomic cascade , the role of the collisional processes preserving the principal quantum number is also very important . the stark transitions affect the population of the sublevels and together elastic scattering they decelerate the exotic atoms thus influencing their energy distribution during the cascade . starting from the classical paper by leon and bethe , stark transitions has been treated in the semiclassical straight - line - trajectory approximation ( see and", "summary": "the scattering processes of exotic atoms in excited states from hydrogen such as elastic scattering , stark transitions and coulomb de - excitation are studied within a close coupling approach . the vacuum polarization and the strong interaction shifts of -states ( in case of hadronic atoms ) are taken into account . the differential and integral cross sections of the above processes are calculated to use them as the input in cascade calculations . the effect of closed channels on the scattering processes is investigated . * scattering processes of excited exotic atoms : close - coupling approach * + institute of nuclear physics , moscow state university , 119992 moscow , russia institution1"}
{"article": "studies of massive galaxy clusters and groups at typically find environments little - to - no star formation activity , in sharp contrast field . over - dense regions are dominated by red , passively - evolving s0 and elliptical galaxies , whereas more sparsely - populated regions tend to have galaxies spiral morphologies , younger stellar populations , and systematically higher star formation rates . an observed trend of increasing blue galaxy fraction redshift ( the butcher - oemler effect ; * ? ? ? * ) has been interpreted as evidence for higher star formation activity and stellar mass build - up in higher redshift clusters or alternatively , that star formation is quenched more recently by one or more processes in over - dense regions . several physical mechanisms can account for the quenching of star formation in over - dense regions ( for a review , see * ? ? ? galaxies in environments sufficiently low velocity dispersions can be strongly perturbed by mergers . galaxies can also be transformed more gradually by an ensemble of small perturbations neighbours , a process called harassment . tidal forces can strip away a galaxy s halo gas ( starvation ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) , cutting off a fuel source for future star formation and leading to a gradual decline in sf activity . in the high - density cores of massive clusters , the hot intra - cluster medium ( icm ) can quench star formation by removing gas from galaxies via ram - pressure stripping . the relative strengths of these physical mechanisms are strongly dependent on the cluster or group properties ( dynamical state , mass , and intra - cluster or intra - group medium ) and environment . targeted studies of galaxy clusters or groups at have revealed overwhelming evidence that galaxy transformation occurs not just in dense cluster cores , but at lower densities characteristic of cluster outskirts or galaxy groups . studies star formation tracers in the ir , uv , and optical emission - line measures have shown evidence of pre - processing , whereby infalling galaxies undergo changes prior to their arrival in the galaxy cluster , or galaxies are transformed entirely in the group environment . the pre - processing hypothesis has also been supported by studies of the environmental dependence on galaxy morphology and colour . numerical simulations have also been used to study the causes and implications of galaxy pre - processing . showed that the dominant physical processes galaxies are likely subjected to in group environments , specifically the frequent weak tidal interactions of harassment , are capable of transforming late - type , disk - dominated galaxies into bulge - dominated , early - types . furthermore , used simulations of dark matter halo merger trees , semi - analytic models ( sams ) to populate the haloes galaxies , and traced the histories of the simulated galaxies that ended up accreting onto cluster - mass haloes in different epochs . in doing so , determined what fraction of those cluster galaxies had resided in haloes characteristic of group - masses for a long enough time to have been pre - processed prior to entering the cluster . the results of their simulation showed that at low redshift a large fraction of cluster galaxies could have been affected by their environment prior to entering the cluster , while at earlier epochs the fraction of pre - processed galaxies in clusters should steadily decline . the fraction of cluster galaxies affected by pre - processing in the simulation depends on the assumed timescale for the physical process(es ) in group environments to affect galaxies , and also has a stellar mass dependence . although many assumptions go into this simulation , the result highlights a key point that the role of pre - processing has likely varied significantly over cosmic time , and that at pre - processing should be extremely prevalent . recent studies have suggested that the quenching of sf activity in cosmic history is primarily driven by two distinct , and possibly separable , components : secular evolution ( or ` mass quenching ' ) and environmentally - driven processes ( or environment quenching ; * ? ? ? * ; * ? ? ? . however , see also for a discussion about how history bias affects one s ability to disentangle mass- and environment - quenching . nevertheless , any attempt to examine the environmental dependence on galaxy evolution must include a careful account for the possibility that one s galaxy selection function has mass biases , particularly since the galaxy stellar mass function is known to vary environment . concerns about biases introduced by the galaxy selection function are compounded when examining galaxies over a wide range in redshift , as one s sensitivity , in galaxy mass and in other properties , like sfr , will undoubtedly also vary . as a result , in many of these studies that extend to higher- one must restrict one s sample to only massive galaxies high sfrs , and thereby have a less complete picture of the effects of environment on galaxy evolution . furthermore , studies extending to higher- tend to sample a smaller dynamic range of environments , which similarly reduces one s ability to draw general conclusions about environmentally - driven processes . a comprehensive view of galaxy evolution in different environments must be sensitive to a large dynamic range of local densities in order to capture not just the dense regions , like clusters and groups , but the more diffuse filament and void regimes . a key challenge faced when interpreting the many results examining galaxy evolution , in addition to the aforementioned sources of potential bias , is the wide range of methods employed to characterise environment . recently , used an array of different environmental mapping techniques , which could be roughly grouped into two categories : nearest - neighbour methods , which measure galaxy density aperture that changes depending on the local galaxy density , and fixed - aperture techniques , whose apertures do not vary , to examine a mock galaxy catalogue . found that these techniques can analyse the same data set and get different results , but that the nearest - neighbour methods appear to be optimal for mapping the density fields within massive haloes , while the fixed - aperture methods are better suited for probing superhalo distance scales . therefore , the technique that is optimal to identify large scale structures ( lss ) , like clusters , groups , and filaments , is not necessarily the best choice for measuring the density fields within those structures . in this work , we seek to quantify the role of pre - processing in the local universe by analysing the rest - frame colour and star - formation activity of galaxies as a function of environment over about three orders of magnitude in projected density in the coma supercluster . by focusing on a low- field , we ensure that our sample of galaxies , taken from the sloan digital sky survey ( sdss ; * ? ? ? * ) , is spectroscopically complete down to dwarf masses . furthermore , we do not have to rely on photometric redshift ( photo- ) measurements , which would introduce additional contamination due to interlopers in our sample and significant smearing along the line - of - sight . to map the environments of the supercluster , we employ two complementary techniques : voronoi tessellation ( vt ) and the minimal spanning tree ( mst ) . the former is a nearest - neighbour - based approach , which can measure the local density field effectively over the large dynamic range of densities that we find in the coma supercluster . the latter technique is most effective at characterising continuous structures , like clusters , groups , and filaments , and therefore we use the mst to differentiate the types of environment extending over super - halo scales . our combined vt and mst approach allows us to select discrete components of the cosmic web by exploiting the fundamental density contrasts of the cluster , group , filament , and void environments . another benefit of the proximity of our target field is sensitivity to low sfrs , as our combined approach of using the galaxy evolution explorer ( galex ; * ? ? ? * ) and wide - field infrared survey explorer ( wise ; * ? ? ? * ) to recover unobscured and dust - obscured star - formation activity , respectively , across the entire coma supercluster down to 0.02 . section describes the coma supercluster and our sample selection process , from sdss , galex , and wise . in section we outline our techniques for mapping the lss in the coma supercluster , and in section we present our resulting sfrs and comparisons of sf activity and colour versus environment . in section we discuss the implications of our results , and compare our work to previous studies . throughout this paper we use cosmological parameters , , and km s mpc , where pertinent cosmological quantities have been calculated using the online cosmology calculator of e. l. wright . throughout we assume a kroupa imf , and hereafter we will refer to galaxies stellar masses m as dwarf galaxies , and those as massive galaxies . the coma supercluster is an ideal field to observe signatures of galaxy transformation in different environments . it contains two rich galaxy clusters , abell 1656 and abell 1367 , and several galaxy groups distributed in a filamentary pattern between the two clusters . furthermore , the two clusters are in very different dynamical states , a1656 being relaxed and a1367 still undergoing significant merging . the close proximity of the supercluster allows us to probe its galaxy population down to dwarf masses spectroscopically complete sample , and the geometric alignment of the supercluster , galaxy distribution extending largely perpendicular to our line - of - sight , makes it an ideal case study to examine galaxies in a wide range of environments minimal projection effects . past studies of the coma supercluster have been primarily focused on the most massive cluster , a1656 . its low redshift , high galactic latitude , and richness ensured that it received a great deal of attention from observers in early extragalactic studies ( see * ? ? ? * and", "summary": "we examine the effects of pre - processing across the coma supercluster , including 3505 galaxies over deg , by quantifying the degree to which star - forming ( sf ) activity is quenched as a function of environment . we characterise environment using the complementary techniques of voronoi tessellation , to measure the density field , and the minimal spanning tree , to define continuous structures , and so we measure sf activity as a function of local density and the type of environment ( cluster , group , filament , and void ) , and quantify the degree to which environment contributes to quenching of sf activity . our sample covers over two orders of magnitude in stellar mass ( 10 to 10 ) , and consequently we trace the effects of environment on sf activity for dwarf and massive galaxies , distinguishing so - called ` mass quenching ' from ` environment quenching ' . environmentally - driven quenching of sf activity , measured relative to the void galaxies , occurs to progressively greater degrees in filaments , groups , and clusters , and this trend holds for dwarf and massive galaxies alike . a similar trend is found using colours , but more significant disparity between galaxy mass bins driven by increased internal dust extinction in massive galaxies . the sfr distributions of massive sf galaxies have no significant environmental dependence , but the distributions for dwarf sf galaxies are found to be statistically distinct in most environments . pre - processing plays a significant role at low redshift , as environmentally - driven galaxy evolution affects nearly half of the galaxies in the group environment , and a significant fraction of the galaxies in the more diffuse filaments . our study underscores the need for sensitivity to dwarf galaxies to separate mass - driven from environmentally - driven effects , and the use of unbiased tracers of sf activity . galaxies : clusters : general galaxies : evolution infrared : galaxies ultraviolet : galaxies ."}
{"article": "precise doppler surveys of main sequence stars have revealed eight companions that have masses under 5 m/ , orbital inclination , , remaining unknown ( mayor et al . 1999 , marcy & butler 1998 , noyes et al . 1997 , cochran et al . 1997 ) . these `` planetary '' companions exhibit both circular and eccentric orbits , consistent formation in dissipative circumstellar disks , followed by gravitational perturbations ( cf . lin et al . 1995 , artymowicz 1997 , levison et al . 1998 ) . the semimajor axes are all less than 2.5 au , most being less than 0.3 au . this `` piling up '' of planets near their host stars appears to be a real effect , although enhanced by the selection effect that favors detection of small orbits . jupiters orbiting between 0.5 and 1.5 au would be easily detected current doppler precision of 5 , but none has been found . this distribution of orbits supports models in which orbital migration in a gaseous protoplanetary disk drags jupiter mass planets inward ( lin et al . 1995 , trilling et al . 1998 ) . the distribution of the masses of substellar companions reveals two populations . our survey of 107 gk dwarfs revealed none that had = 10 80 m(marcy & butler 1998 ) . thus , `` brown dwarf '' companions occur frequency less than % , within 5 au . similarly , mayor et al . ( 1997 , 1999 ) surveyed gk dwarfs , and found at most 4 companions between 10 80 m . ( hipparcos astrometry has shown that seven previously suspected brown dwarfs from that sample are actually h burning stars . ) in contrast , at least 5% of gk stars harbor companions masses from 0.5 5 m . for example , in our doppler survey of 107 main sequence stars at lick observatory , we found 6 companions that have = 0.5 5 m(marcy and butler 1998 , this paper ) . thus , relative to this well populated planetary decade of masses , there exists a brown dwarf `` desert '' at masses 10 80 m , within 5 au . the efforts described above have focussed on g and k type main sequence stars having masses between 0.8 and 1.2 m . the question arises regarding the prevalence of planets around the m dwarfs which constitute 70% of the stars in the galaxy . here we describe the detection of the first apparent planetary companion to an m dwarf , gliese 876 , located 4.7 pc from the sun . gliese 876 ( = hip 113020 ) has v magnitude of 10.1 , a spectral type of m4v and a parallax from hipparcos of 0.213 ( perryman et al . 1997 ) . adopting this parallax and the bolometric correction of delfosse et al . ( 1998 ) gives = 9.52 , which implies a luminosity of , = 0.0124 l . the mass of the star gliese 876 can be derived from its k - band apparent magnitude ( k=5.04 ) and parallax , along empirical mass luminosity relation ( henry & mccarthy 1993 ) . this gives = 0.32 0.03 m . gliese 876 is chromospherically inactive ( delfosse et al . 1998 ) , which suggests that it is older than gyr . however its space motion is slow which suggests that its age is less than 10 gyr . its metalicity is not known well , though a preliminary synthesis of the spectrum indicates that it is metal poor by a factor of 23 relative to the sun ( valenti , 1998 ) . doppler shifts for gliese 876 have been obtained at both lick and keck observatories , using the hamilton and hires echelle spectrometers , respectively ( vogt 1987 , vogt et al . the first observations were made in 1994.9 ( at lick ) and in 1997.4 ( at keck ) , and both data sets extend to the present . the calibration of wavelength and the measurement of the spectrometer psf was determined for each exposure and for each 2 chunk of spectrum by using iodine absorption lines superimposed on the stellar spectrum ( butler et al . 1996 ) . figures 1 and 2 show all of the individual velocity measurements as a function of time , along separate keplerian fits . the velocities from lick observatory have typical uncertainties of 30 and those from keck are 6 ms . poisson statistics of the photons dominate the velocity errors for this relatively faint ( v=10.1 ) star . error bars on all points are the uncertainty in the mean of the velocities from the many 2 wide chunks into which the spectrum was divided . doppler measurements of gliese 876 at haute provence by delfosse et al . ( mayor et al . 1999 ) also show an amplitude and periodicity in agreement those reported here , thus constituting an immediate confirmation . it remains to be seen if their orbital parameters agree those quoted here . the lick and keck data each carry independent and arbitrary velocity zero - points . the relative zero point has been determined by combining the two data sets and adjusting the velocity offset until the keplerian fit ( see 3 ) yields a minimum in the statistic . thus , the lick and keck velocities were forced to have the same zero - point . independent keplerian fits were determined from the lick and keck data sets , and the resulting curves and orbital parameters are shown in figures 1 and 2 . the final orbital parameters are given in table , based on an orbital fit to the combined data set . the uncertainties reflect the differences in the two independent orbital fits . the two solutions agree within their uncertainties . the joint orbital period is = 60.85 0.15 d , and the eccentricity is = 0.27 0.03 . the orbital solution implies a planetary orbital semi - major axis of 0.21 0.01 au , and a minimum mass of = 2.1 0.2 m . this inferred is proportional to the assumed mass of the host star ( 0.32 .03 m ) which contributes most of the uncertainty in the companion mass . the periodic repetition of an asymmetric radial velocity variation is apparent from the raw data and from the fits in figures 1 and 2 . the orbit is clearly not circular . there is no pattern in the residuals , thus excluding the presence of any second planet mass greater than 1 jupiter mass and a period of 4 years or less in the gliese 876 system . the lick and keck velocities can be merged to yield a final fit , as shown in figure 3 . this shows that the two sets share a common orbital phase in addition to similar best fit orbital parameters . we note that two points from lick sit off the keplerian curve by 2 , and we suspect that the quoted errors of in those cases may be underestimated due to the low signal to noise ratios of those spectra . the large velocity amplitude of 220 for gliese 876 leaves orbital motion as the probable cause of the velocity variations . spots on a rotating star can , in principle , cause artifical velocity variations . but for gliese 876 , the equatorial rotation velocity is less than 2 kms , and the star is photometrically stable to within .02 mag ( marcy and chen 1992 , weiss 1996 , delfosse et al . therefore , spots can not alter the apparent velocity by more than .02 2000 = 40 . we have not checked for stellar pulsations , but the photometric stability suggests that any pulsations are not significant here . moreover , acoustic oscillations and g modes for a 0.3 m dwarf would have time scales of minutes and hours , respectively , unlike the observed 60 day velocity period . the companion to gliese 876 , = 2.1 .2 m , has a likely mass of 2 to 4 m , assuming unbiased orbital inclinations . for an assumed companion mass of 2.1 m , the astrometric semimajor axis would be 0.28 mas . hipparcos astrometry exhibits no wobble at a 2 upper limit of 4 mas ( perryman et al . thus , the upper limit to the companion mass is 29 m . at 4.7 pc , this is the closet known extrasolar planet . the semimajor axis implies an angular separation 0.045 arcsec , greatest separation of 0.062 arcsec . it is thus a prime candidate for direct imaging adaptive optics and interferometry ( i.e. , keck , lbt , sim , vlti ) . astrometric detection is also favored due to : 1 . its close proximity to the sun , 2 . the large mass of the planet , 3 . the low mass of the star , 4 . the small orbital period which permits many cycles to be monitored within a season . gliese 876 is apparently the first m dwarf known planetary companion . we have surveyed only 24 m dwarfs from lick observatory during the past 4 yr ( poor precision of 25 ) , which implies that the occurrence of jupiter mass planets within 2 au of m dwarfs could be a few percent , based on this one detection . the duration and paucity of keck observations render them not yet adequate ( yr ) to add information on the occurrence of planets around m dwarfs . the small orbital semi - major axis of =0.21 au and the eccentricity of =0.27 pose two profound puzzles regarding the origin of such planetary orbits . there is too little mass within a planetary feeding zone in a nominal protoplanetary disk at distances of 0.2 au to provide 2 jupiter masses of material to a growing planet ( cf . lissauer 1995 ) . one suggestion is that giant planets form several au from the star and then migrate inwards . orbital migration can be induced by interactions between the planet and the gas in the protoplanetary disk , bringing the planet inwards ( lin et al . 1995 , trilling et al . 1998 ) . however , it is not clear what would cause the planet around gliese 876 to cease its migration at 0.2 au . neither tidal interactions star nor a magnetospherically cleared hole at the disk center would extend to 0.2 au , and thus they can not halt the migration . a similar , as yet - unidentified parking mechanism appears needed for the planets around 55 cancri and cor bor ( noyes et al . 1997 , butler et al . 1997 ) . the non circular orbits for both cor bor ( =0.16 0.06 ) and for this planet around gliese 876 ( =0.27.03 ) imply that significant orbital eccentricities are common for jupiter mass companions orbiting between 0.1 and 0.3 au from their star . some physical mechanism must be identified which generally produces sizable eccentricities , in contrast to the inexplicably low eccentricities of the giant planets in our solar system . infrared speckle reveals no companions to gliese 876 from 1 au outward ( henry & mccarthy 1990 ) , and the lack of large variations in the velocities rule out stellar companions within 1 au . thus , the eccentricity of the planetary companion around gliese 876 could not have been pumped by a stellar companion . apparently , migration , if necessary , did not enforce circularity in the final orbits of gliese 876 or cor bor . one possible explanation is that gravitational scattering of planetary cores ( of earth mass and larger ) can dominate the orbital evolution ( rasio and ford 1996 , weidenschilling and marzari 1997 , lin and ida 1996 ) . orbit crossings and global instabilities among planetesimals in the disk can lead to dramatic orbit changes and large eccentricities ( levison et al . 1998 ) . long lived gas in a protoplanetary disk may lead to circular orbits in such planetary systems . other systems that lose their gas may suffer dynamical instabilities , leading to eccentric orbits at a variety of semimajor axes . however , the latter scenario , if common , does not explain the apparent paucity of jupiters from 0.5 to 1.5 au , and it remains to be seen if jupiters are common farther out . the equilibrium temperature at optical depth unity in the atmosphere of the planet around gliese 876 is estimated to be -70 c , too cold for water in liquid form ( saumon 1998 ) . temperatures would be higher at deeper layers in the atmosphere . any bodies orbiting interior to 0.2 au would have surface temperatures above -70 c. it would be interesting to determine if planets could reside in stable orbits within 0.2 au , perhaps in mean motion resonances giant planet discovered here . we thank kevin apps for analysis of hipparcos astrometry . we thank xavier delfosse , michel mayor , and didier queloz for communicating their velocities for gliese 876 . we thank m. duncan , d. lin , and g.basri for useful conversations . we acknowedge support by nasa grant nagw-3182 and nsf grant ast95 - 20443 ( to gwm ) , and by nsf grant ast-9619418 and nasa grant nag5 - 4445 ( to ssv ) and by sun microsystems . we thank the nasa and uc telescope assignment committees for allocations of telescope time . lcc orbital period ( days ) & 60.85 & 0.15 + velocity semi - amplitude ( ms ) & 239 & 5 + eccentricity & 0.27 & 0.03 + longitude of periastron ( deg ) & 24 & 6 + periastron date ( julian date ) & 2450301.0 & 1.0 + ( m ) & 2.11 & 0.20 + semimajor axis a ( au ) & 0.21 & 0.01 +", "summary": "doppler measurements of the m4 dwarf star , gliese 876 , taken at both lick and keck observatory reveal periodic , keplerian velocity variations period of 61 days . the orbital fit implies that the companion has a mass of , = 2.1 m , an orbital eccentricity of , = 0.27.03 , and a semimajor axis of , = 0.21 au . the planet is the first found around an m dwarf , and was drawn from a survey of 24 such stars at lick observatory . it is the closest extrasolar planet yet found , providing opportunities for follow up detection . the presence of a giant planet on a non - circular orbit , 0.2 au from a 1/3 m star , presents a challenge to planet formation theory . this planet detection around an m dwarf suggests that giant planets are numerous in the galaxy ."}
{"article": "let us begin following facts : 1 . for any differential graded algebra , the hochschild cohomology has a gerstenhaber algebra structure . 2 . let be a closed , oriented -dimensional -manifold , be the free loop space . then , has a batalin - vilkovisky ( in particular , gerstenhaber ) algebra structure . 3 . let denote the differential graded algebra of differential forms on . there exists a linear map defined by iterated integrals of differential forms , which preserves the gerstenhaber structures . \\(a ) is originally due to gerstenhaber . ( b ) is due to chas - sullivan , which is the very first paper on string topology . ( c ) relates the geometric construction ( b ) to the algebraic construction ( a ) . it seems that ( c ) is also well - known to specialists ( see remark ) . ( a)(c ) concern algebraic structures on homology level , and it is an important and interesting problem to define chain level refinements of these structures . for ( a ) , so called deligne s conjecture claims that a certain chain model of the little disks operad acts on the hochschild cochain complex . various affirmative solutions to this conjecture and its variations are known ; see part i section 1.19 , section 13.3.15 , and the", "summary": "the aim of this paper is to define a chain level refinement of the batalin - vilkovisky ( bv ) algebra structure on homology of the free loop space of a closed -manifold . namely , we propose a new chain model of the free loop space , and define an action of a certain chain model of the framed little disks operad on it , recovering the original bv structure on homology level . we also compare this structure to a solution of deligne s conjecture for hochschild cochain complexes of differential graded algebras . to define the chain model of the loop space , we introduce a notion of de rham chains , which is a hybrid of singular chains and differential forms ."}
{"article": "there is evidence for the existence of supermassive black holes ( smbhs ) over a range of epochs ; smbhs masses m are ubiquitous in local galactic bulges ( e.g. magorrian et al . 1998 : ferrarese 2002 ) , while the smbhs powering quasars are estimated to range between m ( see e.g. shields et al . evidence for the early assembly of smbhs , when interpreted within a hierarchical cosmology , suggests that smbh coalescence may be a frequent event . if this is the case , the gravitational waves ( gws ) generated during smbh coalescence are a prime candidate for detection by the laser interferometer space antennae ( lisa , folkner et al . 1998 ; flanagan & hughes 1998 ; hughes et al . 2001 ) . estimates of the smbh coalescence rate depend crucially on the occupation fraction of smbhs in halos , and therefore on the adopted model for the formation and growth of smbhs . within a hierarchical cdm cosmology , both seeded smbh formation models and ongoing formation models are consistent present - day ubiquity of smbhs in galactic bulges ( menou et al . 2001 ) . the formation of a smbh may be limited to potential wells above a minimum depth . if so , then there exists a critical halo virial temperature below which a halo can not host smbh formation . if is low ( eg . k ) , then smbhs are abundant in small halos , and predicted event rates are in the order of per year ( wyithe & loeb 2003 ; haehnelt 2004 ) . this event rate may be significantly lower , less than one per year , if k and smbhs form only at the centres of massive galaxies ( haehnelt 2004 ) . hence the detection rate has the potential to constrain the global smbh population ] . the rate of coalescence detectable by lisa depends on the form of the gw signal and the instrument s sensitivity curve . previous estimates of the event rate have used characteristic ( rather than time - dependent ) gw signals to determine approximate detection limits ( wyithe & loeb 2003 ) or have estimated the number of detectable events by comparing the sensitivity curve total gravitational wave background due to coalescing bbhs ( sesana et al . recently sesana et al . ( 2004b ) estimated the expected event rate for a detailed physical model for smbh growth . we perform the first empirically motivated calculations for the lisa detection rate of smbh mergers in a hierarchical cosmology that use accurate signal to noise ratios ( snrs ) to determine detection criteria . in we describe the calculation of snrs for the lisa detection of bbh coalescence . in we discuss our calculation of the smbh merger rate , including our halo merger rate predictions , estimate for the occupation fraction of smbhs in halos and the relationship . finally , we present our event rate predictions as a function of before concluding in . throughout this work we assume , , , km s mpc km s mpc , and a primordial power spectrum slope as determined by the wilkinson microwave anisotropy probe ( wmap , spergel et al . the efficiency which bbhs coalesce is highly uncertain . initially , the smbhs sink independently toward the centre of a merged system due to dynamical friction from the dark matter background until they form a bound binary ( begelman , blandford & rees 1980 ) . the efficiency of this process depends on the orbital parameters of the merging dark matter halos ( van den bosch et al . 1999 ; colpi , mayer & governato 1999 ) . as the orbital separation decreases , 3-body interactions stars that pass within of the bbh centre of mass ( the `` loss cone '' ) increasingly dominate the energy loss . depending on the orbital parameters of the binary and the background distribution of stars , this process may result in a hardened binary system . if hardening continues until a binary separation where energy losses are dominated by gws , the binary will coalesce . yu ( 2002 ) argues that the efficiency of bbh coalescence hinges on the time - scale for bbh hardening during the hard binary phase . during this stage , three - body interactions between the bbh and individual stars eject stars into highly elliptical orbits , lowering the inner stellar density and slowing further hardening ( eg . volonteri et al . the deceleration of the hardening rate is compounded by the preferential depletion of stars within the loss cone ( region of parameter space where angular momentum is low enough that stars pass near the bbh ) , resulting in a deficiency of stars that can extract energy from the binary system ( see yu 2002 ) . uncertainties in the efficiency of processes which may replenish loss cone stars make this effect difficult to analyse . two - body stellar relaxation is expected to result in some diffusion of stars back into the loss cone ( binney & tremaine 1987 ) but it is unclear that this process alone can support sufficient hardening . numerical n - body simulations have been used to include the effect of the bbh wander within the star field ( due to 3-body interactions stars ) , which increases the effective size of the loss cone and may prevent the coalescence from stalling ( quinlan & hernquist 1997 ; milosavljevi ' c & merritt 2001 ; chatterjee , hernquist & loeb 2003 ) . other scenarios which may aid evolution of the bbh into the gw dominated regime have been proposed , including the effects of gaseous disks ( gould & rix 2000 ) , flattened or triaxial stellar distributions ( yu 2002 ) and disruption by a third smbh ( hut & rees 1992 ) . the efficiency of bbh coalescence is of prime concern for lisa detection rates . whilst undoubtably still an open question , we note that there are plausible mechanisms to extract the required energy from the binary system . for the purposes of our calculation we therefore assume that hardening of the binary to the gw dominated regime occurs efficiency of unity . all event rates quoted in this paper are proportional to . the gravitational wave dominated portion of bbh coalescence may be divided into three main phases ( hughes 2002 ) . the binary begins in the inspiral phase , smbhs slowly spiralling into tighter orbits due to the adiabatic loss of gw energy . eventually the dynamics become relativistically unstable and the smbhs violently plunge to form a single object ( merger phase ) . the final gw signal can be described by modelling the merged system as a perturbed kerr smbh ( ringdown phase ) . the dynamics of the inspiral and ringdown phases are well understood and theoretical waveforms for the gws have been derived . however , certain parameters of the ringdown solution depend on unknown details of the merger phase and must be guided by the results of numerical simulation ( see ) . detection of gws from a single binary source will be complicated by the presence of galactic and extra - galactic gw foregrounds , and by lisa s sensitivity to gws from all sky directions . matched filter template searches will therefore be necessary to detect the gw signal from an individual event ( hughes et al . 2001 ) . the snr for a matched filter detection is defined by the ratio of the coherently folded signal and noise powers : where is the fourier transform of the dimensionless strain and is the spectral power of the noise . we calculate snrs for the final year ( before the merger phase ) of the inspiral signal . the effective duration of the ringdown phase is much shorter than one year and we therefore calculate ringdown snrs over the entire phase . estimates of lisa s noise spectrum are evolving plans for the instrument design . a recently suggested sensitivity goal ( bender 2003 ) has a ( dimensionless ) threshold sensitivity low frequency power - law slope of for frequencies ranging between and hz , and a power - law slope of for frequencies of to hz . bender ( 2003 ) suggests a hard low frequency cut off at hz , roughly corresponding to the lowest resolvable frequency for a year long mission . lisa will be sensitive to frequencies up to hz . as a general rule is required for the confident detection of a signal ( hughes et al . 2001 ) . as the orbital separation of the binary shrinks , both the amplitude and frequency of the inspiralling strain increase . to calculate accurate inspiral phase snrs , it is important to include the frequency dependence of the strain in the integration of signal to noise . we achieve this using the technique outlined by flanagan & hughes ( 1998 , henceforth fh98 ) . fh98 show that sky averaged squared snr ( can be re - expressed in terms of the emitted gw energy spectrum where is the frequency of the gw . this is related to the observed gw frequency via the cosmological redshift of the source ) . since the gw frequency of bbh coalescence typically increases time , this frequency may be used to delineate the inspiral and merger phases . the observed gw frequency of the inspiral signal at an observed time prior to the merger phase is given by ( fh98 ) ^{5/3 } t^{\\prime}.\\ ] ] depending on the binary characteristics , may lie below the lisa waveband . we therefore use the greater of and as the lower limit of integration in equation . we use the technique described by hughes ( 2002 ) to calculate snrs for the ringdown phase . bbh coalescence is expected to result in a rotating smbh bar - like excitation of the event horizon ( hughes 2002 ) . this distortion of the kerr solution may be modelled by the bar - like ] where is the comoving distance to a source at redshift . the quality factor is related to the damp - time of the gw signal by . the final factor in equation accounts for the reduced signal amplitude for unequal mass bbh coalescence ( fh98 ) . numerical simulations suggest that ( baker 2001 ; fh98 and", "summary": "the gravitational waves generated during supermassive black hole ( smbh ) coalescence are prime candidates for detection by the satellite lisa . we use the extended press - schechter formalism combined empirically motivated estimates for the smbh dark matter halo mass relation and smbh occupation fraction to estimate the maximum coalescence rate for major smbh mergers . assuming efficient binary coalescence , and guided by the lowest nuclear black hole mass inferred in local galactic bulges and nearby low - luminosity active galactic nuclei ( m ) we predict approximately 15 detections per year at a signal to noise greater than five , in each of the inspiral and ringdown phases . rare coalescences between smbhs having masses in excess of m will be more readily detected via gravitational waves from the ringdown phase . black hole physics , cosmology : theory , gravitational waves"}
{"article": "one of the most promising solutions to the hierarchy problem is the randall - sundrum ( rs ) model . in this model there is a single extra dimension compactified on non - factorizable metric of here is the extra - dimensional coordinate , and is the inverse of the curvature , . two branes define the boundaries of the extra dimension . one , at , is called the uv , or planck , brane . the other , at , is the ir , or , brane . picking , which is natural in realistic stabilization mechanisms , solves the hierarchy problem . in the original rs model the sm was confined to the ir brane , and only gravity propagated in the bulk . it has since been realized that both gauge and fermion fields can live in the bulk in a realistic model . these models are realistic , but the parameter space can be strongly reduced by precision electroweak constraints . much of this problem can be traced to the fact that the massive gauge fields receive a contribution to their mass from the bulk geometry which does not respect the custodial . this can be fixed by expanding the gauge group to , which dramatically improves the electroweak fit . the breaking of this extended electroweak symmetry proceeds in two stages : on the uv brane ; on the ir brane , where is the diagonal of the groups . this paper investigates the properties of the higgs sector that accomplishes this breaking . we now ask what drives the breaking on each brane . on the planck brane all degrees of freedom will have planck scale masses , so we can ignore them . we can then implement the breaking boundary conditions to good approximation . this leads to the boundary conditions at here and are ratios of 5d gauge couplings : , and . on the brane , the masses will be scale , so we should look at the higgs sector in detail . the simplest structure that will create the breaking pattern is a real higgs that is a bidoublet under . this leads to the boundary conditions at note that in the limit we obtain the usual higgsless boundary conditions , and this model reduces to the higgsless model in . we will use this parameter , to interpolate between the sm limit , and the higgsless limit . to write down the effective 4d theory , we expand the 5d fields into kaluza klein ( kk ) fields , we can now obtain the gauge boson wavefunctions by solving the equation of motion subject to the boundary conditions and . this produces a spectrum of eigenvalues corresponding to the excitations of the gauge fields . the lowest masses in each of the charged and neutral sectors will correspond to the and bosons . the neutral sector also contains a zero mode , corresponding to the photon . fig shows the eigenvalue for the as a function of the parameter . one interesting feature of this model is that the and wavefunctions are suppressed near the ir brane , as can be seen by inspecting the boundary conditions . this suppression increases for increasing . this means that the coupling of massive gauge bosons to the higgs will generically be suppressed . shows the coupling of the to the higgs . for values of near unity the lep bounds on the higgs mass can be dramatically reduced . ( for larger values of the model is effectively higgsless . ) the fermion sector of this model is more complicated . again , the higgs vev induces mixed boundary conditions that link left and right handed fields to give the fermions masses . however , there are two new degrees of freedom . first , since 5d fermions are achiral , ther can always be a mass term in the bulk . the main effect of this term is to shift the location of the fermion zero mode in the bulk . by changing this parameter we can cause the zero mode to be localized either near the uv or ir brane , and also can change the degree of this localization . this allows us to control the overlap of the zero mode ir brane , and consequently the strength which the fermion interacts higgs . in this way the hierarchy of fermion masses can be generated by order one changes in the 5d masses . the second complication arises from the symmetry which enforces that , for example , if unbroken . this mass relation can be modified by mixing fermions localized to the planck brane , where the is broken . for full details , see . note that there are tree - level corrections to precision electroweak observables , coming largely from the kk excitations of the gauge bosons . unfortunately , the magnitude of these corrections is highly sensitive to the configuration of the fermion sector . for the specific configuration studied in we find the constraint . there are , however , special points in the fermion parameter space where the constraint becomes trivial , so a wide range of should be considered . the final interesting shift in higgs properties is in the couplings to massless gauge bosons , i.e. gluons and photons . the coupling of the higgs to gluon pairs is induced through top loops . however , in this model the kk excitations also couple to the higgs . furthermore , note that we have arranged small 4d yukawa couplings for the other fermions by small wavefunction overlaps would - be zero modes . the 5d yukawa couplings are all order 1 , and the excited states have no wavefunction suppression . hence there are large contributions to the higgs - glue - glue coupling from the kk excitations of all colored fermions . this leads to an enhancement in that coupling , as seen in fig . . there are similar corrections to the higgs - gamma - gamma coupling . the situation there is more complicated , however , since there are also contributions from boson loops , which are dominant in the sm , and the higgs coupling to s is suppressed . we can now look at the behavior of the higgs branching ratios , as shown in fig . . note in particular the dominance of over a wide range , and the late onset of . this is driven by the symmetry , which gives a large enhancement of the -quark yukawa , and the suppression of the gauge boson couplings . note also the reduction in the mode . this will make discovery at the lhc difficult . the suppression of the coupling to gauge bosons also means that production at the ilc will be reduced , making this higgs a particularly difficult one to find . however , it will be essential to measure the higgs couplings precision to identify a warped extra dimension as the correct theory of new physics , if indeed this is what is realized in nature . 9 b. lillie , arxiv : hep - ph/0505074 . l. randall and r. sundrum , phys . lett . * 83 * , 3370 ( 1999 ) . w. d. goldberger and m. b. wise , phys . * 83 * , 4922 ( 1999 ) . h. davoudiasl , j. l. hewett and t. g. rizzo , phys . lett . * 84 * , 2080 ( 2000 ) . h. davoudiasl , j. l. hewett and t. g. rizzo , phys . b * 473 * , 43 ( 2000 ) and phys . d * 63 * , 075004 ( 2001 ) ; a. pomarol , phys . b * 486 * , 153 ( 2000 ) ; y. grossman and m. neubert , phys . b * 474 * , 361 ( 2000 ) ; t. gherghetta and a. pomarol , nucl . b * 586 * , 141 ( 2000 ) . k. agashe , a. delgado , m. j. may and r. sundrum , jhep * 0308 * , 050 ( 2003 ) . c. csaki , c. grojean , h. murayama , l. pilo and j. terning , phys . d * 69 * , 055006 ( 2004 ) . c. csaki , c. grojean , l. pilo and j. terning , phys . * 92 * , 101802 ( 2004 ) . g. cacciapaglia , c. csaki , c. grojean and j. terning , phys . d * 70 * , 075014 ( 2004 ) and phys . d * 71 * , 035015 ( 2005 ) ; g. cacciapaglia , c. csaki , c. grojean , m. reece and j. terning , arxiv : hep - ph/0505001 . y. nomura , jhep * 0311 * , 050 ( 2003 ) . r. barbieri , a. pomarol and r. rattazzi , phys . b * 591 * , 141 ( 2004 ) . h. davoudiasl , j. l. hewett , b. lillie and t. g. rizzo , phys . d * 70 * , 015006 ( 2004 ) and jhep * 0405 * , 015 ( 2004 ) ; j. l. hewett , b. lillie and t. g. rizzo , jhep * 0410 * , 014 ( 2004 ) ; r. s. chivukula , e. h. simmons , h. j. he , m. kurachi and m. tanabashi , phys . d * 70 * , 075008 ( 2004 ) and phys . b * 603 * , 210 ( 2004 ) . a. birkedal , k. matchev and m. perelstein , phys . * 94 * , 191803 ( 2005 ) . c. csaki , c. grojean , j. hubisz , y. shirman and j. terning , phys . d * 70 * , 015012 ( 2004 ) .", "summary": "we study the corrections to higgs physics in a model of a single warped extra dimension fields except the higgs in the bulk , and a gauge symmetry extended to . we find that generically the higgs coupling to electroweak gauge boson pairs is suppressed , the coupling to gluons is enhanced , and the coupling to photons is often suppressed , but can be enhanced ."}
{"article": "essentially all astronomical measurements are performed via electromagnetic waves . the availability of accurate gravitational wave measurements within the next decade or so will thus be a significant development for astronomy . in particular , since the propagation of photons and gravitons could differ at a fundamental level , gravitational waves emitted by cosmologically - distant `` space - time sirens , '' such as coalescing pairs of massive black holes , could be used as valuable new probes of physics on cosmological scales . black holes masses are present at the center of numerous nearby galaxies ( e.g. * ? ? ? * ; * ? ? ? as such galaxies collide over cosmic times , their central black holes coalesce , releasing ergs of binding energy in the form of gravitational waves ( hereafter gws ) . to measure the gws emitted by these cosmologically - distant space - time sirens , esa and nasa will build the laser interferometer space antenna , lisa . gws emitted by black hole binaries have the unfamiliar property of providing a direct measure of the luminosity distance , , to the black holes , without extrinsic calibration . owing to the highly coherent nature of gw emission , the amplitude ( or strain ) , , frequency , , and frequency derivative , , of the leading order ( quadrupolar ) gw inspiral signal scale as ^{5/3 } f^{2/3}}{d l } , \\\\ \\dot f ( t ) & \\propto & \\left ^{5/3 } f^{11/3},\\ ] ] where represents the two transverse gw polarizations , is the black hole pair `` chirp '' mass and its redshift . provided the gw source can be reasonably well localized on the sky , an extended observation of the chirping signal leads to precise measurements of , , and thus , independently . as illustrated in fig . , lisa s orbital configuration allows for a `` triangulation '' of gw sources on the sky , to within a solid angle deg typically . this permits very accurate measurements , e.g. distances errors at typically . masses are independently determined to very high accuracy ( typically ; e.g. , ) = in principle , the same sky localization that helps determine the distance to a source accurately can be used to find the host galaxy of a pair of merging black holes seen by lisa . the secure identification of the host galaxy would enable a wide variety of new galactic black hole studies ( see ) . initially , the prospects for finding the host galaxy of a pair of merging black holes were considered to be poor , simply because of the large number of galactic candidates located in the deg lisa sky error - box ( e.g. , * ? ? ? * ; * ? ? ? * ) recently , however , this possibility has been reconsidered , more optimistic conclusions . given a cosmology , it is possible to translate the accurate luminosity distance measurement to the gw source into a narrow redshift slice in which the host galaxy must be located . various contributions to the redshift errors that arise in performing this conversion are shown in fig . , for a representative equal - mass binary , as a function of the gw source redshift . at redshifts , where most black hole binary sources are expected to be found , weak lensing errors due to line - of - sight inhomogeneities ( on top of the smooth average cosmology ) are the main limitation to an accurate determination of the redshift slice in which the host galaxy ought to be located . have studied in detail the possibility that the three - dimensional information available ( sky localization + redshift slice ) could be used to single out a quasar , or any other unusually rare object ( such as a star - bust galaxy ) , in the lisa error box , after coalescence . finding such a statistically rare object post - merger would make it a good host galaxy candidate for the newly - coalesced pair of black holes . = however , it maybe much more advantageous to use a pre - merger strategy to identify the host galaxy of a pair of coalescing black holes seen by lisa . indeed , one can use near real - time gw information on the sky localization , in combination accurate timing of the inspiral event , to predetermine well in advance where on the sky the merger is located . a unique host galaxy identification could then proceed through coordinated observations traditional telescopes , by monitoring in real time the sky area for unusual electromagnetic emission , as the coalescence proceeds . a variety of mechanisms exist through which disturbed gas in the vicinity of black hole pairs will power electromagnetic emission during and after coalescence . for example , at the time of coalescence , ergs of kinetic energy are delivered to the recoiling black hole remnant and its environment , for typical recoil velocities km / s ( e.g. , * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) . this may lead to detectable signatures and permit the coincident identification of a unique host galaxy . the detailed nature of such electromagnetic counterparts remains largely unknown , however . to a large extent , lisa s ability to localize a long - lived source on the sky is related to the gw signal being modulated as a result of the detector s revolution and change of orientation when the constellation orbits around the sun ( fig . ) . even though most of the gw snr accumulates during the final stages of inspiral / coalescence for typical gw sources , reasonably good information on sky localizations must be available well before final coalescence since this information accumulates slowly , over the long signal modulation ( orbital ) timescale . because of significant cross - correlations between sky localization and distance errors , it turns out that this argument is also largely valid for luminosity distance errors . figure shows the pre - merger time evolution of luminosity distance and angular sky localization errors for a representative black hole pair at . errors improve quickly at early times but their evolution slows down considerably at late times . according to both panels , even accounting for random orientations of various source and detector angles ( shown as best , typical and worst cases ) , significant information is available days to weeks prior to the final coalescence . including black hole spins in the analysis has been shown to result in significant improvements on the errors during the last few days to hours prior to coalescence . expected availability , by the time lisa is operational , of sensitive large field - of - view ( fov ) astronomical instruments for weak lensing and supernova studies , it becomes interesting to estimate the amount of time prior to merger during which the lisa sky localization falls within the fov of such an instrument . when this happens , continuous monitoring of the designated sky area , until final coalescence , becomes possible . have performed a detailed analysis of this possibility , using lsst and its deg fov as a reference . figure shows results for representative equal - mass binaries , as a function of their total mass and redshift . the various contours show that prospects for electromagnetic monitoring days to weeks before the coalescence are good for sources at redshifts . monitoring for the best gw sources out to - may even be possible . a large variety of new galactic black hole astrophysics would be enabled by successful identifications of the host galaxies of coalescing black hole pairs . we mention only a few possibilities here and refer the interested reader to and for additional discussions . from the black hole masses , spins and binary orientation , all accurately constrained by the gw signal , one would be able to study the physics of the post - merger accretion flow onto the remnant black hole unprecedented accuracy . this would include precise constraints on the eddington ratio of the accreting source , its emission and absorption geometries and possibly its jet phenomenology . similarly , studies of the galactic host might tell us about the nature ( dry / wet ) and the timing of the galactic merger that resulted in the black hole binary coalescence . finally , measuring velocity dispersions , , for several host galaxies , together black hole masses known from the gw signal , would allow us to accurately map the evolution of the relation cosmic time , at least for such transitional objects as the hosts of coalescing black hole pairs . another consequence of successfully identifying the host galaxies of coalescing black hole pairs is the possibility to draw a gravitational hubble diagram , i.e. one that relates the gravitational luminosity distances , , of these gw sources to the electromagnetic redshifts , , of their host galaxies . one of the main interests of a gravitational hubble diagram arises from its immunity to common systematics affecting electromagnetic measurements . indeed , a gravitational hubble diagram , which is based on gravitational distance measurements self - calibrated sources , is not susceptible to any significant bias from absorption , scattering or reddening of gws . in practice , however , the value of such a diagram is limited by line - of - sight matter inhomogeneities , which generate weak lensing uncertainties on the gravitational measurement ( see fig . ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? while the lensing effect can in principle be averaged out over many random lines - of - sights , it may not be possible to do so for coalescing pairs of massive black holes if lisa merger event rates are modest ( e.g. , a few tens per year at ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? weak lensing errors on individual measurements amount to distance uncertainties ranging from at to at ( e.g. * ? ? ? * ) , which makes a gravitational hubble diagram imprecise even at moderate redshifts . the extent to which lisa events can be used to draw a meaningful hubble diagram will thus depend strongly on the actual distribution of massive black hole merger events redshifts and the corresponding efficiency of host galaxy identifications . as we describe in , however , white dwarf spiraling into massive black holes may offer a practical avenue for precision cosmology lisa . the possibility that the accelerated expansion of the universe results from a failure of general relativity has fueled much theoretical work on large scale modifications of gravity over the past few years . since building a satisfactory theory of modified relativistic gravity is a formidable task , any insight that can be gained from direct observational constraints on the linearized gw regime can not be overlooked . lisa , ability to measure the gw signal from cosmologically - distant sources , may thus be one of our best probes of modified gravity on cosmological scales . one may expect gravity modifications to contain a new length scale , , beyond which gravity deviates from general relativity . in order to explain the observed accelerated expansion of the universe , this scale is expected to be of the order of the current hubble radius , . an existence proof of modifications of this type is given by dgp gravity , a braneworld model infinite extra dimension . discuss the possibility that extra - dimensional leakage of gravity in dgp - like scenarios may lead to cosmologically - distant gw sources appearing dimmer than they truly are , from the loss of gw energy flux to the extra - dimensional bulk . indeed , in the presence of large distance leakage , flux conservation over a source - centered hypersphere requires that the gw amplitude scales distance from the source as where is the total number of space - time dimensions accessible to gravity modes . thus , for , it deviates from the usual scaling . in principle , black hole merger events and associated host galaxies could thus reveal the leakage of gravity over scales of order a few hubble distances , by comparison to purely electromagnetic hubble diagrams , which are immune to such leakage effects . this is only one of several possible modified gravity signatures in the gws from cosmologically - distant sources . another class of signatures is related to the gw polarization signal , possibly additional polarizations beyond the two transverse quadrupolar modes of general relativity ( e.g. , * ? ? ? . signatures also exist in relation to the gw propagation velocity which , in modified gravity scenarios , can differ from the speed of light . in this respect , the possibility to time a cosmological gw , relative to an electromagnetic signal causally associated black hole merger , may offer unique diagnostics of large - scale modified gravity . this could reveal , for instance , that the phase of the gw signal deviates from general relativistic expectations , once propagated over cosmological distances . have explored further the possibilities of measuring photon and graviton arrival times from a same cosmological source . a general difficulty this approach is that there will be a systematic and a priori unknown delay in the emission of photons , relative to the emission of gravitons , since the former must causally lag behind the perturbing gravitational event . this difficulty could be overcome if it were possible to calibrate the relative timing of the photon and graviton signals at the source . prior to coalescence , gas present in the near environment of the black hole binary would be gravitationally perturbed in such a way that it could radiate a variable electromagnetic signal period closely matching that of the leading - order quadrupolar perturbation induced by the coalescing binary ( see fig . ) . this would help identify the electromagnetic counterparts of specific gw events . in addition , it may be possible to match the variability frequencies of the electromagnetic and gw signals . the offset in phase between the fourier components of the two signals similar frequencies could be used to effectively calibrate the intrinsic delay in electromagnetic emission at the source . late inspiral and coalescence can be tracked via the gw signal , so that the relative timing of the gravitational and electromagnetic signals may be known to within a fraction of the binary s orbital time . any drift in arrival - time frequency between the gravitational and electromagnetic chirping signals , as the source spans about a decade in gw frequency during the last 2 weeks before merger , could then be attributed to a fundamental difference in the way photons and gravitons propagate over cosmological distances . for instance , such a drift could occur if the graviton is massive , resulting in a frequency - dependent propagation velocity ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? this tracking possibility is illustrated graphically in fig . . interestingly , while lorentz invariance has been extensively tested for standard model fields , lorentz symmetry could be violated in the gravity sector , especially on cosmological scales ( e.g. , * ? ? ? * ; * ? ? ? * ) . good enough understanding of the source , electromagnetic counterparts to black hole binary mergers may offer unique tests of lorentz violations in the gravity sector , via the opportunity to match and track the gravitational and electromagnetic signals in frequency and phase . it may be possible , as the black hole binary decays toward final coalescence , spanning a range of frequencies , to measure the delays in graviton vs. photon arrival times as a function of increasing frequency of the chirping signal . the consistency expected if lorentz symmetry is satisfied in the gravity sector could be tested explicitly for gravitons propagated over cosmological scales . to have any chance to perform such new tests of gravitational physics , one will need to identify the electromagnetic counterparts of coalescing pairs of massive black hole binaries as early as possible . this may be one of the strongest motivations behind ambitious efforts to localize these rare , transient events well before final coalescence . as seen before , a large number of sources must be accumulated to turn a gravitational hubble diagram into a high precision tool for cosmology . white dwarf frequently spiraling into ( moderately ) massive black holes may offer unique opportunities in this respect . an additional goal of the lisa mission is the detection of gws emitted by compact objects being captured by massive black holes ( the so - called extreme mass ratio inspirals , or emris ) . present a detailed parameter estimation analysis for this class of lisa events and show that they could be detected good snr out to a distance gpc . in addition , these authors found that the sky localization errors for these events ( steradians at gpc ) are comparable to the case of black hole binary merger events . no electromagnetic counterpart is expected from emris of dense neutron stars or stellar - mass black holes . on the other hand , partial ( or total ) disruptions of inspiraling low - density white dwarfs ( wds ) could produce such counterparts and thus help identify host galaxies for such events . to the best of our knowledge , the possibility to find the electromagnetic counterparts of this subclass of lisa emris and use them for precision cosmology has not been previously discussed in the literature . as a result of its relatively low density , a typical wd suffers complete disruption around a non - spinning black hole of mass . this mass limit is increased to perhaps if the black hole is spinning rapidly . even if the wd were not disrupted , some level of partial shedding of its lower density outer layers ( e.g. * ? ? ? * ) may be expected as the inspiral proceeds . as the stream of debris from a partially stripped wd shocks against itself or the inspiraling wd ( e.g. , * ? ? ? * ) , some level of electromagnetic emission during such emris is expected . a tidally - triggered detonation of the wd is yet another possibility . all these arguments point to the possibility that electromagnetic counterparts may exist for a subset of all the emris detected by lisa ( the one corresponding to wd inspirals ) . the fraction of all emris which involve wds is , indeed , expected to be substantial . if electromagnetic counterparts for a subset of all lisa emris can be detected , the rewards will be significant . just like black hole binary merger events , emris uniquely identified counterparts and host galaxies could be used to draw a gravitational hubble diagram , significant advantages that , at redshifts as low as , weak lensing due to line - of - sight inhomogeneities would be small or negligible ( fig . ) and that the relation at these low redshifts is strongly sensitive to the dominant dark energy content . dark energy becomes dynamically significant , affecting the expansion rate and geometry of the universe , and modifying , at ( see , e.g. * ? ? ? * for a review ) . indeed , as emphasized by , once cosmic microwave background anisotropies are measured by planck , will be known accurately at , and a low redshift measurement will provide the best complement to constrain dark energy parameters . wd emris detections lisa will occur frequently , and they could perhaps be singled out on the basis of the comparatively low mass of the inspiraling compact object . it remains to be determined how the lisa sky localization error evolves - merger ( or pre - disruption ) time for such events and what is the nature of their electromagnetic counterparts . but altogether , the various advantages that we have outlined point to the need for a detailed assessment of the potential use of wd emris for precision cosmology lisa . for centuries , astronomers have measured distances exclusively light . direct gravitational measurements , gravitational hubble diagrams and comparisons between the propagation of electromagnetic and gravitational signals offer fundamentally new ways to probe physics on cosmological scales . the novelty involved in joint , time - constrained electromagnetic and gravitational measurements will require that special efforts be made to reach out across the gw and astronomy communities .", "summary": "the notion that microparsec - scale black holes can be used to probe gigaparsec - scale physics may seem counterintuitive , at first . yet , the gravitational observatory lisa will detect cosmologically - distant coalescing pairs of massive black holes , accurately measure their luminosity distance and help identify an electromagnetic counterpart or a host galaxy . a wide variety of new black hole studies and a gravitational version of hubble s diagram become possible if host galaxies are successfully identified . furthermore , if dark energy is a manifestation of large - scale modified gravity , deviations from general relativistic expectations could become apparent in a gravitational signal propagated over cosmological scales , especially when compared to the electromagnetic signal from a same source . finally , since inspirals of white dwarfs into massive black holes at cosmological distances may permit pre - merger localizations , we suggest that careful monitoring of these events and any associated electromagnetic counterpart could lead to high - precision cosmological measurements lisa ."}
{"article": "narrow - line seyfert 1 galaxies ( nls1s ) are a special and interesting group of active galactic nuclei ( agns ) . they show narrow optical balmer emission lines emission ( /h ) , strong emission , and soft x - ray excess . nls1s show remarkable radio - loud / radio - quiet bimodality . only of nls1s are radio - loud objects . the fraction is much smaller than that found in qsos . very radio - loud nls1s ( rl - nls1s , ) are even much fewer , where the radio loudness is commonly defined as the flux ratio of radio to optical at . so far , it is still a puzzle why rl - nls1s are so scarce . at present , the origin of rl - nls1s is also still poorly understood . a few efforts have been made in the past few years to understand the nature of rl - nls1s . yuan et al . ( 2008 ) found that the broadband spectra of some rl - nls1s are similar to those of high - energy - peaked bl lac objects , and suggested that some of them may be bl lac objects actually . basing upon the recent observation taken by satellite , some rl - nls1s display a hard x - ray component suggesting the presence of relativistic jets on the line of sight . the presence of the relativistic jets motivates us to search for intranight optical variability in some rl - nls1s , because of the well - known beaming effect ( e.g. , wagner & witzel 1995 ) . argued that sdssj094857.3 + 002225 is a right candidate for searching for rl - nls1s beaming effect . the object is a very radio - loud nls1 at . the reported radio loudness derived from the radio flux at 5 ghz ranges from 194 to 1982 . it is in the crates catalog as a flat - spectral radio source . the simultaneous observations taken by both swift and fermi also suggest that the broadband spectral energy distribution is similar to those of flat - spectral radio quasars . recent photometry from the guide star catalogs 2.21 is mag . previous studies revealed multi - wavelength variabilities in the object at timescales from day to year . previous radio observations indicate its fluctuation in the radio band on the timescale from weeks to years . also said that the object shows long - term variability in both the radio and optical bands . the amplitude of the variation in the radio can be within a year . the long - term variability amplitude may be about 1 mag in the optical band . the latest multi - wavelength campaign carried out by discovered an optical variability on day timescales . dramatic flux variabilities in both x - rays and radio 37 ghz were also found in the study . in this letter , we report an optical monitor for the rl - nls1 sdssj094857.3 + 002225 . the monitor was designed to search for intranight optical variability ( inov ) in the object . the inov should be detected if the object indeed hosts a relativistic jet beaming toward the observers . our observations were carried out at the xinglong observatory of national astronomical observatories , chinese academy of sciences ( naoc ) , using the 80 cm tnt telescope . the telescope is a cassegrain system beam . a liquid nitrogen cooled pi va1300b 1300 ln ccd was used as the detector that covers arcmin of the sky . each pixel of the ccd corresponds to .5 arcsec . gain and readout noise of the ccd is 2.3 electrons adu and 5 electrons , respectively . the standard johnson b - and r -band filters were used in the observations . we monitored the object on seven moonless nights in 2009 . they are february 27 , march 1 , 5 , and april 2426 , and 28 . the typical exposure time is for each frame . continuous monitoring for this object was run as long as possible in each night . the sky flat - field frames in both b and r passbands were obtained before and after each observation run during the twilight time . dark frames are not needed because the temperature of the detector is so low ( c ) that the dark electrons can be entirely ignored . the observed data are preliminarily reduced through the standard routine by iraf package , including bias and flat - field corrections . several bright comparison stars are selected from the same ccd frame to calculate differential light curve . because the comparison stars are brighter than the object , several check stars brightness comparable to the object are selected to assess the errors in photometry . the instrumental magnitudes of the object and of those selected stars are calculated by the apphot task . the aperture photometry is adopted because the object is a point - like source without extended emission . in each frame , the fwhm of the object is comparable those of the field stars . the circular aperture radius twice of the mean fwhm of the field stars was therefore adopted in our calculations . all the results reported below are based on these radii . our observations can be divided into two parts . both of them contain about 1 week . the source was well monitored on the nights of 2009 february 27 , march 1 , march 5 , april 25 , and april 28 . ( the corresponding dates on the time - axis of figure 1 are 3345 , 3347 , 3351 , 3402 , and 3405 , respectively . ) there were no or only scarce data on the other nights because of the bad weather . the intrinsic brightness of the comparison stars was obtained by the formulae given by lupton ( 2005 ) and the sloan digital sky survey ( sdss ) database was used . then the apparent magnitudes of the object can be calculated from the differential instrumental magnitudes . the light curves of the observations are plotted in figure 1 . the upper two light curves show the variation of the object in the b ( by blue solid squares ) and r ( by red solid circles ) bands . the corresponding variations of the comparison stars are plotted by the bottom to light curves . the fluctuations of the comparison stars are not larger than 0.05 mag . the error bars overplotted on the light curve are estimated from the selected check stars brightness comparable to that of the object . in addition to a long - term variation amplitude about 1 mag , the obtained light curves indicate that there were several nights during which the inov can be clearly identified in the object in both the b and r bands . the variations in both bands are similar to each other . the amplitudes of the rapid variations are so large that the short - term variability is quite obvious on 2009 march 1 , 5 , and april 25 . in particular , the weather was relatively good on 2009 march 1 and april 25 , which results in relatively smaller error bars . for example , the typical error bars on april 25 are 0.05 mag and 0.02 mag in the b and r bands , respectively . the brightness of the object changes about 0.50.6 mag in both bands within several hours on the same night . the inset in figure 1 shows the details of the variation within 4 hr on the night of april 25 . although the errors are relatively large on the nights of march 5 and april 28 because of the relatively poor weather , the presence of inov can still be identified from the observations . when we do aperture photometry , there is a problem that whether the contamination from the host galaxy of the target agn contributes to the light variability . some authors argued that the fluctuations in the seeing may result in spurious variable contributions from the host galaxy within the photometric aperture , especially when the apertures are small . we argue that the contamination from the host galaxy is not important in the current study . first of all , no clear features of the host galaxy could be identified from the images taken by sdss , likely because the object is far away from us ( at ) . thus , the host galaxy is much fainter than the agn . second , as described above , the photometry apertures we adopted in this study are twice of the fwhm of field stars , which is large enough to include most of the emission from the underlying host galaxy . the particular rl - nls1 galaxy sdssj094857.3 + 002225 was monitored in optical bands by naoc 80 cm tnt telescope to search for its inov phenomenon . our optical monitoring indeed provides clear evidence for the presence of inov in both the b and r bands in the object . the object exhibits optical variability not only on the timescale of a week , but also on several hours . the detection of the inov indicates that the object contains a relativistic jet on the line of sight of an observer , which confirms the conclusion drawn from the high - energy observations ( e.g. , abdo et al . 2009a , 2009b ) and from the inverted radio spectrum and high brightness temperature ( zhou et al . 2003 ) . sdssj094857.3 + 002225 is particular for its observational properties . on the one hand , its optical spectrum strong emission is typical of nls1s . the narrow h emission yields a relatively low black hole ( bh ) mass and a high eddington ratio ( zhou et al . 2003 ) . on the other hand , some observational behaviors are characteristic of blazars relativistic jets close to the line of sight , such as the inov detected here , flat radio spectrum , high brightness temperature , and variable -ray emission ( see citations in section 1 ) . so far , outstanding rl - nls1s blazer - like radio emission have been revealed by multi - wavelength observations in several cases including the object sdssj094857.3 + 002225 . we refer the reads to yuan et al . ( 2008 ) for a brief summarization . successful launch of fermi satellite , -ray emission was detected in four rl - nls1s , including the object studied here , which suggests the presence of fully developed jets in these objects . the authors argued that the four rl - nls1s may form a new class of -ray agns because of their small bh masses , large eddington ratios , and possibly disk - like morphology of the host galaxies . the intrinsic mechanism of rl - nls1s is an attractive field . there are two possible models for interpreting rl - nls1s . the first one is the inclination model . the model suspects that the ( at least a fraction of ) rl - nls1s are preferentially viewed pole - on . the observed narrow width of the balmer emission lines could be resulted from small inclination if the broad - line region ( blr ) is constrained to a plane . in fact , there is some evidence supporting a flat blr in some rl - agns . in this scenario , the bh mass is largely underestimated in these objects since the current available estimation of the bh mass of agn from single - epoch spectroscopic observation comes from an assumption of an isotropic distribution of the broad - line clouds random orbital inclinations . although the inclination model sounds reasonable because it is able to shift the location of rl - nls1s on the plane to the massive bh end , the massive bhs are not supported by the lack of massive bulges in several cases in which the host galaxies can be resolved . the second is the accretion mode model . the rl - nls1s small bh masses are accreting close to or even above the eddington limit . low - mass bhs may lead to narrow emission lines when keplerian velocities are considered mostly . the accretion is thought related to the radio emission . different accretion modes may result in different phenomena and maybe can explain the differences in the radio loudness . accretion processes are known related to the spin of the accreting bhs . so the rapid spin of bhs may also affect the radio loudness of nls1s . it is possible that accretion mode combining spin can explain the nature of the rl - nls1s . although our monitor indicates that the extremely high radio emission in rl - nls1 sdssj0948 + 57.3 + 002225 is mainly contributed from the beamed non - thermal jet small viewing angle ( can also be found in the aforementioned other studies ) , more information is needed in the future to investigate the origin of the relativistic jet . we are very grateful to dr . s. komossa for her helpful discussion and useful suggestions .", "summary": "sdssj094857.3 + 002225 is a very radio - loud narrow - line seyfert 1 ( nls1 ) galaxy . here , we report our discovery of the intranight optical variability ( inov ) of this galaxy through the optical monitoring in the b and r bands that covered seven nights in 2009 . violent rapid variability in the optical bands was identified in this rl - nls1 for the first time , and the amplitudes of the inov reaches 0.5 mag in both the b and r bands on the timescale of several hours . the detection of the inov provides a piece of strong evidence supporting the fact that the object carries a relativistic jet small viewing angle , which confirms the conclusion drawn from the previous multi - wavelength studies ."}
{"article": "magneto - optical ( mo ) effects have found important applications in data storage , telecommunications , imaging , spectroscopy, as well as in magnonics . an increasingly broad application of nanotechnologies in these areas sets new requirements for novel mo devices by demanding , among other things , a stronger mo response and smaller dimensions . for example , small dimensions are important for d imaging systems based on holographic principles. such systems require a spatial light modulator ( slm ) a device used to modulate amplitude , phase , or polarisation of light waves in space and time . basically , an slm device can produce high quality d images if it possesses pixels sizes m and also is fast enough to address a large number of pixels within a single image frame . slm devices exploiting mo effects have a very fast response time . however , their typical pixel sizes are m. at the nanoscale , mo effects can be enhanced by using subwavelength diffraction gratings , magneto - photonic crystals , and nanoantennas , which are made of pure magnetic materials or consist of alternating magnetic - nonmagnetic layers . however , as a typical grating period is nm and there should be tens of periods to achieve optimal optical properties , the footprint of the grating is large . magneto - photonic crystals often have comparable dimensions and suffer from similar disadvantages . typical dimensions of ferromagnetic / normal metal nanoantennas can be much smaller than m because of magneto - plasmonic resonances which give an additional degree of freedom for light manipulation at the nanoscale. however , due to huge absorption losses in ferromagnetic metals , plasmonic resonance properties of such nanoantennas are not very strong as compared nanoantennas fabricated of gold or silver ( nonmagnetic metals relatively low absorption losses ) . consequently , measures have to be taken to mitigate absorption losses , which can be done by reducing the amount of ferromagnetic metals and tailoring fano resonance effects. . alternatively , by analogy subwavelength gratings, losses in nanoantennas can be reduced by using magneto - dielectrics instead of ferromagnetic metals . normally , magnetic gratings , photonic crystals and nanoantennas are used to enhance the faraday rotation and kerr effect in different configurations . for instance , if the incident light is -polarised and the static external magnetic field is applied perpendicularly to the plane of incidence , the so - called transverse mo kerr effect ( tmoke ) is observed in the reflection mode . less well - known are transverse mo effects observed in the transmission mode . these effects are similar to the tmoke but occur in transparent magnetic films or plates . an example of a transverse mo effect in the transmission mode is the transverse faraday effect ( tfe ) . this effect can be used in imaging , data storage systems and magnonics . the tfe has been observed in transparent magnetic plates and fabry - perot resonators . because the tfe response is amplified as a result of the wave propagating back and forth within a magnetised medium , it is enhanced in a fabry - perot resonator . however , a typical fabry - perot resonator consists of a m - thick plate of a transparent magnetic material sandwiched between a pair of mirrors , which in turn consist of alternating layers of high- and low - refractive - index quarter - wave - thick dielectrics. consequently , the dimensions of the resonator are also very large , which makes it unsuitable for miniaturisation . in this paper , we predict and demonstrate theoretically a large multifrequency tfe in single microspheres made of bi-substituted yttrium - iron magnetic garnet ( bi : yig ) . bi : yig is a magneto - dielectric exhibiting large mo activity and high transparency in the visible and infrared spectral ranges. by exploiting high - quality factor resonances of a bi : yig microsphere we show a strong tfe response at multiple wavelengths at the same time . the strength of the predicted tfe is comparable strength of the tmoke in subwavelength magnetic gratings . moreover , the observed tfe response is higher than that in micron - thick transparent magnetic plates . however , the dimensions of a single sphere are significantly smaller as compared area occupied by a subwavelength grating or the thickness of a plate used in modern mo devices . the problem of light scattering by a homogeneous sphere of arbitrary diameter and dielectric permittivity is exactly soluble by using the mie theory. whereas the mie theory can be extended to calculate the scattering by homogeneous magnetic spheres described by their magnetic permeability , the problem of light scattering by a sphere magnetised along a certain coordinate direction is more difficult . this is because the dielectric permittivity becomes a tensor describing the interaction between the light and the static external magnetic field ( or the internal magnetisation of the medium) by considering bi : yig as an isotropic material , the three diagonal elements of become identical , and in the presence of a static external magnetic field along the y -axis , there is a non - zero off - diagonal element , which couples the x - and z -components of the optical electric field due to low absorption losses in bi : yig the refractive index and of bi : yig can be assumed to be real and also frequency - independent over a narrow range of wavelengths : and . because bi : yig is a ferrimagnetic material , the spin - orbit coupling is the dominant source of the mo interaction and it makes proportional to the magnetisation of the medium . by considering the off - diagonal elements of in the mie theory , one can take into account the physical mechanisms responsible for the mo kerr and faraday effects contribution to the optical response of a sphere . it has been shown that the mo kerr effect in a homogeneous cobalt sphere is small but detectable. the small mo response of cobalt spheres is due to large optical and magneto - optical absorption effects in this ferromagnetic metal . considerable optical absorption losses are typical of all metals , including gold and silver . these losses have long been known to be the drawback of metallic nanostructures used in photonic devices such as , e.g. , nanoantennas . consequently , a large and growing body of research investigates all - dielectric nanostructures , e.g. , low - loss single - sphere nanoantennas . in this context , the use of bi : yig as the model material of the microsphere opens up opportunities to overcome the drawback of metallic ferromagnetic spheres . it is also worth noting brillouin light scattering ( bls ) from spin - wave modes in uniformly magnetised ferromagnetic and ferrimagnetic spheres . the fluctuation of magnetisation due to spin - wave modes causes a time - dependent change of the dielectric permittivity tensor of the material of the sphere . the contribution of the transverse magnetisation to allows generating a description of bls by processes in which a single spin - wave quantum ( magnon ) is created or destroyed . in this case , bi : yig still can be used as the model material of the microsphere because bls has been used to study nonlinear spin wave phenomena in bi : yig structures. furthermore , microspheres can also be made of pure yttrium iron garnet ( yig ) , which is a very well - known material used in magnonics. finally , both semiconductor and ferromagnetic properties have been established in some of the rare earth mononitrides , which thus attract interest for the potential to exploit the spin of charge carriers in spintronics . the refractive index of these materials is and they are also transparent in the visible and infrared spectral ranges. most significantly , these materials also exhibit significant mo activity. thus , they might be employed instead of bi : yig . fig . (a ) schematically shows the scattering by an arbitrary homogeneous nonmagnetic sphere . by applying the mie theory for nonmagnetic spheres we show that the intensity of the forward scattered light has multiple peaks in the spectral range , where is the diameter of the sphere and is the wavelength in the free space . the intensity of the backscattered light in this spectral range is low . this implies that at the resonance the single microsphere has a very directive far - field emission pattern . for example , in order to achieve the maximum forward - scattering intensity in the visible spectral range a bi : yig sphere diameter m is needed . it is noteworthy that a nonmagnetised sphere m will be in the so - called multi - stripe domain state. basically , light can be scattered by the stripe domain structure. however , the strength of this process is very low and it can be neglected , i.e. we will assume that a nonmagnetised bi : yig sphere has the optical properties of a homogeneous nonmagnetic sphere same refractive index . the application of the static magnetic field orientated along the y -axis will magnetically saturate the sphere by aligning the direction of magnetisation inside the sphere along the y -axis . therefore , in the saturated state the mo properties of the sphere can be modelled by using the tensor . in this case , the conventional mie theory can not be applied ; it must be extended employing , e.g. , a perturbation approach. alternatively , approximate approaches such as , e.g. , a modified discrete dipole approximation ( dda ) may be employed . however , these methods have disadvantages . the perturbation approach requires the application of the green s function in spherical coordinates. the application of the dda to large mo spheres may require unaffordable computational efforts. consequently , we will use a finite - difference time - domain ( fdtd ) method . although the fdtd method is also computationally demanding because it uses the staircase approximation of the surface of the sphere and thus requires a very fine finite - difference grid , its application to large mie scattering problems is known to produce accurate results. the computing power of a modern desktop computer is enough for these simulations . furthermore , the fdtd can be applied to scatterers more complex shape than the sphere . of course , in this case for scatterers of a complex shape one also needs to solve a micromagnetics problem to find the distribution of the magnetisation inside the scatterer . the solid line in fig . shows the forward - scattering intensity differential quantifying the strength of the tfe in the microsphere as a function of the normalised wavelength . in this case , is the intensity of the forward - scattered light ( shown for reference in fig . by the dashed line ) and is the saturation magnetisation for bi : yig . the change in the sign of implies the change in the direction of the static external magnetic field by and it leads to the change in the sign of . recall that a similar differential , being the reflectivity , is used to quantify the strength of the tmoke in gratings and other mo devices operating in the reflection mode. however , in contrast to all - magneto - dielectric gratings operating at a single wavelength, in fig . the multiple maxima of are observed at a multiple wavelength corresponding to the sharp resonances supported by the microsphere . we note that the peak values of are of the same order of magnitude as the value of in the gratings. but the footprint of a single microsphere is much smaller than the area occupied by a grating . quantifying the strength of the tfe in the plate as a function of the angle of incidence for the wavelength in the free space nm . dashed line the transmittance of the nonmagnetised plate . thanks to the one - dimensional character of the problem , these results were obtained using the fresnel formula for p -polarised light . , width=321 ] to further demonstrate the advantages of the microsphere over the existing mo devices used to enhance transverse mo effects , we calculate the tfe in a m - thick plate made of bi : yig . such plates have practical applications in fabry - perot resonator - based mo devices. the considered plate is a one - dimensional scatterer spatial variation along the z -direction so that . therefore , for a x - or y -polarised incident wave , there is no z -component of the optical electric and magnetic fields , and for the incident p -polarised light the medium of the plate exhibits an effective refractive index ^{1/2}$ ] ( the medium does not exhibit mo activity for the s -polarised light). due to the dependence of on the magnitude of the transmitted p -light is sensitive to the magnetisation . importantly , the tfe is not bipolar , so changing the direction of the static external magnetic field from to ( i.e. changing ) does not alter the magnitude of the transmission . hence , the tfe is quantified by the differential . importantly , the tfe can take place only in scatterers where a nonhomogeneous or leaky refracted wave is induced by a wave obliquely incident at the interface , i.e. the tfe vanishes at both the normal and grazing incidence. consequently , in fig . (b ) we plot as a function of the angle of incidence for the wavelength in the free space nm . we note that at this wavelength a sphere m would produce the maximum of the tfe response ( fig . ) . figure (b ) shows that in the absence of the static external magnetic field the transmission curve for the p -polarised light has multiple maxima due to interference effects . the curve of the differential follows the behaviour of . around the brewster angle one observes because vanishing surface reflectivity results in minimal interference effects . it is noteworthy that for the chosen thickness of the slab , which is times larger than the diameter of the reference sphere m , the strength of the tfe is ten times smaller than in the sphere . furthermore , in a m - thick plate ( not shown ) the strength of the tfe plummets down because the interference effect is significantly weaker . of course , the fabrication techniques for magnetic films and plates are very much well - established and less effort demanding than those for single magnetic microspheres . however , the recent advances in making ultra - fine magnetic garnet particles make it possible to fabricate single scatterers close - to - spherical shape. yig powders controllable individual particle sizes of m can be obtained by a microwave heating method. furthermore , a magnetic garnet microsphere can be fabricated using direct laser writing . finally , laser - based printing techniques can potentially be applied. we proposed an efficient scheme for enhancing the transverse faraday effect in single magneto - dielectric microspheres . we investigated the scenario of a sphere made of a typical magnetic garnet exhibiting a realistically low absorption and high magneto - optical activity in the visible and infrared spectral ranges . we demonstrated the transverse faraday effect of the order of , which is larger or comparable typical values attainable modern mo devices which , however , have a significantly larger footprint as compared microspheres . our findings may find applications in nanophotonics , imaging , and magnonics .", "summary": "we propose using a single magneto - dielectric microsphere as a device for enhancing the transverse faraday effect at multiple wavelengths at the same time . although the diameter of the sphere can be m , the numerically predicted strength of its magneto - optical ( mo ) response can be an order of magnitude stronger than in mo devices based on thick magnetic plates . the mo response of a microsphere is also comparable that of subwavelength magneto - dielectric gratings which , however , operate at a single wavelength and occupy a large area . in contrast to gratings and thick plates , the compact size of the microsphere and its capability to support spin - wave excitations make it suitable for applications in nanophotonics , imaging systems , and magnonics ."}
{"article": "the proper - motion observations of pulsars show that the pulsars had the kick velocity in the formation stage . the young pulsars have proper velocity of . the physical mechanism of such kick velocity may be due to the harrison tademaru mechanism , anisotropic emission of neutrinos , anisotropic explosion and so on ( see lorimer for the review ) . therefore , it is also reasonable to assume the existence of the proper motion of the pulsars in the formation process of pop iii nss , although there is no direct evidence since no pop iii star or pulsar is observed . while , repetto et al . suggest that bhs also have a natal kick velocity comparable to pulsars from the galactic latitude distribution of the low mass x - ray binaries in our galaxy . but , first , this is not the direct observation of proper motion of bhs , and second , since the mass of pop iii bhs is larger than pop i and pop ii bhs , their kick velocity might be so small that it can be neglected . therefore , we take into account the natal kick for pop iii nss but not for pop iii bhs in this paper . the kick speed obeys a maxwellian distribution as \\,,\\ ] ] where is the dispersion . the details of the method how to calculate the natal kick are shown in ref . . in this paper , we perform population synthesis monte carlo simulations of pop iii binary stars . we calculate the pop iii - bh and pop i and ii - bh for comparison . pop i and pop ii stars mean solar metal stars and metal poor stars whose metallicity is less than 10% of solar metallicity , respectively . in this paper , we consider five metallicity cases of ( pop iii ) , and ( pop i ) . there are important differences between pop iii and pop i and ii . pop iii stars are ( 1 ) more massive , , ( 2 ) smaller stellar radius compared that of pop i and ii , and ( 3 ) no stellar wind mass loss . these properties play key roles in binary interactions . in order to estimate the event rate of - bh mergers and the properties of - bh , we use the binary population synthesis method which is the monte calro simulation of binary evolution . first , we choose the binary initial conditions such as the primary mass , the mass ratio , the separation , and the eccentricity when the binary is born . these binary initial conditions are chosen by the monte calro method and the initial distribution functions such as the initial mass function ( imf ) , the initial mass ratio function ( imrf ) , the initial separation function ( isf ) , and the initial eccentricity distribution function ( ief ) . we adopt these distribution functions for pop iii stars and pop i and ii stars as table .", "summary": "in the population synthesis simulations of pop iii stars , many bh ( black hole)-bh binaries merger time less than the age of the universe are formed , while ( neutron star)-bh binaries are not . the reason is that pop iii stars have no metal so that no mass loss is expected . then , in the final supernova explosion to , much mass is lost so that the semi major axis becomes too large for pop iii - bh binaries to merge within . however it is almost established that the kick velocity of the order of exists for from the observation of the proper motion of the pulsar . therefore , the semi major axis of the half of - bh binaries can be smaller than that of the previous argument for pop iii - bh binaries to decrease the merging time . we perform population synthesis monte carlo simulations of pop iii - bh binaries including the kick of and find that the event rate of pop iii - bh merger rate is . this suggests that there is a good chance of the detection of pop iii - bh mergers in o2 of advanced ligo and advanced virgo from this autumn ."}
{"article": "it has been known for several decades that bright low - mass x - ray binaries ( lmxbs ) are times overabundant in globular clusters ( gcs ) relative to the galactic field ( katz 1975 ; clark 1975 ) . more specifically , gcs contain 13 of the bright galactic lmxbs , but only .01% of the total stellar mass content of the galaxy . the reason for this is thought to be the existence of dynamical lmxb formation channels , which are only available in dense gc cores . potential channels include the direct collision of a neutron star ( ) red giants ( verbunt 1987 , davies et al . 1992 , ivanova et al . 2005 ) , the tidal capture of a main sequence star by a ( fabian , pringle & rees 1975 ; bailyn & grindlay 1987 ) and exchange interactions between nss and primordial binaries ( hilles 1976 ; rasio et al . 2000 ) . if the dominant lmxb formation channels are different in gcs and the galactic field , the properties of their respective lmxb populations may also be different . in particular , most of the bright lmxbs in gcs might be ultracompact x - ray binaries ( ucxbs ; bildsten & deloye 2004 , ivanova et al . ucxbs , which are interacting binaries extremely small binary separations ( cm ) and short orbital periods ( 1 hr ) , appear to be rare amongst the galactic field lmxb population : the list of confirmed ucxbs ( measured ) in int zand et al . ( 2007 ) contains only 5 objects that belong to this population . by contrast , 3 of the 13 gc lmxbs are confirmed ucxbs ; these are 4u1820 - 30 in ngc6624 ( min , stella et al . 1987 ) , 4u1850 - 087 in ngc6712 ( min , homer et al . 1996 ) and cxoj212958.1 + 121002 in m15 ( = m15-x2 ; dieball et al . 2005 ) , several more suggested to be ultracompact x - ray binaries on the basis of more indirect evidence ( see e.g. verbunt & lewin 2006 for a review ) . since the period distribution of gc lmxbs may be a direct tracer of the dynamical close encounters taking place in gc cores , it is important to establish orbital periods for as many of these sources as possible . doing so could also lead to a significant increase in the size of the total ucxb sample . this is desirable , because ucxbs are astrophysically important systems in their own right . this is because they are laboratories for accretion and binary evolution in extreme settings , and because they are strong gravitational wave sources that may be detectable by lisa ( nelemans & jonker 2006 ; nelemans 2009 ) . here , we present time - resolved , far - uv photometry of the lmxb 4u 0513 - 40 in ngc 1851 , which was suspected to be a ucxb based on several strands of circumstantial evidence ( deutsch etal 2000 ; verbunt 2005 ; nelemans & jonker 2006 ; int zand etal . 2007 ) . our far - uv data of this system contain a 17 min periodic signal that is present in all four observing epochs , is consistent being coherent and is probably caused by a reflection effect associated irradiated surface of the donor star in this system . based on all this , we argue that the observed periodic variability is an orbital signature , and thus that 4u 0513 - 40 should be regarded as a confirmed ucxb min . ngc 1851 was observed three times f140lp filter in the solar blind channel ( sbc ) of the advanced camera for surveys ( acs ) on board the hst . this instrument / detector / filter combination has a plate scale of 0.032 pixel , a pivot wavelength of , and an rms bandwidth of . all of the observations took place in august of 2006 . each observing epoch consisted of 4 hst orbits , broken up into a series of 90 second exposures . in total , we obtained 273 of these exposures . in addition , we also examined archival data taken in march of 1999 space telescope imaging spectrograph ( stis ) , using the fuv - mama / f25qtz detector / filter combination , plate scale of 0.025 pixel , and . a full description of the data , as well as their reduction and analysis will be provided in a separate publication ( zurek et al . 2009 , in preparation ) . briefly , all of the fuv count rates and magnitudes presented in this paper were calculated via standard aperture photometry techniques , as implemented in the daophot package within iraf . for the photometry on our acs / sbc ( stis / fuv - mama ) images , we used an aperture radius of 4 ( 7 ) pixels and a sky annulus extending from 10 to 20 ( 15 to 35 ) pixels . aperture photometry is sufficient for our purposes because the fuv image is not particularly crowded ( see figure 1 ) . the wavelength - dependent throughput curves of the acs / sbc / f140lp and stis / fuv - mama / f25qtz instrument / detector / filter combinations are very similar , though not identical . therefore we checked for far - uv variability by comparing the acs and stis count rates , after correcting for throughput differences and the different photometric aperture sizes and background regions that were used . we have calculated this correction factor from a set of ( mostly blue horizontal branch ) stars that are common to both sets of images . we find that for these stars , our acs / sbc count rates are 3.3 times larger than our stis / f25qtz ones . homer et al . ( 2001 ) have already used the hst / stis / f25qtz observations to identify the optical / far - uv counterpart of 4u 0513 - 40 . they confirm the suggestion of deutsch et al . ( 2000 ) that `` star a '' ( in the nomenclature of deutsch et al . ) is the correct counterpart to the lmxb , while two other blue sources previously suggested as possible counterparts by aurire , bonnet - bidaud & koch - miramond ( 1994 ) , designated as x-1 and x-2b , are inconsistent precise chandra position of 4u 0513 - 40 . figure 1 shows the location of these 3 sources in our acs / sbc images . since homer et al . ( 2001 ) had already reported a negative search for far - uv variability associated star a in the stis observations , we started by focusing on the newer , higher signal - to - noise acs data . the acs - based far - uv light curves of all 3 objects are shown in figure 2 . it is immediately obvious that star a , the counterpart proposed by deutsch et al . ( 2000 ) and homer et al . ( 2001 ) , does , in fact , exhibit strong far - uv variability , especially between the 3 observing epochs . for example , the mean count rate drops by a factor of about 2 between epochs 2 and 3 . no similar change in count rate is seen in either x-1 or x-2b , which bracket star a in far - uv brightness . we then searched for periodic signals in the data by carrying out a power spectral analysis . figure 3 shows the lomb - scargle power spectra calculated for all 3 sources from the combined acs data sets . it is immediately obvious that only star a shows clear evidence of a signal at a frequency other than hst s orbital frequency . more specifically , there is an obvious peak at a frequency of about c d ( which corresponds to a period of min ) . in an effort to better understand the star a power spectrum ( specifically the power excess at and the sidebands at ) , we have created a simple model light curve . this model has exactly the same time sampling as the observations , contains a single 17-min periodic signal amplitude 0.75 c s and accounts for the dominant long - term trend in the data by setting the simulated mean count rate in each epoch equal to the observed one . the power spectrum generated from this simple noise free model is shown in the second panel of figure 3 ( labelled `` star a simulation '' ) , and clearly captures all of the main features of the data . this shows that both the sidebands around and the strong apparent signal at are sampling artifacts . the latter , in particular , is due to leakage from the low - frequency power excess associated long - term variability . in order to test if the 17 min signal is persistent , we carried out power spectral analysis on each epoch independently , where we now also included the stis data that was obtained 7 years before the acs observations . the result is shown in figure 4 . the periodicity was indeed present in all 4 epochs ( 1 stis + 3 acs ) , but was noticeably weaker in the stis data and in the third acs epoch . considered in isolation , the power excess at in each of those epochs would be marginally significant at best . both figures 3 and 4 show that there are several possible aliases associated 17 min signal . in order to establish the relative likelihoods for each of these and get estimates of the errors associated each of them , we carried out a bootstrap analysis . only the acs data was used for this purpose , since the signal is weakest in the stis data and since no unique cycle count can be assigned to the large time interval between the stis and acs observations . we began by removing long - term trends from the data stream by estimating the mean count rate in each hst orbit and subtracting these averages from the data . next , we created 1000 mock time series by sampling replacement from the orbit - mean - subtracted acs data . finally , we created power spectra for all of these fake data sets and recorded the frequencies corresponding to peak flux . the histogram created from this set of peak frequencies is shown in figure 5 ( superposed on the orbit - mean subtracted power spectrum for all of the data , which is shown as the shaded region ) . as expected from the power spectrum , there are clearly four dominant plausible aliases . the relative number of bootstrap trials associated each alias is a measure of the likelihood that this alias is the correct one ( see southworth et al 2006 , 2007 , 2008 and dillon et al . 2008 ) . similarly , the location and width of the histogram peak associated each alias provides a simple estimate of the period and period error for this alias . our final results for the four viable aliases are : we also tried to establish more directly whether the periodic signal is consistent being coherent across all of our epochs and whether the evidence for a changing amplitude is compelling . to this end , we carried out a least - squares fit to the orbit - mean - subtracted stis+acs data set for star a. in this fit , the period was kept fixed at that are present in the power spectrum of the combined stis+acs data . ] , so the free parameters were the phase and amplitude ( both assumed to be constant across the data ) . the result of this fit is shown in figure 6 . it illustrates rather clearly that the amplitude is not constant across epochs . as already noted above , the signal is strongest in acs epochs 1 and 2 and weakest in the stis data and acs epoch 3 . the fit also shows that the assumption of constant phase is reasonable , i.e. the observed signal is consistent being coherent across the entire data set . in order both to test further the coherence properties of the signal , and to determine its average waveform , we have folded the entire stis+acs data stream for star a onto the same ( sub-)alias that was adopted for the fit in figure 6 . the result is shown in figure 7 , along phase - binned average waveform . again , the data seem to be consistent idea that the signal is fully coherent . moreover , the average waveform is fairly simple and roughly sinusoidal . as a final step , we carried out separate fits fixed period to each individual epoch in order to quantify the changing amplitude of the 17-min signal . table 1 lists the mean count rates and absolute as well as fractional amplitudes of the signal as estimated from these fits . the fractional amplitude varies by over a factor of 3 between epochs , from about 3% to 10% , largest change happening across the 6-day gap between acs epochs 2 and 3 . it is also worth noting that there appears to be a correlation between the fuv brightness of the system ( i.e. the mean count rate ) and the amplitude of the 17-min signal , in the sense that the amplitude is highest when the system is brightest . this correlation holds regardless of whether the amplitude is expressed in absolute or fractional terms . it is worth noting that there is no inconsistency between our claim that the 17-min signal is present in the stis observations , and the non - detection of a periodicity in the same data set by homer et al . ( 2001 ) . as mentioned above , the signal is only marginally detectable if this data set is analysed in isolation . what makes the weak power excess in the stis observations convincing is that it is located at the same frequency as the obvious signal in the acs data set . indeed , homer et al . ( 2001 ) place a formal upper limit of 5% on the amplitude of any signal between 5 min and 6 hrs . this is entirely consistent own estimate of a 4% amplitude for the 17 min signal in the stis data ( see table 1 ) . we have shown that the fuv counterpart to 4u 0513 - 40 in ngc 1851 exhibits a clear periodic signal min . this signal is roughly sinusoidal , has an amplitude of 3%-10% , is present in all four fuv observing epochs and is consistent being fully coherent . these properties are in line those of the orbital signals seen in uv / optical observations of other ucxb ( e.g. homer et al . 1996 ; anderson et al . 1997 ; dieball et al . 2005 ) and simple model in which these signals are due to a `` reflection effect '' associated irradiated donor star in the system ( arons & king 1993 ) . in the arons & king ( 1993 ) model , there are two components that contribute to the fuv / optical light : the irradiated front face of the donor star ( which is likely to be a low - mass , helium - core white dwarf ) , and the accretion disk , whose energy budget is also dominated by irradiation . the observed orbital signal is due to the changing projected area of the irradiated face of the donor star , fractional amplitude being set by the relative contributions of the disk and donor to the phase - averaged fuv / optical light . we have checked that this simple irradiation model matches roughly the fractional fuv signal using reasonable choices of parameters ( including a moderate - to - high inclination ) . the dependence on total fuv brightness is explained straightforwardly by different fuv responses of the donor and disk to variations in the irradiating x - ray luminosity . in this context , a factor of 2 change in total fuv and fractional amplitude would requires roughly an order of magnitude variation in . this is consistent x - ray variability of the source in the rxte data base , where factor of 10 changes in count rate are seen on time - scales as short as weeks . for comparison , the largest previously reported variations in x - ray luminosity from this source were a factor of 5 ( grindlay & hertz 1983 ) . it seems likely that additional effects such as changes in radius , changes in reprocessing efficiency , and disk shielding , play a significant role in the variations of the amplitude of the uv oscillations . based on all this , we are confident that the fuv signal we have discovered is orbital in nature and probably due to a simple reflection effect . we therefore confirm 4u 0513 - 40 as a ucxb min , making it the fourth confirmed ucxb in a galactic gc . the identification of this system as a ucxb is entirely consistent existing circumstantial evidence regarding its nature . more specifically , the optical brightness , x - ray spectrum and burst properties of 4u 0513 - 40 have been known for some time to point towards a ucxb classification ( e.g. verbunt 2005 ) . given the extremely short orbital period we have measured , it is interesting to ask if the gravitational wave signal produced by this source would be detectable by lisa . the gravitational radiation strain for a circular orbit is given in a convenient form by nelemans , yungelson & portegies zwart ( 2001 ) as : where , is the mass of the neutron star primary , and is the mass of the white dwarf donor , and power coming out entirely in the second harmonic , for a circular orbit . if we adopt , kpc ( harris 1996 ) and ( suggested for this by the mass - radius relations in deloye & bildsten ) , we find a strain of . this is at approximately the 1- level for a one year integration lisa , suggesting that the system may be detectable if the mission lifetime is several years . in practice , this will , however , also depend on the strength and frequency - dependence of the gravitational - wave background due to double wds , which may become dominant in the relevant frequency regime ( mhz ; e.g. nelemans et al . an additional challenge for detecting gravitational radiation from this object will be dealing possible effects of acceleration of the binary in the gravitational potential of the globular cluster , which could lead to a measurable frequency drift over several years , for which a correction would have to be made in order to keep all the gravitational wave power in a single frequency bin . the fact that the position and period of the source are already known ( and the latter can still be substantially improved before lisa starts ) will be helpful in this context and also ameliorate the hidden trials problem . we finally point out that , as more ucxb periods are being determined , it seems increasingly likely that there are significant differences between the period distributions of field and gc ucxbs . all four of the confirmed gc ucxbs have min , whereas all five of the confirmed field ucxbs have min ( nelemans & jonker 2006 ; int zand , jonker & markwardt 2007 ) . clearly , this comparison can not yet be taken at face value : the present numbers are still too small and selection effects have not been taken into account . moreover , there is probably no absolute dividing line between the two orbital period distributions . for example , the field lmxb 4u 1543 - 624 probably has an orbital period of around 18 minutes ( wang & chakrabarty 2004 ) , even though it is not yet included in the list of confirmed ucxbs given by nelemans & jonker ( 2006 ) and int zand et al . ( 2007 ) . nevertheless , the period distributions are in line expectation that different ucxb formation channels should dominate in the two different environments . if so , it may be possible to use the period distribution of field ucxbs as a tracer of binary evolution , and that of gc ucxbs as a tracer of stellar dynamics in dense environments .", "summary": "we present far - ultraviolet photometry obtained hubble space telescope of the low - mass x - ray binary 4u 0513 - 40 in the globular cluster ngc 1851 . our observations reveal a clear , roughly sinusoidal periodic signal min and amplitude 3%-10% . the signal appears fully coherent and can be modelled as a simple reprocessing effect associated changing projected area presented by the irradiated face of a white dwarf donor star in the system . all of these properties suggest that the signal we have detected is orbital in nature , thus confirming 4u 0513 - 40 as an ultracompact x - ray binary ( ucxb ) . all four confirmed ucxbs in globular clusters have orbital periods below 30 minutes , whereas almost all ucxbs in the galactic field have orbital periods longer than this . this suggests that the dynamical formation processes dominate ucxb production in clusters , producing a different orbital period distribution than observed among field ucxbs . based on the likely system parameters , we show that 4u 0513 - 40 should be a strong gravitational wave source and may be detectable by lisa over the course of a multi - year mission ."}
{"article": "suppose that at a gas of diffusing particles of constant density is brought in contact spherical absorber of radius in dimensions . the particles are absorbed upon hitting the absorber . remarkably , this simple setting captures the essence of many diffusion - controlled chemical kinetic processes . the evolution of the average coarse - grained particle density of the gas is described by the diffusion equation , \\ ] ] where is the gas diffusivity . here we will be interested in large fluctuations rather than in the average behavior . one important fluctuating quantity is the number of particles that is absorbed during a long time . we will focus on two questions : ( i ) what is the probability that , that is no particle hit the absorber until time ? ( ii ) what is the most likely history of the particle density of the gas conditional on the non - hitting until time ? these questions also appear in the context of a search for an immobile target by a swarm of diffusing searchers , see e.g. ref . and", "summary": "suppose that a lattice gas of constant density , described by the symmetric simple exclusion process , is brought in contact target \" : a spherical absorber of radius . employing the macroscopic fluctuation theory ( mft ) , we evaluate the probability that no gas particle hits the target until a long but finite time . we also find the most likely gas density history conditional on the non - hitting . the results depend on the dimension of space and on the rescaled parameter , where is the gas diffusivity . for small and , is determined by an exact stationary solution of the mft equations that we find . for large , and for any in one dimension , the relevant mft solutions are non - stationary . in this case scales differently relevant parameters , and it also depends on whether the initial condition is random or deterministic . the latter effects also occur if the lattice gas is composed of non - interacting random walkers . finally , we extend the formalism to a whole class of diffusive gases of interacting particles ."}
{"article": "in cold dark matter cosmology , the initially smooth distribution of matter in the universe is expected to collapse into a complex network of filaments and voids , structures which have been termed the `` cosmic web '' . the filamentary distribution of galaxies in the nearby universe has been revealed in detail by recent large galaxy redshift surveys such as the 2dfgrs ( colless et al . 2001 , baugh et al . 2004 ) , the sloan digital sky survey ( sdss , stoughton et al . 2002 , doroshkevich et al . 2004 ) and the 2 all sky survey ( 2mass , maller et al . numerical simulations successfully reproduce this network ( jenkins et al . 1998 ; colberg et al . 2004 ) and indicate that galaxies are only the tip of the iceberg in this cosmic web ( katz et al . 1996 ; miralda - escud et al . hydrodynamic simulations suggest that at the present epoch , in addition to dark matter and galaxies , the filaments are also composed of a mixture of cool , photoionised gas ( the low remnants of the forest ) and a shock heated , low - density gaseous phase at temperatures between k and k that contains most of the baryonic mass , the `` warm - hot '' intergalactic medium ( whim , cen & ostriker 1999 ; dav et al . 1999 ) . observational constraints on the physical conditions , distribution , a nd metal enrichment of gas in the low - redshift cosmic web are currently quite limited . the existence of the whim appears to be a robust prediction of cosmological simulations ( dav et al . thus , observational efforts are increasingly being invested in the search for whim gas and , more generally , the gaseous filamentary structures predicted by the models . large - scale gaseous filaments have been detected in x - ray emission ( wang et al . 1997 ; scharf et al . 2000 ; tittley & henriksen 2001 ; rines et al 2001 ) . however , x - ray emission studies current facilities predominantly reveal gas which is hotter and denser than the whim ; this x - ray emitting gas is not expected to contain a substantial portion of the present - epoch baryons ( dav et al . the most promising method for observing the whim in the near term is to search for uv ( oroman6 , neroman8 ) and x - ray ( oroman7 , oroman8 , neroman9 ) absorption lines due to whim gas in the spectra of background qsos / agns ( tripp et al . 2000 , 2001 ; savage et al . 2002,2005 ; nicastro et al . 2002 ; bergeron et al . 2002 ; richter et al . 2004 ; sembach et al . 2004 ; prochaska et al . 2004 ; danforth & shull 2005 ) . while absorption lines provide a sensitive and powerful probe of the whim , the pencil - beam nature of the measurement along a sight line provides little information on the context of the absorption , e.g. , whether the lines arise in an individual galaxy disk / halo , a galaxy group , or lower - density regions of a large - scale filament or void . thus , to understand the nature of highly ionised absorbers at low redshifts , several groups are pursuing deep galaxy redshift surveys and observations of qsos behind well - defined galaxy groups or clusters . for example , to study gas located in large - scale filaments , bregman et al . ( 2004 ) have searched for absorption lines indicative of the whim in regions between galaxy clusters / superclusters and have identified some candidates . in this paper , we carry out a similar search as part of a broader program that combines a large hst survey of low oroman6 absorption systems observed on sight lines to low quasars ( tripp et al . 2004 ) and a ground based survey to measure the redshifts and properties of the galaxies foreground to the background qsos . the ground based survey is done in two steps : first , multi - band ( u , b , v , r and i ) imagery is obtained to identify the galaxies and to estimate their photometric redshifts . then , spectroscopic redshifts are obtained for the galaxies that are potentially ( according to the photometric redhshifts ) at lower redshift that the background object . as part of the large hst survey , we have observed the quasar hs0624 + 6907 ( = 0.3700 ) e140 m echelle mode of the space telescope imaging spectrograph ( stis ) on board the hubble space telescope . we have also obtained multiband images and spectroscopic redshifts of galaxies in the 0624 field . the sight line to 0624 passes by several foreground abell clusters and provides an opportunity to search for gas in large - scale filaments . we shall show that gas ( absorption systems ) and galaxies are detected at the redshifts of the structures delineated by the abell clusters in this direction . while the absorbing gas is intergalactic , and it is likely that we are probing gas in cosmic web filaments , the properties of these absorbers are surprising . instead of low - metallicity whim gas , we predominantly find cool , photoionised , and high - metallicity gas in these large - scale structures . this paper is organized as follows . the observations and data reduction procedures are described in 2 , including hst /stis and far ultraviolet spectroscopic explorer observations as well as ground - based imaging and galaxy redshift measurements . in 3 , we present information on the foreground environments probed by the 0624 sight line , derived from the literature on abell clusters and from our new galaxy redshift survey . the absorption - line measurement methods are described in 4 , and we investigate the physical state and metallicity of the absorbers in 5 . section 6 reviews the properties of the full sample of ly lines derived from the stis spectrum emphasis on the search for broad ly lines . section 7 discusses the implications of this study , and we summarize our conclusions in 8 . throughout this paper , we use the following cosmological parameters : , and . 0624 was observed stis on 2 jan . 2002 and 23 - 24 feb . 2002 as part of a cycle 10 hst observing program ( id=9184 ) . the echelle spectrograph was used e140 m grating which provides a resolution of 7 fwhm and covers the 1150 range only a few small gaps between orders at wavelengths greater than 1630 . the entrance aperture was used to minimize the effect of the wings of the line spread function . the total exposure time was 61.95 ksec . the data were reduced as described in tripp et al . ( 2001 ) using the stis team version of calstis at the goddard space flight center . the final signal - to - noise ( s / n ) per resolution element is 3 at 1150 , increases linearly to 14 at 1340 and then decreases to 7 at 1730 . for further information on the design and performance of stis , see woodgate et al . ( 1998 ) and kimble et al . ( 1998 ) . hs0624 + 6907 was also observed by the pi team on several occasions between 1999 november and 2002 february ( program ids p1071001 , p1071002 , s6011201 , and s6011202 ) . records spectra four independent spectrographs ( `` channels '' ) , two coatings for coverage of the 905 wavelength range , and two coatings optimized to cover 1100 ( see moos et al . 2000,2002 for details about design and performance ) . the spectrograph resolutions range from 20 km s ( fwhm ) . for hs0624 + 6907 , the total integration time in the lif1 channel was 110 ksec ; the other channels had somewhat lower integration times due to channel coalignment problems during some of the observations . we have retrieved the spectra from the archive and have reduced the data using calfuse version 2.4.0 as described in tripp et al . ( 2005 ) . because the spectra in the individual channels have modest s / n ratios , we have aligned and combined all available lif channels to form the final spectra that we used for our measurements ( we find that combining all available lif data does not degrade the spectral resolution ) . for the spectral range uniquely covered by the sic channels , we used only the sic2a data . finally , we compared absorption lines of comparable strength ( e.g. , feroman2 .94 vs. feroman2 .45 ) observed by fuse and stis in order to align the fuse spectrum stis spectrum and thereby correct the wavelength zero point of the data . one of the primary goals of our low qso absorption line program is to study the connections between galaxies and absorption systems . these studies require good imaging ( for galaxy target selection and information on individual galaxies of interest ) followed by optical spectroscopy for accurate redshift measurements . to initiate the galaxy - absorber study toward 0624 , we first obtained a mosaic of images centered on the qso spicam on the apache point observatory ( apo ) 3.5 m telescope on 2002 october 5 . subsequently , we obtained images of a larger field in better seeing noao 8kk ccd mosaic camera ( mosa , muller et al . 1998 ) , on the kitt peak national observatory ( kpno ) 4 m telescope . the spicam images were used to select targets for the first spectroscopic observing run , but thereafter we only used the better - quality mosa images . 0624 was observed mosa on the 4 m on 2003 january 29 - 30 . the field of view is scale of /pixel . as summarized in table , images were recorded in and standard dithering pattern for filling in gaps between the ccds and for rejection of cosmic rays . photometric standard stars from landolt ( 1992 ) were also observed at regular intervals . during these observations , the seeing ranged from to 1 . the data were reduced iraf software package mscred following standard procedures . the final r - band mosa image of 0624 is shown in figures and . galaxy targets for follow - up spectroscopy were selected from the images using the sextractor software package ( bertin & arnouts 1996 ) . redshifts of 29 galaxies were obtained using the double imaging spectrograph ( dis ) on the apo 3.5 m telescope on the following dates : 2002 november 12 , 2003 january 29 , 2003 april 03 , 2003 april 21 , and 2003 december 25 . spectra were recorded using a single 1.5 arcsec wide slit total exposure times ranging from 360 to per object . the data were processed in the conventional manner , and were wavelength calibrated using helium - neon - argon arc - lamp exposures . small zero - point offsets in wavelength were applied as needed , after comparing observed skyline wavelengths their rest values . the spectra were typically recorded at resolutions of fwhm . llccccccccc & & & & & & & & & + & & & & & & & & & & & qso & 06:30:02.50 & 69:05:03.99 & 0.3700 & 0.0 & 0.000 & 13.8 & 14.2 & 0.1 & -27.7 + 01 & se12 & 06:30:41.70 & 68:58:32.71 & 0.0327 & 7.4 & 0.290 & 16.6 & 17.8 & 1.0 & -19.2 + 02 & se3 & 06:30:55.32 & 69:02:41.99 & 0.0424 & 5.3 & 0.265 & 19.6 & 20.5 & 0.9 & -16.7 + 03 & ne1 & 06:30:56.14 & 69:08:00.90 & 0.0547 & 5.6 & 0.358 & 15.9 & 17.0 & 0.9 & -21.0 + 04 & nw2 & 06:29:46.66 & 69:08:03.59 & 0.0560 & 3.3 & 0.216 & 18.6 & 19.5 & 0.9 & -18.4 + 05 & se4 & 06:30:33.00 & 68:53:02.00 & 0.0622 & 12.3 & 0.887 & 16.8 & 17.9 & 0.9 & -20.5 + 06 & se5 & 06:32:55.20 & 68:56:59.99 & 0.0637 & 17.4 & 1.282 & 16.8 & 18.3 & 1.3 & -20.5 + 07 & se8 & 06:31:01.79 & 68:57:35.89 & 0.0638 & 9.2 & 0.675 & 16.0 & 17.1 & 0.9 & -21.2 + 08 & se1 & 06:30:11.22 & 69:02:09.61 & 0.0640 & 3.0 & 0.222 & 18.8 & 19.4 & 0.7 & -18.5 + 09 & sw3 & 06:29:07.80 & 69:03:32.01 & 0.0650 & 5.1 & 0.384 & 17.4 & 18.3 & 0.9 & -20.0 + 10 & se13 & 06:30:58.30 & 69:04:34.11 & 0.0650 & 5.0 & 0.375 & 16.9 & 18.5 & 1.3 & -20.4 + 11 & se6 & 06:32:50.70 & 68:56:03.00 & 0.0652 & 17.6 & 1.318 & 15.9 & 17.3 & 1.2 & -21.5 + 12 & ne3 & 06:30:21.40 & 69:05:39.70 & 0.0655 & 1.8 & 0.135 & 16.6 & 18.1 & 1.3 & -20.8 + 13 & nw11 & 06:29:23.48 & 69:22:43.29 & 0.0660 & 18.0 & 1.367 & 16.3 & 17.9 & 1.3 & -21.1 + 14 & se7 & 06:32:49.20 & 68:56:00.39 & 0.0664 & 17.5 & 1.334 & 17.0 & 18.0 & 0.7 & -20.4 + 15 & ne2 & 06:32:25.55 & 69:20:05.81 & 0.0733 & 19.7 & 1.646 & 16.5 & 18.0 & 1.3 & -21.1 + 16 & nw1 & 06:29:43.65 & 69:09:35.33 & 0.0760 & 4.8 & 0.417 & 15.9 & 17.3 & 1.1 & -21.8 + 17 & sw2 & 06:28:33.03 & 68:59:26.30 & 0.0763 & 9.8 & 0.849 & 16.6 & 18.3 & 1.3 & -21.1 + 18 & se9 & 06:30:14.81 & 68:49:44.79 & 0.0764 & 15.4 & 1.334 & 16.4 & 18.0 & 1.3 & -21.3 + 19 & nw12 & 06:29:11.59 & 69:07:07.89 & 0.0764 & 5.0 & 0.433 & 16.4 & 18.0 & 1.4 & -21.3 + 20 & se10 & 06:32:52.40 & 68:57:59.01 & 0.0764 & 16.8 & 1.457 & 16.5 & 18.1 & 1.3 & -21.2 + 21 & nw3 & 06:29:53.77 & 69:08:20.51 & 0.0766 & 3.4 & 0.293 & 18.3 & 19.6 & 1.1 & -19.4 + 22 & sw1 & 06:29:33.24 & 69:05:01.00 & 0.0903 & 2.6 & 0.264 & 17.1 & 18.2 & 0.9 & -21.0 + 23 & se11 & 06:30:06.84 & 68:52:22.20 & 0.1001 & 12.7 & 1.407 & 16.5 & 18.1 & 1.2 & -21.9 + 24 & nw7 & 06:26:43.70 & 69:14:06.91 & 0.1009 & 19.9 & 2.215 & 16.7 & 18.2 & 1.4 & -21.6 + 25 & nw9 & 06:29:03.89 & 69:17:33.40 & 0.1108 & 13.5 & 1.639 & 16.4 & 18.2 & 1.3 & -22.2 + 26 & nw4a & 06:29:35.43 & 69:07:25.80 & 0.1125 & 3.4 & 0.415 & 18.5 & 20.2 & 1.2 & -20.1 + 27 & nw8 & 06:28:29.39 & 69:17:28.89 & 0.1126 & 14.9 & 1.832 & 16.7 & 18.5 & 1.3 & -21.9 + 28 & nw10 & 06:29:05.25 & 69:17:46.69 & 0.1129 & 13.7 & 1.685 & 18.1 & 19.9 & 1.3 & -20.5 + 29 & nw6 & 06:29:35.30 & 69:09:44.99 & 0.1429 & 5.3 & 0.794 & 19.4 & 20.4 & 0.8 & -19.8 + 30 & se2 & 06:30:44.35 & 69:01:08.09 & 0.1664 & 5.4 & 0.927 & 19.3 & 20.8 & 1.0 & -20.2 + 31 & nw5 & 06:29:43.52 & 69:09:19.01 & 0.2061 & 4.6 & 0.927 & 18.4 & 20.3 & 1.4 & -21.7 + 32 & nw4b & 06:29:35.62 & 69:07:37.91 & 0.3008 & 3.5 & 0.940 & 21.0 & 22.2 & 0.4 & -19.9 the redshift measurements were made following the procedure described by jenkins et al . we used the iraf routine fxcor to cross - correlate the galaxy spectra that of the radial velocity standard hd 182572 . in general we only used the blue channel dis data for the cross - correlation , where the 4000 break and stellar absorption lines were most apparent . red channel data were usually used to identify and measure the wavelengths of redshifted emission lines ( , h , h , etc . ) when present . the galaxy redshifts obtained in this way are summarized in table and are accurate to between 70 and 170 ( which corresponds to a sight line distance displacement uncertainty of 1.0 to 2.4 mpc for an unperturbed hubble flow ) . we also observed three galaxies echellette spectrometer and imager ( esi ; sheinis et al . 2001 ) on the 10 m keck ii telescope on the nights of 2004 september 10 and 11 during morning twilight . we observed galaxy ne3 ( see table ) in echellette mode 0.5 slit which provides spectral resolution ( fwhm ) . the fainter se13 and sw3 galaxies were observed in low dispersion mode using a 1 slit which affords at . the exposures were flat fielded and wavelength calibrated esiredux package ( prochaska et al . 2003xavier / esi / index.html ] ) . the ne3 redshift was derived from the centroids of the high - resolution naroman1 and h absorption lines , and the redshift uncertainty is km s . for se13 and sw3 , redshifts were measured by fitting naroman1 , h , and caroman2 h and k , and the uncertainties are km s . the completeness of our galaxy redshift survey ( i.e. , the percentage of targets brighter than a given magnitude in the sextractor galaxy catalog good spectroscopic redshifts ) is graphically summarized in figure as a function of limiting magnitude and angular separation from the sight line . in the region centered on 0624 , we have measured spectroscopic redshifts for all galaxies brighter than = 19.0 , and the survey is per cent complete for . as we shall see , there is a prominent cluster of absorption lines in the 0624 spectrum at 0.0635 ; at this redshift , 5 corresponds to a projected distance of 367 kpc , and = 19.0 corresponds to or ( taking from lin et al . 1996 ) . for comparison , the large magellanic cloud has a magnitude equal to or . at this redshift , we have good completeness even for low luminosity galaxies . at larger radii , a substantial number of bright galaxies are found , and our redshift survey is shallower . nevertheless , within a 10 radius circle , our survey is still 60 per cent complete for galaxies brighter than . using information gleaned from the literature in combination galaxy redshift survey , we can identify several large - scale structures that are pierced by the 0624 sight line . in this section we comment on these structures including nearby abell clusters as well as smaller ( and closer ) galaxy groups . clusters are clustered and often reveal even larger cosmic structures , i.e. , superclusters ( einasto et al . 2001 and", "summary": "we present high - resolution ultraviolet spectra of absorption - line systems toward the low qso 0624 . coupled ground - based imaging and spectroscopic galaxy redshifts , we find evidence that many of these absorbers do not arise in galaxy halos but rather are truly integalactic gas clouds distributed within large - scale structures , and moreover , the gas is cool ( k ) and has relatively high metallicity . hst space telescope imaging spectrograph ( stis ) data reveal a dramatic cluster of 13 hroman1 lines within a 1000 interval at . we find 10 galaxies at this redshift impact parameters ranging from kpc to 1.37 mpc . the velocities and velocity spread of the lines in this complex are unlikely to arise in the individual halos of the nearby galaxies ; instead , we attribute the absorption to intragroup medium gas , possibly from a large - scale filament viewed along its long axis . contrary to theoretical expectations , this gas is not the shock - heated warm - hot intergalactic medium ( whim ) ; the width of the lines all indicate a gas temperature k , and metal lines detected in the complex also favor photoionised , cool gas . no oroman6 absorption lines are evident , which is consistent photoionisation models . remarkably , the metallicity is near - solar , ( uncertainty ) , yet the nearest galaxy which might pollute the igm is at least 135 kpc away . tidal stripping from nearby galaxies appears to be the most likely origin of this highly enriched , cool gas . more than six abell galaxy clusters are found within of the sight line suggesting that the qso line of sight passes near a node in the cosmic web . at 0.077 , we find absorption systems as well as galaxies at the redshift of the nearby clusters abell 564 and abell 559 . we conclude that the sight line pierces a filament of gas and galaxies feeding into these clusters . the absorber at = 0.07573 associated abell 564/559 also has a high metallicity , but again the closest galaxy is relatively far from the sight line ( kpc ) . the doppler parameters and hroman1 column densities of the ly lines observed along the entire sight line are consistent those measured toward other low qsos , including a number of broad lines . intergalactic medium galaxies : abundances large - scale structure of the universe quasars : individual ( hs0624 )"}
{"article": "about a decade ago , galactic plane surveys revealed large numbers of infrared dark clouds ( irdcs , ; ) . these are identified as dark patches against the diffuse galactic mid - infrared background . first studies of very opaque irdcs suggested that these have very high densities , column densities , and masses ( 10 ^ 5~cm^{-3} ] , ; ) . since they are dark , they are likely to be in an early evolutionary phase . embedded in irdcs are `` cores '' of a few dozen solar masses . it has therefore been suggested that many irdcs are the long - sought examples of clouds just at the onset of the formation of massive stars and ( proto-)clusters . this notion was corroborated by observations of young massive stars in a few individual irdcs ( ; ; ) . such views also form the framework of schemes for irdc evolution ( e.g. , , ) and reviews ( e.g. , , ) . irdc samples are usually compared to regions of massive star formation ( msf ) , such as orion and m17 ( e.g. , ). this picture can not be complete , though . the above studies ( and ) acknowledge that regions forming low and intermediate mass stars can also appear as shadows in images at mid - infrared wavelength . such irdcs will not form massive stars . unfortunately , the number of irdcs evolving towards msf is presently not known . fractions up to 100% have been considered in the past ( section ) . in this letter , we thus use a novel criterion to provide the first conclusive quantitative demonstration that only few irdcs are headed towards msf . this aids identifying pre - msf irdcs as targets for alma and herschel . as a bonus , the msf threshold identified below the first observational limit of this kind informs theory . in papers i and ii , we show that solar neighborhood clouds devoid of msf ( specifically : perseus , ophiuchus , taurus , and pipe nebula ) generally obey irdcs submitting to eq . would resemble , e.g. , ophiuchus and perseus , but not orion ( which violates eq. ) . figure illustrates why clouds bound for msf must exceed eq. . since star formation necessitates an appropriate mass reservoir , msf requires that a large mass is concentrated in a relatively small volume . based on more detailed theoretical considerations , section puts quantitative limits on this intuitively evident reasoning . as seen in fig . , the masses in this msf region are well above the mass size range bound by eq. . observations of msf clouds confirm eq. as a true msf limit ( section ) . this suggests to use eq. to roughly separate irdcs ( future ) msf from those without . this letter is organized as follows . based on data from section , section confirms ( using known msf clouds ) that eq . approximates an msf limit . many well - studied irdcs ( 25%50% ) fall short of this threshold ( section ) . less certain data for complete irdc samples suggests that most irdcs obey eq. , and will thus not form massive stars ( section ) . still , most of the mass contained by irdcs might be in clouds forming massive stars ( i.e. , those violating eq . ) . ; green and blue shading ) in relation to mass - size laws ( e.g. , =m 0r^b ] , where is distance , since pixels per beam ( as erroneously adopted ) have to be replaced by pixels per clump in eq . ( 5 ) of . ] . in many cases ( , , , ) , the size listed in the original publication refers to the contour at half peak intensity , while the mass measurement includes emission at much lower levels . in these cases , we assume that the sources have a near - gaussian shape ( just as explicitly assumed in many of the original papers ) . for such sources , the mass contained in the half peak column density contour is just a fraction of the total mass ( eq . a.23 of ; the area at half peak intensity is ^ 2 ] derived below ) . lc ) approximates a mass - size limit for msf ( section ) . only a fraction of the irdcs exceed this msf limit ( fig . , section ) . if a star - forming region contains more than one fragment ( i.e. , clump , core , etc . ) , the most compact fragment ( i.e. , maximum /m {lim} ] ) is highlighted by a circle.,title=\"fig : \" ] & + ) approximates a mass - size limit for msf ( section ) . only a fraction of the irdcs exceed this msf limit ( fig . , section ) . if a star - forming region contains more than one fragment ( i.e. , clump , core , etc . ) , the most compact fragment ( i.e. , maximum /m {lim} ] ) , to which we refer as the ` compactness ' . `` secondary cores '' ( only listed by and ) are suppressed by characterizing star - forming regions ( i.e. , a given massive star , or an entire irdc ) by their most compact fragment , ] , for various cloud samples . for a given sample , the ratios below which a certain fraction ( e.g. , 25% ) of the sample members resides are indicated by bars . local non - msf clouds ( fig . ) have a compactness ( eq . ) . the bars for the sample include ( left ) , respectively exclude ( right ) , their ` em ' cores . clearly , the irdcs do not reside in the mass - size space unambiguously associated msf. ] figure gives ] ) . this analysis has two interesting results . first , by number , most of the irdcs have masses and sizes comparable to those of solar neighborhood clouds devoid of massive stars ( i.e. , they are not compact ) . this holds even when adopting the largest reasonable distance . second , the compact clouds contain most of the mass ( more accurately : most of the area - integrated column density ) seen in these irdcs , even for small irdc distances . unfortunately , the survey is ( like most extinction studies ) uncertain in the sense that it assumes that the diffuse galactic emission can be reliably modelled in its spatial distribution . this may not be true . in this spirit , the results from this section should be taken as an indication , not as a final result . consider the following toy model to understand the expected mass - size properties of msf clouds . stars probably form on a timescale slower than the free - fall timescale)^{1/2} ] , 10^{23}~cm^{-2}$ ] , ) only seem to characterize the densest patches in very large and massive irdcs . they are not well suited to describe irdcs on average . some irdcs might further evolve and eventually undergo msf . and particular dust properties could , in principle , erroneously indicate where the reverse is true . however , such caveats are not usually considered when using irdc data to constrain msf . thus we abstain from such considerations . our study suggests that many irdcs , if not most , are not related to msf . one thus has to be prudent when using irdc properties to constrain msf initial conditions . most studies discussing irdcs as pre - msf sites concentrated on very opaque irdcs of large angular size . these clouds often violate eq . , and many of them are good msf candidates . suggest that most of the galactic star formation might come from irdcs . the absence of other likely reservoirs of star - forming gas evinces this too . by number , most irdcs are likely to form stars and clusters of low and intermediate mass , just as ophiuchus and perseus do . still , many irdcs will turn towards msf . interestingly , table suggests that most of the mass located in irdcs is in clouds that will form massive stars . for example , the 250 most compact clouds from the sample ( identified assuming a common distance ) contain more than 50% of the area - integrated column density of all irdcs . this suggests that they also contain a major fraction of the mass seen in irdcs . if this reasoning is correct , just few irdcs ( and not all : ) might contain most of the galaxy s star - forming gas . given the uncertain nature of the properties derived from the data ( section ) , this conclusion is far from certain , though . this letter studies whether infrared dark clouds ( irdcs ) are able to form massive stars . our main conclusions are as follows . * observations of regions without massive star formation ( msf ) suggest that the condition ( eq . ) approximates a threshold for msf ( section ) . msf clouds differ from those obeying eq . in mass - size slope or intercept ( fig . , section ) . * many irdcs ( section ) , if not most ( section ) , do not exceed eq . . without significant further evolution , such clouds are unlikely candidates for msf , but they might well form stars and clusters of up to intermediate mass ( like perseus and ophiuchus ) . very opaque irdcs of large angular size constitute good msf candidates . * provided extinction - based masses can be trusted , just few irdcs might contain a major fraction of the galaxy s star - forming gas ( section ) . these irdcs would be dense and massive enough to host msf . abergel , a. , bernard , j. p. , boulanger , f. , cesarsky , c. , desert , f. x. , falgarone , e. , lagache , g. , perault , m. , puget , j .- l . , reach , w. t. , nordh , l. , olofsson , g. , huldtgren , m. , kaas , a. a. , andre , p. , bontemps , s. , burgdorf , m. , copet , e. , davies , j. , montmerle , t. , persi , p. , & sibille , f. 1996 , astronomy and astrophysics evans , n. j. , dunham , m. m. , j rgensen , j. k. , enoch , m. l. , mern , b. , van dishoeck , e. f. , alcal , j. m. , myers , p. c. , stapelfeldt , k. r. , huard , t. l. , allen , l. e. , harvey , p. m. , van kempen , t. , blake , g. a. , koerner , d. w. , mundy , l. g. , padgett , d. l. , & sargent , a. i. 2009 , , 181 , 321 perault , m. , omont , a. , simon , g. , seguin , p. , ojha , d. , blommaert , j. , felli , m. , gilmore , g. , guglielmo , f. , habing , h. , price , s. , robin , a. , de batz , b. , cesarsky , c. , elbaz , d. , epchtein , n. , fouque , p. , guest , s. , levine , d. , pollock , a. , prusti , t. , siebenmorgen , r. , testi , l. , & tiphene , d. 1996 , astronomy and astrophysics", "summary": "we present a new assessment of the ability of infrared dark clouds ( irdcs ) to form massive stars and clusters . this is done by comparison empirical mass - size threshold for massive star formation ( msf ) . we establish as a novel approximate msf limit , based on clouds without msf . many irdcs , if not most , fall short of this threshold . without significant evolution , such clouds are unlikely msf candidates . this provides a first quantitative assessment of the small number of irdcs evolving towards msf . irdcs below this limit might still form stars and clusters of up to intermediate mass , though ( like , e.g. , the ophiuchus and perseus molecular clouds ) . nevertheless , a major fraction of the mass contained in irdcs might reside in few clouds sustaining msf ."}
{"article": "one of the long - standing problems in nuclear many - body theory has been the convergence of the perturbative expansion for the effective interaction ( or equally well that of effective operators ) derived from realistic nuclear forces to be used in nuclear structure calculations . conventionally , the various terms which appear in a perturbative expansion for are displayed by way of feynman - goldstone diagrams , examples of such diagrams are shown in fig . . it is well known that a realistic nucleon - nucleon interaction contains strong components of short range , which renders a perturbative expansion in terms of meaningless . to overcome this problem , one takes into account the short - range correlations through the solution of the bethe - brueckner - goldstone equation and considers a perturbation in terms of the nuclear reaction matrix . the wavy lines in fig . represent such interactions . however , higher - order perturbative contributions in terms of the -matrix , may be large , and the convergence of the perturbative expansion slow or not convergent at all . actually , barrett and kirson showed that third - order contributions to the effective interaction were substantial , and raised the question whether the perturbative rayleigh - schrdinger ( rs ) expansion in terms of the nuclear -matrix did converge at all . schucan and weidenmller even pointed out that the order - by - order expansion of the effective interaction will ultimately diverge when so - called intruder states are present . typical intruder states for nuclei like o and ca are four - particle - two - hole core - deformed states . it ought however to be mentioned that for nuclei more valence nucleons in e.g. the oxygen mass area , such intruder state configurations may not be important , and a two - body ( or many - body ) effective interaction defined within the -shell only , may represent the relevant degrees of freedom . most microscopic investigations of have been performed for nuclei in the -shell , valence nucleons outside a o core . however , when one extends the area of investigation to nuclei in the mass regions of calcium , tin or lead , one has to face the problem that for diagrams like those displayed in fig . , there are more intermediate states which contribute to each diagram of the effective interaction in e.g. the -shell than in the -shell . moreover , the energy spacing between the various major shells is also smaller for nuclei in the -shell than for those around o . this leads to smaller energy denominators which should enhance third - order or higher - order contributions . thus , the combined action of the above effects could seriously deteriorate the order - by - order convergence ( if it does converge ) of the effective interaction . the only mechanism which could quench these effects , is the fact that the matrix elements of calculated in the -shell should in general be weaker than those in the -shell . the single - particle wave functions for the states around the fermi energy exhibit larger radii and , as the nucleon - nucleon interaction is of short range , the matrix elements of should be weaker for the heavier nuclei . the same arguments apply of course as well for the tin and lead regions . it is then the scope of this work to study the convergence of the effective interaction in terms of the mass number , in order to assess whether higher - order contributions to the two - body effective interaction decrease or increase as increases . to achieve this , we calculate all non - folded valence linked diagrams through third - order in the interaction , and sum higher - order folded diagrams to infinite order for the mass regions beyond closed - shell cores , , , and . the details on how to obtain these effective interactions are briefly sketched in the next section , together results and discussions . some concluding remarks are given in section three . there are basically two main approaches in perturbation theory used to define an effective operator and effective interaction , each hierarchy of sub - approaches . one of these main approaches is an energy - dependent approach , known as brillouin - wigner perturbation theory , while the rayleigh - schrdinger ( rs ) perturbation expansion stands for the energy independent approach . the latter is the most commonly used approach in the literature , an approach which we will also employ here . it is then common practice in perturbation theory to reduce the infinitely many degrees of freedom of the hilbert space to those represented by a physically motivated subspace , the shell - model valence space . in such truncations of the hilbert space , the notions of a projection operator on the model space and its complement are introduced . the projection operators defining the model and excluded spaces are defined by and being the dimension of the model space , and , , and . the wave functions are eigenfunctions of the unperturbed hamiltonian ( eigenvalues ) , where is the kinetic energy and an appropriately chosen one - body potential , in this work that of the harmonic oscillator ( h.o . ) . the oscillator energies will be derived from , being the mass number . this yields , , , and for , , , and , respectively . the full hamiltonian is then rewritten as , being the nucleon - nucleon ( nn ) interaction . below we will replace by the -matrix , which will be used as the starting point for our perturbative treatment . following the above philosophy , we choose the model spaces which are believed , from both experiment and theoretical calculations , to be relevant for calculations of particle - particle effective interactions in the mass areas from to . these are the and orbits for in the mass area of , the , and orbits for , the , , and orbits for nuclei in the mass region of and the , , , and orbits for . for these systems , the closed - shell cores ( he , o , ca and sn ) have equal numbers of protons and neutrons , and the model spaces are the same for both protons and neutrons . for lead however , and , the proton and neutron model spaces are different , i.e. the orbits , , , , and for the proton model space and , , , , , and for the neutron model space . since the effective interaction theory we will employ is tailored to degenerate model spaces , we will make no attempt to derive for lead an effective proton - neutron interaction for these two model spaces . moreover , as discussed in ref . , a multishell effective interaction may show strong non - hermiticities , or even divergencies if a h.o . basis is used . thus , for to we will discuss both isospin and effective interactions , whereas for lead we restrict the attention to and , where is the projection of the total isospin . for the above model spaces , there are in total 15 matrix elements for the effective interaction of , 63 for , 195 for , 353 for , 711 for the neutron model space of and 353 for the proton model space of . the effective interactions for , and are listed in ref. , and have been tested in nuclear structure calculations and a good agreement experimental data obtained for several isotopes in these mass areas . the spectra for isotopes in the lead region will be published elsewhere . having defined the various model spaces , the next step in our calculation is to obtain the nuclear reaction matrix , given by where is the unperturbed energy of the interacting nucleons , and is the unperturbed hamiltonian . for the bare nn interaction we use the one - boson - exchange potential bonn a defined in table a.1 of ref . the operator is a projection operator which prevents the interacting nucleons from scattering into states occupied by other nucleons . note that the exclusion operator used in the calculation of the -matrix in this work is different from the operator used in the evaluation of the effective interaction . the definition of the pauli operator for the -matrix can be found in refs . , where the so - called double - partitioned scheme has been used . this means that low - lying two - particle states are excluded by from the intermediate states in the bethe - goldstone eq . . for the example of the -shell this exclusion refers to states nucleons in the -shell . as a consequence , we have to include in our perturbation expansion ladder type diagrams , such as ( 2 - 3 ) in fig . , where the allowed intermediate states are those of the -shell or corresponding ones for the other model - spaces . the next step is to define the so - called -box of the effective interaction and the -matrix . ] given by where we will replace ( replaces the free nn interaction ) . the -box is made up of non - folded diagrams which are irreducible and valence linked . a diagram is said to be irreducible if between each pair of vertices there is at least one hole state or a particle state outside the model space . in a valence - linked diagram the interactions are linked ( via fermion lines ) to at least one valence line . note that a valence - linked diagram can be either connected ( consisting of a single piece ) or disconnected . in the final expansion including folded diagrams as well , the disconnected diagrams are found to cancel out . this corresponds to the cancellation of unlinked diagrams in the goldstone expansion . we can then obtain an effective interaction in terms of the -box , observe also that the effective interaction is evaluated at a given model space energy , as is the case for the -matrix as well . for all mass areas , we fix . the first iteration is then given by in this work we define the -box to consist of all diagrams through third order in the -matrix , as discussed in ref . less than ten iterations were needed in order to obtain a converged effective interaction for the various values of . for further details , see ref . . in the calculation of the various diagrams , we limit the intermediate state excitations to in oscillator energy , an approximation which is viable if one employs an nn potential weak tensor force ( such as the bonn potential used here ) , as discussed by sommermann it is the aim of this study to explore the effects of the various contributions to . as it will be rather confusing to discuss the effects for individual matrix elements ( recall that depending on the model - space there are up to few hundred matrix elements ) , we define averages of matrix elements by where the summation index refers to all two - particle states of the model - space under consideration , coupled to angular momentum and isospin and we omit to divide number of configurations , as this gives rather small numbers for the heavier nuclei . ] . in the averaging procedure defined in this equation we have weighted the matrix elements by the factor since this factor accounts for the degeneracy of two - particle states respect to the projection quantum numbers and occurs e.g. in the calculation of the energy if all valence states are occupied . it turned out , however , that the main features of the results discussed below are obtained as well , if this weighting factor is dropped . for the operator we will consider , which corresponds to the bare matrix , , the -box including terms up to second order in without folded diagrams , and the effective interaction including all -box diagrams up to second ( third ) order plus all folded diagrams derived from these -boxes . note , that the average defined in eq . includes only diagonal matrix elements . in order to study if the conclusions remain valid for all matrix elements we also define a mean value including all matrix elements by where the summation indices and include again all two - particle states of the model - space considered . beside these averages , which include matrix elements of isospin and , we will also report on results where the averaging is restricted to one of these isospins only . results for the mean values of diagonal matrix elements ( see eq . ) are listed in table , while averages including the non - diagonal matrix elements as well ( see eq . ) are presented in table for the various model - spaces considered . inspecting these tables one observes very clearly that the mean values for the matrix elements are getting less attractive for the model spaces referring to heavy nuclei . this trend can be observed independent on the approximation used to calculate . this behavior reflects the fact that also the effective interaction , calculated inclusion of higher order terms , is of short range and therefore , as we discussed already above , yield weaker matrix elements for the valence nucleons in heavy nuclei as compared to the light systems . furthermore , we observe some features which are valid independent on the mass number and model space considered : * the inclusion of second - order -box diagrams in yields a substantial attraction for the matrix elements and a repulsion for . this difference may be understood by the following argument : for the channel , the major mechanism which accounts for the difference between first and second order , is provided by the core - polarization diagram in ( 2 - 2 ) of fig . . moreover , in the channel , the tensor force component of the nucleon - nucleon interaction is not so important , whereas in the channel the contribution from the - partial wave plays an important role in ladder - type diagrams , such as several of the folded diagrams , or the particle - particle ladder diagram in ( 2 - 3 ) of fig . . typically , for many and particle - particle effective interactions , the particle - particle ladder is of the size of or larger than the core - polarization diagram , while for and , the core - polarization diagram and the -matrix yield the largest contribution to the effective interaction . * the inclusion of folded diagrams yields a repulsive trend going form to . the effect is again much larger in the than in the matrix elements , which can as well be understood from the importance of the particle - particle ladder diagrams in the states . comparing the results of and one observes a repulsion for both isospins . * contrary to this repulsion due to the second - order terms in the folded - diagram expansion , the additional inclusion of terms of third order in yields some attraction in as compared to . except for the case of he , the effect of third - order terms is very weak for the states . this was also observed in ref. in the study of the spectra of nuclei valence particles being only neutrons or protons . there the authors noted that the spectra of e.g. o or ca obtained either a second - order or third - order effective interaction were quite similar . for calculations of the effective interaction for lead or tin , this is a gratifying property since it means that one needs only to evaluate the -box to second order and sum all folded diagrams . finally , in order to discuss the convergence of the perturbation expansion , we compare in table the ratios evaluated from the mean values defined in eq . . these ratios reflect of course the same features which we already discussed above . they emphasize , however , in a much better way that the different ratios are rather insensitive on the mass number which is considered . this means that one can expect the convergence of the perturbation expansion for the residual interaction to be as good ( or bad ) for heavy nuclei as for the light nuclei around o , which are usually studied . for nuclear structure studies of heavy nuclei neutron numbers quite different from the proton number one typically considers model - spaces , which are separate for protons and neutrons , ignoring the residual interaction beyond the mean - field approximation . for these cases ( isospin ) , the effects of terms of second order in seem to be rather important containing a correction of around 50 percent of the average of . however , it is encouraging to note that the inclusion of third order terms yields a correction of only 5 percent or even below . we have studied the behavior of the perturbation expansion for the effective interaction to be used in shell - model studies of nuclei various mass numbers . inspecting appropriate mean values of matrix elements , we have found that the fact that the -matrix becomes smaller in absolute value increasing mass numbers , counterbalances the effects that there are more intermediate states to sum over and that the energy denominators become smaller in each individual diagram of the effective interaction . therefore , the convergence of the perturbation expansion seems to be rather insensitive to the nuclear mass number . we observe that various features of the folded - diagram expansion , which had been discussed for the mass region , can also be found in heavy nuclei . the nuclear structure calculations for heavy nuclei are mainly sensitive to the proton - proton and neutron - neutron residual interactions . for these matrix elements the third - order and second - order averages are very close , indicating that for this isospin channel one can approximate the effective interaction by including all diagrams to second order plus folded diagrams to all orders . for , one still needs to account for third - order contributions . the fact that third - order contributions seem to stabilize for heavier nuclei , has also important consequences for nuclear structure calculations in nuclei in the mass regions of e.g. sn and pb . this means that the methods used to calculate the effective interaction for valence nucleons , applied mainly in the mass regions of o and ca , can be applied to the mass regions of sn and pb , as done recently in refs . .", "summary": "the convergence of the perturbation expansion for the effective interaction to be used in shell - model calculations is investigated as function of the mass number , from to . as the mass number increases , there are more intermediate states to sum over in each higher - order diagram which contributes to the effective interaction . together fact that the energy denominators in each diagram are smaller for larger mass numbers , these two effects could largely enhance higher - order contributions to the effective interaction , thereby deteriorating the order - by - order convergence of the effective interaction . this effect is counterbalanced by the short range of the nucleon - nucleon interaction , which implies that its matrix elements are weaker for valence single - particle states in `` large '' nuclei large mass number as compared to those in light nuclei . these effects are examined by comparing various mean values of the matrix elements . it turns out that the contributions from higher - order terms remain fairly stable as the mass number increases from to . the implications for nuclear structure calculations are discussed ."}
{"article": "neutrino magnetic moments are no doubt among the most well theoretically understood and experimentally studied neutrino electromagnetic properties . as it was shown long ago , in a wide set of theoretical frameworks neutrino magnetic moment is proportional to the neutrino mass and in general very small . for instance , for the minimally extended standard model the dirac neutrino magnetic moment is given by : at the same time , the magnetic moment of hypothetical heavy neutrino ( mass ) is . it should be noted here that much larger values for the neutrino magnetic moments are possible in various extensions of the standard model ( see , for instance , in ) constraints on the neutrino magnetic moment can be obtained in scattering experiments from the observed lack of distortions of the recoil electron energy spectra . recent reactor experiments provides us following upper bounds on the neutrino magnetic moment : ( munu collaboration ) , ( texono collaboration ) . the gemma collaboration has obtain the world best limit . another kind of neutrino experiment borexino ( solar neutrino scattering ) has obtained rather strong bound : . the best astrophysical constraint on the neutrino magnetic moment has been obtained from observation of the red giants cooling . as it was pointed out above the most stringent terrestrial constraints on a neutrino effective magnetic moments have been obtained in ( anti)neutrino - electron scattering experiments and the work to attain further improvements of the limits is in process . in particular , it is expected that the new bound on the level of can be reached by the gemma collaboration in a new series of measurements at the kalinin nuclear power plant much closer displacements of the detector to the reactor that can significantly enhanced the neutrino flux(see ) . an attempt to reasonably improve the experimental bound on a neutrino magnetic moment was undertaken in where it was claimed that the account for the electron binding effect in atom can significantly increase the electromagnetic contribution to the differential cross section in respect to the case when the free electron approximation is used in calculations of the cross section . however , as it was shown in a series of papers the neutrino reactor experiments on measurements of neutrino magnetic moment are not sensitive to the electron binding effect , so that the free electron approximation can be used for them . one may expect that neutrino electromagnetic properties can be much easier visualized when neutrino is propagating in external magnetic fields and dense matter . also , neutrino propagation in matter is a rather longstanding research field nevertheless still having advances and obtaining a lot of interesting predictions for various phenomena . the convenient and elegant way for description of neutrino interaction processes in matter has been recently offered in a series of papers . the developed method is based on the use of solutions of the modified dirac equation for neutrino in matter in feynman diagrams . the method was developed before for studies of different processes in quantum electrodynamics and was called as `` the method of exact solutions '' the gain from the introduction of the method was sustained by prediction and detailed quantum description of the new phenomenon of the spin light of neutrino in matter ( the ) , first predicted in within the quasi - classical treatment of neutrino spin evolution . the essence of the is the electromagnetic radiation in neutrino transition between two different helicity states in matter . the simplification of the process framework , such as use of the uniform , unpolarized and non - moving matter , neglect of the matter influence on the radiated photon , makes the estimate of real process relevance in astrophysical settings far from the practical scope . in this short paper we should like to make a step towards the completeness of the physical picture and to consider the incomprehensible at first glance question of the plasmon mass influence on the . the importance of plasma effects for the in matter was first pointed out in . the investigations already carried out in this area indicated that the plasmon emitted in the has a considerable mass that can affect the physics of the process . to see how the plasmon mass enters the quantities we appeal to the method of exact solutions and carry out all the computations relevant to the . in this respect , in order to have the conformity we also set all the conditions for the task the same as for corresponding studies on the . in particular , we consider only the standard model neutrino interactions and take matter composed of electrons . in the exact solutions method , one starts modified dirac equation for the neutrino in matter in order to have initial and final neutrino states , which would enter the process amplitude . the equation reads as follows : where in the case of neutrino motion through the non - moving and unpolarized matter being matter ( electrons ) number density . under this conditions the equation has plane - wave solution determined by 4-momentum and quantum numbers of helicity and sign of energy . for the details of equation solving and exact form of the wave functions the reader is referred to and , here we cite only the expression for the neutrino energy spectrum : the s - matrix of the process involves the usual dipole electromagnetic vertex +i\\gamma^{5}{\\bf \\sigma}\\big\\}$ ] and for given spinors for the initial and final neutrino states can be written as here is the photon polarization vector , is the transitional magnetic moment and is the normalization length . the delta - functions before spinors convolution part lead to the conservation laws energies for the initial and final neutrinos taken in accordance to . for the photon dispersion , for the purpose of our study it is sufficient to use the simplest expression as it was discussed in our previous studies on the the most appropriate conditions for the radiation to manifest its properties are met in dense astrophysical objects . this is the setting we will use further for the process and in the case of cold plasma the plasmon mass should be taken as the numerical evaluation at typical density gives , while the density parameter . let us now consider the influence of dense plasma on the process of spin light of neutrino . similarly to the original spin light calculation we consider the case of initial neutrino possessing the helicity quantum number and the corresponding final neutrino helicity is . using the neutrino energies corresponding helicities one can resolve the equations in relation to plasmon momentum which is not equal to its energy since we take into account the dispersion of the emitted photon in plasma . for convenience of calculations it is possible to use the following simplification . in most cases the neutrino mass appeared to be the smallest parameter in the considered problem and it is several orders smaller then any other parameter in the system . so we could first examine our process in approximation of zero neutrino mass , though we should not forget that only neutrino - zero mass could naturally possess the magnetic moment . this our simplification should be considered only as a technical one . it should be pointed here that in order to obtain the consistent description of the one should account for the effects of the neutrino mass in the dispersion relation and the neutrino wave functions . from the energy - momentum conservation it follows that the process is kinematically possible only under the condition ( taking account of the above - mentioned simplification ) : provided plasmon momentum we proceed calculation of the radiation rate and total power . the exact calculation of total rate is an intricate problem and the final expression is too large to be presented here . however one can consider the most notable ranges of parameters to investigate some peculiarities of the rate behavior . first of all we calculate the rate for the case of the without plasma influence . this can be done by choosing the limit and the obtained result is in full agreement : from one easily derives the rate for two important cases , i.e. high and ultra - high densities of matter just by choosing correspondingly or as the leading parameter in the brackets . while neutrino mass is the smallest quantity , our system fall within the range of relativistic initial neutrino energies . the corresponding expression for the total power also covers high and ultra - high density cases as well as the intermediate area where the density parameter and the neutrino momentum are comparable : if we account for the plasma influence ( thus , ) on the we can discuss two important situations . one is the area of parameters near the threshold , and the other is connected direct contribution of into the radiation rate expression . the later case is particularly important for this study , because it fulfill the aim of the present research in finding the conditions under which the plasmon mass can not be neglected . for physically reliable conditions the density parameter usually appears to be less then the plasmon mass , which in its turn is less then the neutrino momentum : . obviously the threshold condition should be satisfied . as we consider the conditions similar to different astrophysical objects it is natural to use high - energy neutrino . using the series expansion of the total rate one could obtain the rate of the process in the following form : where . approaching the threshold , the expansion becomes inapplicable , however it is correct in rather wide range of parameters and . near the threshold the the total rate can be presented in the form but the exact coefficient is too unwieldy to be presented here . concerning the power of the plasmon , one can use the expansion : the expression is correct only if the system meets the requirement . otherwise one should use higher orders of quantity in the expansion to achieve a reliable value of intensity . near the threshold the power has the same dependence on the `` distance '' from the threshold as the rate of the process . there is an increasing interest to neutrino electromagnetic properties and neutrino magnetic moments in particular . this interest is stimulated , first by the progress in experimental bounds on magnetic moments which have been recently achieved , as well as theoretical predictions of new processes emerging due to neutrino magnetic moment , such as the and a believe in its importance for possible astrophysical applications . further developing the theory of the spin light of neutrino , we have explicitly shown that the influence of plasmon mass becomes significant ( see and ) when the parameter is comparable , this corresponds to the system near the threshold . as soon as the quantity ( so the system is far from the threshold ) one can use either radiation rate and total power from or their rather compact generalizations and where the plasmon mass is accounted for as a minor adjustment . since high energy neutrinos propagating in matter could be rather typical situation in astrophysics , for instance in neutron stars , the influence of photon dispersion in plasma on the process can be neglected and the threshold generated by the non - zero plasmon mass should not be taken into account . however , the method of exact solutions of modified dirac equation provides us analytical expressions for probability and intensity in the whole range of possible parameters . one of the authors ( a.s . ) is thankful to giorgio bellettini , giorgio chiarelli , mario greco and gino isidori for the invitation to participate in les rencontres de physique de la vallee daoste on results and perspectives in particle physics .", "summary": "recent discussion on the possibility to obtain more stringent bounds on neutrino magnetic moment has stimulated new interest to possible effects induced by neutrino magnetic moment . in particular , in this note after a short review on neutrino magnetic moment we re - examine the effect of plasmon mass on neutrino spin light radiation in dense matter . we track the entry of the plasmon mass quantity in process characteristics and found out that the most substantial role it plays is the formation of the process threshold . it is shown that far from this point the plasmon mass can be omitted in all the corresponding physical quantities and one can rely on the results of massless photon spin light radiation theory in matter ."}
{"article": "for many physical cases in qcd , an observable quantity is usually expressed in terms of truncated series in the coupling constant given coefficients , so that in the next - to - next - to - next - to - leading order ( nlo ) we get where are some numbers , and is a fixed scale . so , the value is the single - scale quantity . the exhausted examples are the followings : 1 . the hadronic fraction of -decay width } { \\gamma } = \\nonumber\\\\ & & { \\cal r} {\\tau}^{ } \\left ( 1 + c 1^{\\tau}\\,)}{\\pi}+ c 2^{\\tau}\\,\\left}{\\pi}\\right)^2 + c 3^{\\tau}\\,\\left}{\\pi}\\right)^3 + \\delta r {}\\right ) , \\ ] ] where }=3.058 $ ] , the coefficients are given by and is a nonperturbative contribution . the hadronic fraction of -decay width } { \\gamma } = { \\cal r} {\\eta c}^{ } \\left ( 1 + d 1\\,{\\pi}\\right),\\ ] ] where } = {2n c}\\,{e c^4}\\ , {\\alpha^2 {\\rm em}}\\ ] ] , is the number of colors , is the electric charge of charmed quark , and the coefficient is given by where is the number of ` active ' flavors , and is the pole mass of charmed quark . the above formulae can be used for the extraction of at the appropriate scale . the value of -corrections is numerically significant . so , the problem is how the truncated series can be improved . the well - established approach to the solution of such the problem is a resummation of some significant terms . we mention two of such techniques . the first is the summation of contributions , where is the first coefficient of -function in qcd . the second procedure is based on an appropriate change of renormalization scheme by to the given order in the coupling constant , which allows one to decrease a role of higher - order corrections or even to minimize it modification of -function resulting in a different running of . the disadvantage of above methods is twofold . first , the next - order correction while computed exactly can essentially differ from the approximation of -dominance . second , the redefinition of renormalization scheme leads to the scale or normalization - point dependence of matching procedure . in this paper we present a procedure to improve the truncated series in the framework of renormalization group by introducing an auxiliary scale and taking a single - scale limit . a general formalism is given in section . the numerical estimates are presented in section . the analysis of scale dependence for the -decay rate is performed , since the normalization at the pole mass involves the additional problem caused by the residual change of by the variation of normalization point in the -mass . our results are summarized in conclusion . for the sake of clarity , let us start consideration of first - order correction . } = 1+c 1 {\\pi}.\\ ] ] introduce an auxiliary scale , so that making use of the renormalization group relation to the first order in , we clearly get ^{\\displaystyle {\\beta 0\\ln\\kappa}},\\ ] ] which gives the ordinary presentation improved by the renormalization group . note , that one finds the limit which will be correct for the further consideration at a fixed order in . the single - scale limit of can be easily evaluated ,\\ ] ] which is our result for the case of first - order correction . in order to proceed higher - order corrections , let me perform the derivation in another way . so , the -function has the form . to the first order it gives ,\\ ] ] at . then , ^{\\displaystyle {\\beta 0\\ln\\kappa}}\\approx \\exp\\left,\\ ] ] and expanding in , we rederive the renormalization group improvement ( rgi ) for the first - order correction . further , we can easily find the rgi for the third order in ( nlo ) . indeed , since ,\\ ] ] we get ^{\\displaystyle +16 \\bar c 3\\,{\\mathfrak a}^2}{\\beta 0+\\beta 1\\,{\\mathfrak a}+ \\beta 2\\,{\\mathfrak a}^2}{\\ln\\kappa^2 } } = \\exp\\left,\\ ] ] where we put expanding in at , we find ^{\\displaystyle +16 \\bar c 3\\,{\\mathfrak a}^2}{\\beta 0+\\beta 1\\,{\\mathfrak a}+ \\beta 2\\,{\\mathfrak a}^2}{\\ln\\kappa^2}}\\approx 1 + c 1\\,{\\pi}+ c 2\\,\\left({\\pi}\\right)^2 + c 3\\,\\left({\\pi}\\right)^3.\\ ] ] thus , the third - order improved expression has the form \\ ] ] we stress the renormalization group motivation used in contrast to ad hoc method of pad approximants . let us show how the improvement works in a simple example . so , we consider a rather oscillating sum , which reveals a ` slow ' convergency , since }=1,\\quad { \\cal e}^{}=0.5,\\quad { \\cal e}^{}=0.8,\\ ] ] while \\ ] ] results in } = 1,\\quad { \\cal e}^{} { } = 0.61,\\quad { \\cal e}^{} { } = 0.72,\\ ] ] which is ` more stable ' . thus , we expect that possesses a more numerical stability in the truncated series . of course , if a series is essentially asymptotic , the improvement can not cancel a ` bad ' convergency . next , we have to mention the numerical problem often appearing -corrections to the amplitudes and the amplitudes squared if those corrections are significantly large . indeed , the correction to the amplitude }(1+c 1\\alpha s)\\ ] ] should lead to }\\right)^2(1 + 2\\,c 1\\alpha s),\\ ] ] so that the ratio numerically deviates from unit . the rgi has no such the problem , since the exponent does not involve the above mismatching . finally , we stress that the rgi does not present some kind of resummation of higher orders . in the resummation technique one certainly suggests a form of higher - order terms . in contrast , we give the exact expression produced by the renormalization group . at small as dictated by the perturbative paradigm , the expression can be expanded till the appropriate order . thus , one could claim that the rgi procedure looks like overflying the accuracy . to my opinion , one should use the rgi point as a central value of the calculated quantity , while the expansion truncated to the given order would indicate a systematic error of numerical estimate . the rgi formula for the -lepton decays into hadrons reads off } \\left\\{\\exp\\left + \\delta r {}\\right\\ } , \\ ] ] where implementing we find which results in where we include the experimental uncertainty , only . for the sake of comparison , the pdg value extracted by the same measurement of rate reads off which respectively gives . we point out that the theoretical uncertainty in pdg is slightly overestimated , to our opinion , since the displacement of central value extracted in two ways equals . thus , the preferable value of coupling constant following from the -lepton hadronic width is given by central point closer to the ` world average ' . the problem estimate of hadronic width of -charmonium is twofold . first , the scale setting in the -correction is beyond the accuracy , since its variation contributes to . so , we should put the arbitrary scale by } \\left ( 1 + d 1\\,{\\pi}\\right ) . \\ ] ] the second point is the prescription for the pole mass of charmed quark . in the perturbative qcd , the pole mass is strictly defined . the relation between the -running mass and the pole mass is known to the -order . explicitly , to the -terms we put where , and . th evalue of pole mass is the renormalization invariant . however , at reasonable scales , the residual dependence due to the truncation of perturbative series is numerically significant . the reason of such the dependence is a growth of coefficients in series as caused by the renormalon . in fact , the pole mass becomes a scale - dependent quantity . to avoid this problem , the operative procedure is to fix a short - distance mass free off the renormalon and to perform the calculations series expressed in terms of . we exploit two schemes , which lead to results close enough to each other . the first scheme is given by the -running mass . taking we calculate the pole mass shown in fig . . we have checked that the implication of rgi procedure to the relation between the pole and running masses is consistent above result , and the effect of rgi can be absorbed into the decrease of -value by about , which below the systematic accuracy of matching procedure as discussed below . ( 100,70 ) ( 3,3)=100 ( 90,0) , ( 0,67) , the second is the potential scheme described in ref . in this case , we calculate the scale - dependent matching of perturbative 2-loop scatic potential involving the 3-loop running phenomenological qcd - motivated static potential containing both the 2-loop short - distance coulomb - like contribution as well as the long - distance linear confining term preserving the infrared stability . then , the potential and , hence , the -masses are free off the renormalon . the heavy quark masses are fixed by the measured spin - average mass - spectra of heavy quarkonia . so , the matching of scale - dependent perturbative potential is extracted numerically as described in ref . thus , the cancellation of renormalon in the sum of gives up to a constant shift independent of the scale . the matching perturbative pole mass in gives , depending on the variation of coupling constant in the limits of . the value of indicates the accuracy of matching procedure . the result is presented in fig. , which reveals a good agreement of two schemes used . ( 100,70 ) ( 3,3)=100 ( 90,0) , ( 0,67) then , the perturbative formula results in the shown in fig . , wherefrom we get at the estimate in is slightly greater than the value given by bodwin and chen . we stress the scale - stability of our result . further , at the same scale we find then , comparing we obtain the final estimate including the theoretical uncertainty due to possible contributions of higher orders and , hence , the induced scale - dependence by the variation of central values as which is in agreement experimental value to be compared obtained in under the resummation of -terms . we point out that the improvement of the experimental accuracy combined calculation of -correction would give a good opportunity to extract the mass of charmed quark . in this respect , we refer to ref . , where the -corrections were taken into account in the ratio of widths for the decays of and , so that the analysis suffers from the uncertainties related relativistic corrections entering the ratio for the different initial states . the advantage of is the cancellation of such the initial state corrections . we have developed a general scheme to improve the estimate of truncated perturbative series in qcd by the tool of renormalization group for the single - scale quantities . the method allows one to get more realistic central values of the quantities as well as to estimate the theoretical uncertainty of results by comparison of rgi values perturbatively expanded ones . the rgi receipt for the calculation of quantity , is given by and . we have applied the approach to the fractions of hadronic widths for the -lepton and -charmonium , which allows us to get realistic estimates of }/{\\gamma}\\ ] ] in a reasonable agreement appropriately measured values . the author thanks prof.g.bodwin for an exciting presentation of his results on the resummation technique for the hadronic fraction of width as he gave at the heavy quarkonium workshop held in cern , nov . 8 - 11 , 2002 . a special gratitude goes to the organizing committee of the workshop , and personally to antonio vairo and nora brambilla for the invitation and a kind hospitality . i also thank prof.r.dzhelyadin for the possibility to visit cern in collaboration lhcb group , to which members i express my gratitude for a hospitatily . i thank prof.a.k.likhoded , who asked me for the meaning of resummation technique , which initiated this work . * * s. narison and a. pich , phys . b * 211 * , 183 ( 1988 ) ; + e. braaten , s. narison and a. pich , nucl . b * 373 * , 581 ( 1992 ) ; + a. l. kataev and v. v. starshenko , mod . lett . a * 10 * , 235 ( 1995 ) . k. hagiwara et al . , phys . d * 66 * , 010001 ( 2002 ) . r. barbieri , e. demilio , g. curci and e. remiddi , nucl . b * 154 * , 535 ( 1979 ) ; + k. hagiwara , c. b. kim and t. yoshino , nucl . b * 177 * , 461 ( 1981 ) . m. beneke and v. m. braun , phys . b * 348 * , 513 ( 1995 ) , nucl . b * 426 * , 301 ( 1994 ) . g. t. bodwin and y. q. chen , phys . d * 64 * , 114008 ( 2001 ) . j. g. korner , f. krajewski and a. a. pivovarov , phys . d * 63 * , 036001 ( 2001 ) . m. beneke , phys . rept . * 317 * , 1 ( 1999 ) . k. melnikov and t. v. ritbergen , phys . b * 482 * , 99 ( 2000 ) ; + k. g. chetyrkin and m. steinhauser , nucl . phys . b * 573 * , 617 ( 2000 ) . n. gray , d. j. broadhurst , w. grafe and k. schilcher , z. phys . c * 48 * , 673 ( 1990 ) ; + d. j. broadhurst , n. gray and k. schilcher , z. phys . c * 52 * , 111 ( 1991 ) . v. v. kiselev , a. e. kovalsky and a. i. onishchenko , phys . d * 64 * , 054009 ( 2001 ) ; + v. v. kiselev , a. k. likhoded , o. n. pakhomova and v. a. saleev , phys . d * 65 * , 034013 ( 2002 ) . a. czarnecki and k. melnikov , phys . b * 519 * , 212 ( 2001 ) .", "summary": "we formulate a general scheme to improve the truncated perturbative expansion in by means of the renormalization group in qcd for the single - scale quantities . the procedure is used for the evaluation of hadronic decay rates of -lepton and -charmonium . the scale dependence of result for is studied in the scheme of fixed value for the -mass of charmed quark . = -1 cm = -2 cm"}
{"article": "spectra of type 1 agn show a diversity of broad and narrow emission lines that provide direct insights into the structure and kinematics of photoionized , and otherwise excited , gas in the vicinity of the putative central massive object . broad emission lines , like much studied h ( e.g. , * ? ? ? * hereafter z10 ) , are thought to arise in or near an accretion disk acting as the fuel reservoir for the central supermassive black hole ( log m m ) . h shows a diversity of line widths as well as profile shifts and asymmetries . despite this diversity some systematics have emerged and are best highlighted via the concept of two type 1 agn populations . population a show the smallest broad - line widths fwhm h=1000 - 4000 and includes the narrow line seyfert 1 ( nlsy1 ) sources ( fwhm 2000 ) . a h profiles are currently best fit by a single lorentz function . population b sources show fwhm h=4000 - 12000 and require two gaussians ( one unshifted and one redshifted ) for a reasonable profile description . `` broad - line '' h profiles as narrow as fwhm = 500 and as broad as fwhm = 40000 have been found . a is predominantly radio - quiet while pop . b involves a mix of radio - quiet and the majority of radio - loud quasars . broad- and narrow - line profile shifts are known and the phenomenology can be confusing . narrow emission lines like 5007 are regarded as a reliable measure of the local quasar rest frame except in the case of `` blue outliers '' , usually found in sources fwhm h= 1500 - 3500 and weak . blue outliers show blueshifts as large as . no pop . b sources blueshifted are known at low z ( or luminosity ) . careful use of and h narrow line as rest frame measures suggests that broad h in pop . a sources rarely shows a systematic red or blue shift above the fwhm profile level . a blueshifted component or asymmetry is observed in some extreme feii strong pop . a sources . b sources show more complex line shift properties . the h profile usually shows two components : 1 ) a `` classical '' broad component ( bc ; fwhm = 4000 5000 ) zero or small ( red or blue ) shift , and 2 ) a very broad ( vbc ; 10000 ) and redshifted component . composites involving the 469 brightest sdss - dr5 quasars suggest that these two components represent the underlying stable structure of h in pop . b sources . broad feii emission has been found in type 1 quasars since the era of photographic spectroscopy in the . feii emission blends are almost ubiquitous in a sample of the brightest ( usually highest s / n ) sdss quasars ( z10 ) . circumstantial evidence has accumulated supporting the assumption that feii emission arises in or near the emitting clouds that produce other low ionization lines like h ( see e.g. , ) . fwhm feii appears to correlate fwhm h over the full range where feii can be detected ( fwhm=1000 - 12000 ) . this can be clearly seen at low by observing the shape ( e.g. , smoothness ) of the feii 4450 - 4700 blue blend ( and the feii multiplet 42 line at 5018 ) near 5007 . in pop . a sources the blend resolves into individual lines while it becomes much smoother in pop . b sources . sources strongest feii emission also show a weakening of h emission as expected if the latter is collisionally quenched in the same dense medium where strong feii emission can be produced . obviously systematic line shifts place important constraints on models for the geometry and kinematics of the broad line region . the most famous example involves a systematic blueshift of high ionization lines ( e.g. , civ 1549 ) relative to low ionization lines ( e.g. , balmer ) especially in pop . a sources ( e.g. , * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? evidence was recently advanced ( * ? ? ? * hereafter h08 ) for the existence of a systematic redshift of feii relative to 5007 ( and hence the balmer lines ) in a majority of type 1 quasars . this result , along narrower estimated feii line width , has been ascribed to feii emission arising in a region dynamics dominated by infall and located at larger radius than the region producing the bulk of h . h08 argue that the amplitude of the shifts correlates inversely source eddington ratio ( l / l ) . interpretations for such an feii redshift have already appeared reflecting the potential importance of such a first - order kinematic signature . having worked on line spectra and profile shifts for many years we were surprised by the h08 claims and decided to test the hypothesis of a systematic feii redshift . could we have missed it ? first let us consider what we know . a quasars show relatively symmetric unshifted lorentz - like h profiles fwhm . in our work using the brightest ( 17.5 or 17.5 ; ) sdss dr5 quasars we processed spectra for pop . a sources ( from a sample of 469 quasars ; z10 ) and we found no evidence for a systematic shift of feii lines relative to h or . such an feii shift should be easiest to detect in the brightest pop . a sdss spectra narrowest broad - line profiles and strongest feii emission . it is immediately suspicious that more and larger feii redshifts are claimed for pop . b sources . in only one pop . a source in our sample sdss j0946 + 0139 do we find a large h peak ( 90 intensity level ) redshift of 1830 . this source is similar to oq208 ( and discussed in h08 ) which shows . sdss j0946 is the only pop . a source large feii redshift in our z10 sample ( 1/260 ) . z10 found 19 quasars h peak ( 9/10 fractional intensity ) blueshifted more than -320 and 4 sources peak redshift more than + 320 . the remaining 241 pop . a sources showed no significant h peak shift ( figure 8 of z10 ) . best feii template fits to these sources show no significant difference in centroid redshift between feii and h . there are two possible causes of small and spurious h ( or feii ) shifts : 1 ) host galaxy contamination and 2 ) blue outliers.except in rare cases host galaxy contamination is unlikely to induce systematic redshifts amplitudes reported by h08 . extreme blue outliers blueshifts in the range 400 - 1000 are rare and therefore can not be the cause of the large and systematic shifts reported in h08 . in fact h08 selection criteria rejected sources likely to be seriously affected by 1 ) or 2 ) . h08 chose 4000 + sources from sdss dr5 computed s / n 10 . z10 also used dr5 where % of sources show s / n 10 . our sample was magnitude - limited slightly shallower redshift upper limit ( z=0.7 instead of 0.8 ) . why do we reach different conclusions about feii shifts ? a big part of the answer could involve how s / n was computed . compute s / n over the range 44305500 . this procedure overestimates the quality of the data because it includes major emission lines in the computation . we compute s / n in the range 5600 - 5800 , which is free of strong lines and represents as close as one can approach to an estimate of continuum s / n near h . using our range the h08 sample shows mean and median s / n values of 10.6 and 7.4 , respectively ; approx . 65% show s / n 10 . we find that only 182 spectra of our bright sample are included in the h08 s . the majority of the h08 s sources are lower s / n than those in our sample . one can not estimate reliable feii line shifts using individual sdss spectra for sources fainter than about g - 17.5 . in rough order of importance our studies indicate that the accuracy of feii shift measures depends on : 1 ) feii strength and feii / h profile widths , 2 ) spectral s / n and 3 ) if estimates depend heavily on fits to the 4430 - 4680 blend , strength of heii 4686 emission . typical individual spectra used by h08 show too low s / n to allow convincing conclusions about feii shift and width typical parameter uncertainties for individual sources are much larger than the ones connected high s / n composites ( for a typical a2 source / n uncertainties of shift estimates are larger than ) . individual source spectra large quoted feii redshift and s / n near the sample median were extracted from the h08 sample and specfit modelled . using an feii template fixed shifts ranging from zero up to the largest values quoted by h08 , can not distinguish between zero and e.g. , 1000 redshift in the majority of the sources . the best recourse is to generate high s / n composite spectra . h08 argue that one can not confirm or refute the existence of a systematic feii redshift using composite spectra because of the large dispersion of fwhm , shifts and flux values for both h and feii . this is likely true for composites generated from random subsamples of sources but not true if one generates composites over more limited ranges of parameter values . one can generate binned composites over limited ranges of fwhm h and feii strength using the 4de1 formalism ( ; z10 ) . 4de1 bins a2 ( fwhm h= 1000 - 4000 , 0.5 1.0 ) and b1 ( fwhm h=4000 8000 , 0.5 ) are of particular interest because they include the largest numbers of sources in random samples . specfit analysis ( ; details in ) of an a2 median composite involving n = 130 z10 sources ( s / n 90 ) gives a best - fit consistent zero feii redshift . the situation for the b1 composite ( n=131 sources from z10 ; s / n 110 ) is less constraining because lines are broader and feii weaker . table 1 reports feii template shifts and 2 uncertainties for specfit tests discussed in this paper . we also report peak shifts of bc extracted from the best specfit solutions along `` core '' shifts measured at the centroid of the line peak after nc subtraction . in no case do we find a significant shift between feii and the rest frame or between feii and . we also do not find any significant feii shifts if we restrict to sources / l ratio ( h08 suggested the shifts might be largest for low l / l sources ) . since we find no evidence for systematic feii redshifts in our z10 bright quasar sample composites it is useful to generate feii shift composites using the h08 sample . we generate them within the 4de1 context thereby restricting the ranges of fwhm h , feii relative strength ( and likely also fwhm feii ) for each composite . since the distribution of feii shifts shown in h08 is continuous we focus on the sources largest quoted shift values . if these shifts are not confirmed then smaller shifts are even less likely to be real . we therefore focus on constructing median composites for all h08 sources falling in 4de1 bins a2 and b1 h08 feii redshift estimates ( figure 1 ) . two composites were constructed for each spectra bin : 1 ) one restriction on feii width ( h08 do not constrain fwhm feii in their template fits so it is sometimes very different from fwhm h ) and 2 ) one feii width constrained to the fwhm range of h in a particular bin ( i.e. , for a2 and for b1 ) . upper and lower panels of figure 1 show bins a2 ( fwhm h 4000 ) and b1 ( fwhm h=4000 - 8000 ) , respectively ( n=156 for bin a2 and n=240 for bin b1 ) . the s / n 55 - 60 for both composites . spectra show best - fit specfit models superimposed . the left and center panels involved feii templates fixed to the best fit and 1500 shifts , respectively . our template prescription is described in graphical results for the best - fits are shown in the right panels of figure 1 . fits were performed over the range 4470 5450 , where feii and continuum emission account for the total flux making it the safest region for normalized computations . values are shown for the range of adopted feii shifts . in order to estimate confidence intervals we considered a set of fits displacements = + , for integer , along best fit and a few additional cases in proximity to the minimum . one can see a clear preference for zero or near - zero fits . the significance of variations is described by statistics appropriate for ratios of values . given the large number of degrees of freedoms in the sampling range ( 4500 4630 , 5040 5090 , 5310 5360 ) any differences between two fits become significant at a 95% confidence level if . the values indicate that zero shift and `` best shift '' values in table 1 are not significantly different . all fits involving shifts 500 are statistically significant . the middle panel of figure 1 upper row demonstrates visually that the fit = + ( and even more the fits larger displacement ) do not reproduce the observed feii emission . both the residuals and results rule out any systematic redshift for at least half of the h08 sample ( pop . note especially the fits to the two relatively isolated multiplet 42 feii lines between h and 4959 and on the red wing of 5007 . the redshifted fit fails to include the blue side of the 4450 4700 blend and the red side is confused by the frequent presence of heii 4686 . the latter line is not mentioned in the h08 study leaving us to conclude that it was not included in their fits . it can certainly give the impression of a redshift of the feii blue blend , which is the most useful feii diagnostic in the optical spectra of low redshift quasars ( the red feii blend is frequently affected by coronal lines as well as mgii host galaxy absorption in lower redshift sources ) . pioneering principal component analysis of the bqs survey found that heii4686 equivalent width anticorrelates sources luminosity ( it is eigenvector 2 ) . there is a tendency for the h08 sources largest feii redshifts to favor a smaller and lower range of source luminosity than those near zero shifts . thus the effect of heii will tend to play a larger role in the sources where the largest feii redshifts have been found . show composite spectra for five bins of feii redshift in their figure 12 . the three bins involving largest feii redshift sources show a prominent heii signature that , if not subtracted , will increase the apparent significance of any assumed feii redshift . only the bin involving sources feii redshift ( within the uncertainties ) shows no evidence of heii emission . figure 9a of h08 suggests that a larger fraction of quasars fwhm h 4000 ( population b ) show large feii redshifts . the lower panels of our figure 1 show specfit models superimposed on a b1 median composite constructed from all h08 sources quoted feii redshift greater than 1000 . the situation is certainly more ambiguous than for the a2 composite . it is hard to identify individual feii features . lines are broad , feii is weak and under these conditions there are serious limitations on the reliability of fwhm and shift estimates for feii ( cf . fig . 3 of ) . the same analysis as done for a2 composite shows much poorer constraints on the feii shift . the best fit yields but is not distinguishable from a zero shift solution . if one actually computes values over the ranges 4474 4640 , 5040 5105 , 5320 5400 , the monotonically increases from 0 shift ( figure 1 , lower rightmost panel ) , although the increase remains insignificant until 1100 , where . b1 feii is too faint and the lines are too broad to make inferences about line shifts and widths . the claim of large feii shifts are not , and can not be , confirmed . recently report an feii study of sdss quasars and any feii redshifts they measure ( their figure 16 ) are much smaller than those reported by h08 ( the average feii shift relative to the narrow lines is 100 240 ) . returning to our previous list of major sources of uncertainty for feii shift and fwhm estimates leads us to suggest that low spectral s / n and above average heii strength are the culprits . the fit to the 4430 4680 blue blend drives the best fit results . the exclusion of heii4686 from the h08 fits likely results in a tendency for heii to `` redshift '' the blue feii blend . this effect in a typically low luminosity sample , where heii is stronger than average , likely drove the conclusion that feii was systematically redshifted . we tested this conclusion omitting the heii line from our fits to the bin a2 and b1 composites generated from the h08 sample . feii shifts in lines 2 and 5 of table 1 increase from -60 to + 770km / s and from 730 to 1570km / s , respectively . the more constraining a2 results suggest that heii can produce the entire systematic redshift claimed by h08 . we do not confirm large feii redshifts relative to narrow and broad h emission in type 1 agn but can not rule out the existence of small red ( or blue ) shifts in particular subsamples . fitting median composites built from spectra large claimed feii shifts indicates small shifts upper limit 300 for bin a2 . in the case of b1 the best fit suggests but the shift is very poorly constrained . in both cases the shifts are not significantly different from 0 . these results do not support the origin of feii emission from a dynamical disjoint region from the one emitting the broad core of . our result also challenges the usefulness of feii shift as orientation parameter . small systematic shifts of feii respect to the rest frame seem plausible but a reliable analysis is possible only on spectra of high s / n ratio . lcccccc a2 - z10 & -40 90 & 10 & 0 & & 130 + a2 - h08 , & -60 400 & 80 & 90 & 70 & 156 + a2 - h08 , & -160 375 & 100 & 10 & 45 & 194 + b1 - z10 & -340 400 & -150 & -80 & & 131 + b1 - h08 , & + 730 & 0 & 100 & & 240 + b1 - h08 , & + 180 450 & -80 & 40 & & 410 + b1 - h08 z10 , & -150 470 & -170 & -140 & 45 & 22 +", "summary": "we test the recent claim by hu et al . ( 2008 ) that feii emission in type 1 agn shows a systematic redshift relative to the local source rest frame and broad - line h . we compile high s / n median composites using sdss spectra from both the hu et al . sample and our own sample of the 469 brightest dr5 spectra . our composites are generated in bins of fwhm h and feii strength as defined in our 4d eigenvector 1 ( 4de1 ) formalism . we find no evidence for a systematic feii redshift and consistency previous assumptions that feii shift and width ( fwhm ) follow h shift and fwhm in virtually all sources . this result is consistent hypothesis that feii emission ( quasi - ubiquitous in type 1 sources ) arises from a broad - line region geometry and kinematics the same as that producing the balmer lines ."}
{"article": "in this talk i will describe some recent work together michael dinsdale concerning the relative size of non - perturbative power corrections for qcd event shape observables . for event shape means the delphi collaboration have found in a recent analysis that , if the next - to - leading order ( nlo ) perturbative corrections are evaluated using the method of effective charges , then one can obtain excellent fits to data without includingany power corrections . in contrast fits based on the use of standard fixed - order perturbation theory in the scheme physical choice of renormalization scale equal to the c.m . energy , require additional power corrections . power corrections of this size are also predicted in a model based on an infrared finite coupling , which is able to fit the data reasonably well in terms of a single parameter . given the delphi result it is interesting to consider how to extend the method of effective charges to event shape distributions rather than means . consider an observable , e.g. an event shape observable- thrust or heavy - jet mass , being the c.m . here . normalised leading coefficient unity , such an observable is called an effective charge . the couplant satisfies the beta - function equation here and are universal , the higher coefficients , , are rs - dependent and may be used to label the scheme , together dimensional transmutation parameter . the effective charge satisfies the equation this corresponds to the beta - function equation in an rs where the higher - order corrections vanish and , the beta - function coefficients in this scheme are the rs - invariant combinations eq.(3 ) for can be integrated to give + \\int {0}^{{}(q)}{dx}\\left\\;.\\ ] ] the dimensionful constant arises as a constant of integration . it is related to the dimensional transmutation parameter by the exact relation , here , is the nlo perturbative coefficient . eq.(5 ) can be recast in the form the final factor converts to the standard convention for . here is the universal function and is here is the nnlo ech rs - invariant . if only a nlo calculation is available , as is the case for jet observables , then , and eq.(10 ) can be used to convert the measured data for the observable into a value of bin - by - bin . such an analysis was carried out in ref . for a number of event shape observables , including thrust and heavy jet mass which we shall focus on here . it was found that the fitted values exhibited a clear plateau region , away from the two - jet region , and the region approaching where the nlo thrust distribution vanishes . the result for 1-thrust corrected for hadronization effects is shown in fig . 1 . another way of motivating the effective charge approach is the idea of `` complete renormalization group improvement '' ( corgi ) . one can write the nlo coefficient as hence one can identify scale - dependent -logs and rs - invariant `` physical '' uv -logs . higher coefficients are polynomials in . given a nlo calculation of , parts of are `` rg - predictable '' . one usually chooses then is -independent , and so are all the . the -dependence of then comes entirely from the rs - dependent coupling . however , if we insist that is held constant independent of the only -dependence resides in the `` physical '' uv -logs in . asymptotic freedom then arises only if we resum these -logs to all - orders . given only a nlo calculation , and assuming for simplicity that that we have a trivial one loop beta - function so that the rg - predictable terms will be summing the geometric progression one obtains \\nonumber \\\\ & = & 1/b{\\ln}(q/{\\lambda} {}).\\ ] ] the -logs `` eat themselves '' and one arrives at the nlo ech result . + as we noted earlier , , use of nlo effective charge perturbation theory ( renormalization group invariant ( rgi ) perturbation theory ) leads to excellent fits for event shape means consistent zero power corrections , as illustrated in figure 2 . taken from ref. . given this result it would seem worthwhile to extend the effective charge approach to event shape distributions . it is commonly stated that the method of effective charges is inapplicable to exclusive quantities which depend on multiple scales . however given an observable depending on scales it can always be written as here the are dimensionless quantities that can be held fixed , allowing the evolution of to be obtained as before . in the 2-jet region for observables large logarithms arise and need to be resummed to all - orders . event shape distributions for thrust or heavy - jet mass contain large kinematical logarithms , , where . here , , denote leading logarithms , next - to - leading logarithms , etc . for thrust and heavy - jet mass the distributions exponentiate here contains the ll and the nll . is independent of , and contains terms that vanish as . it is natural to define an effective charge so that this effective charge will have the expansion here , and the higher coefficients have the structure usually one resums these logarithms to all - orders using the known closed - form expressions for and , where is taken to be the coupling `` physical '' scale choice ( ) . instead we want to resum logarithms to all - orders in the function ( ech ) . the form of the rs - invariants ( eq.(4 ) ) means that the have the structure one can then define all - orders rs - invariant and approximations to , the resummed can then be used to solve for by inserting it in eq.(5 ) . notice that since involves the exact value of there is no matching problem as in the standard approach . the resummed can be straightforwardly numerically computed using chosen so that . the same relation suffices for , although in this case one needs to remove terms , e.g. an term which would otherwise be included in . this can be accomplished by numerically taking limits fixed . + as we have noted a crucial feature of the effective charge approach is that it resums to all - orders rg - predictable pieces of the higher - order coefficients , thus the nlo ech result ( assuming for simplicity ) corresponds to an rs - invariant resummation ( c.f . eq.(13 ) . ) thus even at fixed - order without any resummation of large logs in a partial resummation of large logs is automatically performed . furthermore one might expect that the ll ech result contains already nll pieces of the standard result . + in figure 3 we show various nlo approximations . notice that the solid curve , which corresponds to the exponentiated nlo ech result , is a surprisingly good fit even in the 2-jet region , whereas the dashed curve which is the nlo result , has a badly misplaced peak . the all - orders partial resummation of large logs in eq.(15 ) gives a reasonable 2-jet peak . figure 4 shows that the nll coefficients `` predicted '' from the ll ech result by re - expanding it in the coupling are in good agreement exact coeffiecients out to o . we now turn to fits simultaneously extracting and the size of power corrections from the data . to facilitate this we use the result that inclusion of power corrections effectively shifts the event shape distributions , which can be motivated by considering simple models of hadronization , or through a renormalon analysis . thus we define this shifted result is then fitted to the data for 1-thrust and heavy jet mass . data spanning the c.m . energy range from was used ( see for the complete list of", "summary": "we introduce and motivate the method of effective charges , and consider how to implement an all - orders resummation of large kinematical logarithms in this formalism . fits for qcd and power corrections are performed for the event shape obesrvables 1-thrust and heavy - jet mass , and somewhat smaller power corrections found than in the usual approach employing the `` physical scale '' choice ."}
{"article": "precision experiments in the last two decades have elevated the standard model ( sm ) of particle physics from a promising description to a provisional law of nature , tested as a quantum field theory at the level of one percent or better . despite its triumphs the sm is not an entirely satisfactory theory , however , because it has various theoretical shortcomings . in particular , the gauge hierarchy problem , i.e. , the instability of the electroweak scale under radiative corrections , has spurred the imagination of many theorists and led to the development of a plethora of models of physics beyond the sm that envision new phenomena at or not far above the scale . a particularly appealing proposal for stabilizing the electroweak scale , featuring one compact extra dimension non - factorizable anti - de sitter ( ads ) metric , is the randall - sundrum ( rs ) model , which by virtue of the ads / cft correspondence can be thought of as dual to a strongly coupled four - dimensional ( 4d ) cft . three - branes acting as the boundaries of the warped extra dimension , the ads background generates an exponential hierarchy of energy scales , so that the natural scale at one orbifold fixed point ( the ultra - violet ( uv ) brane ) is much larger than at the other ( the infra - red ( ir ) brane ) , . in the rs framework the gauge hierarchy problem is thus solved by gravitational red - shifting . there are numerous possibilities for building models of electroweak symmetry breaking in ads . the basic building blocks for the construction of a viable theory include , among others , the choice of the bulk gauge group , the zero - mode fermion localization , and the dynamical mechanism for localizing the higgs field on ( or near ) the ir brane . while in the original rs proposal all sm fields were constrained to reside on the ir boundary and the gauge group was taken to be , it was soon realized that allowing gauge and matter fields to spread in the ads bulk not only avoids dangerous higher - dimensional operators suppressed only by powers of , but also admits a natural explanation of the flavor structure of the sm via geometrical sequestering . this way of generating fermion hierarchies also implies a certain amount of suppression of dangerous flavor - changing neutral currents ( fcncs ) , a scheme referred to as the rs - gim mechanism . harmful contributions to the parameter can be cured in an elegant way by extending the bulk hypercharge group to and breaking it to on the uv brane . an appropriate embedding of the down - type sm quarks into the custodial rs model further furnishes the possibility to reduce the tree - level corrections to the vertex and its flavor - changing counterparts . as a result , all existing electroweak precision and cp - conserving fcnc constraints are typically satisfied for the mass of the lightest kaluza - klein ( kk ) gauge boson below a few . however , in spite of the rs - gim mechanism , cp - violating effects in the neutral kaon system and corrections to the neutron electric dipole moment tend to be too large in models flavor anarchy , pushing the new - physics scale to at least and thus beyond the reach of the cern large hadron collider ( lhc ) . relaxing the latter bounds seems to require an additional flavor alignment in warped models and has triggered a lot of model - building activity . the purpose of this article is to perform a thorough analysis of the structure of the rs variant extended gauge symmetry in the bulk , where interchanges the two groups and is responsible for the protection of the vertex . while in the existing literature on the custodial rs model the couplings of the bulk fields to the higgs sector are treated as a perturbation , we instead construct the exact solutions to the bulk equations of motion ( eoms ) subject to appropriate boundary conditions ( bcs ) . in that way we obtain exact results for the profiles and masses of the various sm particles and their kk excitations . this approach is not only more elegant but also offers several advantages over the perturbative approach . in particular , it facilitates the analytic calculation of all terms of order , including those arising from the breaking of the symmetry by the bcs and possibly the bulk masses . the physical interpretation of the obtained results in terms of ( ir)reducible sources of symmetry breaking is thus evident in our approach , while it remains somewhat hidden if the couplings of the bulk fields to the higgs sector are treated as a perturbation from the very beginning . the exact approach also permits to include the mixing of fermions between different generations in a completely general way , making the dependence on the exact realization of the matter sector explicit . in turn , it is straightforward to address questions about the model - dependence of the resulting gauge- and higgs - boson interactions sm fermions . in summary , our work puts the theory of custodial warped extra dimensions on a more sound basis , both at the field theoretical and phenomenological level . in a forthcoming paper we will apply the derived results to tree - level flavor - violating and processes in the quark sector . this article is organized as follows . after recalling important definitions and notations , we discuss in section the kk decomposition of the bulk gauge fields in the presence of the brane - localized higgs sector , working in a covariant gauge . we also show how to compute sums over kk towers of gauge bosons in closed form . the analogous discussion for bulk fermions is presented in section . special attention is devoted to the correct implementation of yukawa couplings containing -odd fermion profiles . in sections and we present the main results of our work . we first analyze the structure of gauge - boson interactions fermions and then study the couplings of the higgs boson to matter . in the first case , we give analytic formulas that expose , on one hand , the prerequisites for achieving a custodial protection of the left - handed -boson couplings and , on the other , which are the terms that necessarily escape protection . in addition , we show explicitly that no protection mechanism is present in the charged - current sector . in the second case , the exact dependence on the realization of the fermion sector of the higgs - fermion couplings is worked out . in our article we concentrate on the leading contributions to the observables of interest , ignoring possible effects of brane - localized kinetic terms . although the uv dynamics is not specified , it is natural to assume that these terms are loop suppressed , so that they can be neglected to first order . the most important phenomenological implications of our findings are discussed in section . we begin by studying the constraints imposed by the precision measurements of the bottom - quark pseudo observables , including all tree - level corrections that avoid protection . we further discuss the phenomenology of rare top decays in the extended rs model and compare it to the one of the minimal formulation . finally , we explore the possible changes of the higgs production cross section and branching fractions at the lhc , including all leading - order quantum corrections stemming from the extended electroweak gauge - boson and fermion sectors . in a series of appendices we collect details on the derivation of the ir bcs and higgs - boson fcncs in the presence of both -even and -odd yukawa couplings , our input values for the sm parameters , and the explicit expressions for the form factors needed to calculate the production cross section and the branching ratios of the higgs boson in the rs model . we work non - factorizable rs geometry where denote the coordinates on the 4d hyper - surfaces of constant metric . the fifth dimension is an orbifold of size labeled by ] . the expressions for and necessary to derive these results can be found in and . in combination these two relations imply that the triple gauge - boson vertex involving two - and one -boson fields does not receive corrections at in the rs model , regardless of the specific gauge group . by the same line of reasoning , it is also readily seen that all quartic gauge - boson vertices first differ at order from the corresponding sm expressions . in view of this extra suppression , we will set the triple gauge - boson couplings of the zero modes to their sm values when evaluating the higgs - boson branching fractions . in this approximation the effect of virtual -boson exchange to is simply given by the combination , which up to the different form factor resembles the form of the corresponding term in . the third term in the numerator of describes the contribution to the amplitude stemming from the virtual exchange of kk quarks . the corresponding one - loop diagram is displayed in the middle of figure . in the up - type quark sector we find where denotes the relative strength of vector coupling of the boson to the up - type quark kk mode defined in analogy to , and . analog expressions apply in the case of down- and -type quark kk modes . since an analytic calculation of turns out to be impractical , we resort to a numerical evaluation of the kk sum employing the method described in section . the predictions for the real parts of , , and corresponding to a set of 150 random model parameter points are depicted in the right panel of figure . the solid lines displayed there indicate the best fit of the form to the sample of points scales in the range \\ , { \\rm } ] , the eoms close to the ir brane take the simpler form combining the first ( second ) fourth ( third ) relation and using , we obtain n^q(t ) & = 0\\ , , \\qquad \\left n^{ q}(t ) = 0 \\ , , \\ ] ] where imposing now the bcs and matching onto the solutions of evaluated in the limit , we find that the differential equations are solved by this implies that in the interval $ ] the -even fermion profiles take the form reinserting the solutions and into , allows us to determine the ir bcs which relate the -even profiles -odd ones at . the resulting expressions read -{\\bm s} n^{ q } ( 1 ^ - ) \\ , \\vec a n^{ q } & = { m {\\rm kk } } \\ , { \\bm y} {\\vec q}^\\dagger \\ , \\big ( {\\vec q } \\big ) ^{-1 } \\ , \\tanh \\big ( {\\vec q } \\big ) \\ , { \\bm c} n^{q } ( 1 ^ - ) \\ , \\vec a n^{q } \\ , , \\ ] ] which , after introducing the rescaled yukawa couplings , resembles employing the regularization for the -function , the flavor - changing higgs - boson couplings become combining , , and and using valid for any arbitrary invertible matrix , we then obtain to . the central values and errors of the quark masses used in our analysis are they correspond to masses evaluated at the scale , obtained by using the low - energy values as compiled in . the central values and errors of the wolfenstein parameters are taken from and read the central values and errors for the parameters entering our analysis of the bottom - quark pseudo observables are we refer to the central values for these quantities as sm reference values . unless noted otherwise , the reference value for the higgs - boson mass is . the form factors and describing the effects of quark and -boson loops in the production and the decay of the higgs boson are given by \\ , , \\\\ a {w}^h ( \\tau ) & = -{4 } \\left \\ , , \\\\ a {q}^h ( \\tau , \\lambda ) & = - i ( \\tau , \\lambda ) + j ( \\tau , \\lambda ) \\ , , \\\\ a {w}^h ( \\tau , \\lambda ) & = c w \\left \\ { 4 \\left ( 3 - {c w^2 } \\right ) i ( \\tau , \\lambda ) + \\left j ( \\tau , \\lambda ) \\right \\ } \\ , . \\ ] ] the functions and take the form \\ , , \\\\ j ( \\tau , \\lambda ) & = {2 \\left ( \\tau - \\lambda \\right ) } + {2 \\left ( \\tau - \\lambda \\right ) ^2 } \\ , \\big + {(\\tau - \\lambda)^2 } \\ , \\big \\ , , \\ ] ] while the functions and read ^ 2 \\ , , & \\tau \\leq 1 \\ , , \\\\ \\arcsin^2 \\left ( \\displaystyle { } \\right ) \\ , , & \\tau > 1 \\ , , \\\\ g(\\tau ) & = \\arcsin \\left ( \\displaystyle { } \\right ) \\ , , & \\tau \\leq 1 \\,,\\\\ \\displaystyle {2 } \\ , \\ , \\left \\ , , & \\tau > 1 \\ , . \\ ] ] l. randall and r. sundrum , phys . lett . * 83 * , 3370 ( 1999 ) . j. m. maldacena , adv . * 2 * , 231 ( 1998 ) . s. s. gubser , i. r. klebanov and a. m. polyakov , phys . b * 428 * , 105 ( 1998 ) . e. witten , adv . * 2 * , 253 ( 1998 ) . h. davoudiasl , j. l. hewett and t. g. rizzo , phys . b * 473 * , 43 ( 2000 ) . a. pomarol , phys . b * 486 * , 153 ( 2000 ) . s. chang , j. hisano , h. nakano , n. okada and m. yamaguchi , phys . 084025 ( 2000 ) . y. grossman and m. neubert , phys . b * 474 * , 361 ( 2000 ) . t. gherghetta and a. pomarol , nucl . b * 586 * , 141 ( 2000 ) . s. j. huber and q. shafi , phys . b * 498 * , 256 ( 2001 ) . s. j. huber , nucl . b * 666 * , 269 ( 2003 ) . n. arkani - hamed and m. schmaltz , phys . d * 61 * , 033005 ( 2000 ) . k. agashe , g. perez and a. soni , phys . lett . * 93 * , 201804 ( 2004 ) . k. agashe , g. perez and a. soni , phys . d * 71 * , 016002 ( 2005 ) . k. agashe , a. delgado , m. j. may and r. sundrum , jhep * 0308 * , 050 ( 2003 ) . k. agashe , r. contino , l. da rold and a. pomarol , phys . b * 641 * , 62 ( 2006 ) . m. blanke , a. j. buras , b. duling , s. gori and a. weiler , jhep * 0903 * , 001 ( 2009 ) ] . c. csaki , a. falkowski and a. weiler , jhep * 0809 * , 008 ( 2008 ) ] . o. gedalia , g. isidori and g. perez , phys . b * 682 * , 200 ( 2009 ) ] . m. bauer , s. casagrande , u. haisch and m. neubert , arxiv:0912.1625 . h. davoudiasl , j. l. hewett and t. g. rizzo , phys . d * 68 * , 045002 ( 2003 ) . m. s. carena , e. ponton , t. m. p. tait and c. e. m. wagner , phys . d * 67 * , 096006 ( 2003 ) . m. s. carena , a. delgado , e. ponton , t. m. p. tait and c. e. m. wagner , phys . d * 68 * , 035010 ( 2003 ) . s. casagrande , f. goertz , u. haisch , m. neubert and t. pfoh , jhep * 0810 * , 094 ( 2008 ) ] . f. goertz and t. pfoh , jhep * 0810 * ( 2008 ) 035 ] . m. bauer , s. casagrande , l. grnder , u. haisch and m. neubert , phys . d * 79 * ( 2009 ) 076001 ] . l. randall and m. d. schwartz , jhep * 0111 * ( 2001 ) 003 . m. e. albrecht , m. blanke , a. j. buras , b. duling and k. gemmler , jhep * 0909 * , 064 ( 2009 ) ] . g. burdman and l. da rold , jhep * 0811 * ( 2008 ) 025 ] . m. e. peskin and t. takeuchi , phys . * 65 * , 964 ( 1990 ) . m. e. peskin and t. takeuchi , phys . rev . d * 46 * ( 1992 ) 381 . c. csaki , j. erlich and j. terning , phys . d * 66 * ( 2002 ) 064021 . a. delgado and a. falkowski , jhep * 0705 * , 097 ( 2007 ) . m. s. carena , e. ponton , j. santiago and c. e. m. wagner , nucl . b * 759 * ( 2006 ) 202 . m. s. carena , e. ponton , j. santiago and c. e. m. wagner , phys . d * 76 * ( 2007 ) 035006 . j. hirn and v. sanz , phys . d * 76 * , 044022 ( 2007 ) . a. azatov , m. toharia and l. zhu , phys . d * 80 * , 035016 ( 2009 ) ] . j. a. bagger , f. feruglio and f. zwirner , phys . * 88 * ( 2002 ) 101601 . a. j. buras , b. duling and s. gori , jhep * 0909 * , 076 ( 2009 ) ] . k. agashe , g. perez and a. soni , phys . d * 75 * ( 2007 ) 015002 . k. agashe and r. contino , phys . d * 80 * , 075016 ( 2009 ) ] . b. duling , arxiv:0912.4208 . j. h. field , mod . a * 13 * , 1937 ( 1998 ) . s. schael et al . , phys . rept . * 427 * , 257 ( 2006 ) . a. b. arbuzov et al . , comput . commun . * 174 * , 728 ( 2006 ) . a. djouadi , g. moreau and f. richard , nucl . b * 773 * , 43 ( 2007 ) . c. bouchart and g. moreau , nucl . b * 810 * , 66 ( 2009 ) ] . the tevatron electroweak working group , arxiv:0803.1683 . t. aaltonen et al . , arxiv:0805.2109 . j. carvalho et al . , eur . j. c * 52 * , 999 ( 2007 ) ] . g. l. bayatian et al . , j. phys . g * 34 * , 995 ( 2007 ) . j. a. aguilar - saavedra and g. c. branco , phys . b * 495 * , 347 ( 2000 ) . m. spira , arxiv : hep - ph/9510347 and", "summary": "we reexamine the randall - sundrum ( rs ) model enlarged gauge symmetry in the presence of a brane - localized higgs sector . in contrast to the existing literature , we perform the kaluza - klein ( kk ) decomposition within the mass basis , which avoids the truncation of the kk towers . expanding the low - energy spectrum as well as the gauge couplings in powers of the higgs vacuum expectation value , we obtain analytic formulas which allow for a deep understanding of the model - specific protection mechanisms of the parameter and the left - handed -boson couplings . in particular , in the latter case we explain which contributions escape protection and identify them irreducible sources of symmetry breaking . we furthermore show explicitly that no protection mechanism is present in the charged - current sector confirming existing model - independent findings . the main focus of the phenomenological part of our work is a detailed discussion of higgs - boson couplings and their impact on physics at the cern large hadron collider . for the first time , a complete one - loop calculation of all relevant higgs - boson production and decay channels is presented , incorporating the effects stemming from the extended electroweak gauge - boson and fermion sectors . mz - th/10 - 18 + may 23 , 2010 + * the custodial randall - sundrum model : + from precision tests to higgs physics * s. casagrande , f. goertz , u. haisch , m. neubert and t. pfoh +"}
{"article": "it has long been thought that electro - magnetic probes i.e. real or virtual photons would provide a way to detect the formation of a quark - gluon plasma in ultra - relativistic heavy ion collisions . the energy distribution of the photons would allow to measure the temperature of the plasma provided the rate of production in the plasma exceeds that of various backgrounds . it is expected that this will occur in a small window in the range for the energy of the photon . at lower values of the energy the rate is dominated by various hadron decay processes while at higher values the usual hard processes ( those occurring in the very early stage of the collision before the plasma is formed ) , calculable by standard perturbative qcd methods , would dominate . in contrast to hadronic observables ( or heavy quarkonia ) which are sensitive to the late evolution of the plasma as well as to the re - hadronisation phase , the photons in the range are produced soon after the plasma is formed and then they escape the plasma without further interaction . we assume the plasma in thermal equilibrium ( temperature t ) vanishing chemical potential . the rate of production , per unit time and volume , of a real photon of momentum is while for a lepton pair of mass it is where is the retarded photon polarisation tensor . the pre - factor provides the expected exponential damping when . this report is devoted to the study of which contains the strong interaction dynamics of quarks and gluons in the plasma . the theoretical framework is that of the effective theory - summed hard thermal loops ( htl ) . we briefly review the status of calculated up to the two - loop approximation . some phenomenological consequences are mentioned . then we turn to a discussion of higher loop corrections . following the htl approach one distinguishes two scales : the hard \" scale , typically of order or larger ( the energy of quarks and gluons in the plasma ) and the soft \" scale of order where , the strong coupling , is assumed to be small . collective effects in the plasma modify the physics at scale i.e. over long distances of . these effects lead to a modification of the propagators and vertices of the theory and one is led to introduce effective ( re - summed ) propagators and vertices . this is easily illustrated example of the fermion propagator , , which in the bare \" theory is simply ( we neglect spin complications and make only a dimensional analysis ) . the thermal contribution to the one loop correction is found to be which is of the same order as the inverse propagator when is of order . the re - summed propagator is then deeply modified for momenta of whereas the thermal corrections appear essentially as higher order effects for hard momenta . likewise , the gluon propagator and vertices are modified by hard thermal loops when the external momenta are soft . one can construct an effective lagrangian in terms of effective propagators and vertices and calculate observables in perturbation theory . in the one - loop approximation , the photon production rate is given by the diagram shown in fig . where the symbol means that effective propagators and vertices are used . the result has been known for some time and can be expressed , in simplified notation , as where is related to the thermal mass of the quark . one notes the presence of a large \" logarithmic term dominating over a constant term \" . the two - loop diagrams are displayed in fig . . in principle , there are more diagrams in the effective theory but only those leading to the dominant contribution are shown . all propagators and vertices should be effective but since the largest contribution arises from hard fermions it is enough , following the htl strategy , to keep bare fermion propagators and -15pt vertices as indicated . only the gluon line needs to be effective since soft momentum through the gluon line dominates the integrals . to evaluate these diagrams it is convenient to distinguish between the contribution arising from a time - like gluon and a space like gluon . the first type leads to a contribution similar to eq . and requires some care as counter - terms ( not shown ) eliminate the parts of the two - loop diagrams already contained in the one - loop diagrams . we concentrate on the second case which in terms of physical processes corresponds to bremsstrahlung production of a photon or production in a quark - antiquark annihilation process where one of the quark is put off - shell by scattering in the plasma ( see fig . ) . the result for hard photons is the reason why these two - loop contributions have the same order as the one - loop one is due to the presence of strong collinear singularities . to calculate one has to cut the propagators as indicated by the dash - dotted lines in fig . . in the integration over the loop hard momentum ( , on shell ) the denominators and of the un - cut fermion propagators simultaneously almost vanish when is parallel to i.e. in the collinear configuration . this leads to an enhancement factor of type where the cut - off emerges from the calculation . for the kinematic range of concern to us here , so that the two - loop diagram is enhanced by a factor which compensates the factor associated to the coupling of the gluon to the quarks . an interesting result of the calculation is the importance of process ii of fig . which grows energy of the photon and dominates over the other contributions when as shown in fig . . phenomenological applications of these results have been carried out and the two - loop processes have been included in hydrodynamic evolution codes to predict the rate of real photon production at rhic or lhc . it is found that the two - loop processes ( especially the annihilation scattering ) lead to an increase by an order of magnitude compared to the one - loop processes . this may even have consequences for heavy ion collisions at sps energies . several effects may reduce these over - optimistic predictions : lack of chemical equilibrium and more importantly higher order corrections as discussed next . since the one - loop and two - loop results are of the same order it is reasonable to worry about the convergence of the perturbative expansion in the effective theory ! the enhancement mechanism operative at two - loop could also be at work at the multi - loop level especially in ladder diagrams , an example of which is shown in fig . : indeed many small \" fermion denominators appear in such diagrams which can produce a pile - up of collinear singularities . a recent study of the three - loop ladder diagram shows that where is the largest of the cut - offs : + , which is the collinear cut - off encountered above : it depends on the thermal quark mass and momentum as well as on the external variables ; + , the debye mass if the added gluon is longitudinal , or if it is transverse . + for the kinematic configuration of interest , in the case of an extra longitudinal gluon one can check that and the debye mass acts as a cut - off result that the three - loop contribution is suppressed by a factor compared to the two - loop . on the contrary , for a transverse gluon , both regulators are of order ( as long as ) and the three - loop diagram is of the same order as the two - loop one . one is therefore in a non - perturbative regime . the problem is similar to the magnetic mass problem pointed out by linde in the perturbative calculation of the free energy , except that here it appears at leading order . another effect which can modify the collinear enhancement mechanism is related to the fermion damping rate . indeed , including the damping rate on the fermion lines , will shift the pole of the propagators away from the real axis : this affects the enhancement mechanism based on the near - vanishing of the denominators . ignoring the requirement of gauge invariance and concentrating only on the mathematical effect of shifting the poles to the complex plane one can do again the two - loop calculation fermion propagators including the damping rate . the result is intuitively simple as a regulator of the form comes out , defined above . the effect of on is shown on fig . for the case of a real photon . the region is dominated by bremsstrahlung emission while the region receives a contribution mainly from the annihilation scattering process ( see fig . ) . the top curve is the result obtained vanishingly small width . one notes the change in the behaviour of as increases : this is due to the different dependences of the real and imaginary parts of . for virtual photon production , one notes that the quantity increases at fixed so that the ratio , which controls the relative importance of the width , decreases . for large enough the effect of will become negligible and the two - loop calculation should be adequate . this is illustrated in fig . . equation lends itself to a simple interpretation . it can be written as where is the mean free path of the quark in the plasma and can be shown to be the formation length of the photon . then , if the effect of the damping rate can be ignored and the corresponding higher order diagrams are suppressed . in the opposite case , re - scattering in the plasma modifies the two - loop result . this is equivalent to say that the landau - pomeranchuk - migdal ( lpm ) effect has to be taken into account in the calculation . two interesting features emerge from the above discussion : 1 ) the lpm effect not only modifies the production of bremsstrahlung photon but also that of very hard photons emitted in the annihilation scattering \" process as illustrated in fig . ; 2 ) if the virtuality of the hard lepton pair is large enough then one falls in the domain and the perturbative calculation at two - loop is sufficient . the problems discussed above are an illustration of a more general situation concerning thermal green s function external momenta close to the light - cone . the production mechanism of hard photons in the plasma is very complex . new processes appear at two - loop which considerably increase the rate of photon production calculated at one - loop . however , for real or small mass virtual photons the higher loop diagrams become important and the rate turns out to be non - perturbative . taking into account higher order effects to obtain a quantitative estimate remains to be done . i thank f. gelis , r. kobes and h. zaraket for a fruitful collaboration on the work discussed above .", "summary": "we discuss the production of real or virtual photons in a quark - gluon plasma . laboratoire de physique thorique lapth , + bp110 , f-74941 , annecy le vieux cedex , france lapth - conf-810/2000"}
{"article": "set theory was proposed intended use to the fields of pattern classification and information processing . indeed , it has attracted many researchers , and their applications to real - life problems are of a great significance . simpson presented the fuzzy min max neural network ( fmm ) , which makes the soft decisions to organize hyperboxes by its degree of belongingness to a particular class , which is known as a membership function . hyperbox is a convex box , completely represented by min and max points . fmm classification results are completely characterized help of a membership function . along this elegant proposal , also presented the characteristics for a good classifier , among which , nonlinear separability , overlapping classes and tuning parameters have proved to be of a great interest to a research community . simpson also presented a clustering approach using fmm in . but many problems in real - life require both classification and clustering . to address this issue , gfmm brought this generality . besides generality , the more significant contribution has proved to be modification to the membership function . the presented membership function computes the belongingness to the hyperbox so that the membership value decreases uniformly as we move away from the hyperbox . another weakness of fmm was the patterns belonging to overlapped region , where the rate of misclassification is considerably high . the tuning parameter , theta , which controls the size of a hyperbox , has a great impact on this overlapped region . smaller theta values produce less overlaps producing high training accuracy , but the efficacy of the network gets compromised , and for larger theta values , accuracy gets decreased . multiple approaches were presented to tackle this problem . earlier , the process of contraction was employed , which used to eliminate all the overlapping regions . this method had the intrinsic problem of representing patterns not belonging to any of the hyperbox , in turn lessening the accuracy . exclusion / inclusion fuzzy classification ( hefc ) network was introduced in , which further reduced the number of hyperboxes and increased the accuracy . inclusion hyperboxes were used to represent patterns belonging to the same class , while exclusion hyperboxes were used to denote the overlapped region , treated as if it is a hyperbox . this notion is used as it is in almost all the newly introduced models . fuzzy min - max neural network classifier compensatory neurons ( fmcn ) was acquainted in . authors categorized the overlap into three parts , namely , full containment , partial overlap and no overlap , and then a new membership function to accommodate belongingness based on the compensation value . authors also analyzed that neatly taking care of overlapped region automatically brings the insensitivity to the hyperbox size parameter , . data core based fuzzy min - max neural network ( dcfmn ) further improved upon fmcn . authors eliminated the need of overlap categorization . they also suggest a new membership function based on noise , geometric center and data cores of the hyperbox . wherein dcfmn improved the accuracy in few cases , there are some serious drawbacks . * * dcfmn introduces two new user controlled variables , and . is used to suppress the influence of the noise and is used to control the descending speed of the membership function . these two variables greatly impact the performance of the model and naturally , defining their values is a tedious job . * there exists an underlying assumption that noise within all the hyperboxes is similar , which may not be true . moreover , the sequence of the training exemplars plays a role as well . * mlf conveys that this membership function is not always preferred , in that , it does not work well for high percentage of samples belonging to overlapped area . multi - level fuzzy min max neural network ( mlf ) addresses the problem of overlapped region elegant approach . it uses separate levels for overlapping regions , and monotonically decreases the hyperbox size . for most cases , mlf produces 100% training accuracy . though mlf achieves a significant milestone , entertaining testing accuracy is rather more important than training accuracy , as it greatly sways the usage of the algorithm in practical scenarios . in this brief , we identify and define a new boundary region , where misclassification rate is substantial . to the best of our knowledge , this kind of approach is presented for the first time , at least we did not come across any similar published work . hence we propose a method , based on data centroids , to evidentially prove that handling this newly introduced area of confusion between hyperboxes of different classes significantly increases the testing accuracy . the paper is organized as follows . mlf is reviewed in section ii . we introduced d - mlf algorithm in section iii . an illustrative example and comparative results of d - mlf model are presented in section iv and v , respectively . finally , conclusion is given in section vi . multi - level fuzzy min max neural network ( mlf ) is a classifier which efficiently caters misclassification of patterns belonging to overlapped region by maintaining a tree structure , which is a homogeneous tree . in mlf training phase , exemplars are continuously recurred to form the hyperboxes and overlaps , each recursion resulting in one level . this recursive procedure is carried till the predefined maximum depth or till overlap exists . hyperbox expansion , based on hyperbox size controlling parameter , is validated using equation ( 1 ) and expansion is carried out by equation ( 2 ) . where , and are min point and max point of hyperbox b respectively , is the dimension of pattern a and d is the number of dimensions . also , prior to each recursion , is updated using equation ( 3 ) where , and thetas for next level and previous level , respectively and , being the value between 0 and 1 , ensures that size of hyperbox in overlapped region is less than its previous level . in the testing phase , overlap regions are first traversed recursively , to discover appropriate subnet to which a test pattern belongs to . thence , in that level , a class of hyperbox having highest membership value hyperboxes in the discovered subnet , is selected as a predicted class . mlf is able to achieve higher accuracy rates than previous fmm methods . this is due to an elegant treatment to the boundary region a confusion area . but , after training , there exists a room for yet another boundary . the region where membership function generates very close by values , it becomes difficult to assign a class high degree of assurance . as per our experiments , mlf , and all the previous classifiers , do not perform well in this area . hence , a definition of this new region , and a methodology to solve it is proposed . in this section , we give details about a newly proposed algorithm , specifically , we define a new boundary region generated due to trained network and propose a solution to correctly classify test patterns belonging to it . figure 1 describes the d - mlf structure , each node in snet contains two segments , hyperboxes segment ( hbs ) and overlapped segment ( ols ) . hbs represents hyperboxes generated in that level , whereas ols represents overlaps in that level . along hyperbox information , data centroid ( dc ) . figure 2 shows the area of confusion considered by mlf and d - mlf . we introduce a boundary region that exists between any two hyperboxes , where , according to our experiments , the rate of misclassification is comparatively high . in the proposed method , the recommendations of mlf are intact , in addition to it , we use distance centroids to improve a classification rate in the anew boundary region . similar to the mlf learning procedure , d - mlf maintains using hbs and ols structures . first , all the patterns are passed through , resulting in creation and expansion of hyperboxes using equations ( 1 ) and ( 2 ) . then each hyperbox is checked rest of hyperboxes to detect the overlap using equation ( 4 ) . where and are the max points and and are the min points of the two hyperboxes , among which overlap is tested . moreover , d - mlf adds a new step at the learning phase , known as data centroid ( dc ) computation , where dc of all input patterns belonging to each hyperbox is maintained in the hbs . dc is computed as follows : where is the data centroid of the hyperbox , is number of patterns belonging to hyperbox and is the pattern in hyperbox . if there exists an overlap , patterns belonging to the overlapped region are again sent to training procedure , where hbs and ols creation takes place for the next level . this process of recursion is followed afterward to train all the patterns . due to computation of ols and process of finding patterns belonging to ols , d - mlf and mlf are not single pass algorithms . in general , given the n overlaps in the first level , entire training data has to be traversed n times . thereafter , in the subsequent stages , data belonging to overlapped region is traversed in order of magnitude of number of overlaps in that region . this is a novel finding , and contradictory to what mlf authors have mentioned . note that , the patterns belonging to overlapped region are not part of the dc computation . this step makes sure that training patterns balloting for more than one class are omitted in the final decision making . + net = d - mlf - train(net , ) + = h.centroid / h.membercount return null h.centroid + = sample ; h.membercount + = 1 ; create new hyperbox h ; h.centroid = sample ; h.membercount = 1 ; sdata = samples which inhabit in i region ; hi.centroid -= s ; hi.membercount -= 1 ; create an overlap - box as and add to ols = d - mlf - train ( sdata , ) ; link to link ; the original mlf used a decision making based on the subnets decision . the selected subnet need not be a leaf node in the tree . we do not alter this model , rather enhance the process of how subnet marks the choice . membership function mentioned in the equation ( 11 ) is used against overlapped boxes . after recursively traversing the ols an appropriate subnet is discovered , to which test pattern belongs to . a membership function explained in the equation ( 6 ) is used , this time , to compute the membership hyperboxes within the selected subnet . \\\\ ) ) \\\\ f(x,\\gamma)={1}\\;\\;\\;\\ ; if \\ ; x\\gamma\\;>\\;1 \\\\ { x}\\;\\;\\;\\ ; if \\ ; 0\\;\\leq\\;x\\gamma\\;\\leq\\;1 \\\\ { 0}\\;\\;\\;\\ ; if \\ ; x\\gamma\\;<\\;0 \\ ] ] where represents belongingness of sample hyperbox . is a difference between min and max point sample and is a tuning parameter to control fuzziness . within these membership values , hyperboxes highest two values are selected to define a boundary . medial region of these hyperboxes , controlled by , is treated as a boundary region . is a user controlled variable , mentioned in the percentage value . at this point , it is necessary to check if test pattern belongs to the boundary region . we define and as incident angles between test pattern and two hyperboxes , respectively . inclusion value is evaluated as follows : further , based on the inclusion value , output class is chosen . if pattern exists in the area outside of the defined boundary , we simply follow a path of mlf , and classify the pattern based on the maximum membership value , which is already computed . if the pattern belongs to the boundary region , euclidean distance between test pattern and the data centroids of the selected hyperboxes is computed . hence , centered on the inclusion value , the output of the network is denoted as either the class of maximum among all the hyperboxes , or as a minimum of the distances of the topmost two hyperboxes where is given by ; where is the class membership for the test sample in subnet , is edge between subnet and the corresponding overlap box that enables the subnet if test sample is in this overlap box . and is the output of ols , which is given by equation ( 10 ) where is number of overlap boxes in ols and is membership function of the overlap box for test sample , given by equation ( 11 ) and is given by equation(12 ) where is the euclidean distance computed amongst sample and the data centroid of the topmost hyperbox using equation ( 13 ) out = d - mlf - test(net , sample ) + out = d - mlf - test ( , sample ) ; return null ; mv = ; mv + = membership ( sample , ) ; = d = eudistance(sample , h1.dc , h2.dc ) ; out = min(d).class ; out = max ( mv).class ; in this illustration , we describe the effectiveness of the proposed model , clearly pointing out the identification and handling of the stated area of confusion . figure 3 illustrates the 2-diamentional data space . we consider 14 data samples for training and 6 data samples for testing . hyperbox size parameter is fixed at 0.3 and a boundary parameter is fixed at 5% . both mlf and d - mlf create two hyperboxes at layer . d - mlf also computes data centroids ( dc ) for each hyperbox , and . here , data centroids of and are and , respectively . patterns which do not belong to boundary region are classified correctly by mlf . but when it comes to boundary region , it fails to correctly classify the patterns . whereas the proposed d - mlf works better in the boundary region as well , as its decision making is not completely based on the membership value , but it also considers data centroids . it can be noted that the patterns in the above example are not uniformly spread out . which is a very common scenario in real - world examples . it occurs because of the dominance of the parameters such as outliers , temporal nature of the variables , etc . due to them , most of the times , the patterns within the overall data , and in case of fuzzy min max hierarchy , within hyperboxes , will not be steadily spread across all the dimensions . as demonstrated above , our proposed method treats them elegantly , without many of the modifications to the state of the art . performance of proposed method ( d - mlf ) is studied on the basis of the classification rate . various experiments were carried out to test d - mlf on different standard datasets . standard datasets such as iris , glass , wine , wisconsin breast cancer ( wbc ) , wisconsin diagnostic breast cancer ( wdbc ) and ionosphere were used . these datasets were obtained from the uci repository of machine learning databases . in these experiments , hyperbox size parameter was chosen as 0.2 , 0.5 and 0.9 . this was to perform the measurements across the spectrum . as we increase the size of the hyperbox , the number of overlaps increase , and so does the misclassification rate . we split the data evenly for training and testing . the average results are shown over 100 experiments . for each iteration , training and testing data is chosen randomly . table 1 shows results , we compare our results to mlf method , as it has been already proven to perform better than the previously proposed fmm methods . .results in this brief , we introduced a new boundary region and distance based mlf classification method to handle patterns belonging to that boundary region . a data centroid based method , d - mlf , minimizes significance of outliers and similar errors in decision making . it has been evidentially proven that the proposal outperforms all the previously proposed fmm methods . more importantly , we have proposed a model suited for data in the real world , extending the state of the art . d - mlf will help humongous application areas such as security , natural language processing , biomedical reasoning , etc . l. a. zadeh , fuzzy sets , information and control , vol . 3 , pp . 338 - 353 , 1965 . p. k. simpson , fuzzy min - max neural networks . classification , ieee trans . neural network , vol . 5 , pp . 776786 , sep . 1992 . simpson , p. k. , fuzzy min - max neural networks - part 2 : clustering , ieee trans fuzzy systems 1 , 3245 1993 . b. gabrys and a. bargiela , general fuzzy min - max neural network for clustering and classification , ieee trans . neural networks , vol . 11 , pp . 769783 , 2000 . bargiela , w. pedrycz , and m. tanaka , an inclusion / exclusion fuzzy hyperbox classifier , int . based intell . , vol . 8 , no . 2 , pp . 9198 , 2004 . a. rizzi , m. panella , and f. m. f. mascioli , adaptive resolution min - max classifiers , ieee trans . neural netw . 2 , pp . 402414 , mar . a. v. nandedkar and p. k. biswas , a fuzzy min - max neural network classifier compensatory neuron architecture , ieee trans . neural netw . 1 , pp . 4254 , jan . 2007 . h. zhang , j. liu , d. ma , and z.wang , data - core - based fuzzy min max neural network for pattern classification , ieee trans . neural netw . 12 , pp . 23392352 , dec . r. davtalab , m. h. dezfoulian and m. mansourizade , multi - level fuzzy min - max neural network classifier , ieee trans . neural netw . 3 , pp.470 - 481 , mar . w. bezdel and h. j. chandler , results of an analysis and recognition of vowels by computer using zero - crossing data , proc . 2060 - 2066 , nov . k. bache and m. lichman . , uci machine learning repository , school inf . california , irvine , ca , usa . , 2013. http://archive.ics.uci.edu/ml", "summary": "recently , a multi - level fuzzy min max neural network ( mlf ) was proposed , which improves the classification accuracy by handling an overlapped region ( area of confusion ) help of a tree structure . in this brief , an extension of mlf is proposed which defines a new boundary region , where the previously proposed methods mark decisions less confidence and hence misclassification is more frequent . a methodology to classify patterns more accurately is presented . our work enhances the testing procedure by means of data centroids . we exhibit an illustrative example , clearly highlighting the advantage of our approach . results on standard datasets are also presented to evidentially prove a consistent improvement in the classification rate . hyperbox , fuzzy min - max , data centroids , neural networks , neurofuzzy , classification , machine learning ."}
{"article": "collisionless shocks are widely thought to be effective accelerators of energetic , nonthermal particles ( hereafter cosmic - rays or crs ) . those particles play central roles in many astrophysical problems . the physical basis of the responsible diffusive shock acceleration ( dsa ) process is now well established through in - situ measurements of heliospheric shocks and through analytic and numerical calculations . while test particle dsa model treatments are relatively well developed ; e.g. , , it has long been recognized that dsa is an integral part of collisionless shock physics and that there are substantial and highly nonlinear backreactions from the crs to the bulk flows and to the mhd wave turbulence mediating the cr diffusive transport ( see , for example , and", "summary": "we have developed a new , very efficient numerical scheme to solve the cr diffusion convection equation that can be applied to the study of the nonlinear time evolution of cr modified shocks for arbitrary spatial diffusion properties . the efficiency of the scheme derives from its use of coarse - grained finite momentum volumes . this approach has enabled us , using momentum bins spanning nine orders of magnitude in momentum , to carry out simulations that agree well results from simulations of modified shocks carried out conventional finite difference scheme requiring more than an order of magnitude more momentum points . the coarse - grained , cgmv scheme reduces execution times by a factor approximately half the ratio of momentum bins used in the two methods . depending on the momentum dependence of the diffusion , additional economies in required spatial and time resolution can be utilized in the cgmv scheme , as well . these allow a computational speed - up of at least an order of magnitude in some cases . ,"}
{"article": "the study of the high - redshift progenitors of today s massive galaxies can provide us invaluable insights into the key mechanisms that shape the evolution of galaxies in the high - mass regime . the latest generation of galaxy formation models are now able to explain the number densities and ages of massive galaxies at high redshift . however , this is only part of the challenge , as recent studies have posed new questions about how the morphologies of massive galaxies evolve redshift . in addition to the basic question of how high - redshift galaxies evolve in size , there is also still much debate about how these massive galaxies evolve in terms of their fundamental morphological type . extensive studies of the local universe have revealed a bimodality in the colour - morphology plane , spheroidal galaxies typically inhabiting the red sequence and disk galaxies making up the blue cloud ( e.g. ( * ? ? ? * baldry et al . 2004 ) ) . however , recent studies at both low ( e.g. ( * ? ? ? * bamford et al . 2009 ) ) and high redshift ( e.g. ( * ? ? ? * van der wel et al . 2011 ) ) have uncovered a significant population of passive disk - dominated galaxies , providing evidence that the physical processes which quench star - formation may be distinct from those responsible for driving morphological transformations . this result is particularly interesting in light of the latest morphological studies of high - redshift massive galaxies by and ( * ? ? ? * van der wel et al . ( 2011 ) ) who find that , in contrast to the local population of massive galaxies ( which is dominated by bulge morphologies ) , by massive galaxies are predominantly disk - dominated systems . in this work we attempt to provide significantly improved clarity on these issues . the candels ( ( * ? ? ? * grogin et al . 2011 ) , ( * ? ? ? * koekemoer et al . 2011 ) ) near - infrared f160w data provides the necessary combination of depth , angular resolution , and area to enable the most detailed study to date of the rest - frame optical morphologies of massive galaxies at in the ukidss ultra deep survey ( ( * ? ? ? * lawrence et al . 2007 ) ) . for this study we have constructed a sample based on photometric redshifts and stellar mass estimates which were determined using the stellar population synthesis models of ( * ? ? ? * bruzual & charlot ( 2003 ) ) assuming a chabrier initial mass function ( see ( * ? ? ? * bruce et al . 2012 ) for full details ) . this provides us total mass - complete sample of galaxies . we have employed the galfit ( ( * ? ? ? * peng et al . 2002 ) ) morphology fitting code to determine the morphological properties for all the objects in our sample . to conduct the double component fitting we define three components : a srsic index fixed at bulge , an fixed disk and a centrally concentrated psf component to account for any agn or nuclear starbursts within our galaxies . these three components are combined to generate six alternative multiple component model fits , of varying complexity , for every object in the sample . these models are formally nested , and thus statistics can be used to determine the `` best '' model given the appropriate number of model parameters . armed this unparalleled morphological information on massive galaxies at high redshift we can consider how the relative number density of galaxies of different morphological type changes during the key epoch in cosmic history probed here . in fig . 1 we illustrate this by binning our sample into four redshift bins of width , and consider three alternative cuts in morphological classification as measured by from our bulge - disk decompositions . in the left - hand panel of fig . 1 we have simply split the sample into two categories : bulge - dominated and disk - dominated . in the central panel we have separated the sample into three categories , object for which classed as `` intermediate '' . finally , in the right - hand panel we have expanded this intermediate category to encompass all objects for which . and using three alternative cuts in morphological classification ( both to try to provide a complete picture , and to facilitate comparison different categorisations in the literature).,width=528 ] from these panels it can be seen that marks a key transition phase , above which massive galaxies are predominantly disk - dominated systems and below which they become increasingly mixed bulge+disk systems . we also note that at the lowest redshifts probed by this study it is seen that , while bulge - dominated objects are on the rise , pure - bulge galaxies ( i.e. objects comparable to present - day giant ellipticals ) have yet to emerge in significant numbers , % of these high - mass galaxies still retaining a significant disk component . this is compared of the local galaxy population , which would be classified as pure - bulges from our definition ( , corresponding to ) from the sample of ( * ? ? ? * buitrago et al . ( 2013 ) ) . thus , our results further challenge theoretical models of galaxy formation to account for the relatively rapid demise of massive star - forming disks , but the relatively gradual emergence of genuinely bulge - dominated morphologies . in addition to our morphological decompositions we also make use of the sed fitting already employed in the sample selection to explore the relationship between star - formation activity and morphological type . 2 shows specific star - formation rate versus morphological type for the massive galaxies in our sample , where morphology is quantified by single srsic index in the left - hand panel , and by bulge - to - total -band flux ratio in the right - hand panel . the values of plotted are derived from the original optical - infrared sed fits employed in the sample selection , and include correction for dust extinction as assessed from the best fitting value of derived during the sed fitting . as a check of the potential failure of this approach to correctly identify reddened dusty star - forming galaxies , we have also searched for 24 m counterparts in the spitzer spuds mips imaging of the uds , and have highlighted in blue stars those objects which yielded a mips counterpart within a search radius of arcsec . to first order , our results show that the well - documented bimodality in the colour - morphology plane seen at low redshift , where spheroidal galaxies inhabit the red sequence , while disk galaxies occupy the blue cloud is at least partly already in place by . nonetheless , the sample also undoubtedly contains star - forming bulge - dominated galaxies and , perhaps more interestingly , a significant population of apparently quiescent disk - dominated objects . to highlight and quantify this population we have indicated by a box on both the panels the region occupied by objects disk - dominated morphologies and . in the left - hand panel , disk - dominated is defined as , and % of the quiescent galaxies lie within this box ( if we exclude the 24 m detections ) , while in the right - hand panel , disk - dominated is defined by , in which case % of the quiescent objects lie within this region . the presence of a significant population of passive disks among the massive galaxy population at these redshifts indicates that star - formation activity can cease without a disk galaxy being turned directly into a disk - free spheroid , as generally previously expected if the process that quenches star formation is a major merger . one possible mechanism for this arises from the latest generation of hydrodynamical simulations ( e.g. ( * ? ? ? * kere et al . 2005 ) , ( * ? ? ? * dekel et al . 2009a ) ) and analytic theories ( e.g. ( * ? ? ? * birnboim & dekel 2003 ) ) , which suggest a formation scenario whereby at high redshift star - formation is fed through inflows of cold gas . another scenario which can account for star - formation quenching , whilst still being consistent existence of passive disks , is the model of violent disk instabilities ( e.g. ( * ? ? ? * dekel et al . 2009b ) ) , coupled morphology quenching \" ( ( * ? ? ? * martig et al . 2009 ) ) .", "summary": "we have used high - resolution , hst wfc3/ir , near - infrared imaging to conduct a detailed bulge - disk decomposition of the morphologies of of the most massive galaxies at in the candels - uds field . we find that , while such massive galaxies at low redshift are generally bulge - dominated , at redshifts they are predominantly mixed bulge+disk systems , and by they are mostly disk - dominated . interestingly , we find that while most of the quiescent galaxies are bulge - dominated , a significant fraction ( % ) of the most quiescent galaxies , have disk - dominated morphologies . thus , our results suggest that the physical mechanisms which quench star - formation activity are not simply connected to those responsible for the morphological transformation of massive galaxies ."}
{"article": "a -graph is a graph which at each vertex has a bijection from the outgoing half - edges to the vertices of a cycle graph . half - edges which are mapped to adjacent vertices are ( formally ) adjacent . half - edges are said to be opposite if they are mapped to vertices of maximal distance in the cycle graph . by an embedding of a -graph into a surface we always mean an embedding of into such that the formal relation of being adjacent coincides relation of being adjacent induced by the embedding . an angle in a -graph is a pair of adjacent half - edges at a vertex . a checkerboard embedding of a -graph into is an embedding such that the cells of admit a 2-coloring under which any cells common edge have different colors . checkerboard embeddings are exactly those embeddings whose first -homology class is zero . in the second named author ( v.o.m . ) gave a solution to the question of whether four - valent framed graphs are planar . in , he addressed the question of determining the genus of surfaces into which four - valent framed graphs can be embedded , in particular considering the special case of surfaces into which four - valent framed graphs may be checkerboard - embedded . in , the first named author ( t.f . ) introduced -graphs as a generalization of four - valent framed graphs , and gave a planarity condition for -graphs each vertex of degree 4 or 6 . in , the authors characterized the genera of orientable surfaces into which -graphs each vertex of degree 4 or 6 may be checkerboard - embedded , generalizing some of the results of . in this paper , we continue the project of generalizing results about embeddability properties of framed four - valent graphs to -graphs each vertex of degree 4 or 6 , now considering checkerboard - embeddability into nonorientable surfaces . in theorem we show that this is equivalent to a problem on matrices . our methods are close to those used in our previous paper , which were themselves based closely on those used by the second named author ( v.o.m . ) in for framed four - valent graphs . the goal of this paper is to provide a method for determining whether a given -graph has a checkerboard embedding into a nonorientable surface of genus . we show that this is equivalent to a problem on matrices . to accomplish this , we fix a cycle in satisfying certain properties , called a rotating - splitting cycle . then we define a correspondence between checkerboard embeddings of and `` permissible separations '' of a chord diagram , where the result of a permissible separation is a pair of chord diagrams . we then show that the number of white ( black ) cells in the embedding is equal to the number of circles resulting from surgery of the first ( second ) of these chord diagrams . the circuit - nullity theorem allows us to calculate the number of circles resulting from surgery of each chord diagram in terms of the rank of their intersection matrices over . from this we have the total number of cells in the embedding , from which the genus of the surface can be easily calculated . the authors of this paper would like to thank victor anatolievich vassiliev and sergei vladimirovich chmutov for valuable discussions . a -atom is a closed 2-surface into which a connected graph ( the skeleton of the -atom ) is embedded in such a way that it divides into black and white cells so that cells sharing an edge have different colors . this embedding induces a -structure on the skeleton . the -structure at each vertex determines a set of angles among which we say that two angles are adjacent if they share a half - edge . two adjacent angles never have the same color . thus the angles around a vertex can be partitioned into two sets and in such a way that for any -atom corresponding to the -graph , either all angles in are black and all angles in are white , or all angles in are white and all angles in are black . thus given a connected -graph , the -atoms corresponding to are uniquely determined by a choice of one of the two possible colorings at each vertex . thus the main problem can be reformulated as follows : given a -graph in which all vertices have degree 4 or 6 , choose a coloring for the angles around each vertex such that the genus of the resulting atom is minimal . if such a graph has vertices , there are corresponding -atoms . an euler circuit of a -graph is a surjective mapping which is one - to - one except at the vertices , and such that every vertex of degree has preimages . given an euler circuit of a -graph , a 4-vertex is rotating respect to if for every , and are on adjacent half - edges around . given an euler circuit of a -graph , a 6-vertex is rotating respect to if for every , and are on adjacent half - edges around . given an euler circuit of a -graph , a 6-vertex is splitting respect to if for some , and are on opposite half - edges around , and for the other two points , and are on adjacent half - edges , and and are on adjacent half - edges . a rotating - splitting circuit is a circuit respect to which every vertex is rotating or splitting . a rotating - splitting circuit induces an orientation on the half - edges around a rotating 6-vertex . if the order of the edges containing and agrees this orientation , then the angle is said be untwisted ; otherwise it is twisted . see figures , , , . if is a connected -graph in which all vertices have degree 4 or 6 , then admits a rotating - splitting circuit . assign to each vertex any rotating or splitting structure . this gives a partition of the edges of into edgewise disjoint cycles . if there is only one such cycle , we are done . if there is more than one cycle , since the graph is connected , there must be a vertex shared by different cycles . if has degree 4 , it must be rotating , and we can join the two cycles meeting at by assigning to the other possible rotating structure . if has degree 6 , we consider the cycles given by starting at , exiting through one of its incident edges , and following the rotating - splitting structure until we come back to . there are three such cycles , up to a change in orientation . if each of these cycles contains a pair of adjacent edges at , we can assign to the rotating structure shown on the right side of figure , so that the three cycles are joined together , and becomes a rotating vertex twisted angles . note that before making the change , may have some structure other than that shown on the left side of figure ; the left side of the figure and the others referenced in this proof are merely examples . if exactly two of the three cycles contain a pair of adjacent edges around , then the third must contain a pair of opposite edges , and we can assign to the splitting structure shown on the right side of figure to join the cycles together . if exactly one of the three cycles contains a pair of adjacent edges around , then the other two must contain pairs of edges which are neither opposite nor adjacent . in this case we can join the cycles by assigning the rotating structure shown on the right side of figure , so that becomes a rotating vertex twisted angle . if none of the cycles contains a pair of adjacent edges , then we have two possibilities : each of the cycles contains a pair of opposite edges , or one of the cycles contains a pair of opposite edges and the other two contain a pair of edges which are neither opposite nor adjacent . if each of the cycles contains a pair of opposite edges , we can assign to the rotating structure shown on the right side of figure to join the cycles . if one of the cycles contains a pair of opposite edges and the other contains a pair of edges which are neither opposite nor adjacent , we can assign to the rotating structure shown on the right side of figure to join the cycles . . . . . . a chord diagram is a cubic graph distinguished hamiltonian cycle ; i.e. an embedding which covers all the vertices of . a signed chord diagram is a chord diagram in which each edge not in the distinguished cycle is assigned a positive or negative sign . a -chord diagram is a graph distinguished simple cycle ( i.e. an embedding ) , such that every vertex in has degree 3 or 4 and for every edge in , one of the following holds : 1 . is in the distinguished cycle . 2 . both of the vertices on are in the distinguished cycle , and both have degree 3 one of the vertices on is in the distinguished cycle , the other is not , and both have degree 3 . both of the vertices on are in the distinguished cycle , one has degree 3 , and the other has degree 4 . a signed -chord diagram is a -chord diagram in which each edge not in the distinguished cycle is assigned a positive or negative sign . an arc of a -chord diagram is an edge in the distinguished cycle of . a chord of a -chord diagram is an edge not in the distinguished cycle of , connecting two vertices of degree 3 which are in the cycle . a triad of a -chord diagram is a vertex not in the distinguished cycle of , together three edges incident to . the vertex is called a triad point . a double chord of a -chord diagram is a pair of edges not in the distinguished cycle of , which are incident to a shared vertex . the vertex is called the principal vertex of the double chord . given a -graph vertices of degree 4 or 6 , and given a rotating - splitting circuit of , we define a -chord diagram as follows : for each 4-vertex in , the two points in which are mapped to by are connected by a chord , whose sign is positive if and only if the two half - edges through which enters are not adjacent . for any rotating 6-vertex in , the three points in which are mapped to by are connected by a triad , and the edge connecting a vertex to the triad point has positive sign if and only the angle into which maps a neighborhood of is not twisted . for any splitting 6-vertex in , the three points in which are mapped to are connected by a double chord , whose principal vertex is such that and are in opposite half - edges around , where the sign of the edge connecting another vertex is positive if and only if is adjacent to . an expansion of as signed -chord diagram a signed chord diagram such that 1 . for every chord in containing vertices and , there is a chord of the same sign in of the same sign connecting vertices and . 2 . for every triad in containing at least one edge positive sign , for some labeling of the vertices of such that the edge connecting to the triad point is positive , contains a chord connecting to and a chord connecting to , chosen in such a way that the chords are not linked . furthermore , the chords connecting to and to in have the same signs as the edges connecting the triad point of to and in , respectively . 3 . for every triad in in which all edges have negative sign , for some labeling of the vertices of , contains a chord connecting to and a chord connecting to , chosen in such a way that the chords are linked . furthermore , the chords connecting to and to in have signs opposite to the edges connecting the triad point of to and in , respectively . 4 . for every double chord in principal vertex , for some labeling of the nonprincipal vertices of , there is a chord in connecting to and a chord in connecting to . these chords are not linked . a permissible separation of a signed chord diagram arising as an expansion of a signed -chord diagram is a pair of signed chord diagrams and such that 1 . every chord in is in exactly one of and . 2 . two chords in which come from the same triad in are both in , or both in . 3 . of any two chords in which come from the same double chord in , one chord is in and the other is in . suppose is checkerboard - embedded in a closed surface . then the rotating - splitting circuit gives a mapping from to which is one - to - one except at the preimages of vertices . this mapping can be smoothed to give an embedding of into , as in figure . observe that the circle divides the surface into a black part and a white part . we can draw the chords of as small edges lying in neighborhoods of vertices of , see figure . 0.3 0.3 0.3 the coloring of divides the chords of into two families : those lying in the white part and those lying in the black part . observe that the two chords in the neighborhood of a rotating vertex are in the same part , and the two chords in the neighborhood of a splitting vertex are in different parts . thus we have a permissible separation of . vice versa , given a -graph vertices of degree 4 or 6 and which satisfies the source - sink condition , a rotating - splitting circuit of , and a permissible separation of , we can recover the coloring of the angles around each vertex of , and thus we can recover the surface . thus given a -graph vertices of degree 4 or 6 and which satisfies the source - sink condition , and an expansion of its -chord diagram , we have a one - to - one correspondence between atoms of and permissible separations of . note that the two chords to be drawn in the neighborhood of any rotating 6-vertex do not cross in , as shown in figures , , , and . thus we have an embedding of into . furthermore , since the embedding of divides into 2-cells , the embedding of does as well . given a chord diagram , surgery of is the following process : for each chord connecting points , delete a neighborhood of and connect the obtained endpoints to and to if is positive , and to and to if is negative . this produces a family of circles ; these are called the result of surgery of . to form the intersection matrix of a signed chord diagram chords , first enumerate the chords . then the intersection matrix is an matrix over , such that if and only if the chord is negative , and for if and only if the chords and are linked . the number of components in the manifold obtained from a signed chord diagram by surgery of the circle is one plus the corank of . given a -graph in which all vertices have degree 4 or 6 and a rotating - splitting circuit of , and a checkerboard embedding of into a nonorientable surface , the nonorientable genus of is given by where and are the results of the permissible separation of induced by the embedding . consider the embedding described above . the number of 2-cells on the white side of the embedding is the number of circles resulting in surgery of . likewise , the number of 2-cells on the black side of the embedding is the number of circles resulting in surgery of . applying the circuit nullity theorem , the total number of 2-cells is . introducing the notation to represent the number of chords in , the number of arcs in is , so its total number of edges is . the number of vertices in is . thus the euler characteristic of is so the nonorientable genus of is . thus has admits an atom of genus if and only if some permissible separation of results in . this can be reduced to a problem on matrices , as follows . a permissible partition of the indices of is a partition of the indices of ( which are just the chords of ) into two parts , in such a way that chords arising from the same triad in are in the same part , and chords arising from the same double chord in are in different parts . clearly , and are a permissible separation of if and only if there exists a permissible partition of the indices of such that is the intersection matrix of and is the intersection matrix of . for a -graph which does not satisfy the source - target condition and which has rotating - splitting circuit , has a checkerboard embedding into a nonorientable surface of genus if and only if there is a permissible partition of the indices of into parts and such that . let be any expansion of . by lemma , has a checkerboard embedding into a surface of genus if and only there is a permissible separation of such that . such a permissible separation exists if and only if there is a permissible partition of into parts and such that . thus , the problem of finding the minimal nonorientable genus into which a -chord diagram each vertex of degree 4 or 6 may be checkerboard - embedded , is equivalent to the problem of finding a permissible partition of the indices of a matrix into parts and which minimizes . a -graph rotating - splitting circuit is embeddable into the projective plane if and only if there exists a permissible separation of such that and . in other words , is -embeddable if and only if there exists a permissible separation of into two chord diagrams , one of which consists of a family of pairwise - linked negative chords and a family of positive chords which are not linked to each other or to the negative chords , and the other of which consists of a family of pairwise - unlinked negative chords . we can test this condition by the following algorithm , which takes time quadratic in the number of chords of : first assign all negative chords to the same chord diagram . then for each assigned chord , assign all positive chords linked to it to the other chord diagram . if an assigned chord originates from a triad , assign the other chord coming from this triad to the same chord diagram , and if the assigned chord originates from a double chord , assign the other chord coming from this double chord to the other chord diagram . then , for each of the newly assigned chords , assign any unassigned linked chords or chords coming from the same triad or double chord , using the same rules described above . repeat this process until for every assigned chord , the linked chords and any chord coming from the same triad or double chord have been assigned . if not all chords have been assigned , take any unassigned chord and arbitrarily assign it to or , and repeat until all chords have been assigned . finally , check whether this is a permissible separation , and whether . is -embeddable if and only if both of these conditions are true . a -graph rotating - splitting circuit is embeddable into the klein bottle if and only if there exists a permissible separation of such that . there are two possible cases in which this can occur : or and . we will first consider the case where . in this case , we have a permissible separation of , each of which consists of a family of pairwise - linked negative chords and a family of positive chords which are not linked to each other or to the negative chords . this condition also admits a quadratic - time test , as follows : assign one of the chords arbitrarily to or . if the chord is positive , assign all chords linked to it to the other chord diagram ; if it is negative , assign all positive linked chords and all negative unlinked chords to the other diagram . regardless of sign , if an assigned chord originates from a triad , assign the other chord coming from this triad to the same chord diagram , and if the assigned chord originates from a double chord , assign the other chord coming from this double chord to the other chord diagram . repeat this process until for every assigned chord , the linked chords and any chord coming from the same triad or double chord have been assigned . if not all chords have been assigned , take any unassigned chord and arbitrarily assign it to or , and repeat until all chords have been assigned . finally , check whether this is a permissible separation , and whether . these conditions are met if and only if there is an embedding of into the klein bottle so that a smoothing of divides the klein bottle into two mbius bands . if this test fails , there is still the possibility that has an embedding into the klein bottle where the smoothing of bounds a disc . to cover this possibility , we choose a negative chord of and perform surgery at that chord , in the manner shown in . since this reverses the orientation of part of the designated cycle , we should also change the sign of all chords which cross , producing a new chord diagram . then for any surface and any embedding of which respects the signs of the chords , there is a corresponding embedding , still respecting the signs of the chords . furthermore , if the distinguished cycle in the embedding into the klein bottle bounds a disc , then the distinguished cycle in the embedding bounds a mbius band . thus has an embedding into the klein bottle where the smoothing of bounds a disc if and only has an embedding into the klein bottle where the distinguished cycle bounds a mbius band . this condition can be checked using the algorithm in the previous paragraph .", "summary": "this paper considers -graphs in which all vertices have degree 4 or 6 , and studies the question of calculating the genus of nonorientable surfaces into which such graphs may be embedded . in a previous paper by the authors , the problem of calculating whether a given -graph in which all vertices have degree 4 or 6 admits a -homologically trivial embedding into a given orientable surface was shown to be equivalent to a problem on matrices . here we extend those results to nonorientable surfaces . the embeddability condition that we obtain yields quadratic - time algorithms to determine whether a -graph vertices of degree 4 or 6 admits a -homologically trivial embedding into the projective plane or into the klein bottle . * keywords : * graph , -graph , surface , embedding , genus * ams subject classification : * primary 05c10 ; secondary 57c15 , 57c27"}
{"article": "natural hamiltonian systems are the mathematical models of those physical systems for which the energy is constant , for example harmonic oscillators or the kepler system . often , as in the previous two examples , more quantities are constants of the motion ( or first integrals ) : angular momentum , laplace - runge - lentz vector , etc . usually , these constants are expressed by quadratic polynomials in the momenta or , for quantum systems , by second - order differential operators . hamiltonian systems constants of the motion of degree higher than two are less common , nevertheless , some of them are of great interest , as for instance the three - body jacobi - calogero and wolfes systems . these systems represent the dynamics of three point - masses on a line under forces determined by the potential functions respectively ( we do not consider here the harmonic oscillator terms ) and they have essentially the same dynamics . both the resulting natural hamiltonians in admit one linear and one quadratic in the momenta constants of the motion , making the systems liouville - integrable and solvable by separation of variables ( see and", "summary": "given an n - dimensional natural hamiltonian l on a riemannian or pseudo - riemannian manifold , we call `` extension '' of l the n+1 dimensional hamiltonian canonically conjugated coordinates . for suitable l , the functions and can be chosen depending on any natural number m such that h admits an extra polynomial first integral in the momenta of degree m , explicitly determined in the form of the m - th power of a differential operator applied to a certain function of coordinates and momenta . in particular , if l is maximally superintegrable ( ms ) then h is ms also . therefore , the extension procedure allows the creation of new superintegrable systems from old ones . for m=2 , the extra first integral generated by the extension procedure determines a second - order symmetry operator of a laplace - beltrami quantization of h , modified by taking in account the curvature of the configuration manifold . the extension procedure can be applied to several hamiltonian systems , including the three - body calogero and wolfes systems ( without harmonic term ) , the tremblay - turbiner - winternitz system and n - dimensional anisotropic harmonic oscillators . we propose here a short review of the known results of the theory and some previews of new ones ."}
{"article": "nearby dark clouds like taurus and perseus contain dozens of dense molecular cores where stars like our sun are currently forming or have done so in the recent past ( myers 1995 ) . their large number , together their proximity and simple structure , make cores unique targets to study the complex physics involved in the formation of a star . dense cores that have not yet formed stars , the so called starless or pre - stellar cores , inform us of the initial conditions of star formation , and their study can help us elucidate the process by which pockets of cloud material condense and become gravitationally unstable . cores deeply embedded young stellar objects ( `` protostellar cores '' ) are unique targets to study the complex motions that occur during the period of accretion , when a combination of infall , outflow , and rotation is necessary to assemble the star and redistribute the gas angular momentum . finally , evolved cores are primary targets to study the interaction between the newly born star and its environment . these feedback effects are responsible for the transition of the protostar from embedded to visible , and may be important determining the final mass of the star and stabilizing the nearby gas via turbulence generation . the observational study of dense cores has advanced enormously over the last decade thanks to the increase in resolution provided by the new millimeter and submillimeter interferometers , and also due to the systematic combination of observations of dust and molecular tracers ( e.g. , bergin & tafalla 2007 ) . this brief review summarizes some new results from dense cores studies and presents a number of current issues that will greatly benefit from alma observations . the limited space of this article makes any attempt to review the field necessarily incomplete , and the reader is referred for further information to the other contributions on star formation in these proceedings , in particular to those by van dishoeck , andr , shepherd , aikawa , wilner , johnstone , and crutcher . despite significant recent progress , our understanding of the structure and evolution of dense cores is still incomplete due in part to limitations in the resolution and sensitivity of the available observations . even the highest resolution data of nearby dense cores can not discern details finer than about 100 au , which is still insufficient to disentangle the complex kinematics of infall and outflow motions in the vicinity of a protostar . probably more important , the low temperatures of the gas and the dust in cores ( k ) make the emission of any core tracer intrinsically weak , so any increase in the resolution needs to be accompanied by a parallel increase in the sensitivity , or the observations will not achieve enough s / n to provide useful information . this is particularly important when using weak , optically thin tracers to sample the innermost gas in the core . these tracers , in addition , often present extended emission , which poses a problem to the current generation of interferometers that cover sparsely the plane and therefore suffer systematically from missing flux . the high resolution and collecting area afforded by alma , combined great sensitivity to extended emission , promises to revolutionize the field of dense cores studies . on the one hand , alma will allow studying the dense cores of nearby clouds greatest detail , achieving subarcsecond resolution high sensitivity . on the other hand , alma will permit the systematic study of dense cores in more distant clouds , enlarging the sample of available targets from the current set of the nearest clouds to cores at distances of at least 1 kpc . the earliest phase of a core , the so - called starless or pre - stellar stage , is characterized by the lack of a point - like object at its center ( e.g. , di francesco et al . 2007 ) . this characterization is of course dependent on the current sensitivity limits of the observations , and is therefore susceptible of misclassifying a core embedded source of very low luminosity ( see the case of vellos below ) . still , the significant number of dense cores pointlike source detected even after deep spitzer space telescope observations suggests that a population of truly starless cores exists in nearby clouds like taurus ( werner et al . 2006 ) . starless cores present systematically a close to constant density of - over the central 5000 - 10000 au followed by an almost power - law drop at large distances . this central flattening of the density profile has been observed in a number of cores using different observational techniques , like millimeter dust continuum emission ( ward - thompson et al . 1999 ) , mir absorption ( bacmann et al . 2000 ) , and nir extinction ( alves et al . 2001 ) , and therefore constitutes a robust result of recent core studies . the presence of a density flattening provides further evidence that starless cores have not yet developed a central singularity , and that they are of pre - stellar nature . the physical origin of the flattening , however , is still a matter of debate , as a number of interpretations are consistent . the most natural one is that the profile results from an equilibrium configuration in which the pressure of an isothermal gas balances its gravitational attraction , the so called bonnor - ebert profile ( e.g. , alves et al . 2001 ) . indeed , the gas temperature in a core is typically close to constant ( k ) , and the associated thermal pressure dominates the turbulent component by a factor of several ( e.g. , tafalla et al . the bonnor - ebert interpretation , however , seems in conflict non - spherical shape of most cores ( typical axial ratio is 2:1 , myers et al . 1991 ) , and fact that the density contrast observed in cores often exceeds the factor of 14 limit for stability of the bonnor - ebert analysis ( bacmann et al . 2000 ) . additional magnetic field support could be responsible for these deviations from the theoretical expectation , but unfortunately , the observation of this magnetic component is extremely hard to make ( see contribution from crutcher in this volume ) . even the apparently `` simple '' structure of the cores still eludes our understanding . when the density distribution of a core , as inferred from dust measurements , is compared observed emission from most molecular tracers , it is commonly found that they disagree significantly . as illustrated in fig . 1 for l1498 in taurus , the dust emission of a core often appears centrally concentrated ( course a relative flattening at the center ) , while all molecular species but nh and nh present ring - like distributions around the continuum peak . radiative transfer analysis of the molecular emission indicates that the abundance of most species drops by at least a factor of 10 towards the high density peak of the molecular core ( caselli et al . 1999 , bergin et al . 2002 , tafalla et al . 2002 ) . such strong abundance decrease is suffered by all the c - bearing molecules as well as other species ( like so ) , while it does not affect significantly nh or nh ( see di francesco et al . 2007 and bergin & tafalla 2007 for reviews ) . nh seems in fact to be enhanced toward the center of most cores ( tafalla et al . 2002 ) , while the nh abundance tends to have a constant value or may drop at the very center of some cores ( bergin et al . 2002 , pagani et al . 2005 ) . cores therefore have a differentiated ( onion - like ) molecular composition , center rich in nh and nh and a series of outer layers containing c - bearing species . the inhomogeneous composition of the starless dense cores most likely results from the freeze out of the main molecular species onto the cold dust grains at the center ( bergin & langer 1997 , aikawa et al . 2005 ) . the high densities and low temperatures typical of dense core centers make the freeze out time ( yr ) become much shorter than the core dynamical scale ( 1 myr ) , and as a consequence , species like co disappear rapidly from the gas phase . other molecular species suffer the same fate as co , but more importantly , the original chemical balance , characterized by a relative large co abundance , is changed dramatically by freeze out . a new chemical balance emerges , and it is characterized by the enhancement of certain n - bearing species , like nh , which are daughter products of n and whose abundance is controlled by the amount of co in the gas phase ( co is the main destroyer of nh ) . even as n freezes out on the dust grains similar binding energy as co ( berg et al . 2005 ) , the nh abundance can increase relatively from its value in the diffuse cloud ( where co is undepleted ) and give rise to the relatively `` high '' abundances ( few 10 ) typical of dense cores . nh can then form from nh via dissociative recombination ( geppert et al . 2004 ) , giving rise to the observed central enhancement ( aikawa et al . 2005 ) . another effect of the co depletion in cores is the enhancement of deuterated species . deuteration at the low ( 10 k ) temperature of dense cores occurs via the enhancement of hd , which then passes the deuterium atom to other species via ion - molecule reactions ( dalgarno & lepp 1984 ) . as hd is mainly destroyed by co , the depletion of co further enhances the hd abundance , which in turn enriches in deuterium a number of additional species . high abundance of hd has in fact been observed in the heavily co - depleted dense core l1544 ( caselli et al . 2003 ) , and a correlation of co depletion and high deuteration has been reported by bacmann et al . ( 2003 ) and crapsi et al . this deuteration in the cold and dense pre - stellar phase is responsible for the extreme deuteration values of species like hco , choh , and nh seen toward protostellar cores ( ceccarelli et al . 1998 , roueff et al . 2000 , van der tak et al . as cores evolve , they are expected to become more and more centrally concentrated until they reach the point of gravitational instability . one of the most pressing issues in star formation studies is to understand whether this process of concentration is driven by the loss of magnetic field support via ambipolar diffusion ( e.g. , shu et al . 1987 , mouschovias & ciolek 1999 ) or by the dissipation of turbulence via shocks ( e.g. , maclow & klessen 2004 ) . observations of dense cores can not yet distinguish between these scenarios , but do show a systematic correlation between central concentration and other indicators of evolution , like co depletion and deuterium fractionation ( crapsi et al . 2005 ) . evidence for inward motions also seems correlated central concentration , and this suggests that some cores that we see now as starless have already begun collapsing to form stars . one of the best candidates for such a collapsing system is the l1544 core in taurus , whose pattern of inward motions has been studied in a number of molecules ( tafalla et al . 1998 , williams et al . 1999 , caselli et al . the l1544 dense core is characterized by a high central density and concentration ( ward - thompson et al . 1999 , tafalla et al . 2002 ) , a high degree of co depletion and deuterium fractionation ( caselli et al . 1999 , 2002 ) , and seems starless despite deep spitzer space telescope observations in the ir ( bourke , private communication ) . clearly this core , an similar objects , will be prime targets for alma observations . cores more evolved than l1544 are expected to contain already a luminous object surrounded by an envelope of accreting material . the little observable difference between the pre and proto - stellar phases of a core is illustrated by the case of l1521f , a core initially thought from molecular data to be an almost twin of l1544 ( crapsi et al . 2004 ) and later found spitzer observations to have a luminous central star ( bourke et al . the central object in l1521f has a luminosity close to 0.1 l , and is characteristic of a new group of objects identified by the spitzer telescope and usually referred as vellos ( very low luminosity objects ) . these vellos seem associated very weak nir nebulosity and low velocity bipolar outflows ( bourke et al . 2005 ) , and their status in the evolutionary sequence of protostars is still unclear . although some vellos could represent precursors of substellar objects ( proto brown dwarfs ) , it seems more likely that in the case of l1521f we are witnessing the very first moments of accretion , when the central source has an extremely low mass . the proto brown dwarf alternative is unlikely in this case because the dense core has about 5 m of mass ( crapsi et al . 2004 ) , and no clear perturbation seems stopping the accretion ( the outflow has too little mechanical power ) . the pristine nature of vellos makes them ideal candidates to study star - forming infall motions . the study of these motions has a long and rich tradition , and is plagued by difficulties as illustrated by the case of b335 . this dense core harbors a very young ( class 0 ) object whose inward motions were first characterized by zhou et al . these authors found that the spectral signatures from this core are in good agreement expectation from the inside - out collapse model of shu ( 1977 ) . high resolution observations plateau de bure interferometer by wilner et al . ( 2000 ) , however , have shown that some of the signatures of `` infall '' ( like the high velocity wings in the cs lines ) arise in fact from outflow acceleration , and not from an increase in velocity of the infalling material as it approaches the central object . a revisit of b335 ( and similar objects ) making use of alma s high angular resolution and selecting appropriate ( i.e. , depletion resistant ) tracers is therefore needed to clarify the still confusing picture of star - forming infall motions . the clean appearance of some vellos , together their weaker outflow emission , offers an interesting alternative to the more evolved ( and massive ) objects like b335 , that have fully developed outflows . because of their lower mass , vellos may present weaker signatures of infall and may be tracing the very first moments of collapse . the combined study of vellos and more luminous class 0 and class i sources should therefore allow us to reconstruct the sequence of star - forming accretion as a function of time . the presence of a protostar at the center of a core affects not only the gas kinematics but its chemistry . the newly born star heats up the nearby gas and dust introducing a temperature gradient in its vicinity . in the au region where the dust temperature exceeds the co evaporation temperature ( - 30 k ) , this molecule returns to the gas phase and undoes part of the chemical processing that occurred during the pre - stellar phase ( jrgensen et al . 2004 , jrgensen 2004 ) . closer to the protostar ( au ) , the dust temperature reaches the 90 - 100 k value at which water evaporates from the grains , further enriching the chemistry . observations of some very young protostellar objects , like iras 16293 - 2422 , show that these very small regions have extreme abundance of a number of complex molecules like hcooh , hcooch , and choch ( cazaux et al . 2003 , bottinelli et al . 2004 ) . the chemical richness of these regions rivals that of the hot cores around massive protostars , justifying their common denomination as `` hot corinos '' ( ceccarelli et al . the exact origin of the complex molecules in these regions , however , is still not fully understood . one possibility is that they result from direct evaporation of species trapped in the water ice , while an alternative is that they result from the processing of simpler evaporated molecules . even the geometry of hot corinos remains unknown , innermost part of the envelope or a more stable disk - like distribution as the most likely locations . despite these temporary uncertainties , hot corinos offer a unique opportunity to study the innermost vicinity of low - mass protostars . their distinctive chemical composition makes them highly selective tracers of the most complex and interesting region of the protostar , where inflow , outflow , and rotation motions play comparable roles , and angular momentum is transfered between different gas components . hot corino studies alma will surely constitute some of the first scientific projects of the instrument . at the same time that protostars accrete material , they eject powerful bipolar outflows of supersonic speed . co observations of these outflows reveal masses that are too large to originate directly from the central protostar , and indicate that most of the moving gas is core ambient material accelerated by a collimated stellar wind ( lada 1985 ) . the lobes of bipolar outflows , in addition , commonly coincide evacuated cavities seen via scattered light from the protostar , further illustrating how the outflow phenomenon represents a major disruption in the core internal structure ( padgett et al . 1999 ) . despite more than two decades of intense outflow research , a number of outstanding problems remain , and alma observations represent our current best hope to solve them ( see also contribution by d. shepherd in this volume ) . the properties of the underlying wind , for example , are not yet understood , and several alternative models have been proposed over the years . the two main types of models that attempt to fit the observations are the jet - driven outflow and the wind - driven shell , each of them number of flavors ( see bachiller 1996 for a review ) . despite significant successes , however , neither type of model can reproduce the rich variety of kinematic properties found by observations , so each of of them is necessarily incomplete ( lee et al . 2002 ) . in the jet driven model , a highly collimated agent shocks and sweeps cloud material along an almost straight line . this model succeeds in explaining the highly collimated co outflows often found toward class 0 objects , but fails to reproduce observations of less collimated flows ( usually powered by class i sources ) , where the co emission arises from gas along limb - brightened shells ( like l1551 , see moriarty - schieven et al . 1987 ) . to fit these less collimated systems , the jet models need to broaden the outflow path , and this has been done by either invoking jet precession/wandering ( masson & chernin 1993 ) or large - scale bow shocks ( raga & cabrit 1993 ) . none of these elements however seems consistent observations ( see arce et al . 2007 for more details ) , and this leaves the jet models limited to fitting the youngest , and admittedly more spectacular , bipolar outflows . wind - driven models , on the other hand , naturally produce shell - like structures thanks to a wide - angle agent that sweeps ambient material ( shu et al . these models , unfortunately , do not reproduce the appearance of the highly collimated outflows or the mass - velocity distribution commonly observed even in the poorly collimated flows ( masson & chernin 1992 ) . a combination of high resolution observations and new developments in outflow modeling are starting to show a possible solution to the current impasse . interferometer mapping of the outflow powered by the very young source iras 04166 + 2706 in taurus shows both jet and shell features simultaneously ( see fig . 2 and poster contribution by santiago - garca et al . the jet - like feature in this outflow , seen in both co and sio emission , is extremely rectilinear , appears only at the highest velocities ( between 30 and 50 km s ) , and shows no evidence for precession or wandering . the shell - like part appears at low velocities ( 2 to 10 km s ) and seems to delineate two opposed cavities iras source at their vertex . this cavity interpretation is supported by the fact that the blue outflow shell coincides walls of a nir scattering nebula seen in spitzer images , as expected from its more favorable projection . in addition , the high velocity jet runs along the axis of the two cavities showing a remarkable degree of symmetry ( see poster contribution for further details ) . the data from iras 04166 + 2706 , therefore , leads to the inevitable conclusion that , at least in some cases , both highly collimated and wide - angle components coexist in the outflow driving agent , and that a model that considers both components simultaneously is needed to explain the observations . interestingly enough , recent realistic modeling of the interaction between the x - wind of shu et al . ( 1994 ) and a toroidal core shows that both jet and shell components should be observed simultaneously in very young outflows ( shang et al . this so - called `` unified '' model of bipolar flows shows in fact a remarkable likeness iras 04166 + 2706 observations , both in geometry and kinematics ( compare fig . 2 and the models in shang et al . 2006 ) . the unified outflow model not only unifies the jet and wide - angle aspects of the outflows , but also brings together the evolution of flows and the dense cores , two elements often treated separately . evidence for outflow - core interaction has been reported in a number of systems ( e.g. , tafalla & myers 1997 , arce & sargent 2006 ) , but no unified framework of how this interaction happens or how outflows and cores evolve in parallel exists yet . the beautiful simulations of shang et al . ( 2006 ) illustrate how the most important elements of this interaction occur inside the central 1000 au region , which corresponds to less than even towards the most nearby clouds . high angular resolution observations alma are clearly needed to sample the complex geometry and kinematics inside this critical region , and thus compare real outflows their simulated counterparts . producing a unified picture of the different and interacting processes occurring during the formation of a solar - type star can be one of most significant achievements of alma .", "summary": "dense cores are the simplest star - forming sites that we know , but despite their simplicity , they still hold a number of mysteries that limit our understanding of how solar - type stars form . alma promises to revolutionize our knowledge of every stage in the life of a core , from the pre - stellar phase to the final disruption by the newly born star . this contribution presents a brief review of the evolution of dense cores and illustrates particular questions that will greatly benefit from the increase in resolution and sensitivity expected from alma ."}
